{"meta":{"version":1,"warehouse":"4.0.0"},"models":{"Asset":[{"_id":"themes/next/source/404.html","path":"404.html","modified":0,"renderable":1},{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":0,"renderable":1},{"_id":"themes/next/source/images/algolia_logo.svg","path":"images/algolia_logo.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/apple-touch-icon-next.png","path":"images/apple-touch-icon-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/avatar.gif","path":"images/avatar.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/ayanami.png","path":"images/ayanami.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/ayanami2.png","path":"images/ayanami2.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/favicon-16x16-next.png","path":"images/favicon-16x16-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/favicon-32x32-next.png","path":"images/favicon-32x32-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/logo.svg","path":"images/logo.svg","modified":0,"renderable":1},{"_id":"themes/next/source/js/algolia-search.js","path":"js/algolia-search.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/bookmark.js","path":"js/bookmark.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/local-search.js","path":"js/local-search.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/motion.js","path":"js/motion.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/next-boot.js","path":"js/next-boot.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/utils.js","path":"js/utils.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/anime.min.js","path":"lib/anime.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/schemes/muse.js","path":"js/schemes/muse.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/schemes/pisces.js","path":"js/schemes/pisces.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.min.js","path":"lib/velocity/velocity.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","path":"lib/velocity/velocity.ui.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/all.min.css","path":"lib/font-awesome/css/all.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/webfonts/fa-brands-400.woff2","path":"lib/font-awesome/webfonts/fa-brands-400.woff2","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/webfonts/fa-regular-400.woff2","path":"lib/font-awesome/webfonts/fa-regular-400.woff2","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/webfonts/fa-solid-900.woff2","path":"lib/font-awesome/webfonts/fa-solid-900.woff2","modified":0,"renderable":1}],"Cache":[{"_id":"source/about/index.md","hash":"f30c924680e93dcdb816bd09d41034ffd4397383","modified":1632124832760},{"_id":"source/_posts/hello-world.md","hash":"23eefe9b99a3782e6c5d0dec24cc4a33cadbf893","modified":1632130653043},{"_id":"source/categories/index.md","hash":"022a8ae3c0de87df4dbb1d5de38940e3ef676e54","modified":1632123770519},{"_id":"source/tags/index.md","hash":"6d48da7133110f9d399b1fbc3fbfd4e85d868254","modified":1632123716567},{"_id":"themes/next/.editorconfig","hash":"731c650ddad6eb0fc7c3d4a91cad1698fe7ad311","modified":1632107253073},{"_id":"themes/next/.eslintrc.json","hash":"d3c11de434171d55d70daadd3914bc33544b74b8","modified":1632107253073},{"_id":"themes/next/.gitattributes","hash":"3e00e1fb043438cd820d94ee3dc9ffb6718996f3","modified":1632107253073},{"_id":"themes/next/.gitignore","hash":"83418530da80e6a78501e1d62a89c3bf5cbaec3d","modified":1632107253079},{"_id":"themes/next/.stylintrc","hash":"6259e2a0b65d46865ab89564b88fc67638668295","modified":1632107253079},{"_id":"themes/next/.travis.yml","hash":"379f31a140ce41e441442add6f673bf397d863ea","modified":1632107253079},{"_id":"themes/next/LICENSE.md","hash":"0a9c7399f102b4eb0a6950dd31264be421557c7d","modified":1632107253079},{"_id":"themes/next/README.md","hash":"7d56751b580d042559b2acf904fca4b42bcb30a7","modified":1632107253080},{"_id":"themes/next/_config.yml","hash":"4886174f1eb1028c945a53eee90cf6775777abea","modified":1632320885441},{"_id":"themes/next/crowdin.yml","hash":"4a53f5985e545c635cb56b2a57ed290cb8cf8942","modified":1632107253081},{"_id":"themes/next/gulpfile.js","hash":"0c76a1ac610ee8cbe8e2cc9cca1c925ffd0edf98","modified":1632107253090},{"_id":"themes/next/package.json","hash":"b099e7cea4406e209130410d13de87988ba37b2a","modified":1632107253120},{"_id":"themes/next/.github/CODE_OF_CONDUCT.md","hash":"778b7e052993ed59f21ed266ba7119ee2e5253fb","modified":1632107253074},{"_id":"themes/next/.github/CONTRIBUTING.md","hash":"5ddde54fb50d11dc08cec899a3588addb56aa386","modified":1632107253074},{"_id":"themes/next/.github/PULL_REQUEST_TEMPLATE.md","hash":"d2f8e6b65783e31787feb05d2ccea86151f53f35","modified":1632107253076},{"_id":"themes/next/.github/config.yml","hash":"df3d970700e6b409edc3d23be8d553db78d5ba3f","modified":1632107253077},{"_id":"themes/next/.github/issue_label_bot.yaml","hash":"533fbe6b2f87d7e7ec6949063bb7ea7eb4fbe52d","modified":1632107253077},{"_id":"themes/next/.github/issue-close-app.yml","hash":"b14756e65546eb9ecc9d4393f0c9a84a3dac1824","modified":1632107253077},{"_id":"themes/next/.github/lock.yml","hash":"3ce3d0a26030a1cd52b273cc6a6d444d7c8d85c2","modified":1632107253077},{"_id":"themes/next/.github/mergeable.yml","hash":"1c1cb77a62df1e3654b151c2da34b4a10d351170","modified":1632107253078},{"_id":"themes/next/.github/release-drafter.yml","hash":"09c3352b2d643acdc6839601ceb38abc38ab97c5","modified":1632107253078},{"_id":"themes/next/.github/stale.yml","hash":"590b65aca710e0fba75d3cf5361a64d13b6b0f63","modified":1632107253078},{"_id":"themes/next/.github/support.yml","hash":"7ce2722d6904c31a086444c422dc49b6aa310651","modified":1632107253078},{"_id":"themes/next/docs/AGPL3.md","hash":"f463f95b169d64983f59fa6f3e4b6760290a0e6b","modified":1632107253081},{"_id":"themes/next/docs/ALGOLIA-SEARCH.md","hash":"60c7e9ef0c578deebad43e9395c958fa61096baf","modified":1632107253082},{"_id":"themes/next/docs/AUTHORS.md","hash":"cde7cc095ac31b421a573042cf61060f90d9ad0d","modified":1632107253082},{"_id":"themes/next/docs/DATA-FILES.md","hash":"980fb8d37701f7fd96b30bb911519de3bbb473d1","modified":1632107253082},{"_id":"themes/next/docs/INSTALLATION.md","hash":"07ea00bee149a1bdc9073e903ee6b411e9f2f818","modified":1632107253082},{"_id":"themes/next/docs/LEANCLOUD-COUNTER-SECURITY.md","hash":"6cc663db5e99fd86bb993c10d446ad26ada88e58","modified":1632107253083},{"_id":"themes/next/docs/LICENSE.txt","hash":"ae5ad07e4f4106bad55535dba042221539e6c7f9","modified":1632107253083},{"_id":"themes/next/docs/MATH.md","hash":"f56946053ade0915ff7efa74d43c38b8dd9e63bb","modified":1632107253084},{"_id":"themes/next/docs/UPDATE-FROM-5.1.X.md","hash":"1e86d32063b490d204baa9d45d8d3cb22c24a37d","modified":1632107253084},{"_id":"themes/next/languages/ar.yml","hash":"abcf220bd615cec0dd50e4d98da56580169d77e1","modified":1632107253090},{"_id":"themes/next/languages/de.yml","hash":"15078b7ede1b084e8a6a15d271f0db9c325bd698","modified":1632107253090},{"_id":"themes/next/languages/en.yml","hash":"dbb64776f9c001c54d0058256c415a9a0724ed5d","modified":1632107253091},{"_id":"themes/next/languages/default.yml","hash":"dbb64776f9c001c54d0058256c415a9a0724ed5d","modified":1632107253091},{"_id":"themes/next/languages/es.yml","hash":"f064c793d56a5e0f20cda93b6f0e355044efc7d8","modified":1632107253091},{"_id":"themes/next/languages/fa.yml","hash":"6c0a7d5bcc26eb45a9f3e02f13117c668e77fffd","modified":1632107253092},{"_id":"themes/next/languages/fr.yml","hash":"3e2f89d4bb4441d33ecc7b5a4ee114f627603391","modified":1632107253092},{"_id":"themes/next/languages/hu.yml","hash":"0ea89ffaefd02a10494995f05a2a59d5e5679a28","modified":1632107253092},{"_id":"themes/next/languages/id.yml","hash":"7599bb0ecf278beb8fde3d17bfc148a3241aef82","modified":1632107253093},{"_id":"themes/next/languages/ja.yml","hash":"bf279d0eb1911806d01a12f27261fbc76a3bb3f9","modified":1632107253093},{"_id":"themes/next/languages/it.yml","hash":"46222f468e66789e9ba13095809eb5e5b63edf30","modified":1632107253093},{"_id":"themes/next/languages/ko.yml","hash":"af4be6cb394abd4e2e9a728418897d2ed4cc5315","modified":1632107253093},{"_id":"themes/next/languages/nl.yml","hash":"9749cf90b250e631dd550a4f32ada3bb20f66dd0","modified":1632107253094},{"_id":"themes/next/languages/pt-BR.yml","hash":"69aa3bef5710b61dc9a0f3b3a8f52f88c4d08c00","modified":1632107253094},{"_id":"themes/next/languages/pt.yml","hash":"f6606dd0b916a465c233f24bd9a70adce34dc8d6","modified":1632107253094},{"_id":"themes/next/languages/ru.yml","hash":"012abc694cf9de281a0610f95f79c594f0a16562","modified":1632107253094},{"_id":"themes/next/languages/tr.yml","hash":"c4e9ab7e047ae13a19f147c6bec163c3ba2c6898","modified":1632107253095},{"_id":"themes/next/languages/uk.yml","hash":"69ef00b1b8225920fcefff6a6b6f2f3aad00b4ce","modified":1632107253095},{"_id":"themes/next/languages/vi.yml","hash":"6a578cc28773bd764f4418110500478f185d6efa","modified":1632107253095},{"_id":"themes/next/languages/zh-CN.yml","hash":"81d73e21402dad729053a3041390435f43136a68","modified":1632107253096},{"_id":"themes/next/languages/zh-HK.yml","hash":"92ccee40c234626bf0142152949811ebe39fcef2","modified":1632107253096},{"_id":"themes/next/languages/zh-TW.yml","hash":"cf0740648725983fb88409d6501876f8b79db41d","modified":1632107253096},{"_id":"themes/next/layout/_layout.swig","hash":"9554bd0f5c5a0438aa7b64065be5561c374d260e","modified":1632107253097},{"_id":"themes/next/layout/archive.swig","hash":"d9bca77f6dcfef71e300a294f731bead11ce199f","modified":1632107253118},{"_id":"themes/next/layout/category.swig","hash":"c546b017a956faaa5f5643c7c8a363af7ac9d6b9","modified":1632107253118},{"_id":"themes/next/layout/index.swig","hash":"8dfd96fb6f833dd5d037de800813105654e8e8e6","modified":1632107253119},{"_id":"themes/next/layout/page.swig","hash":"357d916694d4c9a0fd1140fa56d3d17e067d8b52","modified":1632107253119},{"_id":"themes/next/layout/post.swig","hash":"5f0b5ba2e0a5b763be5e7e96611865e33bba24d7","modified":1632107253119},{"_id":"themes/next/layout/tag.swig","hash":"d44ff8755727f6532e86fc9fc8dc631200ffe161","modified":1632107253119},{"_id":"themes/next/scripts/renderer.js","hash":"e3658eea97b1183ee2e9f676231e53f7994741f6","modified":1632107253127},{"_id":"themes/next/source/404.html","hash":"9a62874d83ad2ec2892e0b88a05339e2cf496dec","modified":1632123562376},{"_id":"themes/next/.github/ISSUE_TEMPLATE/bug-report.md","hash":"e67146befddec3a0dc47dc80d1109070c71d5d04","modified":1632107253075},{"_id":"themes/next/.github/ISSUE_TEMPLATE/feature-request.md","hash":"6beeca0f45a429cd932b6e648617f548ff64c27c","modified":1632107253075},{"_id":"themes/next/.github/ISSUE_TEMPLATE/other.md","hash":"d5aa1a3323639a36bcd9a401484b67537043cd3c","modified":1632107253076},{"_id":"themes/next/.github/ISSUE_TEMPLATE/question.md","hash":"59275aa0582f793fee7be67904dcf52ad33a7181","modified":1632107253076},{"_id":"themes/next/docs/ru/DATA-FILES.md","hash":"54e6a067ed95268eab6be2ba040a7e9b1907928e","modified":1632107253084},{"_id":"themes/next/docs/ru/INSTALLATION.md","hash":"a9cfe5ac9ef727a8650b2b6584482751a26b1460","modified":1632107253085},{"_id":"themes/next/docs/ru/README.md","hash":"1e5ddb26ad6f931f8c06ce2120f257ff38b74fdf","modified":1632107253085},{"_id":"themes/next/docs/ru/UPDATE-FROM-5.1.X.md","hash":"cb8e39c377fc4a14aaf133b4d1338a48560e9e65","modified":1632107253085},{"_id":"themes/next/docs/zh-CN/ALGOLIA-SEARCH.md","hash":"3202be9a8d31986caac640e7a4c7ce22e99917eb","modified":1632107253086},{"_id":"themes/next/docs/zh-CN/CODE_OF_CONDUCT.md","hash":"7e6f227f2aaf30f400d4c065650a4e3d0d61b9e1","modified":1632107253086},{"_id":"themes/next/docs/zh-CN/CONTRIBUTING.md","hash":"611f2930c2b281b80543531b1bf33d082531456a","modified":1632107253087},{"_id":"themes/next/docs/zh-CN/DATA-FILES.md","hash":"2d868cd271d78b08775e28c5b976de8836da4455","modified":1632107253088},{"_id":"themes/next/docs/zh-CN/INSTALLATION.md","hash":"716111dd36d276f463c707dfcc9937fea2a1cf7a","modified":1632107253088},{"_id":"themes/next/docs/zh-CN/LEANCLOUD-COUNTER-SECURITY.md","hash":"50ab381c27611d5bf97bb3907b5ca9998f28187d","modified":1632107253088},{"_id":"themes/next/docs/zh-CN/MATH.md","hash":"0d46f9f50cf2e4183970adce705d1041155b0d37","modified":1632107253089},{"_id":"themes/next/docs/zh-CN/README.md","hash":"8f7c0d0b766024152591d4ccfac715c8e18b37f3","modified":1632107253089},{"_id":"themes/next/docs/zh-CN/UPDATE-FROM-5.1.X.md","hash":"b3201934b966bc731eaf8a4dad4ba4bdcd300c10","modified":1632107253089},{"_id":"themes/next/layout/_macro/post-collapse.swig","hash":"30ade8c806d7826cc50a4a3e46a9e6213fddf333","modified":1632107253097},{"_id":"themes/next/layout/_macro/post.swig","hash":"c3fd56bac90ce45a0c79ddfe68beb223ad0d72b4","modified":1632107253098},{"_id":"themes/next/layout/_macro/sidebar.swig","hash":"5bffdb1448caca7db7b1f84e1693e6657a106d50","modified":1632107253098},{"_id":"themes/next/layout/_partials/comments.swig","hash":"142efb4c6b73d8f736f6784804b40d5871333172","modified":1632107253098},{"_id":"themes/next/layout/_partials/footer.swig","hash":"33f4f58082d90d20f62f8b65b7cbcc8c31b4be47","modified":1632128815445},{"_id":"themes/next/layout/_partials/languages.swig","hash":"c3ea82604a5853fb44c5f4e4663cbe912aa5dcf8","modified":1632107253101},{"_id":"themes/next/layout/_partials/pagination.swig","hash":"2de77d533c91532a8a4052000244d0c1693370df","modified":1632107253102},{"_id":"themes/next/layout/_partials/widgets.swig","hash":"5392dcbb504266f0f61d5b8219914068ef9cdc25","modified":1632107253105},{"_id":"themes/next/layout/_scripts/index.swig","hash":"1822eaf55bbb4bec88871c324fc18ad95580ccb4","modified":1632107253106},{"_id":"themes/next/layout/_scripts/noscript.swig","hash":"7b9e0f776a5be6c3f95bc7f394e1424ba02ba93b","modified":1632107253106},{"_id":"themes/next/layout/_scripts/pjax.swig","hash":"ccff5a773644d33ff22f6b45b6734f52b048f22b","modified":1632107253107},{"_id":"themes/next/layout/_scripts/three.swig","hash":"6b092c6d882b2dfa5273e1b3f60b244cb7c29fcd","modified":1632107253109},{"_id":"themes/next/layout/_scripts/vendors.swig","hash":"244ca2d74ee0d497c87572c6a26b43c62a952673","modified":1632107253109},{"_id":"themes/next/layout/_third-party/baidu-push.swig","hash":"28b0a7e843ec4365db1963646659a153753cd746","modified":1632107253110},{"_id":"themes/next/layout/_third-party/index.swig","hash":"c6b63cbc80938e6e09578b8c67e01adf13a9e3bd","modified":1632107253113},{"_id":"themes/next/layout/_third-party/quicklink.swig","hash":"5ae5adcd6f63ed98b2071e4f7e5e38c4d7d24e1b","modified":1632107253114},{"_id":"themes/next/layout/_third-party/rating.swig","hash":"269102fc5e46bd1ce75abdcce161f0570ae70e2f","modified":1632107253115},{"_id":"themes/next/scripts/events/index.js","hash":"5c355f10fe8c948a7f7cd28bd8120adb7595ebde","modified":1632107253120},{"_id":"themes/next/scripts/filters/default-injects.js","hash":"ad321db012cea520066deb0639335e9bc0dcc343","modified":1632107253124},{"_id":"themes/next/scripts/filters/front-matter.js","hash":"305d03c1e45782988809298c3e3b3c5d5ee438aa","modified":1632107253124},{"_id":"themes/next/scripts/filters/locals.js","hash":"a5e7d05d3bd2ae6dcffad5a8ea0f72c6e55dbd02","modified":1632107253125},{"_id":"themes/next/scripts/filters/minify.js","hash":"21196a48cb127bf476ce598f25f24e8a53ef50c2","modified":1632107253125},{"_id":"themes/next/scripts/filters/post.js","hash":"57f2d817578dd97e206942604365e936a49854de","modified":1632107253125},{"_id":"themes/next/scripts/helpers/engine.js","hash":"eb6b8bbc1dce4846cd5e0fac0452dbff56d07b5d","modified":1632107253126},{"_id":"themes/next/scripts/helpers/font.js","hash":"8fb1c0fc745df28e20b96222974402aab6d13a79","modified":1632107253126},{"_id":"themes/next/scripts/helpers/next-config.js","hash":"b8d7ddfa4baa9b8d6b9066a634aa81c6243beec9","modified":1632107253126},{"_id":"themes/next/scripts/helpers/next-url.js","hash":"4044129368d0e2811859a9661cad8ab47118bc32","modified":1632107253127},{"_id":"themes/next/scripts/tags/button.js","hash":"bb0e8abbc0a6d5b3a1a75a23976f2ac3075aab31","modified":1632107253127},{"_id":"themes/next/scripts/tags/caniuse.js","hash":"840536754121e0da5968f5ad235f29200fc5d769","modified":1632107253128},{"_id":"themes/next/scripts/tags/center-quote.js","hash":"e2d0184bc4a557e1017395b80ff46880078d8537","modified":1632107253128},{"_id":"themes/next/scripts/tags/group-pictures.js","hash":"93ccd3f99d3cb42674f29183c756df63acb5d7f8","modified":1632107253128},{"_id":"themes/next/scripts/tags/label.js","hash":"fc83f4e1be2c34e81cb79938f4f99973eba1ea60","modified":1632107253129},{"_id":"themes/next/scripts/tags/mermaid.js","hash":"81134494ff0134c0dae1b3815caf6606fccd4e46","modified":1632107253129},{"_id":"themes/next/scripts/tags/note.js","hash":"1fdf4f95810fdb983bfd5ad4c4f13fedd4ea2f8d","modified":1632107253129},{"_id":"themes/next/scripts/tags/pdf.js","hash":"37b53661ad00a01a2ca7d2e4a5ad3a926073f8e2","modified":1632107253129},{"_id":"themes/next/scripts/tags/tabs.js","hash":"c70a4a66fd0c28c98ccb6c5d5f398972e5574d28","modified":1632107253130},{"_id":"themes/next/scripts/tags/video.js","hash":"944293fec96e568d9b09bc1280d5dbc9ee1bbd17","modified":1632107253130},{"_id":"themes/next/source/css/_colors.styl","hash":"11aef31a8e76f0f332a274a8bfd4537b73d4f88f","modified":1632107253130},{"_id":"themes/next/source/css/_mixins.styl","hash":"072a3fa473c19b20ccd7536a656cda044dbdae0a","modified":1632107253152},{"_id":"themes/next/source/css/main.styl","hash":"815ef30987d02f3d76dbe4b5ee3a72135a152678","modified":1632107253160},{"_id":"themes/next/source/images/algolia_logo.svg","hash":"45eeea0b5fba833e21e38ea10ed5ab385ceb4f01","modified":1632107253160},{"_id":"themes/next/source/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1632107253160},{"_id":"themes/next/source/images/avatar.gif","hash":"18c53e15eb0c84b139995f9334ed8522b40aeaf6","modified":1632107253161},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","hash":"bc3588c9b2d7c68830524783120ff6cf957cf668","modified":1632107253162},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","hash":"6f55543d1fb9cbc436c101d24f802dec7b41efc3","modified":1632107253162},{"_id":"themes/next/source/images/cc-by-nc.svg","hash":"6f076713fb9bf934aa2c1046bdf2cf2e37bc1eab","modified":1632107253162},{"_id":"themes/next/source/images/cc-by-nd.svg","hash":"42cd73da328077ccc92f859bb8f3cf621b3484f8","modified":1632107253163},{"_id":"themes/next/source/images/cc-by-sa.svg","hash":"70c1535f43e54e5ff35ca81419e77e4c0c301398","modified":1632107253163},{"_id":"themes/next/source/images/cc-by.svg","hash":"e92a33c32d1dac8ed94849b2b4e6456e887efe70","modified":1632107253163},{"_id":"themes/next/source/images/cc-zero.svg","hash":"9bfb52b2f63527a7049247bf00d44e6dc1170e7d","modified":1632107253163},{"_id":"themes/next/source/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1632107253164},{"_id":"themes/next/source/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1632107253164},{"_id":"themes/next/source/images/logo.svg","hash":"169f56fd82941591dad3abd734a50ec7259be950","modified":1632107253164},{"_id":"themes/next/source/js/algolia-search.js","hash":"6a813410e33824d7acc65a369a2983912bb3420c","modified":1632107253165},{"_id":"themes/next/source/js/bookmark.js","hash":"9f05fd3672789311dc0cf5b37e40dc654cb04a2a","modified":1632107253165},{"_id":"themes/next/source/js/local-search.js","hash":"cfa6a0f3f9c2bc759ee507668a21f4e8f250f42a","modified":1632107253165},{"_id":"themes/next/source/js/motion.js","hash":"d5aa1a08cdf3c8d1d8d550fb1801274cc41e5874","modified":1632107253166},{"_id":"themes/next/source/js/next-boot.js","hash":"250d8dcd6322e69e3fbadd0f3e37081c97b47c52","modified":1632107253166},{"_id":"themes/next/source/js/utils.js","hash":"26a82e46fdcadc7c3c2c56a7267284b61a26f7f3","modified":1632107253167},{"_id":"themes/next/source/lib/anime.min.js","hash":"960be51132134acd65c2017cc8a5d69cb419a0cd","modified":1632107253168},{"_id":"themes/next/layout/_partials/head/head-unique.swig","hash":"7d638e413f2548fc990c4a467dd03de6c81fc960","modified":1632107253099},{"_id":"themes/next/layout/_partials/head/head.swig","hash":"90cce9f407e9490756ba99580e3eb09f55b05eaa","modified":1632107253099},{"_id":"themes/next/layout/_partials/header/brand.swig","hash":"91056a6c98cca63ff8cc6956e531ee3faf4b8ad9","modified":1632107253100},{"_id":"themes/next/layout/_partials/header/index.swig","hash":"0dd316f153c492c0a03bd0273d50fa322bc81f11","modified":1632107253100},{"_id":"themes/next/layout/_partials/header/menu-item.swig","hash":"4baa86ca631168fc6388d27f4b1b501b40c877a8","modified":1632107253100},{"_id":"themes/next/layout/_partials/header/menu.swig","hash":"90d3eaba6fbe69bee465ddd67c467fd2c0239dc4","modified":1632107253101},{"_id":"themes/next/layout/_partials/header/sub-menu.swig","hash":"bed6cc2b48cf2655036ba39c9bae73a295228a4d","modified":1632107253101},{"_id":"themes/next/layout/_partials/page/breadcrumb.swig","hash":"91c0addb33006619faa4c32e5d66874e25f1e9b3","modified":1632107253102},{"_id":"themes/next/layout/_partials/page/page-header.swig","hash":"8d4e3dd0d3631ce0b21bc15c259f6ac886de631d","modified":1632107253102},{"_id":"themes/next/layout/_partials/post/post-copyright.swig","hash":"f2eb455c8bf13533427254f0c9b4b17b2498168b","modified":1632107253103},{"_id":"themes/next/layout/_partials/post/post-followme.swig","hash":"d8f785c062c6b0763a778bd4a252e6f5fee0e432","modified":1632107253103},{"_id":"themes/next/layout/_partials/post/post-footer.swig","hash":"ce712c110b5ce8aacba7a86b0558ff89700675c9","modified":1632107253103},{"_id":"themes/next/layout/_partials/post/post-related.swig","hash":"bc7b047a6246df07767373644b1637d91c3a88b1","modified":1632107253103},{"_id":"themes/next/layout/_partials/post/post-reward.swig","hash":"f349a226e5370075bb6924e60da8b0170c7cfcc1","modified":1632107253104},{"_id":"themes/next/layout/_partials/search/algolia-search.swig","hash":"98fd1f5df044f4534e1d4ca9ab092ba5761739a9","modified":1632107253104},{"_id":"themes/next/layout/_partials/search/index.swig","hash":"a6c761d5193cb6f22e9422dbbcf209e05471b0ed","modified":1632107253104},{"_id":"themes/next/layout/_partials/search/localsearch.swig","hash":"128f7d679bb4d53b29203d598d217f029a66dee7","modified":1632107253105},{"_id":"themes/next/layout/_partials/sidebar/site-overview.swig","hash":"7b2ef5db9615267a24b884388925de1e9b447c1f","modified":1632107253105},{"_id":"themes/next/layout/_scripts/pages/schedule.swig","hash":"34c05e9d73b0f081db70990c296b6d6a0f8ea2ca","modified":1632107253107},{"_id":"themes/next/layout/_scripts/schemes/gemini.swig","hash":"34495d408e8467555afee489500b8aad98c52079","modified":1632107253107},{"_id":"themes/next/layout/_scripts/schemes/muse.swig","hash":"0b44f400ec00d2b5add5ee96c11d22465c432376","modified":1632107253108},{"_id":"themes/next/layout/_scripts/schemes/mist.swig","hash":"0b44f400ec00d2b5add5ee96c11d22465c432376","modified":1632107253107},{"_id":"themes/next/layout/_scripts/schemes/pisces.swig","hash":"34495d408e8467555afee489500b8aad98c52079","modified":1632107253109},{"_id":"themes/next/layout/_third-party/analytics/baidu-analytics.swig","hash":"84adaadd83ce447fa9da2cff19006334c9fcbff9","modified":1632107253109},{"_id":"themes/next/layout/_third-party/analytics/google-analytics.swig","hash":"b8819bd056f8a580c5556d4415836a906ed5d7a4","modified":1632107253109},{"_id":"themes/next/layout/_third-party/analytics/index.swig","hash":"85b60e222712ca3b2c4dc2039de2dc36b8d82940","modified":1632107253110},{"_id":"themes/next/layout/_third-party/analytics/growingio.swig","hash":"91c2cb900c76224c5814eeb842d1d5f517f9bf05","modified":1632107253110},{"_id":"themes/next/layout/_third-party/chat/chatra.swig","hash":"2642e8aef5afbe23a2a76efdc955dab2ee04ed48","modified":1632107253111},{"_id":"themes/next/layout/_third-party/chat/tidio.swig","hash":"fb94ee487d75e484e59b7fba96e989f699ff8a83","modified":1632107253111},{"_id":"themes/next/layout/_third-party/comments/changyan.swig","hash":"9298e6d6c4a62a0862fc0f4060ed99779d7b68cb","modified":1632107253111},{"_id":"themes/next/layout/_third-party/comments/disqus.swig","hash":"1b29b99fa921f12c25d3dc95facdf84ef7bb1b5c","modified":1632107253112},{"_id":"themes/next/layout/_third-party/comments/disqusjs.swig","hash":"a42f97eda3748583bac2253c47fe5dfa54f07b8f","modified":1632107253112},{"_id":"themes/next/layout/_third-party/comments/gitalk.swig","hash":"606ad14a29320157df9b8f33738282c51bb393d9","modified":1632107253112},{"_id":"themes/next/layout/_third-party/comments/valine.swig","hash":"ae2707d6e47582bb470c075649ec7bad86a6d5a9","modified":1632107253113},{"_id":"themes/next/layout/_third-party/comments/livere.swig","hash":"3d91899ca079e84d95087b882526d291e6f53918","modified":1632107253113},{"_id":"themes/next/layout/_third-party/math/index.swig","hash":"59df21fcfe9d0ada8cee3188cb1075529c1c3eb8","modified":1632107253113},{"_id":"themes/next/layout/_third-party/math/katex.swig","hash":"276f523e414d4aa7f350a8f2fd3df8a3d8ea9656","modified":1632107253114},{"_id":"themes/next/layout/_third-party/math/mathjax.swig","hash":"1f34b2d3c753a3589ab6c462880bd4eb7df09914","modified":1632107253114},{"_id":"themes/next/layout/_third-party/search/algolia-search.swig","hash":"fd726aad77a57b288f07d6998ec29291c67c7cbb","modified":1632107253115},{"_id":"themes/next/layout/_third-party/search/localsearch.swig","hash":"58296a5c1883f26464c2a5ccf734c19f5fbf395a","modified":1632107253115},{"_id":"themes/next/layout/_third-party/search/swiftype.swig","hash":"aa6ab95b8b76611694613defb4bf25003d1b927f","modified":1632107253116},{"_id":"themes/next/layout/_third-party/statistics/busuanzi-counter.swig","hash":"d2f0e4c598410ec33785abe302c7ea7492bb791a","modified":1632107253116},{"_id":"themes/next/layout/_third-party/statistics/cnzz-analytics.swig","hash":"53a0760c75d5aaabb3ce8e8aa8e003510d59807f","modified":1632107253116},{"_id":"themes/next/layout/_third-party/statistics/firestore.swig","hash":"01d94354d07e72cad47100482068b6be69fcc033","modified":1632107253117},{"_id":"themes/next/layout/_third-party/statistics/index.swig","hash":"964cd6bac668cf6d211a2624fbef3948cfdece55","modified":1632107253117},{"_id":"themes/next/layout/_third-party/statistics/lean-analytics.swig","hash":"c171ea94e9afbba97f06856904264da331559463","modified":1632107253117},{"_id":"themes/next/layout/_third-party/tags/mermaid.swig","hash":"619338ddacf01e3df812e66a997e778f672f4726","modified":1632107253118},{"_id":"themes/next/layout/_third-party/tags/pdf.swig","hash":"5a223b60406cee7438cfe3a5e41d1284425aa7a5","modified":1632107253118},{"_id":"themes/next/scripts/events/lib/config.js","hash":"aefe3b38a22bc155d485e39187f23e4f2ee5680a","modified":1632107253121},{"_id":"themes/next/scripts/events/lib/injects-point.js","hash":"08496b71c9939718e7955704d219e44d7109247b","modified":1632107253121},{"_id":"themes/next/scripts/events/lib/injects.js","hash":"e73f697bb160b223fdde783237148be5f41c1d78","modified":1632107253121},{"_id":"themes/next/scripts/filters/comment/changyan.js","hash":"2f22f48f7370470cef78561a47c2a47c78035385","modified":1632107253122},{"_id":"themes/next/scripts/filters/comment/common.js","hash":"713056d33dbcd8e9748205c5680b456c21174f4e","modified":1632107253122},{"_id":"themes/next/scripts/filters/comment/default-config.js","hash":"0c3bea89d64bc12c1bbe6f208a83773c6fb5375a","modified":1632107253123},{"_id":"themes/next/scripts/filters/comment/disqusjs.js","hash":"67cf90d9a2428c14eb113a64bdd213c22a019aef","modified":1632107253123},{"_id":"themes/next/scripts/filters/comment/disqus.js","hash":"3a80559df0b670ccb065ea9d3bb587d0b61be3a4","modified":1632107253123},{"_id":"themes/next/scripts/filters/comment/gitalk.js","hash":"323a47df6ded894944a2647db44556d6163e67c4","modified":1632107253123},{"_id":"themes/next/scripts/filters/comment/livere.js","hash":"a4f3153ac76a7ffdf6cc70f52f1b2cc218ed393e","modified":1632107253124},{"_id":"themes/next/scripts/filters/comment/valine.js","hash":"851359f5ff90f733a9bd7fe677edbee8b8ac714c","modified":1632107253124},{"_id":"themes/next/source/css/_variables/Gemini.styl","hash":"583ff1e7a2ca889f1f54eb0ca793894466823c7c","modified":1632107253158},{"_id":"themes/next/source/css/_variables/Mist.styl","hash":"5980abbbbeacd8541121f436fa414d24ad5e97c2","modified":1632107253158},{"_id":"themes/next/source/css/_variables/Muse.styl","hash":"c22b58af3327236ec54d5706501aa5a20e15012e","modified":1632107253159},{"_id":"themes/next/source/css/_variables/Pisces.styl","hash":"4e33774b1fe6d0a51f3a428c54c5e600e83bf154","modified":1632107253159},{"_id":"themes/next/source/css/_variables/base.styl","hash":"ad680efdfb2f86546182bf3f59886efbcf3c1b2d","modified":1632107253159},{"_id":"themes/next/source/js/schemes/muse.js","hash":"a18559a9c332199efad0100cf84bb0c23fc0f17a","modified":1632107253166},{"_id":"themes/next/source/js/schemes/pisces.js","hash":"b85a6e2af1387fe64b51e7cd3e2da8616e6f5a3f","modified":1632107253167},{"_id":"themes/next/source/lib/velocity/velocity.min.js","hash":"bf172816a9c57f9040e3d19c24e181a142daf92b","modified":1632107253171},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","hash":"dde584994ac13dc601836e86f4cf490e418d9723","modified":1632107253171},{"_id":"themes/next/source/css/_common/components/back-to-top-sidebar.styl","hash":"510a6f0ba7485dd54ce347cca890ab52c4957081","modified":1632107253131},{"_id":"themes/next/source/css/_common/components/back-to-top.styl","hash":"0534b329d279a6f255112b3305ff92c810f31724","modified":1632107253131},{"_id":"themes/next/source/css/_common/components/components.styl","hash":"d17236df3b4d6def1e4e81133ef4729c390de3ac","modified":1632107253132},{"_id":"themes/next/source/css/_common/components/reading-progress.styl","hash":"c52648a7b09f9fe37858f5694fcc1ffc709ad147","modified":1632107253137},{"_id":"themes/next/source/css/_common/outline/outline.styl","hash":"7a95c27762e1303bf06ee808c63f616cb192fcaf","modified":1632107253142},{"_id":"themes/next/source/css/_common/outline/mobile.styl","hash":"a2ee16cac29a82cfce26804c160286fcbee94161","modified":1632107253142},{"_id":"themes/next/source/css/_common/scaffolding/base.styl","hash":"5540c9259cb7895a5f10a289c7937e5470a7c134","modified":1632107253145},{"_id":"themes/next/source/css/_common/scaffolding/buttons.styl","hash":"45f4badac6ec45cf24355f6157aece1d4d3f1134","modified":1632107253146},{"_id":"themes/next/source/css/_common/scaffolding/comments.styl","hash":"4b068d0d898f4e624937503f0e1428993050bd65","modified":1632107253147},{"_id":"themes/next/source/css/_common/scaffolding/normalize.styl","hash":"6d740699fb6a7640647a8fd77c4ea4992d8d6437","modified":1632107253148},{"_id":"themes/next/source/css/_common/scaffolding/pagination.styl","hash":"b619f39e18398422e0ac4999d8f042a5eaebe9cd","modified":1632107253149},{"_id":"themes/next/source/css/_common/scaffolding/scaffolding.styl","hash":"43045d115f8fe95732c446aa45bf1c97609ff2a5","modified":1632107253149},{"_id":"themes/next/source/css/_common/scaffolding/tables.styl","hash":"f317d2e3886e94f5fbb8781c2e68edd19669ff58","modified":1632107253149},{"_id":"themes/next/source/css/_common/scaffolding/toggles.styl","hash":"20e0e3e3eba384930c022e21511214d244b4c9e7","modified":1632107253152},{"_id":"themes/next/source/css/_schemes/Gemini/index.styl","hash":"e342b8f8e11a3a6aa5a029912c9778c25bf5d135","modified":1632107253153},{"_id":"themes/next/source/css/_schemes/Mist/_layout.styl","hash":"12b265f82840f27112ca2b1be497677f20f87545","modified":1632107253153},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","hash":"b9e87d32da24264bda247c1526afe140c858b0ef","modified":1632107253153},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","hash":"716e8b0f056bf6393e6bc6969ac84598ab8e7a6f","modified":1632107253154},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","hash":"c5142739e01e9f25c8b32b2209af85c787bb2b42","modified":1632107253154},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expand.styl","hash":"e1c29b81a32273a0dedd926cda199a71aea72624","modified":1632107253154},{"_id":"themes/next/source/css/_schemes/Muse/_header.styl","hash":"8674bd88df076a1dfe4023ed6750ded1f5b00223","modified":1632107253155},{"_id":"themes/next/source/css/_schemes/Muse/_layout.styl","hash":"49c76bc723d3952abb613d9d68398ed7305da999","modified":1632107253155},{"_id":"themes/next/source/css/_schemes/Muse/_menu.styl","hash":"4b7f057dbb53efd7cbe7eac7835a793ab3cbb135","modified":1632107253155},{"_id":"themes/next/source/css/_schemes/Muse/_sidebar.styl","hash":"9898323ee5a7ac2a5d4f633c653112280beb2643","modified":1632107253156},{"_id":"themes/next/source/css/_schemes/Muse/index.styl","hash":"25c2a7930da14f023329df20f38df2728057fb4d","modified":1632107253156},{"_id":"themes/next/source/css/_schemes/Muse/_sub-menu.styl","hash":"2d3e05015796a790abd9d68957a5c698c0c9f9b6","modified":1632107253156},{"_id":"themes/next/source/css/_schemes/Pisces/_header.styl","hash":"558794fced306339b98dc2b0ee7f0576802f1355","modified":1632107253157},{"_id":"themes/next/source/css/_schemes/Pisces/_layout.styl","hash":"5de34e1d8a290751641ae456c942410852d5e809","modified":1632107253157},{"_id":"themes/next/source/css/_schemes/Pisces/_sidebar.styl","hash":"dc9318992ce2eb086ebaa2fe56b325e56d24098b","modified":1632107253157},{"_id":"themes/next/source/css/_schemes/Pisces/_menu.styl","hash":"0a9f0d9eb042595502d200fb8c65efb0e6c89aa9","modified":1632107253157},{"_id":"themes/next/source/css/_schemes/Pisces/_sub-menu.styl","hash":"b69ac38b9da8c9c1b7de696fdeea7f9d7705213a","modified":1632107253157},{"_id":"themes/next/source/css/_schemes/Pisces/index.styl","hash":"25c2a7930da14f023329df20f38df2728057fb4d","modified":1632107253157},{"_id":"themes/next/source/lib/font-awesome/css/all.min.css","hash":"82e34d28f8a1169b20b60101d5bb0446deba3514","modified":1632107253169},{"_id":"themes/next/source/lib/font-awesome/webfonts/fa-regular-400.woff2","hash":"260bb01acd44d88dcb7f501a238ab968f86bef9e","modified":1632107253170},{"_id":"themes/next/source/css/_common/components/pages/breadcrumb.styl","hash":"236a039b0900f4267de566b46f62314ad967d30f","modified":1632107253132},{"_id":"themes/next/source/css/_common/components/pages/categories.styl","hash":"18edddb2ffb3f85a68e4367f81e06c461e07bc25","modified":1632107253132},{"_id":"themes/next/source/css/_common/components/pages/pages.styl","hash":"6cf78a379bb656cc0abb4ab80fcae60152ce41ad","modified":1632107253133},{"_id":"themes/next/source/css/_common/components/pages/tag-cloud.styl","hash":"97974c231b4659b8aa5e9321c4d54db5c816d0db","modified":1632107253133},{"_id":"themes/next/source/css/_common/components/pages/schedule.styl","hash":"f6f05f02d50f742c84ee5122016c0563a8bb2cf9","modified":1632107253133},{"_id":"themes/next/source/css/_common/components/post/post-collapse.styl","hash":"a52f8cae599099231866298ed831fdf76c9b6717","modified":1632107253134},{"_id":"themes/next/source/css/_common/components/post/post-copyright.styl","hash":"9af620eba5ccceea21a0e3bc69f6f1fa7637c2f3","modified":1632107253134},{"_id":"themes/next/source/css/_common/components/post/post-eof.styl","hash":"70b3eb9d36543ab92796ac163544e9cf51b7c1e6","modified":1632107253134},{"_id":"themes/next/source/css/_common/components/post/post-expand.styl","hash":"97dec98d0403097d66822f1c90b50b2890c84698","modified":1632107253135},{"_id":"themes/next/source/css/_common/components/post/post-followme.styl","hash":"57b9a179675f1536e017cba457b6ac575e397c4f","modified":1632107253135},{"_id":"themes/next/source/css/_common/components/post/post-gallery.styl","hash":"0dfb97703a519d9438f64f9e41ab1dd37381f733","modified":1632107253135},{"_id":"themes/next/source/css/_common/components/post/post-header.styl","hash":"93ba8172c0d2c37d738e6dbd44fcd5a2e23b92f3","modified":1632107253135},{"_id":"themes/next/source/css/_common/components/post/post-nav.styl","hash":"2c24829d95c742eb9e8316ebf2fbe9f2c168b59a","modified":1632107253136},{"_id":"themes/next/source/css/_common/components/post/post-reward.styl","hash":"66fc406796b6efe6cea76550573b7a632112406a","modified":1632107253136},{"_id":"themes/next/source/css/_common/components/post/post-rtl.styl","hash":"09dda2667628d1f91b2e37d8fc6df1413f961b64","modified":1632107253136},{"_id":"themes/next/source/css/_common/components/post/post-tags.styl","hash":"5cc9e7394c927065c688cba5edd6e0a27587f1d8","modified":1632107253136},{"_id":"themes/next/source/css/_common/components/post/post-widgets.styl","hash":"b266d2ce5e2b117be01537889e839a69004dc0bb","modified":1632107253137},{"_id":"themes/next/source/css/_common/components/post/post.styl","hash":"de6d5f247d8c19405bf20323a0dc567962eba83b","modified":1632124656296},{"_id":"themes/next/source/css/_common/components/third-party/gitalk.styl","hash":"b87f4a06c0db893df4f756f24be182e1a4751f24","modified":1632107253138},{"_id":"themes/next/source/css/_common/components/third-party/math.styl","hash":"d83102771df652769e51ddfd041cf5f4ca1a041d","modified":1632107253138},{"_id":"themes/next/source/css/_common/components/third-party/related-posts.styl","hash":"8ed7a9d5dfac592de703421b543978095129aa5b","modified":1632107253139},{"_id":"themes/next/source/css/_common/components/third-party/search.styl","hash":"bad99f4cccb93b3cefe990a2c85124e60698d32e","modified":1632107253139},{"_id":"themes/next/source/css/_common/components/third-party/third-party.styl","hash":"1f6b0d3ab227697ca115e57fd61122ea7950e19d","modified":1632107253139},{"_id":"themes/next/source/css/_common/outline/footer/footer.styl","hash":"7eeb22c5696f8e0c95161dc57703973cf81c8c12","modified":1632107253140},{"_id":"themes/next/source/css/_common/outline/header/bookmark.styl","hash":"b4f4bae437d4f994af93cf142494ffcd86bae46b","modified":1632107253140},{"_id":"themes/next/source/css/_common/outline/header/github-banner.styl","hash":"b31c86d1a4f89837f9187bed646bda96b2cd286c","modified":1632107253141},{"_id":"themes/next/source/css/_common/outline/header/header.styl","hash":"300058ca12e81013e77ba01fe66ac210525768b6","modified":1632107253141},{"_id":"themes/next/source/css/_common/outline/header/headerband.styl","hash":"6d5f26646e2914474f295de8bf6dc327d4acd529","modified":1632107253141},{"_id":"themes/next/source/css/_common/outline/header/menu.styl","hash":"7a3a56b10ab714c0e2ed240d0939deeecdcad167","modified":1632107253141},{"_id":"themes/next/source/css/_common/outline/header/site-meta.styl","hash":"3d16ac0f4ccaeed868c246d4d49bde543d1f62cb","modified":1632107253141},{"_id":"themes/next/source/css/_common/outline/header/site-nav.styl","hash":"b8c816fba0a9b4a35fbae03ba5b1b2da96ba2687","modified":1632107253141},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-author-links.styl","hash":"49722d555a2edb18094bb2cb3d7336dd72051b93","modified":1632107253142},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-author.styl","hash":"357f825f0a649b2e28cba1481d4c9a0cb402e43a","modified":1632107253143},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-blogroll.styl","hash":"096f908c08ce553e482aadfd3e767a0145191093","modified":1632107253143},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-button.styl","hash":"525242ce9e912c4adfe5134347c67dbdb9e98e3d","modified":1632107253143},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-dimmer.styl","hash":"12f7eaf6b56624cbc411528562d6bb848ff97039","modified":1632107253144},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-nav.styl","hash":"b11b04737a1a0fea3bd9f0081d96ee6c015358d4","modified":1632107253144},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-toc.styl","hash":"fa0a2ea57b7b4ce75b5d18c264af2d92ea3192f9","modified":1632107253144},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-toggle.styl","hash":"098b4bdf49c7300490f959386d5d1185a32543f6","modified":1632107253144},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar.styl","hash":"5d540f683018745a5ed1d6f635df28ea610c1244","modified":1632107253145},{"_id":"themes/next/source/css/_common/outline/sidebar/site-state.styl","hash":"67a1fcb33535122d41acd24f1f49cf02c89b88fa","modified":1632107253145},{"_id":"themes/next/source/css/_common/scaffolding/highlight/copy-code.styl","hash":"4079e616fbf36112dec0674c1e0713d1d9769068","modified":1632107253147},{"_id":"themes/next/source/css/_common/scaffolding/highlight/diff.styl","hash":"83bd737f663a8461e66985af8ddbfc0a731fc939","modified":1632107253147},{"_id":"themes/next/source/css/_common/scaffolding/highlight/highlight.styl","hash":"80488259271bcfe38031f4c2e902463daba9336b","modified":1632107253148},{"_id":"themes/next/source/css/_common/scaffolding/highlight/theme.styl","hash":"c911045b2ce9a66e38d9dd30c7ed078abbc10cbf","modified":1632107253148},{"_id":"themes/next/source/css/_common/scaffolding/tags/blockquote-center.styl","hash":"ceacfa6218f6084c71a230b086e5d2708d29927e","modified":1632107253149},{"_id":"themes/next/source/css/_common/scaffolding/tags/group-pictures.styl","hash":"aca7bb220fc14ef2a8f96282d2a95a96a9238d46","modified":1632107253150},{"_id":"themes/next/source/css/_common/scaffolding/tags/label.styl","hash":"8b7aafb911850c73074cdb6cc87abe4ac8c12e99","modified":1632107253150},{"_id":"themes/next/source/css/_common/scaffolding/tags/note.styl","hash":"adaf0f580fccf4158169eeaf534a18005b39a760","modified":1632107253151},{"_id":"themes/next/source/css/_common/scaffolding/tags/pdf.styl","hash":"03a5bcecc0b12231462ef6ffe432fa77ee71beff","modified":1632107253151},{"_id":"themes/next/source/css/_common/scaffolding/tags/tabs.styl","hash":"3256e39f281f06751a1c0145d9806a0e56d68170","modified":1632107253151},{"_id":"themes/next/source/css/_common/scaffolding/tags/tags.styl","hash":"51d46fa3c7c6b691c61a2c2b0ac005c97cfbf72b","modified":1632107253151},{"_id":"themes/next/source/lib/font-awesome/webfonts/fa-brands-400.woff2","hash":"509988477da79c146cb93fb728405f18e923c2de","modified":1632107253169},{"_id":"themes/next/source/lib/font-awesome/webfonts/fa-solid-900.woff2","hash":"75a88815c47a249eadb5f0edc1675957f860cca7","modified":1632107253170},{"_id":"themes/next/source/images/ayanami2.png","hash":"d5a65d5094434395ed81dd6f1d130325e1e2a717","modified":1632111582634},{"_id":"themes/next/source/images/ayanami.png","hash":"791d9c73a9716ac4783aa9319867602a37938887","modified":1632109132654},{"_id":"public/sitemap.xml","hash":"f993790c9b2446938fbf6e6f2cce8271cbd177fd","modified":1632326061506},{"_id":"public/baidusitemap.xml","hash":"8e319553b91ad8562533a87f9085b3dc502d90db","modified":1632326061506},{"_id":"public/search.xml","hash":"bedf76ca18cc6d35db059ba84520e7300eed78ae","modified":1632326061506},{"_id":"public/about/index.html","hash":"bee20c9e0e903f08686212ed0e11b54b82c9337e","modified":1632326061506},{"_id":"public/categories/index.html","hash":"fafb43f5fe2ab547661f1fbb990b1a840321dcb8","modified":1632326061506},{"_id":"public/tags/index.html","hash":"7d4e49022f09f83af0915bc6021924da1de6521b","modified":1632326061506},{"_id":"public/2021/09/20/hello-world/index.html","hash":"38a87233fa1541881f170781d1ac95760aec4df1","modified":1632205149705},{"_id":"public/archives/index.html","hash":"ca26e6329cf2d9a877e11cac155aecb0a0465d2b","modified":1632326061506},{"_id":"public/archives/2021/index.html","hash":"7e6c3c9160eec9e4b140140f0123fbd812e0f20b","modified":1632326061506},{"_id":"public/archives/2021/09/index.html","hash":"9b140f3532c76bd71a2dabd77e8a82b7eb6fda65","modified":1632326061506},{"_id":"public/index.html","hash":"af8a145800def9cbbfc5d43a43b9b9c9a4309d9d","modified":1632326061506},{"_id":"public/images/algolia_logo.svg","hash":"45eeea0b5fba833e21e38ea10ed5ab385ceb4f01","modified":1632136859588},{"_id":"public/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1632136859588},{"_id":"public/images/avatar.gif","hash":"18c53e15eb0c84b139995f9334ed8522b40aeaf6","modified":1632136859588},{"_id":"public/images/cc-by-nc-sa.svg","hash":"6f55543d1fb9cbc436c101d24f802dec7b41efc3","modified":1632136859588},{"_id":"public/images/cc-by-nc.svg","hash":"6f076713fb9bf934aa2c1046bdf2cf2e37bc1eab","modified":1632136859588},{"_id":"public/images/cc-by-nc-nd.svg","hash":"bc3588c9b2d7c68830524783120ff6cf957cf668","modified":1632136859588},{"_id":"public/images/cc-by-nd.svg","hash":"42cd73da328077ccc92f859bb8f3cf621b3484f8","modified":1632136859588},{"_id":"public/images/cc-by-sa.svg","hash":"70c1535f43e54e5ff35ca81419e77e4c0c301398","modified":1632136859588},{"_id":"public/images/cc-zero.svg","hash":"9bfb52b2f63527a7049247bf00d44e6dc1170e7d","modified":1632136859588},{"_id":"public/images/cc-by.svg","hash":"e92a33c32d1dac8ed94849b2b4e6456e887efe70","modified":1632136859588},{"_id":"public/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1632136859588},{"_id":"public/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1632136859588},{"_id":"public/images/logo.svg","hash":"169f56fd82941591dad3abd734a50ec7259be950","modified":1632136859588},{"_id":"public/lib/font-awesome/webfonts/fa-regular-400.woff2","hash":"260bb01acd44d88dcb7f501a238ab968f86bef9e","modified":1632136859588},{"_id":"public/assets/algolia/algoliasearchLite.min.js","hash":"284416885e4e80e27fa4eae6fc305f4de15b914c","modified":1632136859588},{"_id":"public/lib/font-awesome/webfonts/fa-brands-400.woff2","hash":"509988477da79c146cb93fb728405f18e923c2de","modified":1632136859588},{"_id":"public/lib/font-awesome/webfonts/fa-solid-900.woff2","hash":"75a88815c47a249eadb5f0edc1675957f860cca7","modified":1632136859588},{"_id":"public/assets/algolia/algoliasearchLite.js","hash":"e56ad6b82caf69066de545201014291fc961635e","modified":1632136859588},{"_id":"public/assets/algolia/algoliasearch.min.js","hash":"a3b131a9a47ccc16f4dd8988fabb6d306548db2f","modified":1632136859588},{"_id":"public/404.html","hash":"9a62874d83ad2ec2892e0b88a05339e2cf496dec","modified":1632136859588},{"_id":"public/js/algolia-search.js","hash":"498d233eb5c7af6940baf94c1a1c36fdf1dd2636","modified":1632136859588},{"_id":"public/js/bookmark.js","hash":"9734ebcb9b83489686f5c2da67dc9e6157e988ad","modified":1632136859588},{"_id":"public/js/local-search.js","hash":"35ccf100d8f9c0fd6bfbb7fa88c2a76c42a69110","modified":1632136859588},{"_id":"public/js/motion.js","hash":"72df86f6dfa29cce22abeff9d814c9dddfcf13a9","modified":1632136859588},{"_id":"public/js/next-boot.js","hash":"a1b0636423009d4a4e4cea97bcbf1842bfab582c","modified":1632136859588},{"_id":"public/js/schemes/muse.js","hash":"1eb9b88103ddcf8827b1a7cbc56471a9c5592d53","modified":1632136859588},{"_id":"public/js/schemes/pisces.js","hash":"0ac5ce155bc58c972fe21c4c447f85e6f8755c62","modified":1632136859588},{"_id":"public/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1632136859588},{"_id":"public/css/main.css","hash":"60ffecc730937d9be20ee51425cff3a595c09523","modified":1632136859588},{"_id":"public/assets/algolia/algoliasearch.js","hash":"6948fcdf071e4983e784e8c458cf201536f77792","modified":1632136859588},{"_id":"public/js/utils.js","hash":"730cca7f164eaf258661a61ff3f769851ff1e5da","modified":1632136859588},{"_id":"public/lib/anime.min.js","hash":"47cb482a8a488620a793d50ba8f6752324b46af3","modified":1632136859588},{"_id":"public/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1632136859588},{"_id":"public/lib/font-awesome/css/all.min.css","hash":"0038dc97c79451578b7bd48af60ba62282b4082b","modified":1632136859588},{"_id":"public/images/ayanami2.png","hash":"d5a65d5094434395ed81dd6f1d130325e1e2a717","modified":1632136859588},{"_id":"public/images/ayanami.png","hash":"791d9c73a9716ac4783aa9319867602a37938887","modified":1632136859588},{"_id":"source/_posts/测试travis-ci自动构建.md","hash":"345d7070d23d24d68fa72daa005d6136e865d063","modified":1632165789972},{"_id":"source/_posts/MySQL学习笔记.md","hash":"86455b107bb965819bf3a3d63b9a951823122a1b","modified":1632205716323},{"_id":"public/2021/09/21/MySQL学习笔记/index.html","hash":"44ea4362cbc7909a9b720dc0ec0ed263e5e74e04","modified":1632326061506},{"_id":"public/categories/测试/index.html","hash":"d51dcec17b5d93b99de10c70c2c9125836b7eaa4","modified":1632206006057},{"_id":"public/categories/mysql/index.html","hash":"393d083f36fa1dbe5bd935d7536b5fbc5540ad10","modified":1632326061506},{"_id":"public/tags/测试/index.html","hash":"83f8a82800ff1e7d0336d5f5645a2e3f29bf8143","modified":1632206006057},{"_id":"public/tags/mysql/index.html","hash":"9bdc0f564152b3607e22c7efa9b5d477163d09c1","modified":1632326061506},{"_id":"public/tags/travis/index.html","hash":"d176640fb2929254d69059bca709598a5250f7af","modified":1632206006057},{"_id":"public/2021/09/21/测试travis-ci自动构建/index.html","hash":"813a671553115e881dad24420065be0d8e4a08ca","modified":1632206006057},{"_id":"source/_posts/RabbitMQ.md","hash":"9f47143dd4c99b48b7c66dc01a66fdd2117b00d7","modified":1632325354738},{"_id":"public/categories/rabbitmq/index.html","hash":"09c593805e2b1eb0b3b260b993943499429561b9","modified":1632326061506},{"_id":"public/tags/八股文/index.html","hash":"c3d3ebba036bfe0f84d8d151c282e2b73081b525","modified":1632326061506},{"_id":"public/tags/rabbitmq/index.html","hash":"fff45b8b742cbccfc6bd6a91cdd2827d9818d1b4","modified":1632326061506},{"_id":"public/2021/09/21/RabbitMQ/index.html","hash":"6a4c6758ad814bd9b5e03f5edb12b3e687d3bbc7","modified":1632326061506},{"_id":"public/tags/mq/index.html","hash":"c3ed16057cf41b66c07cb24d1c229b24bfa321c2","modified":1632326061506},{"_id":"source/_posts/LeetCode刷题指南.md","hash":"9c9fbc22f4fe9895478c27e0e7bd5f0574ad3320","modified":1632320049649},{"_id":"source/_posts/面试八股文（一）——-计算机网络.md","hash":"e9f85f2d98f3887625071ab175753e1a2bbc263e","modified":1632326045181},{"_id":"source/_posts/面试八股文（三）——-数据库.md","hash":"9228c23f2a008ca045a07dfbb38069d0771cb787","modified":1632326059104},{"_id":"source/categories/index-1.md","hash":"9dda432e57e0b6899e96c6e42c7178e99775d5ea","modified":1632320897520},{"_id":"source/_posts/面试八股文（二）——-操作系统.md","hash":"85ebc56f0e969a232bec048fcde60b5bc3e822de","modified":1632326042524},{"_id":"public/categories/index-1.html","hash":"d19cbae8d98e47d055ad23aa10dd5c34c7c66eae","modified":1632326061506},{"_id":"public/categories/leetcode/index.html","hash":"e9c88aa3e2e84a316c08ad93ec1acdca627190a8","modified":1632326061506},{"_id":"public/categories/计算机网络/index.html","hash":"9e0e358da29b759e4154c1fe065fd7bd32839a23","modified":1632326061506},{"_id":"public/categories/八股文/数据库/index.html","hash":"127336e7e8ab61b91b78784d5777536cd8790d70","modified":1632326061506},{"_id":"public/categories/八股文/index.html","hash":"6b29066cf10d67ec1083b706622f454f3fc10ac4","modified":1632326061506},{"_id":"public/categories/计算机网络/八股文/index.html","hash":"5079d7ffb775f444a443893d7c0aacab1dbe1b05","modified":1632326061506},{"_id":"public/categories/八股文/数据库/NoSQL/index.html","hash":"f709fd30b06b034970d2aabb516251d7d46f10ac","modified":1632326061506},{"_id":"public/categories/八股文/操作系统/index.html","hash":"ed0e3d7a15112191494403ae070e99c7ba56cdbc","modified":1632326061506},{"_id":"public/tags/leetcode/index.html","hash":"ef2e6b9842cc877417a38343acf435451e9d35fb","modified":1632326061506},{"_id":"public/tags/算法/index.html","hash":"f73d1918b52a2e29afce84e2b81cc43628c63a70","modified":1632326061506},{"_id":"public/tags/计算机网络/index.html","hash":"a32f9c72d3f6062452f9ac895240c2386996c91e","modified":1632326061506},{"_id":"public/tags/数据库/index.html","hash":"2278f4ffc294d86a7431d14645c0d227747c24db","modified":1632326061506},{"_id":"public/tags/MySQL/index.html","hash":"c660abadc739a3c660e8cb24e6d76850248ce271","modified":1632326061506},{"_id":"public/tags/NoSQL/index.html","hash":"4ddbaf20c435690ac2b30836d5bde63a14fb5f09","modified":1632326061506},{"_id":"public/2021/09/22/面试八股文（三）——-数据库/index.html","hash":"e7d333694eff5eed7fcf5210d9d2fa807b408dde","modified":1632326061506},{"_id":"public/2021/09/22/面试八股文（二）——-操作系统/index.html","hash":"0829a097cfc5fcba25ba19b6af7181e41981e919","modified":1632326061506},{"_id":"public/2021/09/22/面试八股文（一）——-计算机网络/index.html","hash":"d241e97ee3633f6351ad3e6415d93a7e6b74728e","modified":1632326061506},{"_id":"public/2021/09/22/LeetCode刷题指南/index.html","hash":"630852e93c2ef79ce3ecb2c09bee0860e331d3a3","modified":1632326061506},{"_id":"public/tags/操作系统/index.html","hash":"11504492de54e05ab6dcc857dd991b97ce2e0d95","modified":1632326061506}],"Category":[{"name":"测试","_id":"ckttol7ii00014cvu4qyp8aii"},{"name":"mysql","_id":"ckttol7ix00084cvu6wiuaxl6"},{"name":"rabbitmq","_id":"ckttosy8n0001y0vueayl4vhm"},{"name":"leetcode","_id":"cktvosie500022svu3nl8duj9"},{"name":"计算机网络","_id":"cktvosieb000a2svu4bydgrpr"},{"name":"八股文","_id":"cktvosiec000c2svuhze8ajrm"},{"name":"八股文","parent":"cktvosieb000a2svu4bydgrpr","_id":"cktvosied000g2svu7od4ffnn"},{"name":"数据库","parent":"cktvosiec000c2svuhze8ajrm","_id":"cktvosiee000i2svu7m5s0kg8"},{"name":"NoSQL","parent":"cktvosiee000i2svu7m5s0kg8","_id":"cktvosiee000n2svu9t9xgolw"},{"name":"操作系统","parent":"cktvosiec000c2svuhze8ajrm","_id":"cktvosieh000w2svug3i186du"}],"Data":[],"Page":[{"title":"about","date":"2021-09-20T08:00:32.000Z","_content":"","source":"about/index.md","raw":"---\ntitle: about\ndate: 2021-09-20 16:00:32\n---\n","updated":"2021-09-20T08:00:32.760Z","path":"about/index.html","comments":1,"layout":"page","_id":"cktsk596p00000svug5604sts","content":"","site":{"data":{}},"length":0,"excerpt":"","more":""},{"title":"categories","date":"2021-09-20T07:42:26.000Z","type":"categories","comments":0,"_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2021-09-20 15:42:26\ntype: \"categories\"\ncomments: false\n---\n","updated":"2021-09-20T07:42:50.519Z","path":"categories/index.html","layout":"page","_id":"cktsk596u00020svugakkaos4","content":"","site":{"data":{}},"length":0,"excerpt":"","more":""},{"title":"tags","date":"2021-09-20T07:41:07.000Z","type":"tags","comments":0,"_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2021-09-20 15:41:07\ntype: \"tags\"\ncomments: false\n---\n","updated":"2021-09-20T07:41:56.567Z","path":"tags/index.html","layout":"page","_id":"cktsk596v00030svu9gvrdrov","content":"","site":{"data":{}},"length":0,"excerpt":"","more":""},{"title":"categories","date":"2021-09-22T14:28:17.000Z","_content":"","source":"categories/index-1.md","raw":"---\ntitle: categories\ndate: 2021-09-22 22:28:17\n---\n","updated":"2021-09-22T14:28:17.520Z","path":"categories/index-1.html","comments":1,"layout":"page","_id":"cktvosidz00002svu8cv06fak","content":"","site":{"data":{}},"length":0,"excerpt":"","more":""}],"Post":[{"title":"MySQL学习笔记","date":"2021-09-21T06:11:01.000Z","updated":"2021-09-21T06:11:03.000Z","description":"mysql学习笔记，从语雀迁移到hexo。","_content":"\n### 一条SQL查询语句是如何执行的\n\n\n```sql\nmysql> select * from T where ID=10；\n```\n\n\n![](https://img-blog.csdnimg.cn/20190410210326412.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=Mnrxq&originHeight=798&originWidth=1086&originalType=binary&ratio=1&status=done&style=none)\n\n\n> 大体来说，MySQL可以分为`Server`层和`存储引擎`层两部分\n\n\n\n- `Server`层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖MySQL的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。\n- `存储引擎层`负责数据的存储和提取。其架构模式是插件式的，支持InnoDB、MyISAM、Memory等多个存储引擎。现在最常用的存储引擎是InnoDB，它从MySQL 5.5.5版本开始成为了默认存储引擎。\n- 不同的存储引擎共用一个Server层，也就是从连接器到执行器的部分\n-\n\n\n\n\n**连接器**\n\n\n- 第一步，你会先连接到这个数据库上，这时候接待你的就是连接器。连接器负责跟客户端建立连接、获取权限、维持和管理连接。连接完成后，如果你没有后续的动作，这个连接就处于空闲状态，你可以在`show processlist`命令中看到它。客户端如果太长时间没动静，连接器就会自动将它断开。这个时间是由参数`wait_timeout`控制的，默认值是`8`小时。数据库里面，长连接是指连接成功后，如果客户端持续有请求，则一直使用同一个连接。短连接则是指每次执行完很少的几次查询就断开连接，下次查询再重新建立一个。\n\n\n\n**查询缓存**\n\n\n- 连接建立完成后，你就可以执行select语句了。执行逻辑就会来到第二步：查询缓存。\n- MySQL拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。之前执行过的语句及其结果可能会以key-value对的形式，被直接缓存在内存中。key是查询的语句，value是查询的结果。如果你的查询能够直接在这个缓存中找到key，那么这个value就会被直接返回给客户端。\n- 如果语句不在查询缓存中，就会继续后面的执行阶段。执行完成后，执行结果会被存入查询缓存中。\n\n\n\n> 大多数情况下我会建议你不要使用查询缓存，为什么呢？因为查询缓存往往弊大于利。查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。\n\n\n\n**分析器**\n\n\n- 如果没有命中查询缓存，就要开始真正执行语句了。首先，MySQL需要知道你要做什么，因此需要对SQL语句做解析。分析器先会做`“词法分析”`,词法分析完后就要做`“语法分析”`。根据词法分析的结果，语法分析器会根据语法规则，判断你输入的这个SQL语句是否满足MySQL语法。如果你的语句不对，就会收到“You have an error in your SQL syntax”的错误提醒\n\n\n\n**优化器**\n\n\n- 经过了分析器，MySQL就知道你要做什么了。在开始执行之前，还要先经过优化器的处理。\n- 优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。\n\n\n\n> 比如你执行下面这样的语句，这个语句是执行两个表的join：\n`mysql> select * from t1 join t2 using(ID) where t1.c=10 and t2.d=20;`\n既可以先从表t1里面取出c=10的记录的ID值，再根据ID值关联到表t2，再判断t2里面d的值是否等于20。\n也可以先从表t2里面取出d=20的记录的ID值，再根据ID值关联到t1，再判断t1里面c的值是否等于10。\n这两种执行方法的逻辑结果是一样的，但是执行的效率会有不同，而优化器的作用就是决定选择使用哪一个方案。\n\n\n\n**执行器**\n\n\n- MySQL通过分析器知道了你要做什么，通过优化器知道了该怎么做，于是就进入了执行器阶段，开始执行语句。\n- 开始执行的时候，要先判断一下你对这个表T有没有执行查询的权限，如果没有，就会返回没有权限的错误\n- 如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。\n\n\n\n> `mysql> select * from T where ID=10;`\n比如我们这个例子中的表T中，ID字段没有索引，那么执行器的执行流程是这样的：\n调用InnoDB引擎接口取这个表的第一行，判断ID值是不是10，如果不是则跳过，如果是则将这行存在结果集中；\n调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。\n执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。\n\n\n\n- 至此，这个整个语句就执行完成了。一条查询语句的执行过程一般是经过连接器、分析器、优化器、执行器等功能模块，最后到达存储引擎。\n\n\n\n### 一条SQL更新语句是如何执行的\n\n\n```sql\nupdate T set c=c+1 where ID=2;\n```\n\n\n- 与查询流程不一样的是，更新流程还涉及两个重要的日志模块 `redo log`（重做日志）和 `binlog`（归档日志）\n- 每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程IO成本、查找成本都很高。为了解决这个问题，MySQL的设计者WAL技术，WAL的全称是Write-Ahead Logging，它的关键点就是`先写日志`，`再写磁盘`\n- 当有一条记录需要更新的时候，InnoDB引擎就会先把记录写到redo log里面，并更新内存，这个时候更新就算完成了。\n- 同时，`InnoDB`引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做。但是`InnoDB`的`redo log`是固定大小的，比如可以配置为一组4个文件，每个文件的大小是1GB,总共就可以记录4GB的操作。从头开始写，写到末尾就又回到开头循环写。\n- 在进行`redo log`写入时，有两个重要参数的write pos(当前记录的位置),`checkpoint`是当前要擦除的位置\n  ![](https://img-blog.csdnimg.cn/20190410230340406.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=evnl5&originHeight=272&originWidth=884&originalType=binary&ratio=1&status=done&style=none)\n- 一边写一边后移，写到第3号文件末尾后就回到0号文件开头,checkpoint也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。write pos和checkpoint之间还空着的部分，可以用来记录新的操作。\n- 如果`write pos`追上`checkpoin`，表示`redo log`满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把checkpoint推进一下。\n- 有了redo log，InnoDB就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为crash-safe(崩溃安全()。\n- redo log是InnoDB引擎特有的日志，而Server层也有自己的日志，称为binlog（归档日志）\n- 最开始MySQL里并没有`InnoDB引擎`。MySQL自带的引擎是MyISAM，但是MyISAM没有crash-safe的能力，binlog日志只能用于归档。而InnoDB是另一个公司以插件形式引入MySQL的，既然只依靠binlog是没有crash-safe能力的，所以InnoDB使用另外一套日志系统——也就是redo log来实现crash-safe能力。\n\n\n\n> `redo log是InnoDB引擎特有的`；binlog是MySQL的Server层实现的，所有引擎都可以使用。\n`redo log是物理日志`，记录的是“在某个数据页上做了什么修改”；`binlog是逻辑日志`，记录的是这个语句的原始逻辑，比如“给ID=2这一行的c字段加1 ”。\nr`edo log是循环写的`，`空间固定`会用完；`binlog是可以追加写入的`。“追加写”是指binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。\n\n\n\n**执行器和InnoDB引擎在执行这个简单的update语句时的内部流程:**\n\n\n- 执行器先找引擎取ID=2这一行。ID是主键，引擎直接用树搜索找到这一行。如果ID=2这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。\n- 执行器拿到引擎给的行数据，把这个值加上1，比如原来是N，现在就是N+1，得到新的一行数据，再调用引擎接口写入这行新数据。\n- 引擎将这行新数据更新到内存中，同时将这个更新操作记录到redo log里面，此时redo log处于prepare状态。然后告知执行器执行完成了，随时可以提交事务。\n- 执行器生成这个操作的binlog，并把binlog写入磁盘。\n- 执行器调用引擎的提交事务接口，引擎把刚刚写入的redo log改成提交（commit）状态，更新完成。\n- redo log的写入拆成了两个步骤：prepare和commit，这就是`\"两阶段提交\"`。\n\n\n\n![](https://img-blog.csdnimg.cn/2019041023325625.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=tDmdi&originHeight=1522&originWidth=1142&originalType=binary&ratio=1&status=done&style=none)\n\n\n> `1 prepare阶段 2 写binlog 3 commit` , 当在`2之前崩溃时`,重启恢复：后发现没有commit，回滚。备份恢复：没有binlog 。\n`当在3之前崩溃`,重启恢复：虽没有commit，但满足prepare和binlog完整，所以重启后会自动commit。备份：有binlog. 一致\n\n\n\n#### 总结\n\n\n- Redo log不是记录数据页“更新之后的状态”，而是记录这个页 “做了什么改动”。\n- Binlog有两种模式，statement 格式的话是记sql语句， row格式会记录行的内容，记两条，更新前和更新后都有。\n\n\n\n### 事务隔离：为什么你改了我还看不见\n\n\n- 事务就是要保证一组数据库操作，要么全部成功，要么全部失败。在MySQL中，事务支持是在引擎层实现的。MySQL默认的`MyISAM`引擎就不支持事务，这也是`MyISAM`被`InnoDB`取代的重要原因之一。\n- 事务的特性：`ACID`即原子性、一致性、隔离性、持久性。多个事务同时执行的时候，就可能出现`脏读`，`不可重复读`，`幻读`，为了解决这些问题，就有了“`隔离级别`”的概念。但是隔离得越严实，效率就会越低\n- SQL标准的事务隔离级别包括：`读未提交`（read uncommitted）、`读提交`（read committed）、`可重复读`（repeatable read）和`串行化`（serializable ）\n\n\n\n> 读未提交是指，一个事务还没提交时，它做的变更就能被别的事务看到。\n读提交是指，一个事务提交之后，它做的变更才会被其他事务看到。\n可重复读是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。未提交的更改对其他事务是不可见的\n串行化:对应一个记录会加读写锁，出现冲突的时候，后访问的事务必须等前一个事务执行完成才能继续执行\n\n\n\n- 在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。在“`可重复读`”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。在`“读提交”`隔离级别下，这个视图是在每个SQL语句开始执行的时候创建的。`“读未提交”`隔离级别下直接返回记录上的最新值，没有视图概念。`串行化`”隔离级别下直接用加锁的方式来避免并行访问\n- 查看数据库的实物隔离级别：`show variables like '%isolation%';`\n- 事务隔离的实现：在MySQL中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。\n\n\n\n假设一个值从1被按顺序改成了2、3、4，在回滚日志里面就会有类似下面的记录。不同时刻启动的事务会有不同的read-view，同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（`MVCC`）\n![](https://img-blog.csdnimg.cn/20190411130916709.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=AC58n&originHeight=407&originWidth=973&originalType=binary&ratio=1&status=done&style=none)\n\n\n- 回滚日志总不能一直保留吧，什么时候删除呢？答案是，在不需要的时候才删除。系统会判断，当没有事务再需要用到这些回滚日志时，回滚日志会被删除。什么时候才不需要了呢？就是当系统里没有比这个回滚日志更早的read-view的时候。\n- 为什么尽量不要使用长事务。长事务意味着系统里面会存在很老的事务视图，在这个事务提交之前，回滚记录都要保留，这会导致大量占用存储空间。除此之外，长事务还占用锁资源，可能会拖垮库。\n- 事务启动方式：一、显式启动事务语句，`begin`或者`start transaction`,提交`commit`，回滚`rollback`；二、`set autocommit=0`，该命令会把这个线程的自动提交关掉。这样只要执行一个select语句，事务就启动，并不会自动提交，直到主动执行`commit`或`rollback`或断开连接。\n- 建议使用方法一，如果考虑多一次交互问题，可以使用`commit work and chain`语法。在`autocommit=1`的情况下用`begin`显式启动事务，如果执行`commit`则提交事务。如果执行`commit work and chain`则提交事务并自动启动下一个事务\n\n\n\n### 深入浅出索引（上）\n\n\n**索引的常见模型**\n\n\n- 索引的出现是为了提高查询效率，常见的三种索引模型分别是`哈希表`、`有序数组`和`搜索树`\n- `哈希表`：一种以`key-value` 存储数据的结构，哈希的思路是把值放在数组里，用一个哈希函数把`key`换算成一个确定的位置，然后把`value`放在数组的这个位置。哈希冲突的处理办法是使用`链表`。哈希表适用只有`等值查询`的场景\n- `有序数组`：按顺序存储。查询用二分法就可以快速查询，时间复杂度是：O(log(N))。查询效率高，更新效率低（涉及到移位）。在等值查询和范围查询场景中的性能就都非常优秀。有序数组索引只适用于静态存储引擎。\n- 二叉搜索树：每个节点的左儿子小于父节点，右儿子大于父节点。查询时间复杂度O(log(N))，更新时间复杂度O(log(N))。数据库存储大多不适用二叉树，因为树高过高，会适用N叉树\n\n\n\n**InnoDB 的索引模型**\n\n\n- `InnoDB`使用了`B+树`索引模型，所以数据都是存储在B+树中的。每一个索引在`InnoDB`里面对应一棵B+树。\n- 索引类型分为`主键索引`和`非主键索引`。主键索引的叶子节点存的是整行数据。在InnoDB里，主键索引也被称为`聚簇索引`。非主键索引的叶子节点内容是主键的值。在InnoDB里，非主键索引也被称为`二级索引`\n\n\n\n![](https://img-blog.csdnimg.cn/20190411164702315.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=GPjHM&originHeight=424&originWidth=1004&originalType=binary&ratio=1&status=done&style=none)\n\n\n**主键索引和普通索引的查询有什么区别？**\n\n\n- 如果语句是`select * from T where ID=500`，即主键查询方式，则只需要搜索ID这棵B+树；\n- 如果语句是`select * from T where k=5`，即普通索引查询方式，则需要先搜索k索引树，得到ID的值为500，再到ID索引树搜索一次。这个过程称为`回表`。\n- 基于非主键索引的查询需要多扫描一棵索引树。因此，我们在应用中应该尽量使用主键查询\n\n\n\n**索引维护**\n\n\n- `B+树`为了维护索引有序性，在插入新值的时候需要做必要的维护。涉及到数据的移动和数据页的增加和删减\n- 一个数据页满了，按照B+Tree算法，新增加一个数据页，叫做`页分裂`，会导致性能下降。空间利用率降低大概50%。当相邻的两个数据页利用率很低的时候会做`数据页合并`，合并的过程是分裂过程的`逆过程`。\n\n\n\n#### 总结\n\n\n- 索引可能因为删除，或者页分裂等原因，导致数据页有空洞，重建索引的过程会创建一个新的索引，把数据按顺序插入，这样页面的利用率最高，也就是索引更紧凑、更省空间。\n\n\n\n> `alter table T drop index k`;     alter table T add index(k);\n要重建主键索引\n`alter table T drop primary key`;      `alter table T add primary key(id)`;\n重建索引k的做法是合理的，可以达到省空间的目的。但是，重建主键的过程不合理。不论是删除主键还是创建主键，都会将整个表重建。所以连着执行这两个语句的话，第一个语句就白做了。\n可以用这个语句代替 ： alter table T engine=InnoDB\n\n\n\n### 深入浅出索引（下）\n\n\n```sql\nmysql> create table T (\nID int primary key,\nk int NOT NULL DEFAULT 0, \ns varchar(16) NOT NULL DEFAULT '',\nindex k(k))\nengine=InnoDB;\n\ninsert into T values(100,1, 'aa'),(200,2,'bb'),(300,3,'cc'),(500,5,'ee'),(600,6,'ff'),(700,7,'gg');\n```\n\n\n![](https://img-blog.csdnimg.cn/20190411193509228.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=iQfIH&originHeight=441&originWidth=989&originalType=binary&ratio=1&status=done&style=none)\n如果我执行 `select * from T where k between 3 and 5`，需要执行几次树的搜索操作，会扫描多少行？\n\n\n**SQL查询语句的执行流程：**\n\n\n- 在k索引树上找到k=3的记录，取得 ID = 300；\n- 再到ID索引树查到ID=300对应的R3；\n- 在k索引树取下一个值k=5，取得ID=500；\n- 再回到ID索引树查到ID=500对应的R4；\n- 在k索引树取下一个值k=6，不满足条件，循环结束。\n- 在这个过程中，回到主键索引树搜索的过程，我们称为回表。可以看到，这个查询过程读了k索引树的3条记录，回表了两次。在这个例子中，由于查询结果所需要的数据只在主键索引上有，所以不得不回表。\n\n\n\n**优化方式**\n\n\n- sql语句修改为`select ID from T where k between 3 and 5`，这时只需要查ID的值，而ID的值已经在k索引树上了，因此可以直接提供查询结果，不需要回表。也就是说，在这个查询里面，索引k已经“覆盖了”我们的查询需求，我们称为`覆盖索引`。\n- 由于`覆盖索引`可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。\n\n\n\n#### 总结\n\n\n- `覆盖索引`：如果查询条件使用的是普通索引（或是联合索引的最左原则字段），查询结果是联合索引的字段或是主键，不用回表操作，直接返回结果，减少IO磁盘读写读取正行数据\n- `最左前缀`：联合索引的最左 N 个字段，也可以是字符串索引的最左 M 个字符\n- `联合索引`：根据创建联合索引的顺序，以最左原则进行where检索，比如（age，name）以age=1 或 age= 1 and name=‘张三’可以使用索引，单以name=‘张三’ 不会使用索引，考虑到存储空间的问题，还请根据业务需求，将查找频繁的数据进行靠左创建索引。\n- 索引下推：`like 'hello%’and age >10` 检索，MySQL5.6版本之前，会对匹配的数据进行回表查询。5.6版本后，会先过滤掉age<10的数据，再进行回表查询，减少回表率，提升检索速度\n\n\n\n### 讲全局锁和表锁：给表加个字段怎么有这么多阻碍\n\n\n> 根据加锁的范围，MySQL里面的锁大致可以分成全局锁、表级锁和行锁三类\n\n\n\n**全局锁**\n\n\n- 对整个数据库实例加锁。MySQL提供加全局读锁的方法：`Flush tables with read lock(FTWRL)`。这个命令可以使整个库处于只读状态。使用该命令之后，数据更新语句、数据定义语句和更新类事务的提交语句等操作都会被阻塞。使用场景：`全库逻辑备份`。\n- 风险是如果在主库备份，在备份期间不能更新，业务停摆。如果在从库备份，备份期间不能执行主库同步的binlog，导致主从延迟。官方自带的逻辑备份工具`mysqldump`，当mysqldump使用参数`--single-transaction`的时候，会启动一个事务，确保拿到一致性视图。而由于`MVCC`的支持，这个过程中数据是可以正常更新的。\n- 一致性读是好，但是前提是引擎要支持这个隔离级别。如果要全库只读，为什么不使用`set global readonly=true`的方式？在有些系统中，`readonly`的值会被用来做其他逻辑，比如判断主备库。所以修改global变量的方式影响太大。\n- 在异常处理机制上有差异。如果执行`FTWRL`命令之后由于客户端发生异常断开，那么MySQL会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为`readonly`之后，如果客户端发生异常，则数据库就会一直保持`readonly`状态，这样会导致整个库长时间处于不可写状态，风险较高。\n\n\n\n**表级锁**\n\n\n- MySQL里面表级锁有两种，一种是表锁，一种是元数据所(meta data lock,MDL)。表锁的语法是:l`ock tables ... read/write`\n- 可以用`unlock tables`主动释放锁，也可以在客户端断开的时候自动释放。`lock tables`语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。\n- 对于`InnoDB`这种支持`行锁`的引擎，一般不使用`lock tables`命令来控制并发，毕竟锁住整个表的影响面还是太大。\n- 另一类表级的锁是`MDL`（metadata lock)。`MDL不需要显式使用`，在访问一个表的时候会被`自动加上`。MDL的作用是，`保证读写的正确性`。当对一个表做增删改查操作的时候，加`MDL读锁`；当要对表做结构变更操作的时候，加`MDL写锁`。`读锁之间不互斥`，因此你可以有多个线程同时对一张表增删改查。`读写锁之间、写锁之间是互斥的`，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。\n- `MDL` 会直到事务提交才会释放，在做表结构变更的时候，一定要小心不要导致锁住线上查询和更新。\n\n\n\n**如何安全地给表加字段**\n\n\n- 给一个表加字段，或者修改字段，或者加索引，需要扫描全表的数据。首先我们要解决长事务，事务不提交，就会一直占着MDL锁。在MySQL的`information_schema` 库的 `innodb_trx` 表中，你可以查到当前执行中的事务。如果你要做`DDL`变更的表刚好有`长事务`在执行，要考虑先暂停DDL，或者`kill`掉这个长事务。\n- 如果你要变更的表是一个`热点表`，虽然数据量不大，但是上面的请求很频繁，这时候kill可能未必管用，因为新的请求马上就来了。比较理想的机制是，在`alter table`语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到`MDL写锁`最好，拿不到也不要阻塞后面的业务语句，先放弃。之后开发人员或者DBA再通过重试命令重复这个过程。\n\n\n\n### 讲行锁功过：怎么减少行锁对性能的影响\n\n\n- MySQL的`行锁`是在引擎层由各个`引擎自己实现`的。但并不是所有的引擎都支持行锁，比`如MyISAM引擎就不支持行锁`。不支持行锁意味着并发控制只能使用表锁，对于这种引擎的表，同一张表上任何时刻只能有一个更新在执行，这就会影响到业务并发度。`InnoDB是支持行锁`的，这也是`MyISAM`被`InnoDB`替代的重要原因之一。\n- `两阶段锁协议`：在`InnoDB`事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。\n- `死锁`：当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁\n\n\n\n![](https://img-blog.csdnimg.cn/20190412161554856.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=Enkur&originHeight=585&originWidth=948&originalType=binary&ratio=1&status=done&style=none)\n\n\n- `事务A`在等待`事务B`释放id=2的行锁，而`事务B在等待事务A`释放id=1的行锁。 事务A和事务B在互相等待对方的资源释放，就是进入了`死锁状态`\n\n\n\n**出现死锁以后，有两种策略：**\n\n\n- 一种策略是，`直接进入等待，直到超时`。这个超时时间可以通过参数`innodb_lock_wait_timeout`来设置。在InnoDB中，默认值是`50s`\n- 另一种策略是，`发起死锁检测`，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数`innodb_deadlock_detect设置为on`，表示开启这个逻辑。默认值本身就是on\n- 正常情况下选择第二种策略，但是它也是有额外负担的，如果瞬间有大量线程请求会消耗消耗大量的CPU资源，但是每秒却执行不了几个事务，因为每次都要检测。\n\n\n\n**怎么解决由这种热点行更新导致的性能问题?**\n\n\n- 问题的症结在于，死锁检测要耗费大量的CPU资源\n- 如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉。 一般不建议采用\n- 控制并发度，对应相同行的更新，在进入引擎之前排队。这样在InnoDB内部就不会有大量的死锁检测工作了。\n- 将热更新的行数据拆分成逻辑上的多行来减少锁冲突，但是业务复杂度可能会大大提高。\n- `innodb行级锁是通过锁索引记录实现的，如果更新的列没建索引是会锁住整个表的。`\n\n\n\n#### 小结\n\n\n如果你要删除一个表里面的前10000行数据，有以下三种方法可以做到：\n\n\n- 第一种，直接执行\t `delete from T limit 10000;`\n- 第二种，在一个连接中循环执行20次 `delete from T limit 500;`\n- 第三种，在20个连接中同时执行\t`delete from T limit 500`\n\n\n\n**三种方案分析**\n\n\n- 方案一，事务相对较长，则占用锁的时间较长，会导致其他客户端等待资源时间较长。\n- 方案二，串行化执行，将相对长的事务分成多次相对短的事务，则每次事务占用锁的时间相对较短，其他客户端在等待相应资源的时间也较短。这样的操作，同时也意味着将资源分片使用（每次执行使用不同片段的资源），可以提高并发性。\n- 方案三，人为自己制造锁竞争，加剧并发量。\n\n\n\n### 事务到底是隔离的还是不隔离的\n\n\n- `innodb`支持`RC(读提交)`和`RR(可重复读)`隔离级别实现是用的一致性视图(consistent read view)\n- .事务在启动时会拍一个快照,这个快照是基于整个库的。基于整个库的意思就是说一个事务内,整个库的修改对于该事务都是不可见的(对于快照读的情况)。如果在事务内`select t`表,另外的事务执行了`DDL t`表,根据发生时间,`要吗锁住要嘛报错`\n\n\n\n**事务是如何实现的MVCC呢?**\n\n\n- 每个事务都有一个事务ID,叫做`transaction id`(严格递增)\n- 事务在启动时,找到已提交的最大事务ID记为up_limit_id。\n- 事务在更新一条语句时,比如id=1改为了id=2.会把id=1和该行之前的`row trx_id`写到`undo log`里。并且在数据页上把id的值改为2,并且把修改这条语句的`transaction id`记在该行行头。\n- 再定一个规矩,一个事务要查看一条数据时,必须先用该事务的`up_limit_id`与该行的`transaction id`做比对\n- 如果`up_limit_id>=transaction id`,那么可以看.如果`up_limit_id<transaction id`,则只能去`undo log`里去取。去undo log查找数据的时候,也需要做比对,必须`up_limit_id>transaction id`,才返回数据\n\n\n\n**什么是当前读,**\n\n\n- 由于当前读都是先读后写,只能读当前的值,所以认为当前读.会更新事务内的up_limit_id为该事务的transaction id\n\n\n\n**为什么**`**RR**`**能实现可重复读而**`**RC**`**不能,分两种情况**\n\n\n- 快照读的情况下,rr(可重复读)不能更新事务内的up_limit_id,而`rc(读提交)`每次会把`up_limit_id`更新为快照读之前最新已提交事务的`transaction id`,则`rc(读提交)`不能可重复读\n- 当前读的情况下,`rr(可重复读)`是利用`record lock+gap lock`来实现的,而`rc(读提交)`没有gap,所以rc不能可重复读\n\n\n\n### MySQL为什么有时候会选错索引\n\n\n- 在MySQL中一张表其实是可以支持多个索引的。但是，你写SQL语句的时候，并没有主动指定使用哪个索引。也就是说，使用哪个索引是由MySQL来确定的。所以有时候由于MySQL选错了索引，而导致执行速度变得很慢\n\n\n\n测试代码\n\n\n```sql\nCREATE TABLE `t` (\n  `id` int(11) NOT NULL,\n  `a` int(11) DEFAULT NULL,\n  `b` int(11) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  KEY `a` (`a`),\n  KEY `b` (`b`)\n) ENGINE=InnoDB；\n```\n\n\n然后，我们往表t中插入10万行记录，取值按整数递增，即：(1,1,1)，(2,2,2)，(3,3,3) 直到(100000,100000,100000)。\n\n\n分析一条SQL语句：\n\n\n```sql\nmysql> select * from t where a between 10000 and 20000;\n```\n\n\n正常情况下，a上有索引，肯定是要使用索引a的。\n\n\n![](https://img-blog.csdnimg.cn/20190414141306715.png#id=OG5aI&originHeight=97&originWidth=1077&originalType=binary&ratio=1&status=done&style=none)\n但是特许情况下如果同时有两个以下下操作执行：\n\n\n- 如果一个A请求首先开启了事物，随后，B请求把数据都删除后，又插入了10万行数据。\n- 这时候， B操作的查询语句`select * from t where a between 10000 and 20000`就不会再选择索引a了，会执行全表扫描，执行时间会比之前慢很多。`为什么会出现这样情况？`因为选择索引是优化器的工作，而优化器选择索引的目的，是找到一个最优的执行方案，并用最小的代价去执行语句。\n- MySQL在真正开始执行语句之前，并不能精确地知道满足这个条件的记录有多少条，而只能根据统计信息来估算记录数。这个统计信息就是索引的“`区分度`”。一个索引上不同的值越多，这个索引的区分度就越好。而一个索引上不同的值的个数，我们称之为`“基数”`（cardinality）。也就是说，这个基数越大，索引的区分度越好。\n- 可以使用`show index table`方法，看到一个索引的基数\n- MySQL是怎样得到索引的基数的呢？MySQL通过采样统计的方法得到基数\n- 如果使用索引a，每次从索引a上拿到一个值，都要回到主键索引上查出整行数据，这个代价优化器也要算进去的。而如果选择扫描10万行，是直接在主键索引上扫描的，没有额外的代价。优化器会估算这两个选择的代价，从结果看来，优化器认为直接扫描主键索引更快。当然，从执行时间看来，这个选择并不是最优的。\n- `analyze table t` 命令可以用来重新统计索引信息\n- 采用`force index`强行选择一个索引。如果force index指定的索引在候选索引列表中，就直接选择这个索引，不再评估其他索引的执行代价。\n\n\n\n![](https://img-blog.csdnimg.cn/20190414141504344.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=LVEvh&originHeight=321&originWidth=921&originalType=binary&ratio=1&status=done&style=none)\n\n\n```sql\nset long_query_time=0;\nselect * from t where a between 10000 and 20000; /*Q1*/\nselect * from t force index(a) where a between 10000 and 20000;/*Q2*/\n\n第一句，是将慢查询日志的阈值设置为0，表示这个线程接下来的语句都会被记录入慢查询日志中；\n第二句，Q1是session B原来的查询；\n第三句，Q2是加了force index(a)来和session B原来的查询语句执行情况对比。\n```\n\n\n- delete 语句删掉了所有的数据，然后再通过call idata()插入了10万行数据，看上去是覆盖了原来的10万行。\n- 但是，session A开启了事务并没有提交，所以之前插入的10万行数据是不能删除的。这样，之前的数据每一行数据都有两个版本，旧版本是delete之前的数据，新版本是标记为deleted的数据。这样，索引a上的数据其实就有两份\n\n\n\n### 怎么给字符串字段加索引\n\n\n- 假设，你现在维护一个支持邮箱登录的系统，用户表是这么定义的：\n\n\n\n```sql\nmysql> create table SUser(\nID bigint unsigned primary key,\nemail varchar(64), \n... \n)engine=innodb;\n```\n\n\n由于要使用邮箱登录，所以业务代码中一定会出现类似于这样的语句：\n\n\n```sql\nmysql> select f1, f2 from SUser where email='xxx';\n```\n\n\n- 如果email这个字段上没有索引，那么这个语句就只能做全表扫描。同时，MySQL是支持前缀索引的，也就是说，你可以定义字符串的一部分作为索引。默认地，如果你创建索引的语句不指定前缀长度，那么索引就会包含整个字符串。\n\n\n\n比如，这两个在email字段上创建索引的语句：\n\n\n```sql\nmysql> alter table SUser add index index1(email);\n或\nmysql> alter table SUser add index index2(email(6));\n```\n\n\n![](https://img-blog.csdnimg.cn/201904142351118.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=FFfQd&originHeight=468&originWidth=1000&originalType=binary&ratio=1&status=done&style=none)\n![](https://img-blog.csdnimg.cn/20190414235147183.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=XF7LV&originHeight=449&originWidth=640&originalType=binary&ratio=1&status=done&style=none)\n\n\n- 第一个语句创建的index1索引里面，包含了每个记录的整个字符串；\n- 第二个语句创建的index2索引里面，对于每个记录都是只取前6个字节。由于email(6)这个索引结构中每个邮箱字段都只取前6个字节,所以占用的空间会更小，这就是使用前缀索引的优势。但是 可能会增加额外的记录扫描次数。\n\n\n\n**使用的是index1的执行流程**\n\n\n- 从`index1`索引树找到满足索引值是’zhangssxyz@xxx.com’的这条记录，取得ID2的值；\n- 到主键上查到主键值是ID2的行，判断email的值是正确的，将这行记录加入结果集；\n- 取index1索引树上刚刚查到的位置的下一条记录，发现已经不满足email='zhangssxyz@xxx.com’的条件了，循环结束\n- 这个过程中，只需要回主键索引取一次数据，所以系统认为只扫描了一行。\n\n\n\n**使用的是index2的执行流程**\n\n\n- 从`index2`索引树找到满足索引值是’zhangs’的记录，找到的第一个是ID1；\n- 到主键上查到主键值是ID1的行，判断出email的值不是’zhangssxyz@xxx.com’，这行记录丢弃；\n- 取index2上刚刚查到的位置的下一条记录，发现仍然是’zhangs’，取出ID2，再到ID索引上取整行然后判断，这次值对了，将这行记录加入结果集；\n- 重复上一步，直到在idxe2上取到的值不是’zhangs’时，循环结束。\n- 在这个过程中，要回主键索引取4次数据，也就是扫描了4行。\n- 但是  对于这个查询语句来说，如果你定义的`index2`不是email(6)而是email(7），也就是说取email字段的前7个字节来构建索引的话，即满足前缀’zhangss’的记录只有一个，也能够直接查到ID2，只扫描一行就结束了。\n- 也就是说`使用前缀索引，定义好长度，就可以做到既节省空间，又不用额外增加太多的查询成本`。\n\n\n\n**前缀索引对覆盖索引的影响**\n\n\n- 使用前缀索引可能会增加扫描行数，这会影响到性能。其实，前缀索引的影响不止如此\n\n\n\n```sql\n#查询1 \nselect id,email from SUser where email='zhangssxyz@xxx.com';\n# 查询2\nselect id,name,email from SUser where email='zhangssxyz@xxx.com';\n```\n\n\n- 如果使用index1（即email整个字符串的索引结构）的话，可以利用覆盖索引，从index1查到结果后直接就返回了，不需要回到ID索引再去查一次。而如果使用index2（即email(6)索引结构）的话，就不得不回到ID索引再去判断email字段的值。\n- 即使你将index2的定义修改为email(18)的前缀索引，这时候虽然index2已经包含了所有的信息，但InnoDB还是要回到id索引再查一下，因为系统并不确定前缀索引的定义是否截断了完整信息。\n- 使用前缀索引就用不上覆盖索引对查询性能的优化了\n\n\n\n#### 小结\n\n\n对于类似于邮箱这样的字段来说，使用前缀索引的效果可能还不错。但是，遇到前缀的区分度不够好的情况时。比如，我们国家的身份证号，一共18位，其中前6位是地址码，所以同一个县的人的身份证号前6位一般会是相同的。\n\n\n假设你维护的数据库是一个市的公民信息系统，这时候如果对身份证号做长度为6的前缀索引的话，这个索引的区分度就非常低了。可能你需要创建长度为12以上的前缀索引，才能够满足区分度要求。但是，`索引选取的越长，占用的磁盘空间就越大，相同的数据页能放下的索引值就越少，搜索的效率也就会越低`。\n\n\n那么，如果我们能够确定业务需求里面只有按照身份证进行等值查询的需求，还有没有别的处理方法呢？这种方法，既可以占用更小的空间，也能达到相同的查询效率。\n\n\n第一种方式是使用`倒序存储`。如果你存储身份证号的时候把它倒过来存，每次查询的时候，你可以这么写：\n\n\n```sql\nmysql> select field_list from t where id_card = reverse('input_id_card_string');\n```\n\n\n由于身份证号的最后6位没有地址码这样的重复逻辑，所以最后这6位很可能就提供了足够的区分度。\n\n\n第二种方式是`使用hash字段`。你可以在表上再创建一个整数字段，来保存身份证的校验码，同时在这个字段上创建索引。\n\n\n```sql\nmysql> alter table t add id_card_crc int unsigned, add index(id_card_crc);\n```\n\n\n然后每次插入新记录的时候，都同时用crc32()这个函数得到校验码填到这个新字段。由于校验码可能存在冲突，也就是说两个不同的身份证号通过crc32()函数得到的结果可能是相同的，所以你的查询语句where部分要判断id_card的值是否精确相同。\n\n\n```sql\nmysql> select field_list from t where id_card_crc=crc32('input_id_card_string') and id_card='input_id_card_string'\n```\n\n\n这样，索引的长度变成了4个字节，比原来小了很多。\n\n\n**使用倒序存储和使用hash字段这两种方法的异同点**\n\n\n- 首先，它们的相同点是，都不支持范围查询。\n- `从占用的额外空间来看`，倒序存储方式在主键索引上，不会消耗额外的存储空间，而hash字段方法需要增加一个字段\n- `在CPU消耗方面`，倒序方式每次写和读的时候，都需要额外调用一次reverse函数，而hash字段的方式需要额外调用一次crc32()函数\n- `从查询效率上看`，使用hash字段方式的查询性能相对更稳定一些。因为crc32算出来的值虽然有冲突的概率，但是概率非常小，可以认为每次查询的平均扫描行数接近1。而倒序存储方式毕竟还是用的前缀索引的方式，也就是说还是会增加扫描行数。\n\n\n\n**字符串字段创建索引的场景你可以使用的方式有：**\n\n\n- 直接创建完整索引，这样可能比较占用空间；\n- 创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引；\n- 倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题；\n- 创建hash字段索引，查询性能稳定，有额外的存储和计算消耗，跟第三种方式一样，都不支持范围扫描。\n\n\n\n**利用学号作为登录名索引设计问题？**\n\n\n> 如果你在维护一个学校的学生信息数据库，学生登录名的统一格式是”学号@gmail.com\", 而学号的规则是：十五位的数字，其中前三位是所在城市编号、第四到第六位是学校编号、第七位到第十位是入学年份、最后五位是顺序编号。\n系统登录的时候都需要学生输入登录名和密码，验证正确后才能继续使用系统。就只考虑登录验证这个行为的话，你会怎么设计这个登录名的索引呢？\n\n\n\n`**设计思路：**`\n\n\n- 由于这个学号的规则，无论是正向还是反向的前缀索引，重复度都比较高。因为维护的只是一个学校的，因此前面6位（其中，前三位是所在城市编号、第四到第六位是学校编号）其实是固定的，邮箱后缀都是@gamil.com，因此可以只存入学年份加顺序编号，它们的长度是9位。\n- 而其实在此基础上，可以用数字类型来存这9位数字。比如201100001，这样只需要占4个字节。其实这个就是一种hash，只是它用了最简单的转换规则：字符串转数字的规则，而刚好我们设定的这个背景，可以保证这个转换后结果的唯一性。\n\n\n\n### 为什么我的MySQL会“抖”一下\n\n\n- 一条SQL语句，正常执行的时候特别快，但是有时也不知道怎么回事，它就会变得特别慢，并且这样的场景很难复现，它不只随机，而且持续时间还很短。看上去，这就像是数据库“抖”了一下\n- 在MySQL里，如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程IO成本、查找成本都很高。为了解决这个问题，MySQL的设计者使用了`WAL技术`，WAL的全称是Write-Ahead Logging，它的关键点就是`先写日志，再写磁盘`。\n- 利用WAL技术，数据库将随机写转换成了顺序写，大大提升了数据库的性能。但是，由此也带来了内存脏页的问题。脏页会被后台线程自动flush，也会由于数据页淘汰而触发flush，而刷脏页的过程由于会占用资源，可能会让你的更新和查询语句的响应时间长一些\n- 当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”。\n- 平时执行很快的更新操作，其实就是在写内存和日志，而MySQL偶尔“抖”一下的那个瞬间，可能就是在刷脏页（`flush`）。\n\n\n\n**什么情况会引发数据库的flush过程呢？**\n\n\n- `InnoDB`在处理更新语句的时候，只做了写日志这一个磁盘操作。这个日志叫作redo log（重做日志）。在更新内存写完`redo log`后，就返回给客户端，本次更新成功。\n- `InnoDB`的`redo log`(重做日志)写满了。这时候系统会停止所有更新操作，把`checkpoint(检查点)`往前推进，`redo log`留出空间可以继续写\n- 第二种场景是：对应的就是系统内存不足。当需要新的内存页，而内存不够用的时候，就要淘汰一些数据页，空出内存给别的数据页使用。如果淘汰的是“脏页”，就要先将脏页写到磁盘。\n- 第三种场景就是`MySQL`认为系统`“空闲”`的时候。也要见缝插针地找时间，只要有机会就刷一点`“脏页”`\n- 第四种场景就是`MySQL正常关闭的情况`。这时候，MySQL会把内存的脏页都flush到磁盘上，这样下次MySQL启动的时候，就可以直接从磁盘上读数据，启动速度会很快。\n\n\n\n**分析一下上面四种场景对性能的影响**\n\n\n- `第一种是“redo log写满了，要flush脏页”`，这种情况是InnoDB要尽量避免的。因为出现这种情况的时候，整个系统就不能再接受更新了，所有的更新都必须堵住。如果你从监控上看，这时候更新数会跌为0。\n- `第二种是“内存不够用了，要先将脏页写到磁盘”`，这种情况其实是常态。InnoDB用缓冲池（buffer pool）管理内存，缓冲池中的内存页有三种状态：第一种是，还没有使用的；第二种是，使用了并且是干净页；第三种是，使用了并且是脏页。InnoDB的策略是尽量使用内存，因此对于一个长时间运行的库来说，未被使用的页面很少。\n- 而当要读入的数据页没有在内存的时候，就必须到缓冲池中申请一个数据页。这时候只能把最久不使用的数据页从内存中淘汰掉：如果要淘汰的是一个干净页，就直接释放出来复用；但如果是脏页呢，就必须将脏页先刷到磁盘，变成干净页后才能复用。\n- 所以，刷脏页虽然是常态，但是出现以下这两种情况，都是会明显影响性能的：一个查询要淘汰的脏页个数太多，会导致查询的响应时间明显变长；日志写满，更新全部堵住，写性能跌为0，这种情况对敏感业务来说，是不能接受的。\n\n\n\n**InnoDB刷脏页的控制策略**\n\n\n- 首先，你要正确地告诉`InnoDB`所在主机的`IO能力`，这样`InnoDB`才能知道需要全力刷脏页的时候，可以刷多快。这就要用到`innodb_io_capacity`这个参数了，它会告诉`InnoDB`你的磁盘能力。这个值我建议你设置成`磁盘的IOPS`。\n- 假设有这样一个场景：`MySQL的写入速度很慢，TPS很低`，但是数据库主机的`IO压力并不大`。主机磁盘用的是SSD，但是`innodb_io_capacity`的值设置的是`300`。于是，InnoDB认为这个系统的能力就这么差，所以刷脏页刷得特别慢，甚至比脏页生成的速度还慢，这样就造成了脏页累积，影响了查询和更新性能。\n- `InnoDB`的刷盘速度就是要参考这两个因素：一个是`脏页比例`，一个是`redo log写盘速度`。\n- 参数`innodb_max_dirty_pages_pct`是`脏页比例上限`，默认值是`75%`。InnoDB会根据当前的脏页比例（假设为M），算出一个范围在0到100之间的数字。`InnoDB`每次写入的日志`都有一个序号`，当前写入的序号跟`checkpoint`对应的序号之间的差值。我们假设为N。InnoDB会根据这个N算出一个范围在0到100之间的数字，这个计算公式可以记为F2(N)。F2(N)算法比较复杂，你只要知道N越大，算出来的值越大就好了。\n- 然后，根据上述算得的F1(M)和F2(N)两个值，取其中较大的值记为R，之后引擎就可以按照`innodb_io_capacity`定义的能力乘以`R%`来控制刷脏页的速度。\n\n\n\n![](https://img-blog.csdnimg.cn/2019041513510966.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=GVQMh&originHeight=1522&originWidth=1142&originalType=binary&ratio=1&status=done&style=none)\n\n\n- InnoDB会在后台刷脏页，而刷脏页的过程是要将内存页写入磁盘。所以，无论是你的查询语句在需要内存的时候可能要求淘汰一个脏页，还是由于刷脏页的逻辑会占用IO资源并可能影响到了你的更新语句，都可能是造成你从业务端感知到MySQL“抖”了一下的原因。\n- 要尽量避免这种情况，你就要合理地设置`innodb_io_capacity的值`，并且平时要多关注脏页比例，不要让它经常接近`75%`。\n\n\n\n> 脏页比例是通过Innodb_buffer_pool_pages_dirty/Innodb_buffer_pool_pages_total得到的\n\n\n\n```sql\nmysql> select VARIABLE_VALUE into @a from global_status where VARIABLE_NAME = 'Innodb_buffer_pool_pages_dirty';\nselect VARIABLE_VALUE into @b from global_status where VARIABLE_NAME = 'Innodb_buffer_pool_pages_total';\nselect @a/@b;\n```\n\n\n- 一旦一个查询请求需要在执行过程中先flush掉一个脏页时，这个查询就可能要比平时慢了。而MySQL中的一个机制，可能让你的查询会更慢：在准备刷一个脏页的时候，如果这个数据页旁边的数据页刚好是脏页，就会把这个“邻居”也带着一起刷掉；而且这个把“邻居”拖下水的逻辑还可以继续蔓延，也就是对于每个邻居数据页，如果跟它相邻的数据页也还是脏页的话，也会被放到一起刷。\n- 在InnoDB中，`innodb_flush_neighbors` 参数就是用来控制这个行为的，`值为1`的时候会有上述的`“连坐”机制`，`值为0时`表示不找邻居，自己刷自己的。\n- 找`“邻居”`这个优化在`机械硬盘时代是很有意义`的，可以`减少很多随机IO`。机械硬盘的随机`IOPS`一般只有几百，相同的逻辑操作减少随机IO就意味着系统性能的大幅度提升。\n- 而如果使用的是`SSD这类IOPS比较高的设备`的话，我就建议你把`innodb_flush_neighbors`的值设置成0。因为这时候`IOPS`往往不是瓶颈，而`“只刷自己”`，就能更快地执行完必要的刷脏页操作，减少SQL语句响应时间。\n- 在MySQL 8.0中`，innodb_flush_neighbors参数的默认值已经是0`了。\n\n\n\n### 为什么表数据删掉一半，表文件大小不变\n\n\n- 一个InnoDB表包含两部分，即：表结构定义和数据。在MySQL 8.0版本以前，表结构是存在以.frm为后缀的文件里。\n- 表数据既可以存在共享表空间里，也可以是单独的文件。这个行为是由参数`innodb_file_per_table`控制的，设置为`OFF`表示的是，表的数据放在`系统共享表空间`，也就是跟数据字典放在一起；设置为`ON`表示的是，每个InnoDB表数据存储在一个以 `.ibd`为后缀的文件中。从`MySQL 5.6.6`版本开始，它的`默认值就是ON`了\n- 建议你不论使用MySQL的哪个版本，都将这个值设置为ON。因为，一个表单独存储为一个文件更容易管理，而且在你不需要这个表的时候，通过`drop table`命令，系统就会直接删除这个文件。而如果是放在共享表空间中，即使表删掉了，空间也是不会回收的。\n- 我们在删除整个表的时候，可以使用drop table命令回收表空间。但是，我们遇到的更多的删除数据的场景是删除某些行，表中的数据被删除了，但是表空间却没有被回收。\n\n\n\n**数据删除流程**\n\n\n![](https://img-blog.csdnimg.cn/20190416104535458.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=roWLU&originHeight=478&originWidth=603&originalType=binary&ratio=1&status=done&style=none)\n\n\n- 假设，我们要删掉R4这个记录，InnoDB引擎只会把R4这个记录标记为删除。如果之后要再插入一个ID在300和600之间的记录时，可能会复用这个位置。但是，磁盘文件的大小并不会缩小。\n- InnoDB的数据是按页存储的，那么如果我们删掉了一个数据页上的所有记录，整个数据页就可以被复用了。\n- 但是，数据页的复用跟记录的复用是不同的。记录的复用，只限于符合范围条件的数据，比如R4这条记录被删除后，如果插入一个ID是400的行，可以直接复用这个空间。但如果插入的是一个ID是800的行，就不能复用这个位置了。\n- 而当整个页从B+树里面摘掉以后，可以复用到任何位置。如果相邻的两个数据页利用率都很小，系统就会把这两个页上的数据合到其中一个页上，另外一个数据页就被标记为可复用。\n- 所以如果我们用delete命令把整个表的数据删除，结果就是，所有的数据页都会被标记为可复用。但是磁盘上，文件不会变小。也就是说，通过delete命令是不能回收表空间的。这些可以复用，而没有被使用的空间，看起来就像是`“空洞”`。\n- 实际上，不止是删除数据会造成空洞，插入数据也会。如果数据是按照索引递增顺序插入的，那么索引是紧凑的。但如果数据是随机插入的，就可能造成索引的数据页分裂。另外，更新索引上的值，可以理解为删除一个旧的值，再插入一个新值。不难理解，这也是会造成空洞的。\n\n\n\n**重建表**\n\n\n- 重建表就是新建一个与表A结构相同的表B，然后按照主键ID递增的顺序，把数据一行一行地从表A里读出来再插入到表B中。由于表B是新建的表，所以表A主键索引上的空洞，在表B中就都不存在了。\n- 可以使用`alter table A engine=InnoDB`命令来重建表。MySQL 5.5之后会自动完成转存数据、交换表名、删除旧表的操作。\n- 重建表的过程中，如果中途有新的数据要写入，就会造成数据丢失。所以在整个`DDL`过程中，表A中不能有更新。也就是说，这个DDL不是`Online`的。在MySQL 5.6版本开始引入的`Online DDL`，对这个操作流程做了优化。\n- 对于很大的表来说，这个操作是很消耗IO和CPU资源的。想要比较安全的操作的话，推荐使用`GitHub`开源的[gh-ost](https://github.com/github/gh-ost)来做。\n\n\n\n**MySQL执行DDL()原理**\n\n\n- `DML`：它们是SELECT、UPDATE、INSERT、DELETE，就象它的名字一样，这4条命令是用来对数据库里的数据进行操作的语言\n- `DDL`：DDL比DML要多，主要的命令有CREATE、ALTER、DROP等，DDL主要是用在定义或改变表(TABLE)的结构，数据类型，表之间的链接和约束等初始化工作上，他们大多在建立表时使用\n- `DCL`：是数据库控制功能。是用来设置或更改数据库用户或角色权限的语句\n- MySQL各版本，对于DDL的处理方式是不同的，主要有三种：\n- `Copy Table`方式：这是InnoDB最早支持的方式。通过临时表拷贝的方式实现的。新建一个带有新结构的临时表，将原表数据全部拷贝到临时表，然后Rename，完成创建操作。这个方式过程中，`原表是可读的，不可写`。但是`会消耗一倍的存储空间`。\n- `Inplace`方式：这是原生MySQL 5.5，以及`innodb_plugin`中提供的方式。所谓Inplace，也就是在`原表上直接进行，不会拷贝临时表`。相对于Copy Table方式，这比较高效率。`原表同样可读的，但是不可写`。\n- `Online方式`：MySQL 5.6以上版本中提供的方式，无论是Copy Table方式，还是Inplace方式，`原表只能允许读取，不可写`。对应用有较大的限制，因此MySQL最新版本中，InnoDB支持了所谓的`Online方式DDL`。与以上两种方式相比，`online方式支持DDL时不仅可以读，还可以写`\n\n\n\n### count(*)语句到底是怎样实现的\n\n\n- 在不同的MySQL引擎中，count(*)有不同的实现方式。\n- `MyISAM引擎`把一个表的总行数存在了磁盘上，因此执行`count(*)`的时候会直接返回这个数，效率很高。这里讨论的是没有过滤条件的count(*)，如果加了where 条件的话，MyISAM表也是不能返回得这么快的。\n- `InnoDB引擎`就麻烦了，它执行count(*)的时候，需要把数据一行一行地从引擎里面读出来，然后累积计数。\n\n\n\n**为什么InnoDB不跟MyISAM一样，也把数字存起来呢？**\n\n\n- 这是因为即使是在同一个时刻的多个查询，由于`多版本并发控制`（MVCC）的原因，InnoDB表“应该返回多少行”也是不确定的。\n- 这和InnoDB的事务设计有关系，`可重复读是它默认的隔离级别`，在代码上就是通过多版本并发控制，也就是MVCC来实现的。每一行记录都要判断自己是否对这个会话可见，因此对于count(*)请求来说，InnoDB只好把数据一行一行地读出依次判断，可见的行才能够用于计算“基于这个查询”的表的总行数。\n- `InnoDB是索引组织表`，`主键索引树的叶子节点是数据`，而`普通索引树的叶子节点是主键值`。所以，普通索引树比主键索引树小很多。对于count(*)这样的操作，遍历哪个索引树得到的结果逻辑上都是一样的。因此，MySQL优化器会找到最小的那棵树来遍历。在保证逻辑正确的前提下，尽量减少扫描的数据量，是数据库系统设计的通用法则之一。\n- MyISAM表虽然count(_)很快，但是不支持事务；show table status命令虽然返回很快，但是不准确；InnoDB表直接count(_)会遍历全表，虽然结果准确，但会导致性能问题。\n\n\n\n### 不同的count用法\n\n\n`select count(?) from t`这样的查询语句里面，`count(*)、count(主键id)、count(字段)和count(1)`等不同用法的性能，有哪些差别。\n\n\n- count()是一个聚合函数，对于返回的结果集，一行行地判断，如果count函数的参数不是NULL，累计值就加1，否则不加。最后返回累计值。\n- 所以，count(*)、count(主键id)和count(1) 都表示返回满足条件的结果集的总行数；而count(字段），则表示返回满足条件的数据行里面，参数“字段”不为NULL的总个数。\n- `对于count(主键id)来说`，InnoDB引擎会遍历整张表，把每一行的id值都取出来，返回给server层。server层拿到id后，判断是不可能为空的，就按行累加。\n- `对于count(1)来说`，InnoDB引擎遍历整张表，但不取值。server层对于返回的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加。\n- `对于count(字段)来说`：如果这个“字段”是定义为not null的话，一行行地从记录里面读出这个字段，判断不能为null，按行累加；如果这个“字段”定义允许为null，那么执行的时候，判断到有可能是null，还要把值取出来再判断一下，不是null才累加。\n- count(_)是例外：并不会把全部字段取出来，而是专门做了优化，不取值。count(_)肯定不是null，按行累加。\n- 所以结论是：按照效率排序的话，count(字段)<count(主键id)<count(1)≈count(_)，所以我建议你，尽量使用count(_)。\n\n\n\n### order by是怎么工作的\n\n\n首先创建一个测试表  `t_city`\n\n\n```sql\nCREATE TABLE `t_city` (\n  `id` int(11) NOT NULL,\n  `city` varchar(16) NOT NULL,\n  `name` varchar(16) NOT NULL,\n  `age` int(11) NOT NULL,\n  `addr` varchar(128) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  KEY `city` (`city`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8;\n```\n\n\n使用存储过程 添加10W条测试数据\n\n\n```sql\ndelimiter ;;\ncreate procedure idata2()\nbegin\n  declare i int;\n  set i=1;\n  while(i<=10000)do\n    insert into t_city values(i,'广州', i,i,i);\n    set i=i+1;\n  end while;\nend;;\ndelimiter ;\ncall idata2();\n```\n\n\n比如有如下sql语句，为避免全表扫描，已经在city字段加上索引\n\n\n```sql\nselect city,name,age from t_city where city='广州' order by name limit 1000;\n```\n\n\n这个语句看上去逻辑很清晰， 那吗数据库内部到底是怎样执行的了？\n\n\n首先先用`explain`看看执行计划\n\n\n```sql\nexplain select city,name,age from t_city where city='广州' order by name limit 1000;\n```\n\n\n![](https://img-blog.csdnimg.cn/20190416172638203.png#id=J8vpw&originHeight=52&originWidth=981&originalType=binary&ratio=1&status=done&style=none)\n**先看下个执行计划各参数的含义：**\n\n\n- `select_type`：显 示查询中每个select子句的类型\n- `table`： 显示这一行的数据是关于哪张表的，有时不是真实的表名字\n- `type`：在表中找到所需行的方式，又称“访问类型”。常用的类型有： ALL, index,  range, ref, eq_ref, const, system, NULL（从左到右，性能从差到好）\n- `possible_keys`：指出MySQL能使用哪个索引在表中找到记录，查询涉及到的字段上若存在索引，则该索引将被列出，但不一定被查询使用\n- `Key`：key列显示MySQL实际决定使用的键（索引）\n- `key_len`：表示索引中使用的字节数，可通过该列计算查询中使用的索引的长度，key_len显示的值为索引字段的最大可能长度，并非实际使用长度，不损失精确性的情况下，长度越短越好\n- `ref`：表示上述表的连接匹配条件，即哪些列或常量被用于查找索引列上的值\n- `rows`： 表示MySQL根据表统计信息及索引选用情况，估算的找到所需的记录所需要读取的行数\n- `Extra`：该列包含MySQL解决查询的详细信息。Extra这个字段中的`“Using filesort”表示的就是需要排序`，MySQL会给每个线程分配一块内存用于排序，称为`sort_buffer`。\n\n\n\n![](https://img-blog.csdnimg.cn/20190416174643103.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=qZTfO&originHeight=642&originWidth=655&originalType=binary&ratio=1&status=done&style=none)\n\n\n- 按name排序”这个动作，可能在内存中完成，也可能需要使用外部排序，这取决于排序所需的内存和参数`sort_buffer_size`。\n- `sort_buffer_size`就是MySQL为排序开辟的内存（`sort_buffer`）的大小。如果要排序的数据量小于sort_buffer_size，排序就在内存中完成。但如果排序数据量太大，内存放不下，则不得不利用磁盘临时文件辅助排序。\n\n\n\n> 确定一个排序语句是否使用了临时文件\n\n\n\n```sql\n/* 打开optimizer_trace，只对本线程有效 */\nSET optimizer_trace='enabled=on'; \n\n/* @a保存Innodb_rows_read的初始值 */\nselect VARIABLE_VALUE into @a from  performance_schema.session_status where variable_name = 'Innodb_rows_read';\n\n/* 执行语句 */\nselect city, name,age from t where city='杭州' order by name limit 1000; \n\n/* 查看 OPTIMIZER_TRACE 输出 */\nSELECT * FROM `information_schema`.`OPTIMIZER_TRACE`\n\n/* @b保存Innodb_rows_read的当前值 */\nselect VARIABLE_VALUE into @b from performance_schema.session_status where variable_name = 'Innodb_rows_read';\n\n/* 计算Innodb_rows_read差值 */\nselect @b-@a;\n```\n\n\n这个方法是通过查看 OPTIMIZER_TRACE 的结果来确认的，你可以从 number_of_tmp_files中看到是否使用了临时文件。\n\n\n![](https://img-blog.csdnimg.cn/2019041617592518.png#id=ZWOG8&originHeight=180&originWidth=712&originalType=binary&ratio=1&status=done&style=none)\n\n\n- `number_of_tmp_files`表示的是，排序过程中使用的临时文件数。内存放不下时，就需要使用外部排序，外部排序一般使用归并排序算法。，MySQL将需要排序的数据分成12份，每一份单独排序后存在这些临时文件中。然后把这12个有序文件再合并成一个有序的大文件。\n- 如果`sort_buffer_size`超过了需要排序的数据量的大小，`number_of_tmp_files`就是0，表示排序可以直接在内存中完成。否则就需要放在临时文件中排序。\n- `sort_buffer_size`越小，需要分成的份数越多，`number_of_tmp_files`的值就越大。\n- `sort_mode` 里面的`packed_additional_fields`的意思是，排序过程对字符串做了`“紧凑”`处理。即使name字段的定义是varchar(16)，在排序过程中还是要按照实际长度来分配空间的。\n- 同时，最后一个查询语句select @b-@a 的返回结果是4000，表示整个执行过程只扫描了4000行。\n- 这里需要注意的是，为了避免对结论造成干扰，我把internal_tmp_disk_storage_engine设置成MyISAM。否则，select @b-@a的结果会大于4000\n- 在上面这个算法过程里面，只对原表的数据读了一遍，剩下的操作都是在sort_buffer和临时文件中执行的。但这个算法有一个问题，就是如果查询要返回的字段很多的话，那么sort_buffer里面要放的字段数太多，这样内存里能够同时放下的行数很少，要分成很多个临时文件，排序的性能会很差。\n\n\n\n**如果MySQL认为排序的单行长度太大会怎么做呢？**\n\n\n- `max_length_for_sort_data`，是MySQL中专门控制用于排序的行数据的长度的一个参数。它的意思是，如果单行的长度超过这个值，MySQL就认为单行太大，要换一个算法。\n\n\n\n### 如何正确地显示随机消息\n\n\n从一个单词表中随机选出三个单词\n\n\n创建测试表\n\n\n```sql\n CREATE TABLE `words` (\n  `id` int(11) NOT NULL AUTO_INCREMENT,\n  `word` varchar(64) DEFAULT NULL,\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB;\n```\n\n\n添加测试数据\n\n\n```sql\ndelimiter ;;\ncreate procedure idata3()\nbegin\n  declare i int;\n  set i=0;\n  while i<10000 do\n    insert into words(word) values(concat(char(97+(i div 1000)), char(97+(i % 1000 div 100)), char(97+(i % 100 div 10)), char(97+(i % 10))));\n    set i=i+1;\n  end while;\nend;;\ndelimiter ;\n\ncall idata3();\n```\n\n\n**首先，会想到用order by rand()来实现这个逻辑**\n\n\n```sql\nEXPLAIN select word from words order by rand() limit 3;\n```\n\n\n![](https://img-blog.csdnimg.cn/20190416182846114.png#id=IcAaX&originHeight=98&originWidth=1076&originalType=binary&ratio=1&status=done&style=none)\n\n\n- Extra字段显示`Using temporary`，表示的是需要使用临时表；`Using filesort`，表示的是需要执行排序操作。因此这个Extra的意思就是，需要临时表，并且需要在临时表上排序\n- order by rand()使用了内存临时表，内存临时表排序的时候使用了rowid排序方法。\n- tmp_table_size这个配置限制了内存临时表的大小，默认值是16M。如果临时表大小超过了tmp_table_size，那么内存临时表就会转成磁盘临时表。\n- 磁盘临时表使用的引擎默认是InnoDB，是由参数internal_tmp_disk_storage_engine控制的。当使用磁盘临时表的时候，对应的就是一个没有显式索引的InnoDB表的排序过程。\n\n\n\n### 幻读是什么，幻读有什么问题\n\n\n- 幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。\n- 在可重复读隔离级别下，普通的查询是快照读，是不会看到别的事务插入的数据的。因此，幻读在“当前读”下才会出现。\n\n\n\n**创建测试数据**\n\n\n```sqll\nCREATE TABLE `t` (\n  `id` int(11) NOT NULL,\n  `c` int(11) DEFAULT NULL,\n  `d` int(11) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  KEY `c` (`c`)\n) ENGINE=InnoDB;\n\ninsert into t values(0,0,0),(5,5,5),\n(10,10,10),(15,15,15),(20,20,20),(25,25,25);\n```\n\n\n**下面的语句序列，是怎么加锁的，加的锁又是什么时候释放的呢？**\n\n\n```sql\nbegin;\nselect * from t where d=5 for update;\ncommit;\n```\n\n\n- 这个语句会命中d=5的这一行，对应的主键id=5，因此在select 语句执行完成后，id=5这一行会加一个写锁，而且由于两阶段锁协议，这个写锁会在执行commit语句的时候释放。\n- 由于字段d上没有索引，因此这条查询语句会做全表扫描。那么，其他被扫描到的，但是不满足条件的5行记录上，会不会被加锁呢？\n\n\n\n![](https://img-blog.csdnimg.cn/20190418165218311.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=GPJCV&originHeight=688&originWidth=984&originalType=binary&ratio=1&status=done&style=none)\n\n\n- 可以看到，session A里执行了三次查询，分别是Q1、Q2和Q3。它们的SQL语句相同，都是select * from t where d=5 for update。这个语句的意思你应该很清楚了，查所有d=5的行，而且使用的是当前读，并且加上写锁\n\n\n\n**图中SQL执行流程**\n\n\n- Q1只返回id=5这一行；\n- 在T2时刻，session B把id=0这一行的d值改成了5，因此T3时刻Q2查出来的是id=0和id=5这两行；\n- 在T4时刻，session C又插入一行（1,1,5），因此T5时刻Q3查出来的是id=0、id=1和id=5的这三行。\n- 其中，Q3读到id=1这一行的现象，被称为`“幻读”`。\n- 在`可重复读`(InnoDB的默认)隔离级别下，普通的查询是快照读，是不会看到别的事务插入的数据的。因此，`幻读在“当前读”下才会出现。`\n- 上面session B的修改结果，被session A之后的select语句用“当前读”看到，不能称为幻读。幻读仅专指“新插入的行”\n\n\n\n从事务可见性规则来分析的话，上面这三条SQL语句的返回结果都没有问题。因为这三个查询都是加了for update，都是当前读。而当前读的规则，就是要能读到所有已经提交的记录的最新值。并且，session B和sessionC的两条语句，执行后就会提交，所以Q2和Q3就是应该看到这两个事务的操作效果，而且也看到了，这跟事务的可见性规则并不矛盾。但是，这是不是真的没问题呢？\n\n\n**幻读有什么问题？**\n\n\n- 首先是语义上的。session A在T1时刻就声明了，“我要把所有d=5的行锁住，不准别的事务进行读写操作”。而实际上，这个语义被破坏了。\n\n\n\n**其次，是数据一致性的问题。**\n\n\n- 我们知道，锁的设计是为了保证数据的一致性。而这个一致性，不止是数据库内部数据状态在此刻的一致性，还包含了数据和日志在逻辑上的一致性\n- 为了说明这个问题，我给session A在T1时刻再加一个更新语句，即：update t set d=100 where d=5。\n  ![](https://img-blog.csdnimg.cn/20190418171046246.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=Wyaze&originHeight=551&originWidth=929&originalType=binary&ratio=1&status=done&style=none)\n  **上面的执行流程**\n- 经过T1时刻，id=5这一行变成 (5,5,100)，当然这个结果最终是在T6时刻正式提交的;\n- 经过T2时刻，id=0这一行变成(0,5,5);\n- 经过T4时刻，表里面多了一行(1,5,5);\n\n\n\n这样看，这些数据也没啥问题，但是我们再来看看这时候binlog里面的内容。\n\n\n- T2时刻，session B事务提交，写入了两条语句；\n- T4时刻，session C事务提交，写入了两条语句；\n- T6时刻，session A事务提交，写入了update t set d=100 where d=5 这条语句。\n\n\n\n放到一起的话，就是这样的：\n\n\n```sql\nupdate t set d=5 where id=0; /*(0,0,5)*/\nupdate t set c=5 where id=0; /*(0,5,5)*/\n\ninsert into t values(1,1,5); /*(1,1,5)*/\nupdate t set c=5 where id=1; /*(1,5,5)*/\n\nupdate t set d=100 where d=5;/*所有d=5的行，d改成100*/\n```\n\n\n> 这个语句序列，不论是拿到备库去执行，还是以后用binlog来克隆一个库，这三行的结果，都变成了 (0,5,100)、(1,5,100)和(5,5,100)。也就是说，id=0和id=1这两行，发生了数据不一致。这个问题很严重，是不行的。\n\n\n\n**如何解决幻读？**\n\n\n- 产生幻读的原因是，行锁只能锁住行，但是新插入记录这个动作，要更新的是记录之间的“间隙”。因此，为了解决幻读问题，InnoDB只好引入新的锁，也就是间隙锁(Gap Lock)。\n- 间隙锁，锁的就是两个值之间的空隙。比如文章开头的表t，初始化插入了6个记录，这就产生了7个间隙。\n- 这样，当你执行 select * from t where d=5 for update的时候，就不止是给数据库中已有的6个记录加上了行锁，还同时加了7个间隙锁。这样就确保了无法再插入新的记录。\n- 也就是说这时候，在一行行扫描的过程中，不仅将给行加上了行锁，还给行两边的空隙，也加上了间隙锁。\n- 间隙锁存在冲突关系的，是“往这个间隙中插入一个记录”这个操作。间隙锁之间都不存在冲突关系。\n- 间隙锁和next-key lock的引入，帮我们解决了幻读的问题，但同时也带来了一些“困扰”\n\n\n\n> 比如现在有这样一个场景 业务逻辑这样的：任意锁住一行，如果这一行不存在的话就插入，如果存在这一行就更新它的数据，代码如下：\n\n\n\n```sql\nbegin;\nselect * from t where id=N for update;\n\n/*如果行不存在*/\ninsert into t values(N,N,N);\n/*如果行存在*/\nupdate t set d=N set id=N;\n\ncommit;\n```\n\n\n> 可能你会说，这个不是`insert ... on duplicate key update` 就能解决吗？但其实在有多个唯一键的时候,这个方法是不能满足要求的。这个逻辑一旦有并发，就会碰到死锁。你一定也觉得奇怪，这个逻辑每次操作前用for update锁起来，已经是最严格的模式了，怎么还会有死锁呢？\n\n\n\n![](https://img-blog.csdnimg.cn/20190418172853342.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=n7URX&originHeight=372&originWidth=982&originalType=binary&ratio=1&status=done&style=none)\n你看到了，其实都不需要用到后面的update语句，就已经形成死锁了。我们按语句执行顺序来分析一下：\n\n\n- session A 执行select ... for update语句，由于id=9这一行并不存在，因此会加上间隙锁(5,10);\n- session B 执行select ... for update语句，同样会加上间隙锁(5,10)，间隙锁之间不会冲突，因此这个语句可以执行成功；\n- session B 试图插入一行(9,9,9)，被session A的间隙锁挡住了，只好进入等待；\n- session A试图插入一行(9,9,9)，被session B的间隙锁挡住了。\n- 至此，两个session进入互相等待状态，形成死锁。当然，InnoDB的死锁检测马上就发现了这对死锁关系，让session A的insert语句报错返回了。\n\n\n\n> `间隙锁是在可重复读隔离级别下才会生效的`。所以，你如果把隔离级别设置为读提交的话，就没有间隙锁了。但同时，你要解决可能出现的数据和日志不一致问题，需要把`binlog`格式设置为row。这，也是现在不少公司使用的配置组合。\n\n","source":"_posts/MySQL学习笔记.md","raw":"---\ntitle: MySQL学习笔记\ndate: 2021-09-21 14:11:01\nupdated: 2021-09-21 14:11:03\ntags: [mysql]\ncategories: mysql\ndescription: mysql学习笔记，从语雀迁移到hexo。\n---\n\n### 一条SQL查询语句是如何执行的\n\n\n```sql\nmysql> select * from T where ID=10；\n```\n\n\n![](https://img-blog.csdnimg.cn/20190410210326412.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=Mnrxq&originHeight=798&originWidth=1086&originalType=binary&ratio=1&status=done&style=none)\n\n\n> 大体来说，MySQL可以分为`Server`层和`存储引擎`层两部分\n\n\n\n- `Server`层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖MySQL的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。\n- `存储引擎层`负责数据的存储和提取。其架构模式是插件式的，支持InnoDB、MyISAM、Memory等多个存储引擎。现在最常用的存储引擎是InnoDB，它从MySQL 5.5.5版本开始成为了默认存储引擎。\n- 不同的存储引擎共用一个Server层，也就是从连接器到执行器的部分\n-\n\n\n\n\n**连接器**\n\n\n- 第一步，你会先连接到这个数据库上，这时候接待你的就是连接器。连接器负责跟客户端建立连接、获取权限、维持和管理连接。连接完成后，如果你没有后续的动作，这个连接就处于空闲状态，你可以在`show processlist`命令中看到它。客户端如果太长时间没动静，连接器就会自动将它断开。这个时间是由参数`wait_timeout`控制的，默认值是`8`小时。数据库里面，长连接是指连接成功后，如果客户端持续有请求，则一直使用同一个连接。短连接则是指每次执行完很少的几次查询就断开连接，下次查询再重新建立一个。\n\n\n\n**查询缓存**\n\n\n- 连接建立完成后，你就可以执行select语句了。执行逻辑就会来到第二步：查询缓存。\n- MySQL拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。之前执行过的语句及其结果可能会以key-value对的形式，被直接缓存在内存中。key是查询的语句，value是查询的结果。如果你的查询能够直接在这个缓存中找到key，那么这个value就会被直接返回给客户端。\n- 如果语句不在查询缓存中，就会继续后面的执行阶段。执行完成后，执行结果会被存入查询缓存中。\n\n\n\n> 大多数情况下我会建议你不要使用查询缓存，为什么呢？因为查询缓存往往弊大于利。查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。\n\n\n\n**分析器**\n\n\n- 如果没有命中查询缓存，就要开始真正执行语句了。首先，MySQL需要知道你要做什么，因此需要对SQL语句做解析。分析器先会做`“词法分析”`,词法分析完后就要做`“语法分析”`。根据词法分析的结果，语法分析器会根据语法规则，判断你输入的这个SQL语句是否满足MySQL语法。如果你的语句不对，就会收到“You have an error in your SQL syntax”的错误提醒\n\n\n\n**优化器**\n\n\n- 经过了分析器，MySQL就知道你要做什么了。在开始执行之前，还要先经过优化器的处理。\n- 优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。\n\n\n\n> 比如你执行下面这样的语句，这个语句是执行两个表的join：\n`mysql> select * from t1 join t2 using(ID) where t1.c=10 and t2.d=20;`\n既可以先从表t1里面取出c=10的记录的ID值，再根据ID值关联到表t2，再判断t2里面d的值是否等于20。\n也可以先从表t2里面取出d=20的记录的ID值，再根据ID值关联到t1，再判断t1里面c的值是否等于10。\n这两种执行方法的逻辑结果是一样的，但是执行的效率会有不同，而优化器的作用就是决定选择使用哪一个方案。\n\n\n\n**执行器**\n\n\n- MySQL通过分析器知道了你要做什么，通过优化器知道了该怎么做，于是就进入了执行器阶段，开始执行语句。\n- 开始执行的时候，要先判断一下你对这个表T有没有执行查询的权限，如果没有，就会返回没有权限的错误\n- 如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。\n\n\n\n> `mysql> select * from T where ID=10;`\n比如我们这个例子中的表T中，ID字段没有索引，那么执行器的执行流程是这样的：\n调用InnoDB引擎接口取这个表的第一行，判断ID值是不是10，如果不是则跳过，如果是则将这行存在结果集中；\n调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。\n执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。\n\n\n\n- 至此，这个整个语句就执行完成了。一条查询语句的执行过程一般是经过连接器、分析器、优化器、执行器等功能模块，最后到达存储引擎。\n\n\n\n### 一条SQL更新语句是如何执行的\n\n\n```sql\nupdate T set c=c+1 where ID=2;\n```\n\n\n- 与查询流程不一样的是，更新流程还涉及两个重要的日志模块 `redo log`（重做日志）和 `binlog`（归档日志）\n- 每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程IO成本、查找成本都很高。为了解决这个问题，MySQL的设计者WAL技术，WAL的全称是Write-Ahead Logging，它的关键点就是`先写日志`，`再写磁盘`\n- 当有一条记录需要更新的时候，InnoDB引擎就会先把记录写到redo log里面，并更新内存，这个时候更新就算完成了。\n- 同时，`InnoDB`引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做。但是`InnoDB`的`redo log`是固定大小的，比如可以配置为一组4个文件，每个文件的大小是1GB,总共就可以记录4GB的操作。从头开始写，写到末尾就又回到开头循环写。\n- 在进行`redo log`写入时，有两个重要参数的write pos(当前记录的位置),`checkpoint`是当前要擦除的位置\n  ![](https://img-blog.csdnimg.cn/20190410230340406.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=evnl5&originHeight=272&originWidth=884&originalType=binary&ratio=1&status=done&style=none)\n- 一边写一边后移，写到第3号文件末尾后就回到0号文件开头,checkpoint也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。write pos和checkpoint之间还空着的部分，可以用来记录新的操作。\n- 如果`write pos`追上`checkpoin`，表示`redo log`满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把checkpoint推进一下。\n- 有了redo log，InnoDB就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为crash-safe(崩溃安全()。\n- redo log是InnoDB引擎特有的日志，而Server层也有自己的日志，称为binlog（归档日志）\n- 最开始MySQL里并没有`InnoDB引擎`。MySQL自带的引擎是MyISAM，但是MyISAM没有crash-safe的能力，binlog日志只能用于归档。而InnoDB是另一个公司以插件形式引入MySQL的，既然只依靠binlog是没有crash-safe能力的，所以InnoDB使用另外一套日志系统——也就是redo log来实现crash-safe能力。\n\n\n\n> `redo log是InnoDB引擎特有的`；binlog是MySQL的Server层实现的，所有引擎都可以使用。\n`redo log是物理日志`，记录的是“在某个数据页上做了什么修改”；`binlog是逻辑日志`，记录的是这个语句的原始逻辑，比如“给ID=2这一行的c字段加1 ”。\nr`edo log是循环写的`，`空间固定`会用完；`binlog是可以追加写入的`。“追加写”是指binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。\n\n\n\n**执行器和InnoDB引擎在执行这个简单的update语句时的内部流程:**\n\n\n- 执行器先找引擎取ID=2这一行。ID是主键，引擎直接用树搜索找到这一行。如果ID=2这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。\n- 执行器拿到引擎给的行数据，把这个值加上1，比如原来是N，现在就是N+1，得到新的一行数据，再调用引擎接口写入这行新数据。\n- 引擎将这行新数据更新到内存中，同时将这个更新操作记录到redo log里面，此时redo log处于prepare状态。然后告知执行器执行完成了，随时可以提交事务。\n- 执行器生成这个操作的binlog，并把binlog写入磁盘。\n- 执行器调用引擎的提交事务接口，引擎把刚刚写入的redo log改成提交（commit）状态，更新完成。\n- redo log的写入拆成了两个步骤：prepare和commit，这就是`\"两阶段提交\"`。\n\n\n\n![](https://img-blog.csdnimg.cn/2019041023325625.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=tDmdi&originHeight=1522&originWidth=1142&originalType=binary&ratio=1&status=done&style=none)\n\n\n> `1 prepare阶段 2 写binlog 3 commit` , 当在`2之前崩溃时`,重启恢复：后发现没有commit，回滚。备份恢复：没有binlog 。\n`当在3之前崩溃`,重启恢复：虽没有commit，但满足prepare和binlog完整，所以重启后会自动commit。备份：有binlog. 一致\n\n\n\n#### 总结\n\n\n- Redo log不是记录数据页“更新之后的状态”，而是记录这个页 “做了什么改动”。\n- Binlog有两种模式，statement 格式的话是记sql语句， row格式会记录行的内容，记两条，更新前和更新后都有。\n\n\n\n### 事务隔离：为什么你改了我还看不见\n\n\n- 事务就是要保证一组数据库操作，要么全部成功，要么全部失败。在MySQL中，事务支持是在引擎层实现的。MySQL默认的`MyISAM`引擎就不支持事务，这也是`MyISAM`被`InnoDB`取代的重要原因之一。\n- 事务的特性：`ACID`即原子性、一致性、隔离性、持久性。多个事务同时执行的时候，就可能出现`脏读`，`不可重复读`，`幻读`，为了解决这些问题，就有了“`隔离级别`”的概念。但是隔离得越严实，效率就会越低\n- SQL标准的事务隔离级别包括：`读未提交`（read uncommitted）、`读提交`（read committed）、`可重复读`（repeatable read）和`串行化`（serializable ）\n\n\n\n> 读未提交是指，一个事务还没提交时，它做的变更就能被别的事务看到。\n读提交是指，一个事务提交之后，它做的变更才会被其他事务看到。\n可重复读是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。未提交的更改对其他事务是不可见的\n串行化:对应一个记录会加读写锁，出现冲突的时候，后访问的事务必须等前一个事务执行完成才能继续执行\n\n\n\n- 在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。在“`可重复读`”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。在`“读提交”`隔离级别下，这个视图是在每个SQL语句开始执行的时候创建的。`“读未提交”`隔离级别下直接返回记录上的最新值，没有视图概念。`串行化`”隔离级别下直接用加锁的方式来避免并行访问\n- 查看数据库的实物隔离级别：`show variables like '%isolation%';`\n- 事务隔离的实现：在MySQL中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。\n\n\n\n假设一个值从1被按顺序改成了2、3、4，在回滚日志里面就会有类似下面的记录。不同时刻启动的事务会有不同的read-view，同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（`MVCC`）\n![](https://img-blog.csdnimg.cn/20190411130916709.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=AC58n&originHeight=407&originWidth=973&originalType=binary&ratio=1&status=done&style=none)\n\n\n- 回滚日志总不能一直保留吧，什么时候删除呢？答案是，在不需要的时候才删除。系统会判断，当没有事务再需要用到这些回滚日志时，回滚日志会被删除。什么时候才不需要了呢？就是当系统里没有比这个回滚日志更早的read-view的时候。\n- 为什么尽量不要使用长事务。长事务意味着系统里面会存在很老的事务视图，在这个事务提交之前，回滚记录都要保留，这会导致大量占用存储空间。除此之外，长事务还占用锁资源，可能会拖垮库。\n- 事务启动方式：一、显式启动事务语句，`begin`或者`start transaction`,提交`commit`，回滚`rollback`；二、`set autocommit=0`，该命令会把这个线程的自动提交关掉。这样只要执行一个select语句，事务就启动，并不会自动提交，直到主动执行`commit`或`rollback`或断开连接。\n- 建议使用方法一，如果考虑多一次交互问题，可以使用`commit work and chain`语法。在`autocommit=1`的情况下用`begin`显式启动事务，如果执行`commit`则提交事务。如果执行`commit work and chain`则提交事务并自动启动下一个事务\n\n\n\n### 深入浅出索引（上）\n\n\n**索引的常见模型**\n\n\n- 索引的出现是为了提高查询效率，常见的三种索引模型分别是`哈希表`、`有序数组`和`搜索树`\n- `哈希表`：一种以`key-value` 存储数据的结构，哈希的思路是把值放在数组里，用一个哈希函数把`key`换算成一个确定的位置，然后把`value`放在数组的这个位置。哈希冲突的处理办法是使用`链表`。哈希表适用只有`等值查询`的场景\n- `有序数组`：按顺序存储。查询用二分法就可以快速查询，时间复杂度是：O(log(N))。查询效率高，更新效率低（涉及到移位）。在等值查询和范围查询场景中的性能就都非常优秀。有序数组索引只适用于静态存储引擎。\n- 二叉搜索树：每个节点的左儿子小于父节点，右儿子大于父节点。查询时间复杂度O(log(N))，更新时间复杂度O(log(N))。数据库存储大多不适用二叉树，因为树高过高，会适用N叉树\n\n\n\n**InnoDB 的索引模型**\n\n\n- `InnoDB`使用了`B+树`索引模型，所以数据都是存储在B+树中的。每一个索引在`InnoDB`里面对应一棵B+树。\n- 索引类型分为`主键索引`和`非主键索引`。主键索引的叶子节点存的是整行数据。在InnoDB里，主键索引也被称为`聚簇索引`。非主键索引的叶子节点内容是主键的值。在InnoDB里，非主键索引也被称为`二级索引`\n\n\n\n![](https://img-blog.csdnimg.cn/20190411164702315.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=GPjHM&originHeight=424&originWidth=1004&originalType=binary&ratio=1&status=done&style=none)\n\n\n**主键索引和普通索引的查询有什么区别？**\n\n\n- 如果语句是`select * from T where ID=500`，即主键查询方式，则只需要搜索ID这棵B+树；\n- 如果语句是`select * from T where k=5`，即普通索引查询方式，则需要先搜索k索引树，得到ID的值为500，再到ID索引树搜索一次。这个过程称为`回表`。\n- 基于非主键索引的查询需要多扫描一棵索引树。因此，我们在应用中应该尽量使用主键查询\n\n\n\n**索引维护**\n\n\n- `B+树`为了维护索引有序性，在插入新值的时候需要做必要的维护。涉及到数据的移动和数据页的增加和删减\n- 一个数据页满了，按照B+Tree算法，新增加一个数据页，叫做`页分裂`，会导致性能下降。空间利用率降低大概50%。当相邻的两个数据页利用率很低的时候会做`数据页合并`，合并的过程是分裂过程的`逆过程`。\n\n\n\n#### 总结\n\n\n- 索引可能因为删除，或者页分裂等原因，导致数据页有空洞，重建索引的过程会创建一个新的索引，把数据按顺序插入，这样页面的利用率最高，也就是索引更紧凑、更省空间。\n\n\n\n> `alter table T drop index k`;     alter table T add index(k);\n要重建主键索引\n`alter table T drop primary key`;      `alter table T add primary key(id)`;\n重建索引k的做法是合理的，可以达到省空间的目的。但是，重建主键的过程不合理。不论是删除主键还是创建主键，都会将整个表重建。所以连着执行这两个语句的话，第一个语句就白做了。\n可以用这个语句代替 ： alter table T engine=InnoDB\n\n\n\n### 深入浅出索引（下）\n\n\n```sql\nmysql> create table T (\nID int primary key,\nk int NOT NULL DEFAULT 0, \ns varchar(16) NOT NULL DEFAULT '',\nindex k(k))\nengine=InnoDB;\n\ninsert into T values(100,1, 'aa'),(200,2,'bb'),(300,3,'cc'),(500,5,'ee'),(600,6,'ff'),(700,7,'gg');\n```\n\n\n![](https://img-blog.csdnimg.cn/20190411193509228.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=iQfIH&originHeight=441&originWidth=989&originalType=binary&ratio=1&status=done&style=none)\n如果我执行 `select * from T where k between 3 and 5`，需要执行几次树的搜索操作，会扫描多少行？\n\n\n**SQL查询语句的执行流程：**\n\n\n- 在k索引树上找到k=3的记录，取得 ID = 300；\n- 再到ID索引树查到ID=300对应的R3；\n- 在k索引树取下一个值k=5，取得ID=500；\n- 再回到ID索引树查到ID=500对应的R4；\n- 在k索引树取下一个值k=6，不满足条件，循环结束。\n- 在这个过程中，回到主键索引树搜索的过程，我们称为回表。可以看到，这个查询过程读了k索引树的3条记录，回表了两次。在这个例子中，由于查询结果所需要的数据只在主键索引上有，所以不得不回表。\n\n\n\n**优化方式**\n\n\n- sql语句修改为`select ID from T where k between 3 and 5`，这时只需要查ID的值，而ID的值已经在k索引树上了，因此可以直接提供查询结果，不需要回表。也就是说，在这个查询里面，索引k已经“覆盖了”我们的查询需求，我们称为`覆盖索引`。\n- 由于`覆盖索引`可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。\n\n\n\n#### 总结\n\n\n- `覆盖索引`：如果查询条件使用的是普通索引（或是联合索引的最左原则字段），查询结果是联合索引的字段或是主键，不用回表操作，直接返回结果，减少IO磁盘读写读取正行数据\n- `最左前缀`：联合索引的最左 N 个字段，也可以是字符串索引的最左 M 个字符\n- `联合索引`：根据创建联合索引的顺序，以最左原则进行where检索，比如（age，name）以age=1 或 age= 1 and name=‘张三’可以使用索引，单以name=‘张三’ 不会使用索引，考虑到存储空间的问题，还请根据业务需求，将查找频繁的数据进行靠左创建索引。\n- 索引下推：`like 'hello%’and age >10` 检索，MySQL5.6版本之前，会对匹配的数据进行回表查询。5.6版本后，会先过滤掉age<10的数据，再进行回表查询，减少回表率，提升检索速度\n\n\n\n### 讲全局锁和表锁：给表加个字段怎么有这么多阻碍\n\n\n> 根据加锁的范围，MySQL里面的锁大致可以分成全局锁、表级锁和行锁三类\n\n\n\n**全局锁**\n\n\n- 对整个数据库实例加锁。MySQL提供加全局读锁的方法：`Flush tables with read lock(FTWRL)`。这个命令可以使整个库处于只读状态。使用该命令之后，数据更新语句、数据定义语句和更新类事务的提交语句等操作都会被阻塞。使用场景：`全库逻辑备份`。\n- 风险是如果在主库备份，在备份期间不能更新，业务停摆。如果在从库备份，备份期间不能执行主库同步的binlog，导致主从延迟。官方自带的逻辑备份工具`mysqldump`，当mysqldump使用参数`--single-transaction`的时候，会启动一个事务，确保拿到一致性视图。而由于`MVCC`的支持，这个过程中数据是可以正常更新的。\n- 一致性读是好，但是前提是引擎要支持这个隔离级别。如果要全库只读，为什么不使用`set global readonly=true`的方式？在有些系统中，`readonly`的值会被用来做其他逻辑，比如判断主备库。所以修改global变量的方式影响太大。\n- 在异常处理机制上有差异。如果执行`FTWRL`命令之后由于客户端发生异常断开，那么MySQL会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为`readonly`之后，如果客户端发生异常，则数据库就会一直保持`readonly`状态，这样会导致整个库长时间处于不可写状态，风险较高。\n\n\n\n**表级锁**\n\n\n- MySQL里面表级锁有两种，一种是表锁，一种是元数据所(meta data lock,MDL)。表锁的语法是:l`ock tables ... read/write`\n- 可以用`unlock tables`主动释放锁，也可以在客户端断开的时候自动释放。`lock tables`语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。\n- 对于`InnoDB`这种支持`行锁`的引擎，一般不使用`lock tables`命令来控制并发，毕竟锁住整个表的影响面还是太大。\n- 另一类表级的锁是`MDL`（metadata lock)。`MDL不需要显式使用`，在访问一个表的时候会被`自动加上`。MDL的作用是，`保证读写的正确性`。当对一个表做增删改查操作的时候，加`MDL读锁`；当要对表做结构变更操作的时候，加`MDL写锁`。`读锁之间不互斥`，因此你可以有多个线程同时对一张表增删改查。`读写锁之间、写锁之间是互斥的`，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。\n- `MDL` 会直到事务提交才会释放，在做表结构变更的时候，一定要小心不要导致锁住线上查询和更新。\n\n\n\n**如何安全地给表加字段**\n\n\n- 给一个表加字段，或者修改字段，或者加索引，需要扫描全表的数据。首先我们要解决长事务，事务不提交，就会一直占着MDL锁。在MySQL的`information_schema` 库的 `innodb_trx` 表中，你可以查到当前执行中的事务。如果你要做`DDL`变更的表刚好有`长事务`在执行，要考虑先暂停DDL，或者`kill`掉这个长事务。\n- 如果你要变更的表是一个`热点表`，虽然数据量不大，但是上面的请求很频繁，这时候kill可能未必管用，因为新的请求马上就来了。比较理想的机制是，在`alter table`语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到`MDL写锁`最好，拿不到也不要阻塞后面的业务语句，先放弃。之后开发人员或者DBA再通过重试命令重复这个过程。\n\n\n\n### 讲行锁功过：怎么减少行锁对性能的影响\n\n\n- MySQL的`行锁`是在引擎层由各个`引擎自己实现`的。但并不是所有的引擎都支持行锁，比`如MyISAM引擎就不支持行锁`。不支持行锁意味着并发控制只能使用表锁，对于这种引擎的表，同一张表上任何时刻只能有一个更新在执行，这就会影响到业务并发度。`InnoDB是支持行锁`的，这也是`MyISAM`被`InnoDB`替代的重要原因之一。\n- `两阶段锁协议`：在`InnoDB`事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。\n- `死锁`：当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁\n\n\n\n![](https://img-blog.csdnimg.cn/20190412161554856.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=Enkur&originHeight=585&originWidth=948&originalType=binary&ratio=1&status=done&style=none)\n\n\n- `事务A`在等待`事务B`释放id=2的行锁，而`事务B在等待事务A`释放id=1的行锁。 事务A和事务B在互相等待对方的资源释放，就是进入了`死锁状态`\n\n\n\n**出现死锁以后，有两种策略：**\n\n\n- 一种策略是，`直接进入等待，直到超时`。这个超时时间可以通过参数`innodb_lock_wait_timeout`来设置。在InnoDB中，默认值是`50s`\n- 另一种策略是，`发起死锁检测`，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数`innodb_deadlock_detect设置为on`，表示开启这个逻辑。默认值本身就是on\n- 正常情况下选择第二种策略，但是它也是有额外负担的，如果瞬间有大量线程请求会消耗消耗大量的CPU资源，但是每秒却执行不了几个事务，因为每次都要检测。\n\n\n\n**怎么解决由这种热点行更新导致的性能问题?**\n\n\n- 问题的症结在于，死锁检测要耗费大量的CPU资源\n- 如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉。 一般不建议采用\n- 控制并发度，对应相同行的更新，在进入引擎之前排队。这样在InnoDB内部就不会有大量的死锁检测工作了。\n- 将热更新的行数据拆分成逻辑上的多行来减少锁冲突，但是业务复杂度可能会大大提高。\n- `innodb行级锁是通过锁索引记录实现的，如果更新的列没建索引是会锁住整个表的。`\n\n\n\n#### 小结\n\n\n如果你要删除一个表里面的前10000行数据，有以下三种方法可以做到：\n\n\n- 第一种，直接执行\t `delete from T limit 10000;`\n- 第二种，在一个连接中循环执行20次 `delete from T limit 500;`\n- 第三种，在20个连接中同时执行\t`delete from T limit 500`\n\n\n\n**三种方案分析**\n\n\n- 方案一，事务相对较长，则占用锁的时间较长，会导致其他客户端等待资源时间较长。\n- 方案二，串行化执行，将相对长的事务分成多次相对短的事务，则每次事务占用锁的时间相对较短，其他客户端在等待相应资源的时间也较短。这样的操作，同时也意味着将资源分片使用（每次执行使用不同片段的资源），可以提高并发性。\n- 方案三，人为自己制造锁竞争，加剧并发量。\n\n\n\n### 事务到底是隔离的还是不隔离的\n\n\n- `innodb`支持`RC(读提交)`和`RR(可重复读)`隔离级别实现是用的一致性视图(consistent read view)\n- .事务在启动时会拍一个快照,这个快照是基于整个库的。基于整个库的意思就是说一个事务内,整个库的修改对于该事务都是不可见的(对于快照读的情况)。如果在事务内`select t`表,另外的事务执行了`DDL t`表,根据发生时间,`要吗锁住要嘛报错`\n\n\n\n**事务是如何实现的MVCC呢?**\n\n\n- 每个事务都有一个事务ID,叫做`transaction id`(严格递增)\n- 事务在启动时,找到已提交的最大事务ID记为up_limit_id。\n- 事务在更新一条语句时,比如id=1改为了id=2.会把id=1和该行之前的`row trx_id`写到`undo log`里。并且在数据页上把id的值改为2,并且把修改这条语句的`transaction id`记在该行行头。\n- 再定一个规矩,一个事务要查看一条数据时,必须先用该事务的`up_limit_id`与该行的`transaction id`做比对\n- 如果`up_limit_id>=transaction id`,那么可以看.如果`up_limit_id<transaction id`,则只能去`undo log`里去取。去undo log查找数据的时候,也需要做比对,必须`up_limit_id>transaction id`,才返回数据\n\n\n\n**什么是当前读,**\n\n\n- 由于当前读都是先读后写,只能读当前的值,所以认为当前读.会更新事务内的up_limit_id为该事务的transaction id\n\n\n\n**为什么**`**RR**`**能实现可重复读而**`**RC**`**不能,分两种情况**\n\n\n- 快照读的情况下,rr(可重复读)不能更新事务内的up_limit_id,而`rc(读提交)`每次会把`up_limit_id`更新为快照读之前最新已提交事务的`transaction id`,则`rc(读提交)`不能可重复读\n- 当前读的情况下,`rr(可重复读)`是利用`record lock+gap lock`来实现的,而`rc(读提交)`没有gap,所以rc不能可重复读\n\n\n\n### MySQL为什么有时候会选错索引\n\n\n- 在MySQL中一张表其实是可以支持多个索引的。但是，你写SQL语句的时候，并没有主动指定使用哪个索引。也就是说，使用哪个索引是由MySQL来确定的。所以有时候由于MySQL选错了索引，而导致执行速度变得很慢\n\n\n\n测试代码\n\n\n```sql\nCREATE TABLE `t` (\n  `id` int(11) NOT NULL,\n  `a` int(11) DEFAULT NULL,\n  `b` int(11) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  KEY `a` (`a`),\n  KEY `b` (`b`)\n) ENGINE=InnoDB；\n```\n\n\n然后，我们往表t中插入10万行记录，取值按整数递增，即：(1,1,1)，(2,2,2)，(3,3,3) 直到(100000,100000,100000)。\n\n\n分析一条SQL语句：\n\n\n```sql\nmysql> select * from t where a between 10000 and 20000;\n```\n\n\n正常情况下，a上有索引，肯定是要使用索引a的。\n\n\n![](https://img-blog.csdnimg.cn/20190414141306715.png#id=OG5aI&originHeight=97&originWidth=1077&originalType=binary&ratio=1&status=done&style=none)\n但是特许情况下如果同时有两个以下下操作执行：\n\n\n- 如果一个A请求首先开启了事物，随后，B请求把数据都删除后，又插入了10万行数据。\n- 这时候， B操作的查询语句`select * from t where a between 10000 and 20000`就不会再选择索引a了，会执行全表扫描，执行时间会比之前慢很多。`为什么会出现这样情况？`因为选择索引是优化器的工作，而优化器选择索引的目的，是找到一个最优的执行方案，并用最小的代价去执行语句。\n- MySQL在真正开始执行语句之前，并不能精确地知道满足这个条件的记录有多少条，而只能根据统计信息来估算记录数。这个统计信息就是索引的“`区分度`”。一个索引上不同的值越多，这个索引的区分度就越好。而一个索引上不同的值的个数，我们称之为`“基数”`（cardinality）。也就是说，这个基数越大，索引的区分度越好。\n- 可以使用`show index table`方法，看到一个索引的基数\n- MySQL是怎样得到索引的基数的呢？MySQL通过采样统计的方法得到基数\n- 如果使用索引a，每次从索引a上拿到一个值，都要回到主键索引上查出整行数据，这个代价优化器也要算进去的。而如果选择扫描10万行，是直接在主键索引上扫描的，没有额外的代价。优化器会估算这两个选择的代价，从结果看来，优化器认为直接扫描主键索引更快。当然，从执行时间看来，这个选择并不是最优的。\n- `analyze table t` 命令可以用来重新统计索引信息\n- 采用`force index`强行选择一个索引。如果force index指定的索引在候选索引列表中，就直接选择这个索引，不再评估其他索引的执行代价。\n\n\n\n![](https://img-blog.csdnimg.cn/20190414141504344.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=LVEvh&originHeight=321&originWidth=921&originalType=binary&ratio=1&status=done&style=none)\n\n\n```sql\nset long_query_time=0;\nselect * from t where a between 10000 and 20000; /*Q1*/\nselect * from t force index(a) where a between 10000 and 20000;/*Q2*/\n\n第一句，是将慢查询日志的阈值设置为0，表示这个线程接下来的语句都会被记录入慢查询日志中；\n第二句，Q1是session B原来的查询；\n第三句，Q2是加了force index(a)来和session B原来的查询语句执行情况对比。\n```\n\n\n- delete 语句删掉了所有的数据，然后再通过call idata()插入了10万行数据，看上去是覆盖了原来的10万行。\n- 但是，session A开启了事务并没有提交，所以之前插入的10万行数据是不能删除的。这样，之前的数据每一行数据都有两个版本，旧版本是delete之前的数据，新版本是标记为deleted的数据。这样，索引a上的数据其实就有两份\n\n\n\n### 怎么给字符串字段加索引\n\n\n- 假设，你现在维护一个支持邮箱登录的系统，用户表是这么定义的：\n\n\n\n```sql\nmysql> create table SUser(\nID bigint unsigned primary key,\nemail varchar(64), \n... \n)engine=innodb;\n```\n\n\n由于要使用邮箱登录，所以业务代码中一定会出现类似于这样的语句：\n\n\n```sql\nmysql> select f1, f2 from SUser where email='xxx';\n```\n\n\n- 如果email这个字段上没有索引，那么这个语句就只能做全表扫描。同时，MySQL是支持前缀索引的，也就是说，你可以定义字符串的一部分作为索引。默认地，如果你创建索引的语句不指定前缀长度，那么索引就会包含整个字符串。\n\n\n\n比如，这两个在email字段上创建索引的语句：\n\n\n```sql\nmysql> alter table SUser add index index1(email);\n或\nmysql> alter table SUser add index index2(email(6));\n```\n\n\n![](https://img-blog.csdnimg.cn/201904142351118.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=FFfQd&originHeight=468&originWidth=1000&originalType=binary&ratio=1&status=done&style=none)\n![](https://img-blog.csdnimg.cn/20190414235147183.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=XF7LV&originHeight=449&originWidth=640&originalType=binary&ratio=1&status=done&style=none)\n\n\n- 第一个语句创建的index1索引里面，包含了每个记录的整个字符串；\n- 第二个语句创建的index2索引里面，对于每个记录都是只取前6个字节。由于email(6)这个索引结构中每个邮箱字段都只取前6个字节,所以占用的空间会更小，这就是使用前缀索引的优势。但是 可能会增加额外的记录扫描次数。\n\n\n\n**使用的是index1的执行流程**\n\n\n- 从`index1`索引树找到满足索引值是’zhangssxyz@xxx.com’的这条记录，取得ID2的值；\n- 到主键上查到主键值是ID2的行，判断email的值是正确的，将这行记录加入结果集；\n- 取index1索引树上刚刚查到的位置的下一条记录，发现已经不满足email='zhangssxyz@xxx.com’的条件了，循环结束\n- 这个过程中，只需要回主键索引取一次数据，所以系统认为只扫描了一行。\n\n\n\n**使用的是index2的执行流程**\n\n\n- 从`index2`索引树找到满足索引值是’zhangs’的记录，找到的第一个是ID1；\n- 到主键上查到主键值是ID1的行，判断出email的值不是’zhangssxyz@xxx.com’，这行记录丢弃；\n- 取index2上刚刚查到的位置的下一条记录，发现仍然是’zhangs’，取出ID2，再到ID索引上取整行然后判断，这次值对了，将这行记录加入结果集；\n- 重复上一步，直到在idxe2上取到的值不是’zhangs’时，循环结束。\n- 在这个过程中，要回主键索引取4次数据，也就是扫描了4行。\n- 但是  对于这个查询语句来说，如果你定义的`index2`不是email(6)而是email(7），也就是说取email字段的前7个字节来构建索引的话，即满足前缀’zhangss’的记录只有一个，也能够直接查到ID2，只扫描一行就结束了。\n- 也就是说`使用前缀索引，定义好长度，就可以做到既节省空间，又不用额外增加太多的查询成本`。\n\n\n\n**前缀索引对覆盖索引的影响**\n\n\n- 使用前缀索引可能会增加扫描行数，这会影响到性能。其实，前缀索引的影响不止如此\n\n\n\n```sql\n#查询1 \nselect id,email from SUser where email='zhangssxyz@xxx.com';\n# 查询2\nselect id,name,email from SUser where email='zhangssxyz@xxx.com';\n```\n\n\n- 如果使用index1（即email整个字符串的索引结构）的话，可以利用覆盖索引，从index1查到结果后直接就返回了，不需要回到ID索引再去查一次。而如果使用index2（即email(6)索引结构）的话，就不得不回到ID索引再去判断email字段的值。\n- 即使你将index2的定义修改为email(18)的前缀索引，这时候虽然index2已经包含了所有的信息，但InnoDB还是要回到id索引再查一下，因为系统并不确定前缀索引的定义是否截断了完整信息。\n- 使用前缀索引就用不上覆盖索引对查询性能的优化了\n\n\n\n#### 小结\n\n\n对于类似于邮箱这样的字段来说，使用前缀索引的效果可能还不错。但是，遇到前缀的区分度不够好的情况时。比如，我们国家的身份证号，一共18位，其中前6位是地址码，所以同一个县的人的身份证号前6位一般会是相同的。\n\n\n假设你维护的数据库是一个市的公民信息系统，这时候如果对身份证号做长度为6的前缀索引的话，这个索引的区分度就非常低了。可能你需要创建长度为12以上的前缀索引，才能够满足区分度要求。但是，`索引选取的越长，占用的磁盘空间就越大，相同的数据页能放下的索引值就越少，搜索的效率也就会越低`。\n\n\n那么，如果我们能够确定业务需求里面只有按照身份证进行等值查询的需求，还有没有别的处理方法呢？这种方法，既可以占用更小的空间，也能达到相同的查询效率。\n\n\n第一种方式是使用`倒序存储`。如果你存储身份证号的时候把它倒过来存，每次查询的时候，你可以这么写：\n\n\n```sql\nmysql> select field_list from t where id_card = reverse('input_id_card_string');\n```\n\n\n由于身份证号的最后6位没有地址码这样的重复逻辑，所以最后这6位很可能就提供了足够的区分度。\n\n\n第二种方式是`使用hash字段`。你可以在表上再创建一个整数字段，来保存身份证的校验码，同时在这个字段上创建索引。\n\n\n```sql\nmysql> alter table t add id_card_crc int unsigned, add index(id_card_crc);\n```\n\n\n然后每次插入新记录的时候，都同时用crc32()这个函数得到校验码填到这个新字段。由于校验码可能存在冲突，也就是说两个不同的身份证号通过crc32()函数得到的结果可能是相同的，所以你的查询语句where部分要判断id_card的值是否精确相同。\n\n\n```sql\nmysql> select field_list from t where id_card_crc=crc32('input_id_card_string') and id_card='input_id_card_string'\n```\n\n\n这样，索引的长度变成了4个字节，比原来小了很多。\n\n\n**使用倒序存储和使用hash字段这两种方法的异同点**\n\n\n- 首先，它们的相同点是，都不支持范围查询。\n- `从占用的额外空间来看`，倒序存储方式在主键索引上，不会消耗额外的存储空间，而hash字段方法需要增加一个字段\n- `在CPU消耗方面`，倒序方式每次写和读的时候，都需要额外调用一次reverse函数，而hash字段的方式需要额外调用一次crc32()函数\n- `从查询效率上看`，使用hash字段方式的查询性能相对更稳定一些。因为crc32算出来的值虽然有冲突的概率，但是概率非常小，可以认为每次查询的平均扫描行数接近1。而倒序存储方式毕竟还是用的前缀索引的方式，也就是说还是会增加扫描行数。\n\n\n\n**字符串字段创建索引的场景你可以使用的方式有：**\n\n\n- 直接创建完整索引，这样可能比较占用空间；\n- 创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引；\n- 倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题；\n- 创建hash字段索引，查询性能稳定，有额外的存储和计算消耗，跟第三种方式一样，都不支持范围扫描。\n\n\n\n**利用学号作为登录名索引设计问题？**\n\n\n> 如果你在维护一个学校的学生信息数据库，学生登录名的统一格式是”学号@gmail.com\", 而学号的规则是：十五位的数字，其中前三位是所在城市编号、第四到第六位是学校编号、第七位到第十位是入学年份、最后五位是顺序编号。\n系统登录的时候都需要学生输入登录名和密码，验证正确后才能继续使用系统。就只考虑登录验证这个行为的话，你会怎么设计这个登录名的索引呢？\n\n\n\n`**设计思路：**`\n\n\n- 由于这个学号的规则，无论是正向还是反向的前缀索引，重复度都比较高。因为维护的只是一个学校的，因此前面6位（其中，前三位是所在城市编号、第四到第六位是学校编号）其实是固定的，邮箱后缀都是@gamil.com，因此可以只存入学年份加顺序编号，它们的长度是9位。\n- 而其实在此基础上，可以用数字类型来存这9位数字。比如201100001，这样只需要占4个字节。其实这个就是一种hash，只是它用了最简单的转换规则：字符串转数字的规则，而刚好我们设定的这个背景，可以保证这个转换后结果的唯一性。\n\n\n\n### 为什么我的MySQL会“抖”一下\n\n\n- 一条SQL语句，正常执行的时候特别快，但是有时也不知道怎么回事，它就会变得特别慢，并且这样的场景很难复现，它不只随机，而且持续时间还很短。看上去，这就像是数据库“抖”了一下\n- 在MySQL里，如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程IO成本、查找成本都很高。为了解决这个问题，MySQL的设计者使用了`WAL技术`，WAL的全称是Write-Ahead Logging，它的关键点就是`先写日志，再写磁盘`。\n- 利用WAL技术，数据库将随机写转换成了顺序写，大大提升了数据库的性能。但是，由此也带来了内存脏页的问题。脏页会被后台线程自动flush，也会由于数据页淘汰而触发flush，而刷脏页的过程由于会占用资源，可能会让你的更新和查询语句的响应时间长一些\n- 当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”。\n- 平时执行很快的更新操作，其实就是在写内存和日志，而MySQL偶尔“抖”一下的那个瞬间，可能就是在刷脏页（`flush`）。\n\n\n\n**什么情况会引发数据库的flush过程呢？**\n\n\n- `InnoDB`在处理更新语句的时候，只做了写日志这一个磁盘操作。这个日志叫作redo log（重做日志）。在更新内存写完`redo log`后，就返回给客户端，本次更新成功。\n- `InnoDB`的`redo log`(重做日志)写满了。这时候系统会停止所有更新操作，把`checkpoint(检查点)`往前推进，`redo log`留出空间可以继续写\n- 第二种场景是：对应的就是系统内存不足。当需要新的内存页，而内存不够用的时候，就要淘汰一些数据页，空出内存给别的数据页使用。如果淘汰的是“脏页”，就要先将脏页写到磁盘。\n- 第三种场景就是`MySQL`认为系统`“空闲”`的时候。也要见缝插针地找时间，只要有机会就刷一点`“脏页”`\n- 第四种场景就是`MySQL正常关闭的情况`。这时候，MySQL会把内存的脏页都flush到磁盘上，这样下次MySQL启动的时候，就可以直接从磁盘上读数据，启动速度会很快。\n\n\n\n**分析一下上面四种场景对性能的影响**\n\n\n- `第一种是“redo log写满了，要flush脏页”`，这种情况是InnoDB要尽量避免的。因为出现这种情况的时候，整个系统就不能再接受更新了，所有的更新都必须堵住。如果你从监控上看，这时候更新数会跌为0。\n- `第二种是“内存不够用了，要先将脏页写到磁盘”`，这种情况其实是常态。InnoDB用缓冲池（buffer pool）管理内存，缓冲池中的内存页有三种状态：第一种是，还没有使用的；第二种是，使用了并且是干净页；第三种是，使用了并且是脏页。InnoDB的策略是尽量使用内存，因此对于一个长时间运行的库来说，未被使用的页面很少。\n- 而当要读入的数据页没有在内存的时候，就必须到缓冲池中申请一个数据页。这时候只能把最久不使用的数据页从内存中淘汰掉：如果要淘汰的是一个干净页，就直接释放出来复用；但如果是脏页呢，就必须将脏页先刷到磁盘，变成干净页后才能复用。\n- 所以，刷脏页虽然是常态，但是出现以下这两种情况，都是会明显影响性能的：一个查询要淘汰的脏页个数太多，会导致查询的响应时间明显变长；日志写满，更新全部堵住，写性能跌为0，这种情况对敏感业务来说，是不能接受的。\n\n\n\n**InnoDB刷脏页的控制策略**\n\n\n- 首先，你要正确地告诉`InnoDB`所在主机的`IO能力`，这样`InnoDB`才能知道需要全力刷脏页的时候，可以刷多快。这就要用到`innodb_io_capacity`这个参数了，它会告诉`InnoDB`你的磁盘能力。这个值我建议你设置成`磁盘的IOPS`。\n- 假设有这样一个场景：`MySQL的写入速度很慢，TPS很低`，但是数据库主机的`IO压力并不大`。主机磁盘用的是SSD，但是`innodb_io_capacity`的值设置的是`300`。于是，InnoDB认为这个系统的能力就这么差，所以刷脏页刷得特别慢，甚至比脏页生成的速度还慢，这样就造成了脏页累积，影响了查询和更新性能。\n- `InnoDB`的刷盘速度就是要参考这两个因素：一个是`脏页比例`，一个是`redo log写盘速度`。\n- 参数`innodb_max_dirty_pages_pct`是`脏页比例上限`，默认值是`75%`。InnoDB会根据当前的脏页比例（假设为M），算出一个范围在0到100之间的数字。`InnoDB`每次写入的日志`都有一个序号`，当前写入的序号跟`checkpoint`对应的序号之间的差值。我们假设为N。InnoDB会根据这个N算出一个范围在0到100之间的数字，这个计算公式可以记为F2(N)。F2(N)算法比较复杂，你只要知道N越大，算出来的值越大就好了。\n- 然后，根据上述算得的F1(M)和F2(N)两个值，取其中较大的值记为R，之后引擎就可以按照`innodb_io_capacity`定义的能力乘以`R%`来控制刷脏页的速度。\n\n\n\n![](https://img-blog.csdnimg.cn/2019041513510966.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=GVQMh&originHeight=1522&originWidth=1142&originalType=binary&ratio=1&status=done&style=none)\n\n\n- InnoDB会在后台刷脏页，而刷脏页的过程是要将内存页写入磁盘。所以，无论是你的查询语句在需要内存的时候可能要求淘汰一个脏页，还是由于刷脏页的逻辑会占用IO资源并可能影响到了你的更新语句，都可能是造成你从业务端感知到MySQL“抖”了一下的原因。\n- 要尽量避免这种情况，你就要合理地设置`innodb_io_capacity的值`，并且平时要多关注脏页比例，不要让它经常接近`75%`。\n\n\n\n> 脏页比例是通过Innodb_buffer_pool_pages_dirty/Innodb_buffer_pool_pages_total得到的\n\n\n\n```sql\nmysql> select VARIABLE_VALUE into @a from global_status where VARIABLE_NAME = 'Innodb_buffer_pool_pages_dirty';\nselect VARIABLE_VALUE into @b from global_status where VARIABLE_NAME = 'Innodb_buffer_pool_pages_total';\nselect @a/@b;\n```\n\n\n- 一旦一个查询请求需要在执行过程中先flush掉一个脏页时，这个查询就可能要比平时慢了。而MySQL中的一个机制，可能让你的查询会更慢：在准备刷一个脏页的时候，如果这个数据页旁边的数据页刚好是脏页，就会把这个“邻居”也带着一起刷掉；而且这个把“邻居”拖下水的逻辑还可以继续蔓延，也就是对于每个邻居数据页，如果跟它相邻的数据页也还是脏页的话，也会被放到一起刷。\n- 在InnoDB中，`innodb_flush_neighbors` 参数就是用来控制这个行为的，`值为1`的时候会有上述的`“连坐”机制`，`值为0时`表示不找邻居，自己刷自己的。\n- 找`“邻居”`这个优化在`机械硬盘时代是很有意义`的，可以`减少很多随机IO`。机械硬盘的随机`IOPS`一般只有几百，相同的逻辑操作减少随机IO就意味着系统性能的大幅度提升。\n- 而如果使用的是`SSD这类IOPS比较高的设备`的话，我就建议你把`innodb_flush_neighbors`的值设置成0。因为这时候`IOPS`往往不是瓶颈，而`“只刷自己”`，就能更快地执行完必要的刷脏页操作，减少SQL语句响应时间。\n- 在MySQL 8.0中`，innodb_flush_neighbors参数的默认值已经是0`了。\n\n\n\n### 为什么表数据删掉一半，表文件大小不变\n\n\n- 一个InnoDB表包含两部分，即：表结构定义和数据。在MySQL 8.0版本以前，表结构是存在以.frm为后缀的文件里。\n- 表数据既可以存在共享表空间里，也可以是单独的文件。这个行为是由参数`innodb_file_per_table`控制的，设置为`OFF`表示的是，表的数据放在`系统共享表空间`，也就是跟数据字典放在一起；设置为`ON`表示的是，每个InnoDB表数据存储在一个以 `.ibd`为后缀的文件中。从`MySQL 5.6.6`版本开始，它的`默认值就是ON`了\n- 建议你不论使用MySQL的哪个版本，都将这个值设置为ON。因为，一个表单独存储为一个文件更容易管理，而且在你不需要这个表的时候，通过`drop table`命令，系统就会直接删除这个文件。而如果是放在共享表空间中，即使表删掉了，空间也是不会回收的。\n- 我们在删除整个表的时候，可以使用drop table命令回收表空间。但是，我们遇到的更多的删除数据的场景是删除某些行，表中的数据被删除了，但是表空间却没有被回收。\n\n\n\n**数据删除流程**\n\n\n![](https://img-blog.csdnimg.cn/20190416104535458.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=roWLU&originHeight=478&originWidth=603&originalType=binary&ratio=1&status=done&style=none)\n\n\n- 假设，我们要删掉R4这个记录，InnoDB引擎只会把R4这个记录标记为删除。如果之后要再插入一个ID在300和600之间的记录时，可能会复用这个位置。但是，磁盘文件的大小并不会缩小。\n- InnoDB的数据是按页存储的，那么如果我们删掉了一个数据页上的所有记录，整个数据页就可以被复用了。\n- 但是，数据页的复用跟记录的复用是不同的。记录的复用，只限于符合范围条件的数据，比如R4这条记录被删除后，如果插入一个ID是400的行，可以直接复用这个空间。但如果插入的是一个ID是800的行，就不能复用这个位置了。\n- 而当整个页从B+树里面摘掉以后，可以复用到任何位置。如果相邻的两个数据页利用率都很小，系统就会把这两个页上的数据合到其中一个页上，另外一个数据页就被标记为可复用。\n- 所以如果我们用delete命令把整个表的数据删除，结果就是，所有的数据页都会被标记为可复用。但是磁盘上，文件不会变小。也就是说，通过delete命令是不能回收表空间的。这些可以复用，而没有被使用的空间，看起来就像是`“空洞”`。\n- 实际上，不止是删除数据会造成空洞，插入数据也会。如果数据是按照索引递增顺序插入的，那么索引是紧凑的。但如果数据是随机插入的，就可能造成索引的数据页分裂。另外，更新索引上的值，可以理解为删除一个旧的值，再插入一个新值。不难理解，这也是会造成空洞的。\n\n\n\n**重建表**\n\n\n- 重建表就是新建一个与表A结构相同的表B，然后按照主键ID递增的顺序，把数据一行一行地从表A里读出来再插入到表B中。由于表B是新建的表，所以表A主键索引上的空洞，在表B中就都不存在了。\n- 可以使用`alter table A engine=InnoDB`命令来重建表。MySQL 5.5之后会自动完成转存数据、交换表名、删除旧表的操作。\n- 重建表的过程中，如果中途有新的数据要写入，就会造成数据丢失。所以在整个`DDL`过程中，表A中不能有更新。也就是说，这个DDL不是`Online`的。在MySQL 5.6版本开始引入的`Online DDL`，对这个操作流程做了优化。\n- 对于很大的表来说，这个操作是很消耗IO和CPU资源的。想要比较安全的操作的话，推荐使用`GitHub`开源的[gh-ost](https://github.com/github/gh-ost)来做。\n\n\n\n**MySQL执行DDL()原理**\n\n\n- `DML`：它们是SELECT、UPDATE、INSERT、DELETE，就象它的名字一样，这4条命令是用来对数据库里的数据进行操作的语言\n- `DDL`：DDL比DML要多，主要的命令有CREATE、ALTER、DROP等，DDL主要是用在定义或改变表(TABLE)的结构，数据类型，表之间的链接和约束等初始化工作上，他们大多在建立表时使用\n- `DCL`：是数据库控制功能。是用来设置或更改数据库用户或角色权限的语句\n- MySQL各版本，对于DDL的处理方式是不同的，主要有三种：\n- `Copy Table`方式：这是InnoDB最早支持的方式。通过临时表拷贝的方式实现的。新建一个带有新结构的临时表，将原表数据全部拷贝到临时表，然后Rename，完成创建操作。这个方式过程中，`原表是可读的，不可写`。但是`会消耗一倍的存储空间`。\n- `Inplace`方式：这是原生MySQL 5.5，以及`innodb_plugin`中提供的方式。所谓Inplace，也就是在`原表上直接进行，不会拷贝临时表`。相对于Copy Table方式，这比较高效率。`原表同样可读的，但是不可写`。\n- `Online方式`：MySQL 5.6以上版本中提供的方式，无论是Copy Table方式，还是Inplace方式，`原表只能允许读取，不可写`。对应用有较大的限制，因此MySQL最新版本中，InnoDB支持了所谓的`Online方式DDL`。与以上两种方式相比，`online方式支持DDL时不仅可以读，还可以写`\n\n\n\n### count(*)语句到底是怎样实现的\n\n\n- 在不同的MySQL引擎中，count(*)有不同的实现方式。\n- `MyISAM引擎`把一个表的总行数存在了磁盘上，因此执行`count(*)`的时候会直接返回这个数，效率很高。这里讨论的是没有过滤条件的count(*)，如果加了where 条件的话，MyISAM表也是不能返回得这么快的。\n- `InnoDB引擎`就麻烦了，它执行count(*)的时候，需要把数据一行一行地从引擎里面读出来，然后累积计数。\n\n\n\n**为什么InnoDB不跟MyISAM一样，也把数字存起来呢？**\n\n\n- 这是因为即使是在同一个时刻的多个查询，由于`多版本并发控制`（MVCC）的原因，InnoDB表“应该返回多少行”也是不确定的。\n- 这和InnoDB的事务设计有关系，`可重复读是它默认的隔离级别`，在代码上就是通过多版本并发控制，也就是MVCC来实现的。每一行记录都要判断自己是否对这个会话可见，因此对于count(*)请求来说，InnoDB只好把数据一行一行地读出依次判断，可见的行才能够用于计算“基于这个查询”的表的总行数。\n- `InnoDB是索引组织表`，`主键索引树的叶子节点是数据`，而`普通索引树的叶子节点是主键值`。所以，普通索引树比主键索引树小很多。对于count(*)这样的操作，遍历哪个索引树得到的结果逻辑上都是一样的。因此，MySQL优化器会找到最小的那棵树来遍历。在保证逻辑正确的前提下，尽量减少扫描的数据量，是数据库系统设计的通用法则之一。\n- MyISAM表虽然count(_)很快，但是不支持事务；show table status命令虽然返回很快，但是不准确；InnoDB表直接count(_)会遍历全表，虽然结果准确，但会导致性能问题。\n\n\n\n### 不同的count用法\n\n\n`select count(?) from t`这样的查询语句里面，`count(*)、count(主键id)、count(字段)和count(1)`等不同用法的性能，有哪些差别。\n\n\n- count()是一个聚合函数，对于返回的结果集，一行行地判断，如果count函数的参数不是NULL，累计值就加1，否则不加。最后返回累计值。\n- 所以，count(*)、count(主键id)和count(1) 都表示返回满足条件的结果集的总行数；而count(字段），则表示返回满足条件的数据行里面，参数“字段”不为NULL的总个数。\n- `对于count(主键id)来说`，InnoDB引擎会遍历整张表，把每一行的id值都取出来，返回给server层。server层拿到id后，判断是不可能为空的，就按行累加。\n- `对于count(1)来说`，InnoDB引擎遍历整张表，但不取值。server层对于返回的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加。\n- `对于count(字段)来说`：如果这个“字段”是定义为not null的话，一行行地从记录里面读出这个字段，判断不能为null，按行累加；如果这个“字段”定义允许为null，那么执行的时候，判断到有可能是null，还要把值取出来再判断一下，不是null才累加。\n- count(_)是例外：并不会把全部字段取出来，而是专门做了优化，不取值。count(_)肯定不是null，按行累加。\n- 所以结论是：按照效率排序的话，count(字段)<count(主键id)<count(1)≈count(_)，所以我建议你，尽量使用count(_)。\n\n\n\n### order by是怎么工作的\n\n\n首先创建一个测试表  `t_city`\n\n\n```sql\nCREATE TABLE `t_city` (\n  `id` int(11) NOT NULL,\n  `city` varchar(16) NOT NULL,\n  `name` varchar(16) NOT NULL,\n  `age` int(11) NOT NULL,\n  `addr` varchar(128) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  KEY `city` (`city`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8;\n```\n\n\n使用存储过程 添加10W条测试数据\n\n\n```sql\ndelimiter ;;\ncreate procedure idata2()\nbegin\n  declare i int;\n  set i=1;\n  while(i<=10000)do\n    insert into t_city values(i,'广州', i,i,i);\n    set i=i+1;\n  end while;\nend;;\ndelimiter ;\ncall idata2();\n```\n\n\n比如有如下sql语句，为避免全表扫描，已经在city字段加上索引\n\n\n```sql\nselect city,name,age from t_city where city='广州' order by name limit 1000;\n```\n\n\n这个语句看上去逻辑很清晰， 那吗数据库内部到底是怎样执行的了？\n\n\n首先先用`explain`看看执行计划\n\n\n```sql\nexplain select city,name,age from t_city where city='广州' order by name limit 1000;\n```\n\n\n![](https://img-blog.csdnimg.cn/20190416172638203.png#id=J8vpw&originHeight=52&originWidth=981&originalType=binary&ratio=1&status=done&style=none)\n**先看下个执行计划各参数的含义：**\n\n\n- `select_type`：显 示查询中每个select子句的类型\n- `table`： 显示这一行的数据是关于哪张表的，有时不是真实的表名字\n- `type`：在表中找到所需行的方式，又称“访问类型”。常用的类型有： ALL, index,  range, ref, eq_ref, const, system, NULL（从左到右，性能从差到好）\n- `possible_keys`：指出MySQL能使用哪个索引在表中找到记录，查询涉及到的字段上若存在索引，则该索引将被列出，但不一定被查询使用\n- `Key`：key列显示MySQL实际决定使用的键（索引）\n- `key_len`：表示索引中使用的字节数，可通过该列计算查询中使用的索引的长度，key_len显示的值为索引字段的最大可能长度，并非实际使用长度，不损失精确性的情况下，长度越短越好\n- `ref`：表示上述表的连接匹配条件，即哪些列或常量被用于查找索引列上的值\n- `rows`： 表示MySQL根据表统计信息及索引选用情况，估算的找到所需的记录所需要读取的行数\n- `Extra`：该列包含MySQL解决查询的详细信息。Extra这个字段中的`“Using filesort”表示的就是需要排序`，MySQL会给每个线程分配一块内存用于排序，称为`sort_buffer`。\n\n\n\n![](https://img-blog.csdnimg.cn/20190416174643103.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=qZTfO&originHeight=642&originWidth=655&originalType=binary&ratio=1&status=done&style=none)\n\n\n- 按name排序”这个动作，可能在内存中完成，也可能需要使用外部排序，这取决于排序所需的内存和参数`sort_buffer_size`。\n- `sort_buffer_size`就是MySQL为排序开辟的内存（`sort_buffer`）的大小。如果要排序的数据量小于sort_buffer_size，排序就在内存中完成。但如果排序数据量太大，内存放不下，则不得不利用磁盘临时文件辅助排序。\n\n\n\n> 确定一个排序语句是否使用了临时文件\n\n\n\n```sql\n/* 打开optimizer_trace，只对本线程有效 */\nSET optimizer_trace='enabled=on'; \n\n/* @a保存Innodb_rows_read的初始值 */\nselect VARIABLE_VALUE into @a from  performance_schema.session_status where variable_name = 'Innodb_rows_read';\n\n/* 执行语句 */\nselect city, name,age from t where city='杭州' order by name limit 1000; \n\n/* 查看 OPTIMIZER_TRACE 输出 */\nSELECT * FROM `information_schema`.`OPTIMIZER_TRACE`\n\n/* @b保存Innodb_rows_read的当前值 */\nselect VARIABLE_VALUE into @b from performance_schema.session_status where variable_name = 'Innodb_rows_read';\n\n/* 计算Innodb_rows_read差值 */\nselect @b-@a;\n```\n\n\n这个方法是通过查看 OPTIMIZER_TRACE 的结果来确认的，你可以从 number_of_tmp_files中看到是否使用了临时文件。\n\n\n![](https://img-blog.csdnimg.cn/2019041617592518.png#id=ZWOG8&originHeight=180&originWidth=712&originalType=binary&ratio=1&status=done&style=none)\n\n\n- `number_of_tmp_files`表示的是，排序过程中使用的临时文件数。内存放不下时，就需要使用外部排序，外部排序一般使用归并排序算法。，MySQL将需要排序的数据分成12份，每一份单独排序后存在这些临时文件中。然后把这12个有序文件再合并成一个有序的大文件。\n- 如果`sort_buffer_size`超过了需要排序的数据量的大小，`number_of_tmp_files`就是0，表示排序可以直接在内存中完成。否则就需要放在临时文件中排序。\n- `sort_buffer_size`越小，需要分成的份数越多，`number_of_tmp_files`的值就越大。\n- `sort_mode` 里面的`packed_additional_fields`的意思是，排序过程对字符串做了`“紧凑”`处理。即使name字段的定义是varchar(16)，在排序过程中还是要按照实际长度来分配空间的。\n- 同时，最后一个查询语句select @b-@a 的返回结果是4000，表示整个执行过程只扫描了4000行。\n- 这里需要注意的是，为了避免对结论造成干扰，我把internal_tmp_disk_storage_engine设置成MyISAM。否则，select @b-@a的结果会大于4000\n- 在上面这个算法过程里面，只对原表的数据读了一遍，剩下的操作都是在sort_buffer和临时文件中执行的。但这个算法有一个问题，就是如果查询要返回的字段很多的话，那么sort_buffer里面要放的字段数太多，这样内存里能够同时放下的行数很少，要分成很多个临时文件，排序的性能会很差。\n\n\n\n**如果MySQL认为排序的单行长度太大会怎么做呢？**\n\n\n- `max_length_for_sort_data`，是MySQL中专门控制用于排序的行数据的长度的一个参数。它的意思是，如果单行的长度超过这个值，MySQL就认为单行太大，要换一个算法。\n\n\n\n### 如何正确地显示随机消息\n\n\n从一个单词表中随机选出三个单词\n\n\n创建测试表\n\n\n```sql\n CREATE TABLE `words` (\n  `id` int(11) NOT NULL AUTO_INCREMENT,\n  `word` varchar(64) DEFAULT NULL,\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB;\n```\n\n\n添加测试数据\n\n\n```sql\ndelimiter ;;\ncreate procedure idata3()\nbegin\n  declare i int;\n  set i=0;\n  while i<10000 do\n    insert into words(word) values(concat(char(97+(i div 1000)), char(97+(i % 1000 div 100)), char(97+(i % 100 div 10)), char(97+(i % 10))));\n    set i=i+1;\n  end while;\nend;;\ndelimiter ;\n\ncall idata3();\n```\n\n\n**首先，会想到用order by rand()来实现这个逻辑**\n\n\n```sql\nEXPLAIN select word from words order by rand() limit 3;\n```\n\n\n![](https://img-blog.csdnimg.cn/20190416182846114.png#id=IcAaX&originHeight=98&originWidth=1076&originalType=binary&ratio=1&status=done&style=none)\n\n\n- Extra字段显示`Using temporary`，表示的是需要使用临时表；`Using filesort`，表示的是需要执行排序操作。因此这个Extra的意思就是，需要临时表，并且需要在临时表上排序\n- order by rand()使用了内存临时表，内存临时表排序的时候使用了rowid排序方法。\n- tmp_table_size这个配置限制了内存临时表的大小，默认值是16M。如果临时表大小超过了tmp_table_size，那么内存临时表就会转成磁盘临时表。\n- 磁盘临时表使用的引擎默认是InnoDB，是由参数internal_tmp_disk_storage_engine控制的。当使用磁盘临时表的时候，对应的就是一个没有显式索引的InnoDB表的排序过程。\n\n\n\n### 幻读是什么，幻读有什么问题\n\n\n- 幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。\n- 在可重复读隔离级别下，普通的查询是快照读，是不会看到别的事务插入的数据的。因此，幻读在“当前读”下才会出现。\n\n\n\n**创建测试数据**\n\n\n```sqll\nCREATE TABLE `t` (\n  `id` int(11) NOT NULL,\n  `c` int(11) DEFAULT NULL,\n  `d` int(11) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  KEY `c` (`c`)\n) ENGINE=InnoDB;\n\ninsert into t values(0,0,0),(5,5,5),\n(10,10,10),(15,15,15),(20,20,20),(25,25,25);\n```\n\n\n**下面的语句序列，是怎么加锁的，加的锁又是什么时候释放的呢？**\n\n\n```sql\nbegin;\nselect * from t where d=5 for update;\ncommit;\n```\n\n\n- 这个语句会命中d=5的这一行，对应的主键id=5，因此在select 语句执行完成后，id=5这一行会加一个写锁，而且由于两阶段锁协议，这个写锁会在执行commit语句的时候释放。\n- 由于字段d上没有索引，因此这条查询语句会做全表扫描。那么，其他被扫描到的，但是不满足条件的5行记录上，会不会被加锁呢？\n\n\n\n![](https://img-blog.csdnimg.cn/20190418165218311.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=GPJCV&originHeight=688&originWidth=984&originalType=binary&ratio=1&status=done&style=none)\n\n\n- 可以看到，session A里执行了三次查询，分别是Q1、Q2和Q3。它们的SQL语句相同，都是select * from t where d=5 for update。这个语句的意思你应该很清楚了，查所有d=5的行，而且使用的是当前读，并且加上写锁\n\n\n\n**图中SQL执行流程**\n\n\n- Q1只返回id=5这一行；\n- 在T2时刻，session B把id=0这一行的d值改成了5，因此T3时刻Q2查出来的是id=0和id=5这两行；\n- 在T4时刻，session C又插入一行（1,1,5），因此T5时刻Q3查出来的是id=0、id=1和id=5的这三行。\n- 其中，Q3读到id=1这一行的现象，被称为`“幻读”`。\n- 在`可重复读`(InnoDB的默认)隔离级别下，普通的查询是快照读，是不会看到别的事务插入的数据的。因此，`幻读在“当前读”下才会出现。`\n- 上面session B的修改结果，被session A之后的select语句用“当前读”看到，不能称为幻读。幻读仅专指“新插入的行”\n\n\n\n从事务可见性规则来分析的话，上面这三条SQL语句的返回结果都没有问题。因为这三个查询都是加了for update，都是当前读。而当前读的规则，就是要能读到所有已经提交的记录的最新值。并且，session B和sessionC的两条语句，执行后就会提交，所以Q2和Q3就是应该看到这两个事务的操作效果，而且也看到了，这跟事务的可见性规则并不矛盾。但是，这是不是真的没问题呢？\n\n\n**幻读有什么问题？**\n\n\n- 首先是语义上的。session A在T1时刻就声明了，“我要把所有d=5的行锁住，不准别的事务进行读写操作”。而实际上，这个语义被破坏了。\n\n\n\n**其次，是数据一致性的问题。**\n\n\n- 我们知道，锁的设计是为了保证数据的一致性。而这个一致性，不止是数据库内部数据状态在此刻的一致性，还包含了数据和日志在逻辑上的一致性\n- 为了说明这个问题，我给session A在T1时刻再加一个更新语句，即：update t set d=100 where d=5。\n  ![](https://img-blog.csdnimg.cn/20190418171046246.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=Wyaze&originHeight=551&originWidth=929&originalType=binary&ratio=1&status=done&style=none)\n  **上面的执行流程**\n- 经过T1时刻，id=5这一行变成 (5,5,100)，当然这个结果最终是在T6时刻正式提交的;\n- 经过T2时刻，id=0这一行变成(0,5,5);\n- 经过T4时刻，表里面多了一行(1,5,5);\n\n\n\n这样看，这些数据也没啥问题，但是我们再来看看这时候binlog里面的内容。\n\n\n- T2时刻，session B事务提交，写入了两条语句；\n- T4时刻，session C事务提交，写入了两条语句；\n- T6时刻，session A事务提交，写入了update t set d=100 where d=5 这条语句。\n\n\n\n放到一起的话，就是这样的：\n\n\n```sql\nupdate t set d=5 where id=0; /*(0,0,5)*/\nupdate t set c=5 where id=0; /*(0,5,5)*/\n\ninsert into t values(1,1,5); /*(1,1,5)*/\nupdate t set c=5 where id=1; /*(1,5,5)*/\n\nupdate t set d=100 where d=5;/*所有d=5的行，d改成100*/\n```\n\n\n> 这个语句序列，不论是拿到备库去执行，还是以后用binlog来克隆一个库，这三行的结果，都变成了 (0,5,100)、(1,5,100)和(5,5,100)。也就是说，id=0和id=1这两行，发生了数据不一致。这个问题很严重，是不行的。\n\n\n\n**如何解决幻读？**\n\n\n- 产生幻读的原因是，行锁只能锁住行，但是新插入记录这个动作，要更新的是记录之间的“间隙”。因此，为了解决幻读问题，InnoDB只好引入新的锁，也就是间隙锁(Gap Lock)。\n- 间隙锁，锁的就是两个值之间的空隙。比如文章开头的表t，初始化插入了6个记录，这就产生了7个间隙。\n- 这样，当你执行 select * from t where d=5 for update的时候，就不止是给数据库中已有的6个记录加上了行锁，还同时加了7个间隙锁。这样就确保了无法再插入新的记录。\n- 也就是说这时候，在一行行扫描的过程中，不仅将给行加上了行锁，还给行两边的空隙，也加上了间隙锁。\n- 间隙锁存在冲突关系的，是“往这个间隙中插入一个记录”这个操作。间隙锁之间都不存在冲突关系。\n- 间隙锁和next-key lock的引入，帮我们解决了幻读的问题，但同时也带来了一些“困扰”\n\n\n\n> 比如现在有这样一个场景 业务逻辑这样的：任意锁住一行，如果这一行不存在的话就插入，如果存在这一行就更新它的数据，代码如下：\n\n\n\n```sql\nbegin;\nselect * from t where id=N for update;\n\n/*如果行不存在*/\ninsert into t values(N,N,N);\n/*如果行存在*/\nupdate t set d=N set id=N;\n\ncommit;\n```\n\n\n> 可能你会说，这个不是`insert ... on duplicate key update` 就能解决吗？但其实在有多个唯一键的时候,这个方法是不能满足要求的。这个逻辑一旦有并发，就会碰到死锁。你一定也觉得奇怪，这个逻辑每次操作前用for update锁起来，已经是最严格的模式了，怎么还会有死锁呢？\n\n\n\n![](https://img-blog.csdnimg.cn/20190418172853342.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=n7URX&originHeight=372&originWidth=982&originalType=binary&ratio=1&status=done&style=none)\n你看到了，其实都不需要用到后面的update语句，就已经形成死锁了。我们按语句执行顺序来分析一下：\n\n\n- session A 执行select ... for update语句，由于id=9这一行并不存在，因此会加上间隙锁(5,10);\n- session B 执行select ... for update语句，同样会加上间隙锁(5,10)，间隙锁之间不会冲突，因此这个语句可以执行成功；\n- session B 试图插入一行(9,9,9)，被session A的间隙锁挡住了，只好进入等待；\n- session A试图插入一行(9,9,9)，被session B的间隙锁挡住了。\n- 至此，两个session进入互相等待状态，形成死锁。当然，InnoDB的死锁检测马上就发现了这对死锁关系，让session A的insert语句报错返回了。\n\n\n\n> `间隙锁是在可重复读隔离级别下才会生效的`。所以，你如果把隔离级别设置为读提交的话，就没有间隙锁了。但同时，你要解决可能出现的数据和日志不一致问题，需要把`binlog`格式设置为row。这，也是现在不少公司使用的配置组合。\n\n","slug":"MySQL学习笔记","published":1,"_id":"ckttol7iw00074cvu4xsa305a","comments":1,"layout":"post","photos":[],"link":"","content":"<h3 id=\"一条SQL查询语句是如何执行的\"><a href=\"#一条SQL查询语句是如何执行的\" class=\"headerlink\" title=\"一条SQL查询语句是如何执行的\"></a>一条SQL查询语句是如何执行的</h3><figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql<span class=\"operator\">&gt;</span> <span class=\"keyword\">select</span> <span class=\"operator\">*</span> <span class=\"keyword\">from</span> T <span class=\"keyword\">where</span> ID<span class=\"operator\">=</span><span class=\"number\">10</span>；</span><br></pre></td></tr></table></figure>\n\n\n<p><img src=\"https://img-blog.csdnimg.cn/20190410210326412.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=Mnrxq&originHeight=798&originWidth=1086&originalType=binary&ratio=1&status=done&style=none\"></p>\n<blockquote>\n<p>大体来说，MySQL可以分为<code>Server</code>层和<code>存储引擎</code>层两部分</p>\n</blockquote>\n<ul>\n<li><code>Server</code>层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖MySQL的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。</li>\n<li><code>存储引擎层</code>负责数据的存储和提取。其架构模式是插件式的，支持InnoDB、MyISAM、Memory等多个存储引擎。现在最常用的存储引擎是InnoDB，它从MySQL 5.5.5版本开始成为了默认存储引擎。</li>\n<li>不同的存储引擎共用一个Server层，也就是从连接器到执行器的部分</li>\n<li></li>\n</ul>\n<p><strong>连接器</strong></p>\n<ul>\n<li>第一步，你会先连接到这个数据库上，这时候接待你的就是连接器。连接器负责跟客户端建立连接、获取权限、维持和管理连接。连接完成后，如果你没有后续的动作，这个连接就处于空闲状态，你可以在<code>show processlist</code>命令中看到它。客户端如果太长时间没动静，连接器就会自动将它断开。这个时间是由参数<code>wait_timeout</code>控制的，默认值是<code>8</code>小时。数据库里面，长连接是指连接成功后，如果客户端持续有请求，则一直使用同一个连接。短连接则是指每次执行完很少的几次查询就断开连接，下次查询再重新建立一个。</li>\n</ul>\n<p><strong>查询缓存</strong></p>\n<ul>\n<li>连接建立完成后，你就可以执行select语句了。执行逻辑就会来到第二步：查询缓存。</li>\n<li>MySQL拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。之前执行过的语句及其结果可能会以key-value对的形式，被直接缓存在内存中。key是查询的语句，value是查询的结果。如果你的查询能够直接在这个缓存中找到key，那么这个value就会被直接返回给客户端。</li>\n<li>如果语句不在查询缓存中，就会继续后面的执行阶段。执行完成后，执行结果会被存入查询缓存中。</li>\n</ul>\n<blockquote>\n<p>大多数情况下我会建议你不要使用查询缓存，为什么呢？因为查询缓存往往弊大于利。查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。</p>\n</blockquote>\n<p><strong>分析器</strong></p>\n<ul>\n<li>如果没有命中查询缓存，就要开始真正执行语句了。首先，MySQL需要知道你要做什么，因此需要对SQL语句做解析。分析器先会做<code>“词法分析”</code>,词法分析完后就要做<code>“语法分析”</code>。根据词法分析的结果，语法分析器会根据语法规则，判断你输入的这个SQL语句是否满足MySQL语法。如果你的语句不对，就会收到“You have an error in your SQL syntax”的错误提醒</li>\n</ul>\n<p><strong>优化器</strong></p>\n<ul>\n<li>经过了分析器，MySQL就知道你要做什么了。在开始执行之前，还要先经过优化器的处理。</li>\n<li>优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。</li>\n</ul>\n<blockquote>\n<p>比如你执行下面这样的语句，这个语句是执行两个表的join：<br><code>mysql&gt; select * from t1 join t2 using(ID) where t1.c=10 and t2.d=20;</code><br>既可以先从表t1里面取出c=10的记录的ID值，再根据ID值关联到表t2，再判断t2里面d的值是否等于20。<br>也可以先从表t2里面取出d=20的记录的ID值，再根据ID值关联到t1，再判断t1里面c的值是否等于10。<br>这两种执行方法的逻辑结果是一样的，但是执行的效率会有不同，而优化器的作用就是决定选择使用哪一个方案。</p>\n</blockquote>\n<p><strong>执行器</strong></p>\n<ul>\n<li>MySQL通过分析器知道了你要做什么，通过优化器知道了该怎么做，于是就进入了执行器阶段，开始执行语句。</li>\n<li>开始执行的时候，要先判断一下你对这个表T有没有执行查询的权限，如果没有，就会返回没有权限的错误</li>\n<li>如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。</li>\n</ul>\n<blockquote>\n<p><code>mysql&gt; select * from T where ID=10;</code><br>比如我们这个例子中的表T中，ID字段没有索引，那么执行器的执行流程是这样的：<br>调用InnoDB引擎接口取这个表的第一行，判断ID值是不是10，如果不是则跳过，如果是则将这行存在结果集中；<br>调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。<br>执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。</p>\n</blockquote>\n<ul>\n<li>至此，这个整个语句就执行完成了。一条查询语句的执行过程一般是经过连接器、分析器、优化器、执行器等功能模块，最后到达存储引擎。</li>\n</ul>\n<h3 id=\"一条SQL更新语句是如何执行的\"><a href=\"#一条SQL更新语句是如何执行的\" class=\"headerlink\" title=\"一条SQL更新语句是如何执行的\"></a>一条SQL更新语句是如何执行的</h3><figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">update T <span class=\"keyword\">set</span> c<span class=\"operator\">=</span>c<span class=\"operator\">+</span><span class=\"number\">1</span> <span class=\"keyword\">where</span> ID<span class=\"operator\">=</span><span class=\"number\">2</span>;</span><br></pre></td></tr></table></figure>\n\n\n<ul>\n<li>与查询流程不一样的是，更新流程还涉及两个重要的日志模块 <code>redo log</code>（重做日志）和 <code>binlog</code>（归档日志）</li>\n<li>每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程IO成本、查找成本都很高。为了解决这个问题，MySQL的设计者WAL技术，WAL的全称是Write-Ahead Logging，它的关键点就是<code>先写日志</code>，<code>再写磁盘</code></li>\n<li>当有一条记录需要更新的时候，InnoDB引擎就会先把记录写到redo log里面，并更新内存，这个时候更新就算完成了。</li>\n<li>同时，<code>InnoDB</code>引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做。但是<code>InnoDB</code>的<code>redo log</code>是固定大小的，比如可以配置为一组4个文件，每个文件的大小是1GB,总共就可以记录4GB的操作。从头开始写，写到末尾就又回到开头循环写。</li>\n<li>在进行<code>redo log</code>写入时，有两个重要参数的write pos(当前记录的位置),<code>checkpoint</code>是当前要擦除的位置<br><img src=\"https://img-blog.csdnimg.cn/20190410230340406.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=evnl5&originHeight=272&originWidth=884&originalType=binary&ratio=1&status=done&style=none\"></li>\n<li>一边写一边后移，写到第3号文件末尾后就回到0号文件开头,checkpoint也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。write pos和checkpoint之间还空着的部分，可以用来记录新的操作。</li>\n<li>如果<code>write pos</code>追上<code>checkpoin</code>，表示<code>redo log</code>满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把checkpoint推进一下。</li>\n<li>有了redo log，InnoDB就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为crash-safe(崩溃安全()。</li>\n<li>redo log是InnoDB引擎特有的日志，而Server层也有自己的日志，称为binlog（归档日志）</li>\n<li>最开始MySQL里并没有<code>InnoDB引擎</code>。MySQL自带的引擎是MyISAM，但是MyISAM没有crash-safe的能力，binlog日志只能用于归档。而InnoDB是另一个公司以插件形式引入MySQL的，既然只依靠binlog是没有crash-safe能力的，所以InnoDB使用另外一套日志系统——也就是redo log来实现crash-safe能力。</li>\n</ul>\n<blockquote>\n<p><code>redo log是InnoDB引擎特有的</code>；binlog是MySQL的Server层实现的，所有引擎都可以使用。<br><code>redo log是物理日志</code>，记录的是“在某个数据页上做了什么修改”；<code>binlog是逻辑日志</code>，记录的是这个语句的原始逻辑，比如“给ID=2这一行的c字段加1 ”。<br>r<code>edo log是循环写的</code>，<code>空间固定</code>会用完；<code>binlog是可以追加写入的</code>。“追加写”是指binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。</p>\n</blockquote>\n<p><strong>执行器和InnoDB引擎在执行这个简单的update语句时的内部流程:</strong></p>\n<ul>\n<li>执行器先找引擎取ID=2这一行。ID是主键，引擎直接用树搜索找到这一行。如果ID=2这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。</li>\n<li>执行器拿到引擎给的行数据，把这个值加上1，比如原来是N，现在就是N+1，得到新的一行数据，再调用引擎接口写入这行新数据。</li>\n<li>引擎将这行新数据更新到内存中，同时将这个更新操作记录到redo log里面，此时redo log处于prepare状态。然后告知执行器执行完成了，随时可以提交事务。</li>\n<li>执行器生成这个操作的binlog，并把binlog写入磁盘。</li>\n<li>执行器调用引擎的提交事务接口，引擎把刚刚写入的redo log改成提交（commit）状态，更新完成。</li>\n<li>redo log的写入拆成了两个步骤：prepare和commit，这就是<code>&quot;两阶段提交&quot;</code>。</li>\n</ul>\n<p><img src=\"https://img-blog.csdnimg.cn/2019041023325625.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=tDmdi&originHeight=1522&originWidth=1142&originalType=binary&ratio=1&status=done&style=none\"></p>\n<blockquote>\n<p><code>1 prepare阶段 2 写binlog 3 commit</code> , 当在<code>2之前崩溃时</code>,重启恢复：后发现没有commit，回滚。备份恢复：没有binlog 。<br><code>当在3之前崩溃</code>,重启恢复：虽没有commit，但满足prepare和binlog完整，所以重启后会自动commit。备份：有binlog. 一致</p>\n</blockquote>\n<h4 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h4><ul>\n<li>Redo log不是记录数据页“更新之后的状态”，而是记录这个页 “做了什么改动”。</li>\n<li>Binlog有两种模式，statement 格式的话是记sql语句， row格式会记录行的内容，记两条，更新前和更新后都有。</li>\n</ul>\n<h3 id=\"事务隔离：为什么你改了我还看不见\"><a href=\"#事务隔离：为什么你改了我还看不见\" class=\"headerlink\" title=\"事务隔离：为什么你改了我还看不见\"></a>事务隔离：为什么你改了我还看不见</h3><ul>\n<li>事务就是要保证一组数据库操作，要么全部成功，要么全部失败。在MySQL中，事务支持是在引擎层实现的。MySQL默认的<code>MyISAM</code>引擎就不支持事务，这也是<code>MyISAM</code>被<code>InnoDB</code>取代的重要原因之一。</li>\n<li>事务的特性：<code>ACID</code>即原子性、一致性、隔离性、持久性。多个事务同时执行的时候，就可能出现<code>脏读</code>，<code>不可重复读</code>，<code>幻读</code>，为了解决这些问题，就有了“<code>隔离级别</code>”的概念。但是隔离得越严实，效率就会越低</li>\n<li>SQL标准的事务隔离级别包括：<code>读未提交</code>（read uncommitted）、<code>读提交</code>（read committed）、<code>可重复读</code>（repeatable read）和<code>串行化</code>（serializable ）</li>\n</ul>\n<blockquote>\n<p>读未提交是指，一个事务还没提交时，它做的变更就能被别的事务看到。<br>读提交是指，一个事务提交之后，它做的变更才会被其他事务看到。<br>可重复读是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。未提交的更改对其他事务是不可见的<br>串行化:对应一个记录会加读写锁，出现冲突的时候，后访问的事务必须等前一个事务执行完成才能继续执行</p>\n</blockquote>\n<ul>\n<li>在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。在“<code>可重复读</code>”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。在<code>“读提交”</code>隔离级别下，这个视图是在每个SQL语句开始执行的时候创建的。<code>“读未提交”</code>隔离级别下直接返回记录上的最新值，没有视图概念。<code>串行化</code>”隔离级别下直接用加锁的方式来避免并行访问</li>\n<li>查看数据库的实物隔离级别：<code>show variables like &#39;%isolation%&#39;;</code></li>\n<li>事务隔离的实现：在MySQL中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。</li>\n</ul>\n<p>假设一个值从1被按顺序改成了2、3、4，在回滚日志里面就会有类似下面的记录。不同时刻启动的事务会有不同的read-view，同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（<code>MVCC</code>）<br><img src=\"https://img-blog.csdnimg.cn/20190411130916709.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=AC58n&originHeight=407&originWidth=973&originalType=binary&ratio=1&status=done&style=none\"></p>\n<ul>\n<li>回滚日志总不能一直保留吧，什么时候删除呢？答案是，在不需要的时候才删除。系统会判断，当没有事务再需要用到这些回滚日志时，回滚日志会被删除。什么时候才不需要了呢？就是当系统里没有比这个回滚日志更早的read-view的时候。</li>\n<li>为什么尽量不要使用长事务。长事务意味着系统里面会存在很老的事务视图，在这个事务提交之前，回滚记录都要保留，这会导致大量占用存储空间。除此之外，长事务还占用锁资源，可能会拖垮库。</li>\n<li>事务启动方式：一、显式启动事务语句，<code>begin</code>或者<code>start transaction</code>,提交<code>commit</code>，回滚<code>rollback</code>；二、<code>set autocommit=0</code>，该命令会把这个线程的自动提交关掉。这样只要执行一个select语句，事务就启动，并不会自动提交，直到主动执行<code>commit</code>或<code>rollback</code>或断开连接。</li>\n<li>建议使用方法一，如果考虑多一次交互问题，可以使用<code>commit work and chain</code>语法。在<code>autocommit=1</code>的情况下用<code>begin</code>显式启动事务，如果执行<code>commit</code>则提交事务。如果执行<code>commit work and chain</code>则提交事务并自动启动下一个事务</li>\n</ul>\n<h3 id=\"深入浅出索引（上）\"><a href=\"#深入浅出索引（上）\" class=\"headerlink\" title=\"深入浅出索引（上）\"></a>深入浅出索引（上）</h3><p><strong>索引的常见模型</strong></p>\n<ul>\n<li>索引的出现是为了提高查询效率，常见的三种索引模型分别是<code>哈希表</code>、<code>有序数组</code>和<code>搜索树</code></li>\n<li><code>哈希表</code>：一种以<code>key-value</code> 存储数据的结构，哈希的思路是把值放在数组里，用一个哈希函数把<code>key</code>换算成一个确定的位置，然后把<code>value</code>放在数组的这个位置。哈希冲突的处理办法是使用<code>链表</code>。哈希表适用只有<code>等值查询</code>的场景</li>\n<li><code>有序数组</code>：按顺序存储。查询用二分法就可以快速查询，时间复杂度是：O(log(N))。查询效率高，更新效率低（涉及到移位）。在等值查询和范围查询场景中的性能就都非常优秀。有序数组索引只适用于静态存储引擎。</li>\n<li>二叉搜索树：每个节点的左儿子小于父节点，右儿子大于父节点。查询时间复杂度O(log(N))，更新时间复杂度O(log(N))。数据库存储大多不适用二叉树，因为树高过高，会适用N叉树</li>\n</ul>\n<p><strong>InnoDB 的索引模型</strong></p>\n<ul>\n<li><code>InnoDB</code>使用了<code>B+树</code>索引模型，所以数据都是存储在B+树中的。每一个索引在<code>InnoDB</code>里面对应一棵B+树。</li>\n<li>索引类型分为<code>主键索引</code>和<code>非主键索引</code>。主键索引的叶子节点存的是整行数据。在InnoDB里，主键索引也被称为<code>聚簇索引</code>。非主键索引的叶子节点内容是主键的值。在InnoDB里，非主键索引也被称为<code>二级索引</code></li>\n</ul>\n<p><img src=\"https://img-blog.csdnimg.cn/20190411164702315.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=GPjHM&originHeight=424&originWidth=1004&originalType=binary&ratio=1&status=done&style=none\"></p>\n<p><strong>主键索引和普通索引的查询有什么区别？</strong></p>\n<ul>\n<li>如果语句是<code>select * from T where ID=500</code>，即主键查询方式，则只需要搜索ID这棵B+树；</li>\n<li>如果语句是<code>select * from T where k=5</code>，即普通索引查询方式，则需要先搜索k索引树，得到ID的值为500，再到ID索引树搜索一次。这个过程称为<code>回表</code>。</li>\n<li>基于非主键索引的查询需要多扫描一棵索引树。因此，我们在应用中应该尽量使用主键查询</li>\n</ul>\n<p><strong>索引维护</strong></p>\n<ul>\n<li><code>B+树</code>为了维护索引有序性，在插入新值的时候需要做必要的维护。涉及到数据的移动和数据页的增加和删减</li>\n<li>一个数据页满了，按照B+Tree算法，新增加一个数据页，叫做<code>页分裂</code>，会导致性能下降。空间利用率降低大概50%。当相邻的两个数据页利用率很低的时候会做<code>数据页合并</code>，合并的过程是分裂过程的<code>逆过程</code>。</li>\n</ul>\n<h4 id=\"总结-1\"><a href=\"#总结-1\" class=\"headerlink\" title=\"总结\"></a>总结</h4><ul>\n<li>索引可能因为删除，或者页分裂等原因，导致数据页有空洞，重建索引的过程会创建一个新的索引，把数据按顺序插入，这样页面的利用率最高，也就是索引更紧凑、更省空间。</li>\n</ul>\n<blockquote>\n<p><code>alter table T drop index k</code>;     alter table T add index(k);<br>要重建主键索引<br><code>alter table T drop primary key</code>;      <code>alter table T add primary key(id)</code>;<br>重建索引k的做法是合理的，可以达到省空间的目的。但是，重建主键的过程不合理。不论是删除主键还是创建主键，都会将整个表重建。所以连着执行这两个语句的话，第一个语句就白做了。<br>可以用这个语句代替 ： alter table T engine=InnoDB</p>\n</blockquote>\n<h3 id=\"深入浅出索引（下）\"><a href=\"#深入浅出索引（下）\" class=\"headerlink\" title=\"深入浅出索引（下）\"></a>深入浅出索引（下）</h3><figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql<span class=\"operator\">&gt;</span> <span class=\"keyword\">create</span> <span class=\"keyword\">table</span> T (</span><br><span class=\"line\">ID <span class=\"type\">int</span> <span class=\"keyword\">primary</span> key,</span><br><span class=\"line\">k <span class=\"type\">int</span> <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span> <span class=\"keyword\">DEFAULT</span> <span class=\"number\">0</span>, </span><br><span class=\"line\">s <span class=\"type\">varchar</span>(<span class=\"number\">16</span>) <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span> <span class=\"keyword\">DEFAULT</span> <span class=\"string\">&#x27;&#x27;</span>,</span><br><span class=\"line\">index k(k))</span><br><span class=\"line\">engine<span class=\"operator\">=</span>InnoDB;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">insert</span> <span class=\"keyword\">into</span> T <span class=\"keyword\">values</span>(<span class=\"number\">100</span>,<span class=\"number\">1</span>, <span class=\"string\">&#x27;aa&#x27;</span>),(<span class=\"number\">200</span>,<span class=\"number\">2</span>,<span class=\"string\">&#x27;bb&#x27;</span>),(<span class=\"number\">300</span>,<span class=\"number\">3</span>,<span class=\"string\">&#x27;cc&#x27;</span>),(<span class=\"number\">500</span>,<span class=\"number\">5</span>,<span class=\"string\">&#x27;ee&#x27;</span>),(<span class=\"number\">600</span>,<span class=\"number\">6</span>,<span class=\"string\">&#x27;ff&#x27;</span>),(<span class=\"number\">700</span>,<span class=\"number\">7</span>,<span class=\"string\">&#x27;gg&#x27;</span>);</span><br></pre></td></tr></table></figure>\n\n\n<p><img src=\"https://img-blog.csdnimg.cn/20190411193509228.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=iQfIH&originHeight=441&originWidth=989&originalType=binary&ratio=1&status=done&style=none\"><br>如果我执行 <code>select * from T where k between 3 and 5</code>，需要执行几次树的搜索操作，会扫描多少行？</p>\n<p><strong>SQL查询语句的执行流程：</strong></p>\n<ul>\n<li>在k索引树上找到k=3的记录，取得 ID = 300；</li>\n<li>再到ID索引树查到ID=300对应的R3；</li>\n<li>在k索引树取下一个值k=5，取得ID=500；</li>\n<li>再回到ID索引树查到ID=500对应的R4；</li>\n<li>在k索引树取下一个值k=6，不满足条件，循环结束。</li>\n<li>在这个过程中，回到主键索引树搜索的过程，我们称为回表。可以看到，这个查询过程读了k索引树的3条记录，回表了两次。在这个例子中，由于查询结果所需要的数据只在主键索引上有，所以不得不回表。</li>\n</ul>\n<p><strong>优化方式</strong></p>\n<ul>\n<li>sql语句修改为<code>select ID from T where k between 3 and 5</code>，这时只需要查ID的值，而ID的值已经在k索引树上了，因此可以直接提供查询结果，不需要回表。也就是说，在这个查询里面，索引k已经“覆盖了”我们的查询需求，我们称为<code>覆盖索引</code>。</li>\n<li>由于<code>覆盖索引</code>可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。</li>\n</ul>\n<h4 id=\"总结-2\"><a href=\"#总结-2\" class=\"headerlink\" title=\"总结\"></a>总结</h4><ul>\n<li><code>覆盖索引</code>：如果查询条件使用的是普通索引（或是联合索引的最左原则字段），查询结果是联合索引的字段或是主键，不用回表操作，直接返回结果，减少IO磁盘读写读取正行数据</li>\n<li><code>最左前缀</code>：联合索引的最左 N 个字段，也可以是字符串索引的最左 M 个字符</li>\n<li><code>联合索引</code>：根据创建联合索引的顺序，以最左原则进行where检索，比如（age，name）以age=1 或 age= 1 and name=‘张三’可以使用索引，单以name=‘张三’ 不会使用索引，考虑到存储空间的问题，还请根据业务需求，将查找频繁的数据进行靠左创建索引。</li>\n<li>索引下推：<code>like &#39;hello%’and age &gt;10</code> 检索，MySQL5.6版本之前，会对匹配的数据进行回表查询。5.6版本后，会先过滤掉age&lt;10的数据，再进行回表查询，减少回表率，提升检索速度</li>\n</ul>\n<h3 id=\"讲全局锁和表锁：给表加个字段怎么有这么多阻碍\"><a href=\"#讲全局锁和表锁：给表加个字段怎么有这么多阻碍\" class=\"headerlink\" title=\"讲全局锁和表锁：给表加个字段怎么有这么多阻碍\"></a>讲全局锁和表锁：给表加个字段怎么有这么多阻碍</h3><blockquote>\n<p>根据加锁的范围，MySQL里面的锁大致可以分成全局锁、表级锁和行锁三类</p>\n</blockquote>\n<p><strong>全局锁</strong></p>\n<ul>\n<li>对整个数据库实例加锁。MySQL提供加全局读锁的方法：<code>Flush tables with read lock(FTWRL)</code>。这个命令可以使整个库处于只读状态。使用该命令之后，数据更新语句、数据定义语句和更新类事务的提交语句等操作都会被阻塞。使用场景：<code>全库逻辑备份</code>。</li>\n<li>风险是如果在主库备份，在备份期间不能更新，业务停摆。如果在从库备份，备份期间不能执行主库同步的binlog，导致主从延迟。官方自带的逻辑备份工具<code>mysqldump</code>，当mysqldump使用参数<code>--single-transaction</code>的时候，会启动一个事务，确保拿到一致性视图。而由于<code>MVCC</code>的支持，这个过程中数据是可以正常更新的。</li>\n<li>一致性读是好，但是前提是引擎要支持这个隔离级别。如果要全库只读，为什么不使用<code>set global readonly=true</code>的方式？在有些系统中，<code>readonly</code>的值会被用来做其他逻辑，比如判断主备库。所以修改global变量的方式影响太大。</li>\n<li>在异常处理机制上有差异。如果执行<code>FTWRL</code>命令之后由于客户端发生异常断开，那么MySQL会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为<code>readonly</code>之后，如果客户端发生异常，则数据库就会一直保持<code>readonly</code>状态，这样会导致整个库长时间处于不可写状态，风险较高。</li>\n</ul>\n<p><strong>表级锁</strong></p>\n<ul>\n<li>MySQL里面表级锁有两种，一种是表锁，一种是元数据所(meta data lock,MDL)。表锁的语法是:l<code>ock tables ... read/write</code></li>\n<li>可以用<code>unlock tables</code>主动释放锁，也可以在客户端断开的时候自动释放。<code>lock tables</code>语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。</li>\n<li>对于<code>InnoDB</code>这种支持<code>行锁</code>的引擎，一般不使用<code>lock tables</code>命令来控制并发，毕竟锁住整个表的影响面还是太大。</li>\n<li>另一类表级的锁是<code>MDL</code>（metadata lock)。<code>MDL不需要显式使用</code>，在访问一个表的时候会被<code>自动加上</code>。MDL的作用是，<code>保证读写的正确性</code>。当对一个表做增删改查操作的时候，加<code>MDL读锁</code>；当要对表做结构变更操作的时候，加<code>MDL写锁</code>。<code>读锁之间不互斥</code>，因此你可以有多个线程同时对一张表增删改查。<code>读写锁之间、写锁之间是互斥的</code>，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。</li>\n<li><code>MDL</code> 会直到事务提交才会释放，在做表结构变更的时候，一定要小心不要导致锁住线上查询和更新。</li>\n</ul>\n<p><strong>如何安全地给表加字段</strong></p>\n<ul>\n<li>给一个表加字段，或者修改字段，或者加索引，需要扫描全表的数据。首先我们要解决长事务，事务不提交，就会一直占着MDL锁。在MySQL的<code>information_schema</code> 库的 <code>innodb_trx</code> 表中，你可以查到当前执行中的事务。如果你要做<code>DDL</code>变更的表刚好有<code>长事务</code>在执行，要考虑先暂停DDL，或者<code>kill</code>掉这个长事务。</li>\n<li>如果你要变更的表是一个<code>热点表</code>，虽然数据量不大，但是上面的请求很频繁，这时候kill可能未必管用，因为新的请求马上就来了。比较理想的机制是，在<code>alter table</code>语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到<code>MDL写锁</code>最好，拿不到也不要阻塞后面的业务语句，先放弃。之后开发人员或者DBA再通过重试命令重复这个过程。</li>\n</ul>\n<h3 id=\"讲行锁功过：怎么减少行锁对性能的影响\"><a href=\"#讲行锁功过：怎么减少行锁对性能的影响\" class=\"headerlink\" title=\"讲行锁功过：怎么减少行锁对性能的影响\"></a>讲行锁功过：怎么减少行锁对性能的影响</h3><ul>\n<li>MySQL的<code>行锁</code>是在引擎层由各个<code>引擎自己实现</code>的。但并不是所有的引擎都支持行锁，比<code>如MyISAM引擎就不支持行锁</code>。不支持行锁意味着并发控制只能使用表锁，对于这种引擎的表，同一张表上任何时刻只能有一个更新在执行，这就会影响到业务并发度。<code>InnoDB是支持行锁</code>的，这也是<code>MyISAM</code>被<code>InnoDB</code>替代的重要原因之一。</li>\n<li><code>两阶段锁协议</code>：在<code>InnoDB</code>事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。</li>\n<li><code>死锁</code>：当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁</li>\n</ul>\n<p><img src=\"https://img-blog.csdnimg.cn/20190412161554856.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=Enkur&originHeight=585&originWidth=948&originalType=binary&ratio=1&status=done&style=none\"></p>\n<ul>\n<li><code>事务A</code>在等待<code>事务B</code>释放id=2的行锁，而<code>事务B在等待事务A</code>释放id=1的行锁。 事务A和事务B在互相等待对方的资源释放，就是进入了<code>死锁状态</code></li>\n</ul>\n<p><strong>出现死锁以后，有两种策略：</strong></p>\n<ul>\n<li>一种策略是，<code>直接进入等待，直到超时</code>。这个超时时间可以通过参数<code>innodb_lock_wait_timeout</code>来设置。在InnoDB中，默认值是<code>50s</code></li>\n<li>另一种策略是，<code>发起死锁检测</code>，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数<code>innodb_deadlock_detect设置为on</code>，表示开启这个逻辑。默认值本身就是on</li>\n<li>正常情况下选择第二种策略，但是它也是有额外负担的，如果瞬间有大量线程请求会消耗消耗大量的CPU资源，但是每秒却执行不了几个事务，因为每次都要检测。</li>\n</ul>\n<p><strong>怎么解决由这种热点行更新导致的性能问题?</strong></p>\n<ul>\n<li>问题的症结在于，死锁检测要耗费大量的CPU资源</li>\n<li>如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉。 一般不建议采用</li>\n<li>控制并发度，对应相同行的更新，在进入引擎之前排队。这样在InnoDB内部就不会有大量的死锁检测工作了。</li>\n<li>将热更新的行数据拆分成逻辑上的多行来减少锁冲突，但是业务复杂度可能会大大提高。</li>\n<li><code>innodb行级锁是通过锁索引记录实现的，如果更新的列没建索引是会锁住整个表的。</code></li>\n</ul>\n<h4 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a>小结</h4><p>如果你要删除一个表里面的前10000行数据，有以下三种方法可以做到：</p>\n<ul>\n<li>第一种，直接执行     <code>delete from T limit 10000;</code></li>\n<li>第二种，在一个连接中循环执行20次 <code>delete from T limit 500;</code></li>\n<li>第三种，在20个连接中同时执行    <code>delete from T limit 500</code></li>\n</ul>\n<p><strong>三种方案分析</strong></p>\n<ul>\n<li>方案一，事务相对较长，则占用锁的时间较长，会导致其他客户端等待资源时间较长。</li>\n<li>方案二，串行化执行，将相对长的事务分成多次相对短的事务，则每次事务占用锁的时间相对较短，其他客户端在等待相应资源的时间也较短。这样的操作，同时也意味着将资源分片使用（每次执行使用不同片段的资源），可以提高并发性。</li>\n<li>方案三，人为自己制造锁竞争，加剧并发量。</li>\n</ul>\n<h3 id=\"事务到底是隔离的还是不隔离的\"><a href=\"#事务到底是隔离的还是不隔离的\" class=\"headerlink\" title=\"事务到底是隔离的还是不隔离的\"></a>事务到底是隔离的还是不隔离的</h3><ul>\n<li><code>innodb</code>支持<code>RC(读提交)</code>和<code>RR(可重复读)</code>隔离级别实现是用的一致性视图(consistent read view)</li>\n<li>.事务在启动时会拍一个快照,这个快照是基于整个库的。基于整个库的意思就是说一个事务内,整个库的修改对于该事务都是不可见的(对于快照读的情况)。如果在事务内<code>select t</code>表,另外的事务执行了<code>DDL t</code>表,根据发生时间,<code>要吗锁住要嘛报错</code></li>\n</ul>\n<p><strong>事务是如何实现的MVCC呢?</strong></p>\n<ul>\n<li>每个事务都有一个事务ID,叫做<code>transaction id</code>(严格递增)</li>\n<li>事务在启动时,找到已提交的最大事务ID记为up_limit_id。</li>\n<li>事务在更新一条语句时,比如id=1改为了id=2.会把id=1和该行之前的<code>row trx_id</code>写到<code>undo log</code>里。并且在数据页上把id的值改为2,并且把修改这条语句的<code>transaction id</code>记在该行行头。</li>\n<li>再定一个规矩,一个事务要查看一条数据时,必须先用该事务的<code>up_limit_id</code>与该行的<code>transaction id</code>做比对</li>\n<li>如果<code>up_limit_id&gt;=transaction id</code>,那么可以看.如果<code>up_limit_id&lt;transaction id</code>,则只能去<code>undo log</code>里去取。去undo log查找数据的时候,也需要做比对,必须<code>up_limit_id&gt;transaction id</code>,才返回数据</li>\n</ul>\n<p><strong>什么是当前读,</strong></p>\n<ul>\n<li>由于当前读都是先读后写,只能读当前的值,所以认为当前读.会更新事务内的up_limit_id为该事务的transaction id</li>\n</ul>\n<p><strong>为什么</strong><code>**RR**</code><strong>能实现可重复读而</strong><code>**RC**</code><strong>不能,分两种情况</strong></p>\n<ul>\n<li>快照读的情况下,rr(可重复读)不能更新事务内的up_limit_id,而<code>rc(读提交)</code>每次会把<code>up_limit_id</code>更新为快照读之前最新已提交事务的<code>transaction id</code>,则<code>rc(读提交)</code>不能可重复读</li>\n<li>当前读的情况下,<code>rr(可重复读)</code>是利用<code>record lock+gap lock</code>来实现的,而<code>rc(读提交)</code>没有gap,所以rc不能可重复读</li>\n</ul>\n<h3 id=\"MySQL为什么有时候会选错索引\"><a href=\"#MySQL为什么有时候会选错索引\" class=\"headerlink\" title=\"MySQL为什么有时候会选错索引\"></a>MySQL为什么有时候会选错索引</h3><ul>\n<li>在MySQL中一张表其实是可以支持多个索引的。但是，你写SQL语句的时候，并没有主动指定使用哪个索引。也就是说，使用哪个索引是由MySQL来确定的。所以有时候由于MySQL选错了索引，而导致执行速度变得很慢</li>\n</ul>\n<p>测试代码</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">CREATE</span> <span class=\"keyword\">TABLE</span> `t` (</span><br><span class=\"line\">  `id` <span class=\"type\">int</span>(<span class=\"number\">11</span>) <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  `a` <span class=\"type\">int</span>(<span class=\"number\">11</span>) <span class=\"keyword\">DEFAULT</span> <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  `b` <span class=\"type\">int</span>(<span class=\"number\">11</span>) <span class=\"keyword\">DEFAULT</span> <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  <span class=\"keyword\">PRIMARY</span> KEY (`id`),</span><br><span class=\"line\">  KEY `a` (`a`),</span><br><span class=\"line\">  KEY `b` (`b`)</span><br><span class=\"line\">) ENGINE<span class=\"operator\">=</span>InnoDB；</span><br></pre></td></tr></table></figure>\n\n\n<p>然后，我们往表t中插入10万行记录，取值按整数递增，即：(1,1,1)，(2,2,2)，(3,3,3) 直到(100000,100000,100000)。</p>\n<p>分析一条SQL语句：</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql<span class=\"operator\">&gt;</span> <span class=\"keyword\">select</span> <span class=\"operator\">*</span> <span class=\"keyword\">from</span> t <span class=\"keyword\">where</span> a <span class=\"keyword\">between</span> <span class=\"number\">10000</span> <span class=\"keyword\">and</span> <span class=\"number\">20000</span>;</span><br></pre></td></tr></table></figure>\n\n\n<p>正常情况下，a上有索引，肯定是要使用索引a的。</p>\n<p><img src=\"https://img-blog.csdnimg.cn/20190414141306715.png#id=OG5aI&originHeight=97&originWidth=1077&originalType=binary&ratio=1&status=done&style=none\"><br>但是特许情况下如果同时有两个以下下操作执行：</p>\n<ul>\n<li>如果一个A请求首先开启了事物，随后，B请求把数据都删除后，又插入了10万行数据。</li>\n<li>这时候， B操作的查询语句<code>select * from t where a between 10000 and 20000</code>就不会再选择索引a了，会执行全表扫描，执行时间会比之前慢很多。<code>为什么会出现这样情况？</code>因为选择索引是优化器的工作，而优化器选择索引的目的，是找到一个最优的执行方案，并用最小的代价去执行语句。</li>\n<li>MySQL在真正开始执行语句之前，并不能精确地知道满足这个条件的记录有多少条，而只能根据统计信息来估算记录数。这个统计信息就是索引的“<code>区分度</code>”。一个索引上不同的值越多，这个索引的区分度就越好。而一个索引上不同的值的个数，我们称之为<code>“基数”</code>（cardinality）。也就是说，这个基数越大，索引的区分度越好。</li>\n<li>可以使用<code>show index table</code>方法，看到一个索引的基数</li>\n<li>MySQL是怎样得到索引的基数的呢？MySQL通过采样统计的方法得到基数</li>\n<li>如果使用索引a，每次从索引a上拿到一个值，都要回到主键索引上查出整行数据，这个代价优化器也要算进去的。而如果选择扫描10万行，是直接在主键索引上扫描的，没有额外的代价。优化器会估算这两个选择的代价，从结果看来，优化器认为直接扫描主键索引更快。当然，从执行时间看来，这个选择并不是最优的。</li>\n<li><code>analyze table t</code> 命令可以用来重新统计索引信息</li>\n<li>采用<code>force index</code>强行选择一个索引。如果force index指定的索引在候选索引列表中，就直接选择这个索引，不再评估其他索引的执行代价。</li>\n</ul>\n<p><img src=\"https://img-blog.csdnimg.cn/20190414141504344.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=LVEvh&originHeight=321&originWidth=921&originalType=binary&ratio=1&status=done&style=none\"></p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">set</span> long_query_time<span class=\"operator\">=</span><span class=\"number\">0</span>;</span><br><span class=\"line\"><span class=\"keyword\">select</span> <span class=\"operator\">*</span> <span class=\"keyword\">from</span> t <span class=\"keyword\">where</span> a <span class=\"keyword\">between</span> <span class=\"number\">10000</span> <span class=\"keyword\">and</span> <span class=\"number\">20000</span>; <span class=\"comment\">/*Q1*/</span></span><br><span class=\"line\"><span class=\"keyword\">select</span> <span class=\"operator\">*</span> <span class=\"keyword\">from</span> t force index(a) <span class=\"keyword\">where</span> a <span class=\"keyword\">between</span> <span class=\"number\">10000</span> <span class=\"keyword\">and</span> <span class=\"number\">20000</span>;<span class=\"comment\">/*Q2*/</span></span><br><span class=\"line\"></span><br><span class=\"line\">第一句，是将慢查询日志的阈值设置为<span class=\"number\">0</span>，表示这个线程接下来的语句都会被记录入慢查询日志中；</span><br><span class=\"line\">第二句，Q1是session B原来的查询；</span><br><span class=\"line\">第三句，Q2是加了force index(a)来和session B原来的查询语句执行情况对比。</span><br></pre></td></tr></table></figure>\n\n\n<ul>\n<li>delete 语句删掉了所有的数据，然后再通过call idata()插入了10万行数据，看上去是覆盖了原来的10万行。</li>\n<li>但是，session A开启了事务并没有提交，所以之前插入的10万行数据是不能删除的。这样，之前的数据每一行数据都有两个版本，旧版本是delete之前的数据，新版本是标记为deleted的数据。这样，索引a上的数据其实就有两份</li>\n</ul>\n<h3 id=\"怎么给字符串字段加索引\"><a href=\"#怎么给字符串字段加索引\" class=\"headerlink\" title=\"怎么给字符串字段加索引\"></a>怎么给字符串字段加索引</h3><ul>\n<li>假设，你现在维护一个支持邮箱登录的系统，用户表是这么定义的：</li>\n</ul>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql<span class=\"operator\">&gt;</span> <span class=\"keyword\">create</span> <span class=\"keyword\">table</span> SUser(</span><br><span class=\"line\">ID <span class=\"type\">bigint</span> unsigned <span class=\"keyword\">primary</span> key,</span><br><span class=\"line\">email <span class=\"type\">varchar</span>(<span class=\"number\">64</span>), </span><br><span class=\"line\">... </span><br><span class=\"line\">)engine<span class=\"operator\">=</span>innodb;</span><br></pre></td></tr></table></figure>\n\n\n<p>由于要使用邮箱登录，所以业务代码中一定会出现类似于这样的语句：</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql<span class=\"operator\">&gt;</span> <span class=\"keyword\">select</span> f1, f2 <span class=\"keyword\">from</span> SUser <span class=\"keyword\">where</span> email<span class=\"operator\">=</span><span class=\"string\">&#x27;xxx&#x27;</span>;</span><br></pre></td></tr></table></figure>\n\n\n<ul>\n<li>如果email这个字段上没有索引，那么这个语句就只能做全表扫描。同时，MySQL是支持前缀索引的，也就是说，你可以定义字符串的一部分作为索引。默认地，如果你创建索引的语句不指定前缀长度，那么索引就会包含整个字符串。</li>\n</ul>\n<p>比如，这两个在email字段上创建索引的语句：</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql<span class=\"operator\">&gt;</span> <span class=\"keyword\">alter</span> <span class=\"keyword\">table</span> SUser <span class=\"keyword\">add</span> index index1(email);</span><br><span class=\"line\">或</span><br><span class=\"line\">mysql<span class=\"operator\">&gt;</span> <span class=\"keyword\">alter</span> <span class=\"keyword\">table</span> SUser <span class=\"keyword\">add</span> index index2(email(<span class=\"number\">6</span>));</span><br></pre></td></tr></table></figure>\n\n\n<p><img src=\"https://img-blog.csdnimg.cn/201904142351118.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=FFfQd&originHeight=468&originWidth=1000&originalType=binary&ratio=1&status=done&style=none\"><br><img src=\"https://img-blog.csdnimg.cn/20190414235147183.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=XF7LV&originHeight=449&originWidth=640&originalType=binary&ratio=1&status=done&style=none\"></p>\n<ul>\n<li>第一个语句创建的index1索引里面，包含了每个记录的整个字符串；</li>\n<li>第二个语句创建的index2索引里面，对于每个记录都是只取前6个字节。由于email(6)这个索引结构中每个邮箱字段都只取前6个字节,所以占用的空间会更小，这就是使用前缀索引的优势。但是 可能会增加额外的记录扫描次数。</li>\n</ul>\n<p><strong>使用的是index1的执行流程</strong></p>\n<ul>\n<li>从<code>index1</code>索引树找到满足索引值是’<a href=\"mailto:&#x7a;&#104;&#x61;&#110;&#103;&#115;&#115;&#120;&#x79;&#122;&#x40;&#120;&#120;&#x78;&#x2e;&#99;&#x6f;&#x6d;\">&#x7a;&#104;&#x61;&#110;&#103;&#115;&#115;&#120;&#x79;&#122;&#x40;&#120;&#120;&#x78;&#x2e;&#99;&#x6f;&#x6d;</a>’的这条记录，取得ID2的值；</li>\n<li>到主键上查到主键值是ID2的行，判断email的值是正确的，将这行记录加入结果集；</li>\n<li>取index1索引树上刚刚查到的位置的下一条记录，发现已经不满足email=‘<a href=\"mailto:&#122;&#104;&#97;&#x6e;&#x67;&#x73;&#x73;&#120;&#x79;&#x7a;&#x40;&#120;&#120;&#120;&#46;&#99;&#x6f;&#x6d;\">&#122;&#104;&#97;&#x6e;&#x67;&#x73;&#x73;&#120;&#x79;&#x7a;&#x40;&#120;&#120;&#120;&#46;&#99;&#x6f;&#x6d;</a>’的条件了，循环结束</li>\n<li>这个过程中，只需要回主键索引取一次数据，所以系统认为只扫描了一行。</li>\n</ul>\n<p><strong>使用的是index2的执行流程</strong></p>\n<ul>\n<li>从<code>index2</code>索引树找到满足索引值是’zhangs’的记录，找到的第一个是ID1；</li>\n<li>到主键上查到主键值是ID1的行，判断出email的值不是’<a href=\"mailto:&#x7a;&#x68;&#97;&#110;&#x67;&#115;&#115;&#x78;&#121;&#122;&#64;&#x78;&#x78;&#120;&#46;&#x63;&#x6f;&#x6d;\">&#x7a;&#x68;&#97;&#110;&#x67;&#115;&#115;&#x78;&#121;&#122;&#64;&#x78;&#x78;&#120;&#46;&#x63;&#x6f;&#x6d;</a>’，这行记录丢弃；</li>\n<li>取index2上刚刚查到的位置的下一条记录，发现仍然是’zhangs’，取出ID2，再到ID索引上取整行然后判断，这次值对了，将这行记录加入结果集；</li>\n<li>重复上一步，直到在idxe2上取到的值不是’zhangs’时，循环结束。</li>\n<li>在这个过程中，要回主键索引取4次数据，也就是扫描了4行。</li>\n<li>但是  对于这个查询语句来说，如果你定义的<code>index2</code>不是email(6)而是email(7），也就是说取email字段的前7个字节来构建索引的话，即满足前缀’zhangss’的记录只有一个，也能够直接查到ID2，只扫描一行就结束了。</li>\n<li>也就是说<code>使用前缀索引，定义好长度，就可以做到既节省空间，又不用额外增加太多的查询成本</code>。</li>\n</ul>\n<p><strong>前缀索引对覆盖索引的影响</strong></p>\n<ul>\n<li>使用前缀索引可能会增加扫描行数，这会影响到性能。其实，前缀索引的影响不止如此</li>\n</ul>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#查询<span class=\"number\">1</span> </span><br><span class=\"line\"><span class=\"keyword\">select</span> id,email <span class=\"keyword\">from</span> SUser <span class=\"keyword\">where</span> email<span class=\"operator\">=</span><span class=\"string\">&#x27;zhangssxyz@xxx.com&#x27;</span>;</span><br><span class=\"line\"># 查询<span class=\"number\">2</span></span><br><span class=\"line\"><span class=\"keyword\">select</span> id,name,email <span class=\"keyword\">from</span> SUser <span class=\"keyword\">where</span> email<span class=\"operator\">=</span><span class=\"string\">&#x27;zhangssxyz@xxx.com&#x27;</span>;</span><br></pre></td></tr></table></figure>\n\n\n<ul>\n<li>如果使用index1（即email整个字符串的索引结构）的话，可以利用覆盖索引，从index1查到结果后直接就返回了，不需要回到ID索引再去查一次。而如果使用index2（即email(6)索引结构）的话，就不得不回到ID索引再去判断email字段的值。</li>\n<li>即使你将index2的定义修改为email(18)的前缀索引，这时候虽然index2已经包含了所有的信息，但InnoDB还是要回到id索引再查一下，因为系统并不确定前缀索引的定义是否截断了完整信息。</li>\n<li>使用前缀索引就用不上覆盖索引对查询性能的优化了</li>\n</ul>\n<h4 id=\"小结-1\"><a href=\"#小结-1\" class=\"headerlink\" title=\"小结\"></a>小结</h4><p>对于类似于邮箱这样的字段来说，使用前缀索引的效果可能还不错。但是，遇到前缀的区分度不够好的情况时。比如，我们国家的身份证号，一共18位，其中前6位是地址码，所以同一个县的人的身份证号前6位一般会是相同的。</p>\n<p>假设你维护的数据库是一个市的公民信息系统，这时候如果对身份证号做长度为6的前缀索引的话，这个索引的区分度就非常低了。可能你需要创建长度为12以上的前缀索引，才能够满足区分度要求。但是，<code>索引选取的越长，占用的磁盘空间就越大，相同的数据页能放下的索引值就越少，搜索的效率也就会越低</code>。</p>\n<p>那么，如果我们能够确定业务需求里面只有按照身份证进行等值查询的需求，还有没有别的处理方法呢？这种方法，既可以占用更小的空间，也能达到相同的查询效率。</p>\n<p>第一种方式是使用<code>倒序存储</code>。如果你存储身份证号的时候把它倒过来存，每次查询的时候，你可以这么写：</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql<span class=\"operator\">&gt;</span> <span class=\"keyword\">select</span> field_list <span class=\"keyword\">from</span> t <span class=\"keyword\">where</span> id_card <span class=\"operator\">=</span> reverse(<span class=\"string\">&#x27;input_id_card_string&#x27;</span>);</span><br></pre></td></tr></table></figure>\n\n\n<p>由于身份证号的最后6位没有地址码这样的重复逻辑，所以最后这6位很可能就提供了足够的区分度。</p>\n<p>第二种方式是<code>使用hash字段</code>。你可以在表上再创建一个整数字段，来保存身份证的校验码，同时在这个字段上创建索引。</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql<span class=\"operator\">&gt;</span> <span class=\"keyword\">alter</span> <span class=\"keyword\">table</span> t <span class=\"keyword\">add</span> id_card_crc <span class=\"type\">int</span> unsigned, <span class=\"keyword\">add</span> index(id_card_crc);</span><br></pre></td></tr></table></figure>\n\n\n<p>然后每次插入新记录的时候，都同时用crc32()这个函数得到校验码填到这个新字段。由于校验码可能存在冲突，也就是说两个不同的身份证号通过crc32()函数得到的结果可能是相同的，所以你的查询语句where部分要判断id_card的值是否精确相同。</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql<span class=\"operator\">&gt;</span> <span class=\"keyword\">select</span> field_list <span class=\"keyword\">from</span> t <span class=\"keyword\">where</span> id_card_crc<span class=\"operator\">=</span>crc32(<span class=\"string\">&#x27;input_id_card_string&#x27;</span>) <span class=\"keyword\">and</span> id_card<span class=\"operator\">=</span><span class=\"string\">&#x27;input_id_card_string&#x27;</span></span><br></pre></td></tr></table></figure>\n\n\n<p>这样，索引的长度变成了4个字节，比原来小了很多。</p>\n<p><strong>使用倒序存储和使用hash字段这两种方法的异同点</strong></p>\n<ul>\n<li>首先，它们的相同点是，都不支持范围查询。</li>\n<li><code>从占用的额外空间来看</code>，倒序存储方式在主键索引上，不会消耗额外的存储空间，而hash字段方法需要增加一个字段</li>\n<li><code>在CPU消耗方面</code>，倒序方式每次写和读的时候，都需要额外调用一次reverse函数，而hash字段的方式需要额外调用一次crc32()函数</li>\n<li><code>从查询效率上看</code>，使用hash字段方式的查询性能相对更稳定一些。因为crc32算出来的值虽然有冲突的概率，但是概率非常小，可以认为每次查询的平均扫描行数接近1。而倒序存储方式毕竟还是用的前缀索引的方式，也就是说还是会增加扫描行数。</li>\n</ul>\n<p><strong>字符串字段创建索引的场景你可以使用的方式有：</strong></p>\n<ul>\n<li>直接创建完整索引，这样可能比较占用空间；</li>\n<li>创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引；</li>\n<li>倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题；</li>\n<li>创建hash字段索引，查询性能稳定，有额外的存储和计算消耗，跟第三种方式一样，都不支持范围扫描。</li>\n</ul>\n<p><strong>利用学号作为登录名索引设计问题？</strong></p>\n<blockquote>\n<p>如果你在维护一个学校的学生信息数据库，学生登录名的统一格式是”学号@gmail.com”, 而学号的规则是：十五位的数字，其中前三位是所在城市编号、第四到第六位是学校编号、第七位到第十位是入学年份、最后五位是顺序编号。<br>系统登录的时候都需要学生输入登录名和密码，验证正确后才能继续使用系统。就只考虑登录验证这个行为的话，你会怎么设计这个登录名的索引呢？</p>\n</blockquote>\n<p><code>**设计思路：**</code></p>\n<ul>\n<li>由于这个学号的规则，无论是正向还是反向的前缀索引，重复度都比较高。因为维护的只是一个学校的，因此前面6位（其中，前三位是所在城市编号、第四到第六位是学校编号）其实是固定的，邮箱后缀都是@gamil.com，因此可以只存入学年份加顺序编号，它们的长度是9位。</li>\n<li>而其实在此基础上，可以用数字类型来存这9位数字。比如201100001，这样只需要占4个字节。其实这个就是一种hash，只是它用了最简单的转换规则：字符串转数字的规则，而刚好我们设定的这个背景，可以保证这个转换后结果的唯一性。</li>\n</ul>\n<h3 id=\"为什么我的MySQL会“抖”一下\"><a href=\"#为什么我的MySQL会“抖”一下\" class=\"headerlink\" title=\"为什么我的MySQL会“抖”一下\"></a>为什么我的MySQL会“抖”一下</h3><ul>\n<li>一条SQL语句，正常执行的时候特别快，但是有时也不知道怎么回事，它就会变得特别慢，并且这样的场景很难复现，它不只随机，而且持续时间还很短。看上去，这就像是数据库“抖”了一下</li>\n<li>在MySQL里，如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程IO成本、查找成本都很高。为了解决这个问题，MySQL的设计者使用了<code>WAL技术</code>，WAL的全称是Write-Ahead Logging，它的关键点就是<code>先写日志，再写磁盘</code>。</li>\n<li>利用WAL技术，数据库将随机写转换成了顺序写，大大提升了数据库的性能。但是，由此也带来了内存脏页的问题。脏页会被后台线程自动flush，也会由于数据页淘汰而触发flush，而刷脏页的过程由于会占用资源，可能会让你的更新和查询语句的响应时间长一些</li>\n<li>当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”。</li>\n<li>平时执行很快的更新操作，其实就是在写内存和日志，而MySQL偶尔“抖”一下的那个瞬间，可能就是在刷脏页（<code>flush</code>）。</li>\n</ul>\n<p><strong>什么情况会引发数据库的flush过程呢？</strong></p>\n<ul>\n<li><code>InnoDB</code>在处理更新语句的时候，只做了写日志这一个磁盘操作。这个日志叫作redo log（重做日志）。在更新内存写完<code>redo log</code>后，就返回给客户端，本次更新成功。</li>\n<li><code>InnoDB</code>的<code>redo log</code>(重做日志)写满了。这时候系统会停止所有更新操作，把<code>checkpoint(检查点)</code>往前推进，<code>redo log</code>留出空间可以继续写</li>\n<li>第二种场景是：对应的就是系统内存不足。当需要新的内存页，而内存不够用的时候，就要淘汰一些数据页，空出内存给别的数据页使用。如果淘汰的是“脏页”，就要先将脏页写到磁盘。</li>\n<li>第三种场景就是<code>MySQL</code>认为系统<code>“空闲”</code>的时候。也要见缝插针地找时间，只要有机会就刷一点<code>“脏页”</code></li>\n<li>第四种场景就是<code>MySQL正常关闭的情况</code>。这时候，MySQL会把内存的脏页都flush到磁盘上，这样下次MySQL启动的时候，就可以直接从磁盘上读数据，启动速度会很快。</li>\n</ul>\n<p><strong>分析一下上面四种场景对性能的影响</strong></p>\n<ul>\n<li><code>第一种是“redo log写满了，要flush脏页”</code>，这种情况是InnoDB要尽量避免的。因为出现这种情况的时候，整个系统就不能再接受更新了，所有的更新都必须堵住。如果你从监控上看，这时候更新数会跌为0。</li>\n<li><code>第二种是“内存不够用了，要先将脏页写到磁盘”</code>，这种情况其实是常态。InnoDB用缓冲池（buffer pool）管理内存，缓冲池中的内存页有三种状态：第一种是，还没有使用的；第二种是，使用了并且是干净页；第三种是，使用了并且是脏页。InnoDB的策略是尽量使用内存，因此对于一个长时间运行的库来说，未被使用的页面很少。</li>\n<li>而当要读入的数据页没有在内存的时候，就必须到缓冲池中申请一个数据页。这时候只能把最久不使用的数据页从内存中淘汰掉：如果要淘汰的是一个干净页，就直接释放出来复用；但如果是脏页呢，就必须将脏页先刷到磁盘，变成干净页后才能复用。</li>\n<li>所以，刷脏页虽然是常态，但是出现以下这两种情况，都是会明显影响性能的：一个查询要淘汰的脏页个数太多，会导致查询的响应时间明显变长；日志写满，更新全部堵住，写性能跌为0，这种情况对敏感业务来说，是不能接受的。</li>\n</ul>\n<p><strong>InnoDB刷脏页的控制策略</strong></p>\n<ul>\n<li>首先，你要正确地告诉<code>InnoDB</code>所在主机的<code>IO能力</code>，这样<code>InnoDB</code>才能知道需要全力刷脏页的时候，可以刷多快。这就要用到<code>innodb_io_capacity</code>这个参数了，它会告诉<code>InnoDB</code>你的磁盘能力。这个值我建议你设置成<code>磁盘的IOPS</code>。</li>\n<li>假设有这样一个场景：<code>MySQL的写入速度很慢，TPS很低</code>，但是数据库主机的<code>IO压力并不大</code>。主机磁盘用的是SSD，但是<code>innodb_io_capacity</code>的值设置的是<code>300</code>。于是，InnoDB认为这个系统的能力就这么差，所以刷脏页刷得特别慢，甚至比脏页生成的速度还慢，这样就造成了脏页累积，影响了查询和更新性能。</li>\n<li><code>InnoDB</code>的刷盘速度就是要参考这两个因素：一个是<code>脏页比例</code>，一个是<code>redo log写盘速度</code>。</li>\n<li>参数<code>innodb_max_dirty_pages_pct</code>是<code>脏页比例上限</code>，默认值是<code>75%</code>。InnoDB会根据当前的脏页比例（假设为M），算出一个范围在0到100之间的数字。<code>InnoDB</code>每次写入的日志<code>都有一个序号</code>，当前写入的序号跟<code>checkpoint</code>对应的序号之间的差值。我们假设为N。InnoDB会根据这个N算出一个范围在0到100之间的数字，这个计算公式可以记为F2(N)。F2(N)算法比较复杂，你只要知道N越大，算出来的值越大就好了。</li>\n<li>然后，根据上述算得的F1(M)和F2(N)两个值，取其中较大的值记为R，之后引擎就可以按照<code>innodb_io_capacity</code>定义的能力乘以<code>R%</code>来控制刷脏页的速度。</li>\n</ul>\n<p><img src=\"https://img-blog.csdnimg.cn/2019041513510966.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=GVQMh&originHeight=1522&originWidth=1142&originalType=binary&ratio=1&status=done&style=none\"></p>\n<ul>\n<li>InnoDB会在后台刷脏页，而刷脏页的过程是要将内存页写入磁盘。所以，无论是你的查询语句在需要内存的时候可能要求淘汰一个脏页，还是由于刷脏页的逻辑会占用IO资源并可能影响到了你的更新语句，都可能是造成你从业务端感知到MySQL“抖”了一下的原因。</li>\n<li>要尽量避免这种情况，你就要合理地设置<code>innodb_io_capacity的值</code>，并且平时要多关注脏页比例，不要让它经常接近<code>75%</code>。</li>\n</ul>\n<blockquote>\n<p>脏页比例是通过Innodb_buffer_pool_pages_dirty/Innodb_buffer_pool_pages_total得到的</p>\n</blockquote>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql<span class=\"operator\">&gt;</span> <span class=\"keyword\">select</span> VARIABLE_VALUE <span class=\"keyword\">into</span> <span class=\"variable\">@a</span> <span class=\"keyword\">from</span> global_status <span class=\"keyword\">where</span> VARIABLE_NAME <span class=\"operator\">=</span> <span class=\"string\">&#x27;Innodb_buffer_pool_pages_dirty&#x27;</span>;</span><br><span class=\"line\"><span class=\"keyword\">select</span> VARIABLE_VALUE <span class=\"keyword\">into</span> <span class=\"variable\">@b</span> <span class=\"keyword\">from</span> global_status <span class=\"keyword\">where</span> VARIABLE_NAME <span class=\"operator\">=</span> <span class=\"string\">&#x27;Innodb_buffer_pool_pages_total&#x27;</span>;</span><br><span class=\"line\"><span class=\"keyword\">select</span> <span class=\"variable\">@a</span><span class=\"operator\">/</span><span class=\"variable\">@b</span>;</span><br></pre></td></tr></table></figure>\n\n\n<ul>\n<li>一旦一个查询请求需要在执行过程中先flush掉一个脏页时，这个查询就可能要比平时慢了。而MySQL中的一个机制，可能让你的查询会更慢：在准备刷一个脏页的时候，如果这个数据页旁边的数据页刚好是脏页，就会把这个“邻居”也带着一起刷掉；而且这个把“邻居”拖下水的逻辑还可以继续蔓延，也就是对于每个邻居数据页，如果跟它相邻的数据页也还是脏页的话，也会被放到一起刷。</li>\n<li>在InnoDB中，<code>innodb_flush_neighbors</code> 参数就是用来控制这个行为的，<code>值为1</code>的时候会有上述的<code>“连坐”机制</code>，<code>值为0时</code>表示不找邻居，自己刷自己的。</li>\n<li>找<code>“邻居”</code>这个优化在<code>机械硬盘时代是很有意义</code>的，可以<code>减少很多随机IO</code>。机械硬盘的随机<code>IOPS</code>一般只有几百，相同的逻辑操作减少随机IO就意味着系统性能的大幅度提升。</li>\n<li>而如果使用的是<code>SSD这类IOPS比较高的设备</code>的话，我就建议你把<code>innodb_flush_neighbors</code>的值设置成0。因为这时候<code>IOPS</code>往往不是瓶颈，而<code>“只刷自己”</code>，就能更快地执行完必要的刷脏页操作，减少SQL语句响应时间。</li>\n<li>在MySQL 8.0中<code>，innodb_flush_neighbors参数的默认值已经是0</code>了。</li>\n</ul>\n<h3 id=\"为什么表数据删掉一半，表文件大小不变\"><a href=\"#为什么表数据删掉一半，表文件大小不变\" class=\"headerlink\" title=\"为什么表数据删掉一半，表文件大小不变\"></a>为什么表数据删掉一半，表文件大小不变</h3><ul>\n<li>一个InnoDB表包含两部分，即：表结构定义和数据。在MySQL 8.0版本以前，表结构是存在以.frm为后缀的文件里。</li>\n<li>表数据既可以存在共享表空间里，也可以是单独的文件。这个行为是由参数<code>innodb_file_per_table</code>控制的，设置为<code>OFF</code>表示的是，表的数据放在<code>系统共享表空间</code>，也就是跟数据字典放在一起；设置为<code>ON</code>表示的是，每个InnoDB表数据存储在一个以 <code>.ibd</code>为后缀的文件中。从<code>MySQL 5.6.6</code>版本开始，它的<code>默认值就是ON</code>了</li>\n<li>建议你不论使用MySQL的哪个版本，都将这个值设置为ON。因为，一个表单独存储为一个文件更容易管理，而且在你不需要这个表的时候，通过<code>drop table</code>命令，系统就会直接删除这个文件。而如果是放在共享表空间中，即使表删掉了，空间也是不会回收的。</li>\n<li>我们在删除整个表的时候，可以使用drop table命令回收表空间。但是，我们遇到的更多的删除数据的场景是删除某些行，表中的数据被删除了，但是表空间却没有被回收。</li>\n</ul>\n<p><strong>数据删除流程</strong></p>\n<p><img src=\"https://img-blog.csdnimg.cn/20190416104535458.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=roWLU&originHeight=478&originWidth=603&originalType=binary&ratio=1&status=done&style=none\"></p>\n<ul>\n<li>假设，我们要删掉R4这个记录，InnoDB引擎只会把R4这个记录标记为删除。如果之后要再插入一个ID在300和600之间的记录时，可能会复用这个位置。但是，磁盘文件的大小并不会缩小。</li>\n<li>InnoDB的数据是按页存储的，那么如果我们删掉了一个数据页上的所有记录，整个数据页就可以被复用了。</li>\n<li>但是，数据页的复用跟记录的复用是不同的。记录的复用，只限于符合范围条件的数据，比如R4这条记录被删除后，如果插入一个ID是400的行，可以直接复用这个空间。但如果插入的是一个ID是800的行，就不能复用这个位置了。</li>\n<li>而当整个页从B+树里面摘掉以后，可以复用到任何位置。如果相邻的两个数据页利用率都很小，系统就会把这两个页上的数据合到其中一个页上，另外一个数据页就被标记为可复用。</li>\n<li>所以如果我们用delete命令把整个表的数据删除，结果就是，所有的数据页都会被标记为可复用。但是磁盘上，文件不会变小。也就是说，通过delete命令是不能回收表空间的。这些可以复用，而没有被使用的空间，看起来就像是<code>“空洞”</code>。</li>\n<li>实际上，不止是删除数据会造成空洞，插入数据也会。如果数据是按照索引递增顺序插入的，那么索引是紧凑的。但如果数据是随机插入的，就可能造成索引的数据页分裂。另外，更新索引上的值，可以理解为删除一个旧的值，再插入一个新值。不难理解，这也是会造成空洞的。</li>\n</ul>\n<p><strong>重建表</strong></p>\n<ul>\n<li>重建表就是新建一个与表A结构相同的表B，然后按照主键ID递增的顺序，把数据一行一行地从表A里读出来再插入到表B中。由于表B是新建的表，所以表A主键索引上的空洞，在表B中就都不存在了。</li>\n<li>可以使用<code>alter table A engine=InnoDB</code>命令来重建表。MySQL 5.5之后会自动完成转存数据、交换表名、删除旧表的操作。</li>\n<li>重建表的过程中，如果中途有新的数据要写入，就会造成数据丢失。所以在整个<code>DDL</code>过程中，表A中不能有更新。也就是说，这个DDL不是<code>Online</code>的。在MySQL 5.6版本开始引入的<code>Online DDL</code>，对这个操作流程做了优化。</li>\n<li>对于很大的表来说，这个操作是很消耗IO和CPU资源的。想要比较安全的操作的话，推荐使用<code>GitHub</code>开源的<a href=\"https://github.com/github/gh-ost\">gh-ost</a>来做。</li>\n</ul>\n<p><strong>MySQL执行DDL()原理</strong></p>\n<ul>\n<li><code>DML</code>：它们是SELECT、UPDATE、INSERT、DELETE，就象它的名字一样，这4条命令是用来对数据库里的数据进行操作的语言</li>\n<li><code>DDL</code>：DDL比DML要多，主要的命令有CREATE、ALTER、DROP等，DDL主要是用在定义或改变表(TABLE)的结构，数据类型，表之间的链接和约束等初始化工作上，他们大多在建立表时使用</li>\n<li><code>DCL</code>：是数据库控制功能。是用来设置或更改数据库用户或角色权限的语句</li>\n<li>MySQL各版本，对于DDL的处理方式是不同的，主要有三种：</li>\n<li><code>Copy Table</code>方式：这是InnoDB最早支持的方式。通过临时表拷贝的方式实现的。新建一个带有新结构的临时表，将原表数据全部拷贝到临时表，然后Rename，完成创建操作。这个方式过程中，<code>原表是可读的，不可写</code>。但是<code>会消耗一倍的存储空间</code>。</li>\n<li><code>Inplace</code>方式：这是原生MySQL 5.5，以及<code>innodb_plugin</code>中提供的方式。所谓Inplace，也就是在<code>原表上直接进行，不会拷贝临时表</code>。相对于Copy Table方式，这比较高效率。<code>原表同样可读的，但是不可写</code>。</li>\n<li><code>Online方式</code>：MySQL 5.6以上版本中提供的方式，无论是Copy Table方式，还是Inplace方式，<code>原表只能允许读取，不可写</code>。对应用有较大的限制，因此MySQL最新版本中，InnoDB支持了所谓的<code>Online方式DDL</code>。与以上两种方式相比，<code>online方式支持DDL时不仅可以读，还可以写</code></li>\n</ul>\n<h3 id=\"count-语句到底是怎样实现的\"><a href=\"#count-语句到底是怎样实现的\" class=\"headerlink\" title=\"count(*)语句到底是怎样实现的\"></a>count(*)语句到底是怎样实现的</h3><ul>\n<li>在不同的MySQL引擎中，count(*)有不同的实现方式。</li>\n<li><code>MyISAM引擎</code>把一个表的总行数存在了磁盘上，因此执行<code>count(*)</code>的时候会直接返回这个数，效率很高。这里讨论的是没有过滤条件的count(*)，如果加了where 条件的话，MyISAM表也是不能返回得这么快的。</li>\n<li><code>InnoDB引擎</code>就麻烦了，它执行count(*)的时候，需要把数据一行一行地从引擎里面读出来，然后累积计数。</li>\n</ul>\n<p><strong>为什么InnoDB不跟MyISAM一样，也把数字存起来呢？</strong></p>\n<ul>\n<li>这是因为即使是在同一个时刻的多个查询，由于<code>多版本并发控制</code>（MVCC）的原因，InnoDB表“应该返回多少行”也是不确定的。</li>\n<li>这和InnoDB的事务设计有关系，<code>可重复读是它默认的隔离级别</code>，在代码上就是通过多版本并发控制，也就是MVCC来实现的。每一行记录都要判断自己是否对这个会话可见，因此对于count(*)请求来说，InnoDB只好把数据一行一行地读出依次判断，可见的行才能够用于计算“基于这个查询”的表的总行数。</li>\n<li><code>InnoDB是索引组织表</code>，<code>主键索引树的叶子节点是数据</code>，而<code>普通索引树的叶子节点是主键值</code>。所以，普通索引树比主键索引树小很多。对于count(*)这样的操作，遍历哪个索引树得到的结果逻辑上都是一样的。因此，MySQL优化器会找到最小的那棵树来遍历。在保证逻辑正确的前提下，尽量减少扫描的数据量，是数据库系统设计的通用法则之一。</li>\n<li>MyISAM表虽然count(<em>)很快，但是不支持事务；show table status命令虽然返回很快，但是不准确；InnoDB表直接count(</em>)会遍历全表，虽然结果准确，但会导致性能问题。</li>\n</ul>\n<h3 id=\"不同的count用法\"><a href=\"#不同的count用法\" class=\"headerlink\" title=\"不同的count用法\"></a>不同的count用法</h3><p><code>select count(?) from t</code>这样的查询语句里面，<code>count(*)、count(主键id)、count(字段)和count(1)</code>等不同用法的性能，有哪些差别。</p>\n<ul>\n<li>count()是一个聚合函数，对于返回的结果集，一行行地判断，如果count函数的参数不是NULL，累计值就加1，否则不加。最后返回累计值。</li>\n<li>所以，count(*)、count(主键id)和count(1) 都表示返回满足条件的结果集的总行数；而count(字段），则表示返回满足条件的数据行里面，参数“字段”不为NULL的总个数。</li>\n<li><code>对于count(主键id)来说</code>，InnoDB引擎会遍历整张表，把每一行的id值都取出来，返回给server层。server层拿到id后，判断是不可能为空的，就按行累加。</li>\n<li><code>对于count(1)来说</code>，InnoDB引擎遍历整张表，但不取值。server层对于返回的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加。</li>\n<li><code>对于count(字段)来说</code>：如果这个“字段”是定义为not null的话，一行行地从记录里面读出这个字段，判断不能为null，按行累加；如果这个“字段”定义允许为null，那么执行的时候，判断到有可能是null，还要把值取出来再判断一下，不是null才累加。</li>\n<li>count(<em>)是例外：并不会把全部字段取出来，而是专门做了优化，不取值。count(</em>)肯定不是null，按行累加。</li>\n<li>所以结论是：按照效率排序的话，count(字段)&lt;count(主键id)&lt;count(1)≈count(<em>)，所以我建议你，尽量使用count(</em>)。</li>\n</ul>\n<h3 id=\"order-by是怎么工作的\"><a href=\"#order-by是怎么工作的\" class=\"headerlink\" title=\"order by是怎么工作的\"></a>order by是怎么工作的</h3><p>首先创建一个测试表  <code>t_city</code></p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">CREATE</span> <span class=\"keyword\">TABLE</span> `t_city` (</span><br><span class=\"line\">  `id` <span class=\"type\">int</span>(<span class=\"number\">11</span>) <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  `city` <span class=\"type\">varchar</span>(<span class=\"number\">16</span>) <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  `name` <span class=\"type\">varchar</span>(<span class=\"number\">16</span>) <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  `age` <span class=\"type\">int</span>(<span class=\"number\">11</span>) <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  `addr` <span class=\"type\">varchar</span>(<span class=\"number\">128</span>) <span class=\"keyword\">DEFAULT</span> <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  <span class=\"keyword\">PRIMARY</span> KEY (`id`),</span><br><span class=\"line\">  KEY `city` (`city`)</span><br><span class=\"line\">) ENGINE<span class=\"operator\">=</span>InnoDB <span class=\"keyword\">DEFAULT</span> CHARSET<span class=\"operator\">=</span>utf8;</span><br></pre></td></tr></table></figure>\n\n\n<p>使用存储过程 添加10W条测试数据</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">delimiter ;;</span><br><span class=\"line\"><span class=\"keyword\">create</span> <span class=\"keyword\">procedure</span> idata2()</span><br><span class=\"line\"><span class=\"keyword\">begin</span></span><br><span class=\"line\">  <span class=\"keyword\">declare</span> i <span class=\"type\">int</span>;</span><br><span class=\"line\">  <span class=\"keyword\">set</span> i<span class=\"operator\">=</span><span class=\"number\">1</span>;</span><br><span class=\"line\">  while(i<span class=\"operator\">&lt;=</span><span class=\"number\">10000</span>)do</span><br><span class=\"line\">    <span class=\"keyword\">insert</span> <span class=\"keyword\">into</span> t_city <span class=\"keyword\">values</span>(i,<span class=\"string\">&#x27;广州&#x27;</span>, i,i,i);</span><br><span class=\"line\">    <span class=\"keyword\">set</span> i<span class=\"operator\">=</span>i<span class=\"operator\">+</span><span class=\"number\">1</span>;</span><br><span class=\"line\">  <span class=\"keyword\">end</span> while;</span><br><span class=\"line\"><span class=\"keyword\">end</span>;;</span><br><span class=\"line\">delimiter ;</span><br><span class=\"line\"><span class=\"keyword\">call</span> idata2();</span><br></pre></td></tr></table></figure>\n\n\n<p>比如有如下sql语句，为避免全表扫描，已经在city字段加上索引</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">select</span> city,name,age <span class=\"keyword\">from</span> t_city <span class=\"keyword\">where</span> city<span class=\"operator\">=</span><span class=\"string\">&#x27;广州&#x27;</span> <span class=\"keyword\">order</span> <span class=\"keyword\">by</span> name limit <span class=\"number\">1000</span>;</span><br></pre></td></tr></table></figure>\n\n\n<p>这个语句看上去逻辑很清晰， 那吗数据库内部到底是怎样执行的了？</p>\n<p>首先先用<code>explain</code>看看执行计划</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">explain <span class=\"keyword\">select</span> city,name,age <span class=\"keyword\">from</span> t_city <span class=\"keyword\">where</span> city<span class=\"operator\">=</span><span class=\"string\">&#x27;广州&#x27;</span> <span class=\"keyword\">order</span> <span class=\"keyword\">by</span> name limit <span class=\"number\">1000</span>;</span><br></pre></td></tr></table></figure>\n\n\n<p><img src=\"https://img-blog.csdnimg.cn/20190416172638203.png#id=J8vpw&originHeight=52&originWidth=981&originalType=binary&ratio=1&status=done&style=none\"><br><strong>先看下个执行计划各参数的含义：</strong></p>\n<ul>\n<li><code>select_type</code>：显 示查询中每个select子句的类型</li>\n<li><code>table</code>： 显示这一行的数据是关于哪张表的，有时不是真实的表名字</li>\n<li><code>type</code>：在表中找到所需行的方式，又称“访问类型”。常用的类型有： ALL, index,  range, ref, eq_ref, const, system, NULL（从左到右，性能从差到好）</li>\n<li><code>possible_keys</code>：指出MySQL能使用哪个索引在表中找到记录，查询涉及到的字段上若存在索引，则该索引将被列出，但不一定被查询使用</li>\n<li><code>Key</code>：key列显示MySQL实际决定使用的键（索引）</li>\n<li><code>key_len</code>：表示索引中使用的字节数，可通过该列计算查询中使用的索引的长度，key_len显示的值为索引字段的最大可能长度，并非实际使用长度，不损失精确性的情况下，长度越短越好</li>\n<li><code>ref</code>：表示上述表的连接匹配条件，即哪些列或常量被用于查找索引列上的值</li>\n<li><code>rows</code>： 表示MySQL根据表统计信息及索引选用情况，估算的找到所需的记录所需要读取的行数</li>\n<li><code>Extra</code>：该列包含MySQL解决查询的详细信息。Extra这个字段中的<code>“Using filesort”表示的就是需要排序</code>，MySQL会给每个线程分配一块内存用于排序，称为<code>sort_buffer</code>。</li>\n</ul>\n<p><img src=\"https://img-blog.csdnimg.cn/20190416174643103.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=qZTfO&originHeight=642&originWidth=655&originalType=binary&ratio=1&status=done&style=none\"></p>\n<ul>\n<li>按name排序”这个动作，可能在内存中完成，也可能需要使用外部排序，这取决于排序所需的内存和参数<code>sort_buffer_size</code>。</li>\n<li><code>sort_buffer_size</code>就是MySQL为排序开辟的内存（<code>sort_buffer</code>）的大小。如果要排序的数据量小于sort_buffer_size，排序就在内存中完成。但如果排序数据量太大，内存放不下，则不得不利用磁盘临时文件辅助排序。</li>\n</ul>\n<blockquote>\n<p>确定一个排序语句是否使用了临时文件</p>\n</blockquote>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/* 打开optimizer_trace，只对本线程有效 */</span></span><br><span class=\"line\"><span class=\"keyword\">SET</span> optimizer_trace<span class=\"operator\">=</span><span class=\"string\">&#x27;enabled=on&#x27;</span>; </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/* @a保存Innodb_rows_read的初始值 */</span></span><br><span class=\"line\"><span class=\"keyword\">select</span> VARIABLE_VALUE <span class=\"keyword\">into</span> <span class=\"variable\">@a</span> <span class=\"keyword\">from</span>  performance_schema.session_status <span class=\"keyword\">where</span> variable_name <span class=\"operator\">=</span> <span class=\"string\">&#x27;Innodb_rows_read&#x27;</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/* 执行语句 */</span></span><br><span class=\"line\"><span class=\"keyword\">select</span> city, name,age <span class=\"keyword\">from</span> t <span class=\"keyword\">where</span> city<span class=\"operator\">=</span><span class=\"string\">&#x27;杭州&#x27;</span> <span class=\"keyword\">order</span> <span class=\"keyword\">by</span> name limit <span class=\"number\">1000</span>; </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/* 查看 OPTIMIZER_TRACE 输出 */</span></span><br><span class=\"line\"><span class=\"keyword\">SELECT</span> <span class=\"operator\">*</span> <span class=\"keyword\">FROM</span> `information_schema`.`OPTIMIZER_TRACE`</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/* @b保存Innodb_rows_read的当前值 */</span></span><br><span class=\"line\"><span class=\"keyword\">select</span> VARIABLE_VALUE <span class=\"keyword\">into</span> <span class=\"variable\">@b</span> <span class=\"keyword\">from</span> performance_schema.session_status <span class=\"keyword\">where</span> variable_name <span class=\"operator\">=</span> <span class=\"string\">&#x27;Innodb_rows_read&#x27;</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/* 计算Innodb_rows_read差值 */</span></span><br><span class=\"line\"><span class=\"keyword\">select</span> <span class=\"variable\">@b</span><span class=\"operator\">-</span><span class=\"variable\">@a</span>;</span><br></pre></td></tr></table></figure>\n\n\n<p>这个方法是通过查看 OPTIMIZER_TRACE 的结果来确认的，你可以从 number_of_tmp_files中看到是否使用了临时文件。</p>\n<p><img src=\"https://img-blog.csdnimg.cn/2019041617592518.png#id=ZWOG8&originHeight=180&originWidth=712&originalType=binary&ratio=1&status=done&style=none\"></p>\n<ul>\n<li><code>number_of_tmp_files</code>表示的是，排序过程中使用的临时文件数。内存放不下时，就需要使用外部排序，外部排序一般使用归并排序算法。，MySQL将需要排序的数据分成12份，每一份单独排序后存在这些临时文件中。然后把这12个有序文件再合并成一个有序的大文件。</li>\n<li>如果<code>sort_buffer_size</code>超过了需要排序的数据量的大小，<code>number_of_tmp_files</code>就是0，表示排序可以直接在内存中完成。否则就需要放在临时文件中排序。</li>\n<li><code>sort_buffer_size</code>越小，需要分成的份数越多，<code>number_of_tmp_files</code>的值就越大。</li>\n<li><code>sort_mode</code> 里面的<code>packed_additional_fields</code>的意思是，排序过程对字符串做了<code>“紧凑”</code>处理。即使name字段的定义是varchar(16)，在排序过程中还是要按照实际长度来分配空间的。</li>\n<li>同时，最后一个查询语句select @b-@a 的返回结果是4000，表示整个执行过程只扫描了4000行。</li>\n<li>这里需要注意的是，为了避免对结论造成干扰，我把internal_tmp_disk_storage_engine设置成MyISAM。否则，select @b-@a的结果会大于4000</li>\n<li>在上面这个算法过程里面，只对原表的数据读了一遍，剩下的操作都是在sort_buffer和临时文件中执行的。但这个算法有一个问题，就是如果查询要返回的字段很多的话，那么sort_buffer里面要放的字段数太多，这样内存里能够同时放下的行数很少，要分成很多个临时文件，排序的性能会很差。</li>\n</ul>\n<p><strong>如果MySQL认为排序的单行长度太大会怎么做呢？</strong></p>\n<ul>\n<li><code>max_length_for_sort_data</code>，是MySQL中专门控制用于排序的行数据的长度的一个参数。它的意思是，如果单行的长度超过这个值，MySQL就认为单行太大，要换一个算法。</li>\n</ul>\n<h3 id=\"如何正确地显示随机消息\"><a href=\"#如何正确地显示随机消息\" class=\"headerlink\" title=\"如何正确地显示随机消息\"></a>如何正确地显示随机消息</h3><p>从一个单词表中随机选出三个单词</p>\n<p>创建测试表</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"> <span class=\"keyword\">CREATE</span> <span class=\"keyword\">TABLE</span> `words` (</span><br><span class=\"line\">  `id` <span class=\"type\">int</span>(<span class=\"number\">11</span>) <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span> AUTO_INCREMENT,</span><br><span class=\"line\">  `word` <span class=\"type\">varchar</span>(<span class=\"number\">64</span>) <span class=\"keyword\">DEFAULT</span> <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  <span class=\"keyword\">PRIMARY</span> KEY (`id`)</span><br><span class=\"line\">) ENGINE<span class=\"operator\">=</span>InnoDB;</span><br></pre></td></tr></table></figure>\n\n\n<p>添加测试数据</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">delimiter ;;</span><br><span class=\"line\"><span class=\"keyword\">create</span> <span class=\"keyword\">procedure</span> idata3()</span><br><span class=\"line\"><span class=\"keyword\">begin</span></span><br><span class=\"line\">  <span class=\"keyword\">declare</span> i <span class=\"type\">int</span>;</span><br><span class=\"line\">  <span class=\"keyword\">set</span> i<span class=\"operator\">=</span><span class=\"number\">0</span>;</span><br><span class=\"line\">  while i<span class=\"operator\">&lt;</span><span class=\"number\">10000</span> do</span><br><span class=\"line\">    <span class=\"keyword\">insert</span> <span class=\"keyword\">into</span> words(word) <span class=\"keyword\">values</span>(concat(<span class=\"type\">char</span>(<span class=\"number\">97</span><span class=\"operator\">+</span>(i div <span class=\"number\">1000</span>)), <span class=\"type\">char</span>(<span class=\"number\">97</span><span class=\"operator\">+</span>(i <span class=\"operator\">%</span> <span class=\"number\">1000</span> div <span class=\"number\">100</span>)), <span class=\"type\">char</span>(<span class=\"number\">97</span><span class=\"operator\">+</span>(i <span class=\"operator\">%</span> <span class=\"number\">100</span> div <span class=\"number\">10</span>)), <span class=\"type\">char</span>(<span class=\"number\">97</span><span class=\"operator\">+</span>(i <span class=\"operator\">%</span> <span class=\"number\">10</span>))));</span><br><span class=\"line\">    <span class=\"keyword\">set</span> i<span class=\"operator\">=</span>i<span class=\"operator\">+</span><span class=\"number\">1</span>;</span><br><span class=\"line\">  <span class=\"keyword\">end</span> while;</span><br><span class=\"line\"><span class=\"keyword\">end</span>;;</span><br><span class=\"line\">delimiter ;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">call</span> idata3();</span><br></pre></td></tr></table></figure>\n\n\n<p><strong>首先，会想到用order by rand()来实现这个逻辑</strong></p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">EXPLAIN <span class=\"keyword\">select</span> word <span class=\"keyword\">from</span> words <span class=\"keyword\">order</span> <span class=\"keyword\">by</span> rand() limit <span class=\"number\">3</span>;</span><br></pre></td></tr></table></figure>\n\n\n<p><img src=\"https://img-blog.csdnimg.cn/20190416182846114.png#id=IcAaX&originHeight=98&originWidth=1076&originalType=binary&ratio=1&status=done&style=none\"></p>\n<ul>\n<li>Extra字段显示<code>Using temporary</code>，表示的是需要使用临时表；<code>Using filesort</code>，表示的是需要执行排序操作。因此这个Extra的意思就是，需要临时表，并且需要在临时表上排序</li>\n<li>order by rand()使用了内存临时表，内存临时表排序的时候使用了rowid排序方法。</li>\n<li>tmp_table_size这个配置限制了内存临时表的大小，默认值是16M。如果临时表大小超过了tmp_table_size，那么内存临时表就会转成磁盘临时表。</li>\n<li>磁盘临时表使用的引擎默认是InnoDB，是由参数internal_tmp_disk_storage_engine控制的。当使用磁盘临时表的时候，对应的就是一个没有显式索引的InnoDB表的排序过程。</li>\n</ul>\n<h3 id=\"幻读是什么，幻读有什么问题\"><a href=\"#幻读是什么，幻读有什么问题\" class=\"headerlink\" title=\"幻读是什么，幻读有什么问题\"></a>幻读是什么，幻读有什么问题</h3><ul>\n<li>幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。</li>\n<li>在可重复读隔离级别下，普通的查询是快照读，是不会看到别的事务插入的数据的。因此，幻读在“当前读”下才会出现。</li>\n</ul>\n<p><strong>创建测试数据</strong></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CREATE TABLE `t` (</span><br><span class=\"line\">  `id` int(11) NOT NULL,</span><br><span class=\"line\">  `c` int(11) DEFAULT NULL,</span><br><span class=\"line\">  `d` int(11) DEFAULT NULL,</span><br><span class=\"line\">  PRIMARY KEY (`id`),</span><br><span class=\"line\">  KEY `c` (`c`)</span><br><span class=\"line\">) ENGINE=InnoDB;</span><br><span class=\"line\"></span><br><span class=\"line\">insert into t values(0,0,0),(5,5,5),</span><br><span class=\"line\">(10,10,10),(15,15,15),(20,20,20),(25,25,25);</span><br></pre></td></tr></table></figure>\n\n\n<p><strong>下面的语句序列，是怎么加锁的，加的锁又是什么时候释放的呢？</strong></p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">begin</span>;</span><br><span class=\"line\"><span class=\"keyword\">select</span> <span class=\"operator\">*</span> <span class=\"keyword\">from</span> t <span class=\"keyword\">where</span> d<span class=\"operator\">=</span><span class=\"number\">5</span> <span class=\"keyword\">for</span> update;</span><br><span class=\"line\"><span class=\"keyword\">commit</span>;</span><br></pre></td></tr></table></figure>\n\n\n<ul>\n<li>这个语句会命中d=5的这一行，对应的主键id=5，因此在select 语句执行完成后，id=5这一行会加一个写锁，而且由于两阶段锁协议，这个写锁会在执行commit语句的时候释放。</li>\n<li>由于字段d上没有索引，因此这条查询语句会做全表扫描。那么，其他被扫描到的，但是不满足条件的5行记录上，会不会被加锁呢？</li>\n</ul>\n<p><img src=\"https://img-blog.csdnimg.cn/20190418165218311.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=GPJCV&originHeight=688&originWidth=984&originalType=binary&ratio=1&status=done&style=none\"></p>\n<ul>\n<li>可以看到，session A里执行了三次查询，分别是Q1、Q2和Q3。它们的SQL语句相同，都是select * from t where d=5 for update。这个语句的意思你应该很清楚了，查所有d=5的行，而且使用的是当前读，并且加上写锁</li>\n</ul>\n<p><strong>图中SQL执行流程</strong></p>\n<ul>\n<li>Q1只返回id=5这一行；</li>\n<li>在T2时刻，session B把id=0这一行的d值改成了5，因此T3时刻Q2查出来的是id=0和id=5这两行；</li>\n<li>在T4时刻，session C又插入一行（1,1,5），因此T5时刻Q3查出来的是id=0、id=1和id=5的这三行。</li>\n<li>其中，Q3读到id=1这一行的现象，被称为<code>“幻读”</code>。</li>\n<li>在<code>可重复读</code>(InnoDB的默认)隔离级别下，普通的查询是快照读，是不会看到别的事务插入的数据的。因此，<code>幻读在“当前读”下才会出现。</code></li>\n<li>上面session B的修改结果，被session A之后的select语句用“当前读”看到，不能称为幻读。幻读仅专指“新插入的行”</li>\n</ul>\n<p>从事务可见性规则来分析的话，上面这三条SQL语句的返回结果都没有问题。因为这三个查询都是加了for update，都是当前读。而当前读的规则，就是要能读到所有已经提交的记录的最新值。并且，session B和sessionC的两条语句，执行后就会提交，所以Q2和Q3就是应该看到这两个事务的操作效果，而且也看到了，这跟事务的可见性规则并不矛盾。但是，这是不是真的没问题呢？</p>\n<p><strong>幻读有什么问题？</strong></p>\n<ul>\n<li>首先是语义上的。session A在T1时刻就声明了，“我要把所有d=5的行锁住，不准别的事务进行读写操作”。而实际上，这个语义被破坏了。</li>\n</ul>\n<p><strong>其次，是数据一致性的问题。</strong></p>\n<ul>\n<li>我们知道，锁的设计是为了保证数据的一致性。而这个一致性，不止是数据库内部数据状态在此刻的一致性，还包含了数据和日志在逻辑上的一致性</li>\n<li>为了说明这个问题，我给session A在T1时刻再加一个更新语句，即：update t set d=100 where d=5。<br><img src=\"https://img-blog.csdnimg.cn/20190418171046246.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=Wyaze&originHeight=551&originWidth=929&originalType=binary&ratio=1&status=done&style=none\"><br><strong>上面的执行流程</strong></li>\n<li>经过T1时刻，id=5这一行变成 (5,5,100)，当然这个结果最终是在T6时刻正式提交的;</li>\n<li>经过T2时刻，id=0这一行变成(0,5,5);</li>\n<li>经过T4时刻，表里面多了一行(1,5,5);</li>\n</ul>\n<p>这样看，这些数据也没啥问题，但是我们再来看看这时候binlog里面的内容。</p>\n<ul>\n<li>T2时刻，session B事务提交，写入了两条语句；</li>\n<li>T4时刻，session C事务提交，写入了两条语句；</li>\n<li>T6时刻，session A事务提交，写入了update t set d=100 where d=5 这条语句。</li>\n</ul>\n<p>放到一起的话，就是这样的：</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">update t <span class=\"keyword\">set</span> d<span class=\"operator\">=</span><span class=\"number\">5</span> <span class=\"keyword\">where</span> id<span class=\"operator\">=</span><span class=\"number\">0</span>; <span class=\"comment\">/*(0,0,5)*/</span></span><br><span class=\"line\">update t <span class=\"keyword\">set</span> c<span class=\"operator\">=</span><span class=\"number\">5</span> <span class=\"keyword\">where</span> id<span class=\"operator\">=</span><span class=\"number\">0</span>; <span class=\"comment\">/*(0,5,5)*/</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">insert</span> <span class=\"keyword\">into</span> t <span class=\"keyword\">values</span>(<span class=\"number\">1</span>,<span class=\"number\">1</span>,<span class=\"number\">5</span>); <span class=\"comment\">/*(1,1,5)*/</span></span><br><span class=\"line\">update t <span class=\"keyword\">set</span> c<span class=\"operator\">=</span><span class=\"number\">5</span> <span class=\"keyword\">where</span> id<span class=\"operator\">=</span><span class=\"number\">1</span>; <span class=\"comment\">/*(1,5,5)*/</span></span><br><span class=\"line\"></span><br><span class=\"line\">update t <span class=\"keyword\">set</span> d<span class=\"operator\">=</span><span class=\"number\">100</span> <span class=\"keyword\">where</span> d<span class=\"operator\">=</span><span class=\"number\">5</span>;<span class=\"comment\">/*所有d=5的行，d改成100*/</span></span><br></pre></td></tr></table></figure>\n\n\n<blockquote>\n<p>这个语句序列，不论是拿到备库去执行，还是以后用binlog来克隆一个库，这三行的结果，都变成了 (0,5,100)、(1,5,100)和(5,5,100)。也就是说，id=0和id=1这两行，发生了数据不一致。这个问题很严重，是不行的。</p>\n</blockquote>\n<p><strong>如何解决幻读？</strong></p>\n<ul>\n<li>产生幻读的原因是，行锁只能锁住行，但是新插入记录这个动作，要更新的是记录之间的“间隙”。因此，为了解决幻读问题，InnoDB只好引入新的锁，也就是间隙锁(Gap Lock)。</li>\n<li>间隙锁，锁的就是两个值之间的空隙。比如文章开头的表t，初始化插入了6个记录，这就产生了7个间隙。</li>\n<li>这样，当你执行 select * from t where d=5 for update的时候，就不止是给数据库中已有的6个记录加上了行锁，还同时加了7个间隙锁。这样就确保了无法再插入新的记录。</li>\n<li>也就是说这时候，在一行行扫描的过程中，不仅将给行加上了行锁，还给行两边的空隙，也加上了间隙锁。</li>\n<li>间隙锁存在冲突关系的，是“往这个间隙中插入一个记录”这个操作。间隙锁之间都不存在冲突关系。</li>\n<li>间隙锁和next-key lock的引入，帮我们解决了幻读的问题，但同时也带来了一些“困扰”</li>\n</ul>\n<blockquote>\n<p>比如现在有这样一个场景 业务逻辑这样的：任意锁住一行，如果这一行不存在的话就插入，如果存在这一行就更新它的数据，代码如下：</p>\n</blockquote>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">begin</span>;</span><br><span class=\"line\"><span class=\"keyword\">select</span> <span class=\"operator\">*</span> <span class=\"keyword\">from</span> t <span class=\"keyword\">where</span> id<span class=\"operator\">=</span>N <span class=\"keyword\">for</span> update;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/*如果行不存在*/</span></span><br><span class=\"line\"><span class=\"keyword\">insert</span> <span class=\"keyword\">into</span> t <span class=\"keyword\">values</span>(N,N,N);</span><br><span class=\"line\"><span class=\"comment\">/*如果行存在*/</span></span><br><span class=\"line\">update t <span class=\"keyword\">set</span> d<span class=\"operator\">=</span>N <span class=\"keyword\">set</span> id<span class=\"operator\">=</span>N;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">commit</span>;</span><br></pre></td></tr></table></figure>\n\n\n<blockquote>\n<p>可能你会说，这个不是<code>insert ... on duplicate key update</code> 就能解决吗？但其实在有多个唯一键的时候,这个方法是不能满足要求的。这个逻辑一旦有并发，就会碰到死锁。你一定也觉得奇怪，这个逻辑每次操作前用for update锁起来，已经是最严格的模式了，怎么还会有死锁呢？</p>\n</blockquote>\n<p><img src=\"https://img-blog.csdnimg.cn/20190418172853342.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=n7URX&originHeight=372&originWidth=982&originalType=binary&ratio=1&status=done&style=none\"><br>你看到了，其实都不需要用到后面的update语句，就已经形成死锁了。我们按语句执行顺序来分析一下：</p>\n<ul>\n<li>session A 执行select … for update语句，由于id=9这一行并不存在，因此会加上间隙锁(5,10);</li>\n<li>session B 执行select … for update语句，同样会加上间隙锁(5,10)，间隙锁之间不会冲突，因此这个语句可以执行成功；</li>\n<li>session B 试图插入一行(9,9,9)，被session A的间隙锁挡住了，只好进入等待；</li>\n<li>session A试图插入一行(9,9,9)，被session B的间隙锁挡住了。</li>\n<li>至此，两个session进入互相等待状态，形成死锁。当然，InnoDB的死锁检测马上就发现了这对死锁关系，让session A的insert语句报错返回了。</li>\n</ul>\n<blockquote>\n<p><code>间隙锁是在可重复读隔离级别下才会生效的</code>。所以，你如果把隔离级别设置为读提交的话，就没有间隙锁了。但同时，你要解决可能出现的数据和日志不一致问题，需要把<code>binlog</code>格式设置为row。这，也是现在不少公司使用的配置组合。</p>\n</blockquote>\n","site":{"data":{}},"length":28847,"excerpt":"","more":"<h3 id=\"一条SQL查询语句是如何执行的\"><a href=\"#一条SQL查询语句是如何执行的\" class=\"headerlink\" title=\"一条SQL查询语句是如何执行的\"></a>一条SQL查询语句是如何执行的</h3><figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql<span class=\"operator\">&gt;</span> <span class=\"keyword\">select</span> <span class=\"operator\">*</span> <span class=\"keyword\">from</span> T <span class=\"keyword\">where</span> ID<span class=\"operator\">=</span><span class=\"number\">10</span>；</span><br></pre></td></tr></table></figure>\n\n\n<p><img src=\"https://img-blog.csdnimg.cn/20190410210326412.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=Mnrxq&originHeight=798&originWidth=1086&originalType=binary&ratio=1&status=done&style=none\"></p>\n<blockquote>\n<p>大体来说，MySQL可以分为<code>Server</code>层和<code>存储引擎</code>层两部分</p>\n</blockquote>\n<ul>\n<li><code>Server</code>层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖MySQL的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。</li>\n<li><code>存储引擎层</code>负责数据的存储和提取。其架构模式是插件式的，支持InnoDB、MyISAM、Memory等多个存储引擎。现在最常用的存储引擎是InnoDB，它从MySQL 5.5.5版本开始成为了默认存储引擎。</li>\n<li>不同的存储引擎共用一个Server层，也就是从连接器到执行器的部分</li>\n<li></li>\n</ul>\n<p><strong>连接器</strong></p>\n<ul>\n<li>第一步，你会先连接到这个数据库上，这时候接待你的就是连接器。连接器负责跟客户端建立连接、获取权限、维持和管理连接。连接完成后，如果你没有后续的动作，这个连接就处于空闲状态，你可以在<code>show processlist</code>命令中看到它。客户端如果太长时间没动静，连接器就会自动将它断开。这个时间是由参数<code>wait_timeout</code>控制的，默认值是<code>8</code>小时。数据库里面，长连接是指连接成功后，如果客户端持续有请求，则一直使用同一个连接。短连接则是指每次执行完很少的几次查询就断开连接，下次查询再重新建立一个。</li>\n</ul>\n<p><strong>查询缓存</strong></p>\n<ul>\n<li>连接建立完成后，你就可以执行select语句了。执行逻辑就会来到第二步：查询缓存。</li>\n<li>MySQL拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。之前执行过的语句及其结果可能会以key-value对的形式，被直接缓存在内存中。key是查询的语句，value是查询的结果。如果你的查询能够直接在这个缓存中找到key，那么这个value就会被直接返回给客户端。</li>\n<li>如果语句不在查询缓存中，就会继续后面的执行阶段。执行完成后，执行结果会被存入查询缓存中。</li>\n</ul>\n<blockquote>\n<p>大多数情况下我会建议你不要使用查询缓存，为什么呢？因为查询缓存往往弊大于利。查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。</p>\n</blockquote>\n<p><strong>分析器</strong></p>\n<ul>\n<li>如果没有命中查询缓存，就要开始真正执行语句了。首先，MySQL需要知道你要做什么，因此需要对SQL语句做解析。分析器先会做<code>“词法分析”</code>,词法分析完后就要做<code>“语法分析”</code>。根据词法分析的结果，语法分析器会根据语法规则，判断你输入的这个SQL语句是否满足MySQL语法。如果你的语句不对，就会收到“You have an error in your SQL syntax”的错误提醒</li>\n</ul>\n<p><strong>优化器</strong></p>\n<ul>\n<li>经过了分析器，MySQL就知道你要做什么了。在开始执行之前，还要先经过优化器的处理。</li>\n<li>优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。</li>\n</ul>\n<blockquote>\n<p>比如你执行下面这样的语句，这个语句是执行两个表的join：<br><code>mysql&gt; select * from t1 join t2 using(ID) where t1.c=10 and t2.d=20;</code><br>既可以先从表t1里面取出c=10的记录的ID值，再根据ID值关联到表t2，再判断t2里面d的值是否等于20。<br>也可以先从表t2里面取出d=20的记录的ID值，再根据ID值关联到t1，再判断t1里面c的值是否等于10。<br>这两种执行方法的逻辑结果是一样的，但是执行的效率会有不同，而优化器的作用就是决定选择使用哪一个方案。</p>\n</blockquote>\n<p><strong>执行器</strong></p>\n<ul>\n<li>MySQL通过分析器知道了你要做什么，通过优化器知道了该怎么做，于是就进入了执行器阶段，开始执行语句。</li>\n<li>开始执行的时候，要先判断一下你对这个表T有没有执行查询的权限，如果没有，就会返回没有权限的错误</li>\n<li>如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。</li>\n</ul>\n<blockquote>\n<p><code>mysql&gt; select * from T where ID=10;</code><br>比如我们这个例子中的表T中，ID字段没有索引，那么执行器的执行流程是这样的：<br>调用InnoDB引擎接口取这个表的第一行，判断ID值是不是10，如果不是则跳过，如果是则将这行存在结果集中；<br>调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。<br>执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。</p>\n</blockquote>\n<ul>\n<li>至此，这个整个语句就执行完成了。一条查询语句的执行过程一般是经过连接器、分析器、优化器、执行器等功能模块，最后到达存储引擎。</li>\n</ul>\n<h3 id=\"一条SQL更新语句是如何执行的\"><a href=\"#一条SQL更新语句是如何执行的\" class=\"headerlink\" title=\"一条SQL更新语句是如何执行的\"></a>一条SQL更新语句是如何执行的</h3><figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">update T <span class=\"keyword\">set</span> c<span class=\"operator\">=</span>c<span class=\"operator\">+</span><span class=\"number\">1</span> <span class=\"keyword\">where</span> ID<span class=\"operator\">=</span><span class=\"number\">2</span>;</span><br></pre></td></tr></table></figure>\n\n\n<ul>\n<li>与查询流程不一样的是，更新流程还涉及两个重要的日志模块 <code>redo log</code>（重做日志）和 <code>binlog</code>（归档日志）</li>\n<li>每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程IO成本、查找成本都很高。为了解决这个问题，MySQL的设计者WAL技术，WAL的全称是Write-Ahead Logging，它的关键点就是<code>先写日志</code>，<code>再写磁盘</code></li>\n<li>当有一条记录需要更新的时候，InnoDB引擎就会先把记录写到redo log里面，并更新内存，这个时候更新就算完成了。</li>\n<li>同时，<code>InnoDB</code>引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做。但是<code>InnoDB</code>的<code>redo log</code>是固定大小的，比如可以配置为一组4个文件，每个文件的大小是1GB,总共就可以记录4GB的操作。从头开始写，写到末尾就又回到开头循环写。</li>\n<li>在进行<code>redo log</code>写入时，有两个重要参数的write pos(当前记录的位置),<code>checkpoint</code>是当前要擦除的位置<br><img src=\"https://img-blog.csdnimg.cn/20190410230340406.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=evnl5&originHeight=272&originWidth=884&originalType=binary&ratio=1&status=done&style=none\"></li>\n<li>一边写一边后移，写到第3号文件末尾后就回到0号文件开头,checkpoint也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。write pos和checkpoint之间还空着的部分，可以用来记录新的操作。</li>\n<li>如果<code>write pos</code>追上<code>checkpoin</code>，表示<code>redo log</code>满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把checkpoint推进一下。</li>\n<li>有了redo log，InnoDB就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为crash-safe(崩溃安全()。</li>\n<li>redo log是InnoDB引擎特有的日志，而Server层也有自己的日志，称为binlog（归档日志）</li>\n<li>最开始MySQL里并没有<code>InnoDB引擎</code>。MySQL自带的引擎是MyISAM，但是MyISAM没有crash-safe的能力，binlog日志只能用于归档。而InnoDB是另一个公司以插件形式引入MySQL的，既然只依靠binlog是没有crash-safe能力的，所以InnoDB使用另外一套日志系统——也就是redo log来实现crash-safe能力。</li>\n</ul>\n<blockquote>\n<p><code>redo log是InnoDB引擎特有的</code>；binlog是MySQL的Server层实现的，所有引擎都可以使用。<br><code>redo log是物理日志</code>，记录的是“在某个数据页上做了什么修改”；<code>binlog是逻辑日志</code>，记录的是这个语句的原始逻辑，比如“给ID=2这一行的c字段加1 ”。<br>r<code>edo log是循环写的</code>，<code>空间固定</code>会用完；<code>binlog是可以追加写入的</code>。“追加写”是指binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。</p>\n</blockquote>\n<p><strong>执行器和InnoDB引擎在执行这个简单的update语句时的内部流程:</strong></p>\n<ul>\n<li>执行器先找引擎取ID=2这一行。ID是主键，引擎直接用树搜索找到这一行。如果ID=2这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。</li>\n<li>执行器拿到引擎给的行数据，把这个值加上1，比如原来是N，现在就是N+1，得到新的一行数据，再调用引擎接口写入这行新数据。</li>\n<li>引擎将这行新数据更新到内存中，同时将这个更新操作记录到redo log里面，此时redo log处于prepare状态。然后告知执行器执行完成了，随时可以提交事务。</li>\n<li>执行器生成这个操作的binlog，并把binlog写入磁盘。</li>\n<li>执行器调用引擎的提交事务接口，引擎把刚刚写入的redo log改成提交（commit）状态，更新完成。</li>\n<li>redo log的写入拆成了两个步骤：prepare和commit，这就是<code>&quot;两阶段提交&quot;</code>。</li>\n</ul>\n<p><img src=\"https://img-blog.csdnimg.cn/2019041023325625.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=tDmdi&originHeight=1522&originWidth=1142&originalType=binary&ratio=1&status=done&style=none\"></p>\n<blockquote>\n<p><code>1 prepare阶段 2 写binlog 3 commit</code> , 当在<code>2之前崩溃时</code>,重启恢复：后发现没有commit，回滚。备份恢复：没有binlog 。<br><code>当在3之前崩溃</code>,重启恢复：虽没有commit，但满足prepare和binlog完整，所以重启后会自动commit。备份：有binlog. 一致</p>\n</blockquote>\n<h4 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h4><ul>\n<li>Redo log不是记录数据页“更新之后的状态”，而是记录这个页 “做了什么改动”。</li>\n<li>Binlog有两种模式，statement 格式的话是记sql语句， row格式会记录行的内容，记两条，更新前和更新后都有。</li>\n</ul>\n<h3 id=\"事务隔离：为什么你改了我还看不见\"><a href=\"#事务隔离：为什么你改了我还看不见\" class=\"headerlink\" title=\"事务隔离：为什么你改了我还看不见\"></a>事务隔离：为什么你改了我还看不见</h3><ul>\n<li>事务就是要保证一组数据库操作，要么全部成功，要么全部失败。在MySQL中，事务支持是在引擎层实现的。MySQL默认的<code>MyISAM</code>引擎就不支持事务，这也是<code>MyISAM</code>被<code>InnoDB</code>取代的重要原因之一。</li>\n<li>事务的特性：<code>ACID</code>即原子性、一致性、隔离性、持久性。多个事务同时执行的时候，就可能出现<code>脏读</code>，<code>不可重复读</code>，<code>幻读</code>，为了解决这些问题，就有了“<code>隔离级别</code>”的概念。但是隔离得越严实，效率就会越低</li>\n<li>SQL标准的事务隔离级别包括：<code>读未提交</code>（read uncommitted）、<code>读提交</code>（read committed）、<code>可重复读</code>（repeatable read）和<code>串行化</code>（serializable ）</li>\n</ul>\n<blockquote>\n<p>读未提交是指，一个事务还没提交时，它做的变更就能被别的事务看到。<br>读提交是指，一个事务提交之后，它做的变更才会被其他事务看到。<br>可重复读是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。未提交的更改对其他事务是不可见的<br>串行化:对应一个记录会加读写锁，出现冲突的时候，后访问的事务必须等前一个事务执行完成才能继续执行</p>\n</blockquote>\n<ul>\n<li>在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。在“<code>可重复读</code>”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。在<code>“读提交”</code>隔离级别下，这个视图是在每个SQL语句开始执行的时候创建的。<code>“读未提交”</code>隔离级别下直接返回记录上的最新值，没有视图概念。<code>串行化</code>”隔离级别下直接用加锁的方式来避免并行访问</li>\n<li>查看数据库的实物隔离级别：<code>show variables like &#39;%isolation%&#39;;</code></li>\n<li>事务隔离的实现：在MySQL中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。</li>\n</ul>\n<p>假设一个值从1被按顺序改成了2、3、4，在回滚日志里面就会有类似下面的记录。不同时刻启动的事务会有不同的read-view，同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（<code>MVCC</code>）<br><img src=\"https://img-blog.csdnimg.cn/20190411130916709.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=AC58n&originHeight=407&originWidth=973&originalType=binary&ratio=1&status=done&style=none\"></p>\n<ul>\n<li>回滚日志总不能一直保留吧，什么时候删除呢？答案是，在不需要的时候才删除。系统会判断，当没有事务再需要用到这些回滚日志时，回滚日志会被删除。什么时候才不需要了呢？就是当系统里没有比这个回滚日志更早的read-view的时候。</li>\n<li>为什么尽量不要使用长事务。长事务意味着系统里面会存在很老的事务视图，在这个事务提交之前，回滚记录都要保留，这会导致大量占用存储空间。除此之外，长事务还占用锁资源，可能会拖垮库。</li>\n<li>事务启动方式：一、显式启动事务语句，<code>begin</code>或者<code>start transaction</code>,提交<code>commit</code>，回滚<code>rollback</code>；二、<code>set autocommit=0</code>，该命令会把这个线程的自动提交关掉。这样只要执行一个select语句，事务就启动，并不会自动提交，直到主动执行<code>commit</code>或<code>rollback</code>或断开连接。</li>\n<li>建议使用方法一，如果考虑多一次交互问题，可以使用<code>commit work and chain</code>语法。在<code>autocommit=1</code>的情况下用<code>begin</code>显式启动事务，如果执行<code>commit</code>则提交事务。如果执行<code>commit work and chain</code>则提交事务并自动启动下一个事务</li>\n</ul>\n<h3 id=\"深入浅出索引（上）\"><a href=\"#深入浅出索引（上）\" class=\"headerlink\" title=\"深入浅出索引（上）\"></a>深入浅出索引（上）</h3><p><strong>索引的常见模型</strong></p>\n<ul>\n<li>索引的出现是为了提高查询效率，常见的三种索引模型分别是<code>哈希表</code>、<code>有序数组</code>和<code>搜索树</code></li>\n<li><code>哈希表</code>：一种以<code>key-value</code> 存储数据的结构，哈希的思路是把值放在数组里，用一个哈希函数把<code>key</code>换算成一个确定的位置，然后把<code>value</code>放在数组的这个位置。哈希冲突的处理办法是使用<code>链表</code>。哈希表适用只有<code>等值查询</code>的场景</li>\n<li><code>有序数组</code>：按顺序存储。查询用二分法就可以快速查询，时间复杂度是：O(log(N))。查询效率高，更新效率低（涉及到移位）。在等值查询和范围查询场景中的性能就都非常优秀。有序数组索引只适用于静态存储引擎。</li>\n<li>二叉搜索树：每个节点的左儿子小于父节点，右儿子大于父节点。查询时间复杂度O(log(N))，更新时间复杂度O(log(N))。数据库存储大多不适用二叉树，因为树高过高，会适用N叉树</li>\n</ul>\n<p><strong>InnoDB 的索引模型</strong></p>\n<ul>\n<li><code>InnoDB</code>使用了<code>B+树</code>索引模型，所以数据都是存储在B+树中的。每一个索引在<code>InnoDB</code>里面对应一棵B+树。</li>\n<li>索引类型分为<code>主键索引</code>和<code>非主键索引</code>。主键索引的叶子节点存的是整行数据。在InnoDB里，主键索引也被称为<code>聚簇索引</code>。非主键索引的叶子节点内容是主键的值。在InnoDB里，非主键索引也被称为<code>二级索引</code></li>\n</ul>\n<p><img src=\"https://img-blog.csdnimg.cn/20190411164702315.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=GPjHM&originHeight=424&originWidth=1004&originalType=binary&ratio=1&status=done&style=none\"></p>\n<p><strong>主键索引和普通索引的查询有什么区别？</strong></p>\n<ul>\n<li>如果语句是<code>select * from T where ID=500</code>，即主键查询方式，则只需要搜索ID这棵B+树；</li>\n<li>如果语句是<code>select * from T where k=5</code>，即普通索引查询方式，则需要先搜索k索引树，得到ID的值为500，再到ID索引树搜索一次。这个过程称为<code>回表</code>。</li>\n<li>基于非主键索引的查询需要多扫描一棵索引树。因此，我们在应用中应该尽量使用主键查询</li>\n</ul>\n<p><strong>索引维护</strong></p>\n<ul>\n<li><code>B+树</code>为了维护索引有序性，在插入新值的时候需要做必要的维护。涉及到数据的移动和数据页的增加和删减</li>\n<li>一个数据页满了，按照B+Tree算法，新增加一个数据页，叫做<code>页分裂</code>，会导致性能下降。空间利用率降低大概50%。当相邻的两个数据页利用率很低的时候会做<code>数据页合并</code>，合并的过程是分裂过程的<code>逆过程</code>。</li>\n</ul>\n<h4 id=\"总结-1\"><a href=\"#总结-1\" class=\"headerlink\" title=\"总结\"></a>总结</h4><ul>\n<li>索引可能因为删除，或者页分裂等原因，导致数据页有空洞，重建索引的过程会创建一个新的索引，把数据按顺序插入，这样页面的利用率最高，也就是索引更紧凑、更省空间。</li>\n</ul>\n<blockquote>\n<p><code>alter table T drop index k</code>;     alter table T add index(k);<br>要重建主键索引<br><code>alter table T drop primary key</code>;      <code>alter table T add primary key(id)</code>;<br>重建索引k的做法是合理的，可以达到省空间的目的。但是，重建主键的过程不合理。不论是删除主键还是创建主键，都会将整个表重建。所以连着执行这两个语句的话，第一个语句就白做了。<br>可以用这个语句代替 ： alter table T engine=InnoDB</p>\n</blockquote>\n<h3 id=\"深入浅出索引（下）\"><a href=\"#深入浅出索引（下）\" class=\"headerlink\" title=\"深入浅出索引（下）\"></a>深入浅出索引（下）</h3><figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql<span class=\"operator\">&gt;</span> <span class=\"keyword\">create</span> <span class=\"keyword\">table</span> T (</span><br><span class=\"line\">ID <span class=\"type\">int</span> <span class=\"keyword\">primary</span> key,</span><br><span class=\"line\">k <span class=\"type\">int</span> <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span> <span class=\"keyword\">DEFAULT</span> <span class=\"number\">0</span>, </span><br><span class=\"line\">s <span class=\"type\">varchar</span>(<span class=\"number\">16</span>) <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span> <span class=\"keyword\">DEFAULT</span> <span class=\"string\">&#x27;&#x27;</span>,</span><br><span class=\"line\">index k(k))</span><br><span class=\"line\">engine<span class=\"operator\">=</span>InnoDB;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">insert</span> <span class=\"keyword\">into</span> T <span class=\"keyword\">values</span>(<span class=\"number\">100</span>,<span class=\"number\">1</span>, <span class=\"string\">&#x27;aa&#x27;</span>),(<span class=\"number\">200</span>,<span class=\"number\">2</span>,<span class=\"string\">&#x27;bb&#x27;</span>),(<span class=\"number\">300</span>,<span class=\"number\">3</span>,<span class=\"string\">&#x27;cc&#x27;</span>),(<span class=\"number\">500</span>,<span class=\"number\">5</span>,<span class=\"string\">&#x27;ee&#x27;</span>),(<span class=\"number\">600</span>,<span class=\"number\">6</span>,<span class=\"string\">&#x27;ff&#x27;</span>),(<span class=\"number\">700</span>,<span class=\"number\">7</span>,<span class=\"string\">&#x27;gg&#x27;</span>);</span><br></pre></td></tr></table></figure>\n\n\n<p><img src=\"https://img-blog.csdnimg.cn/20190411193509228.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=iQfIH&originHeight=441&originWidth=989&originalType=binary&ratio=1&status=done&style=none\"><br>如果我执行 <code>select * from T where k between 3 and 5</code>，需要执行几次树的搜索操作，会扫描多少行？</p>\n<p><strong>SQL查询语句的执行流程：</strong></p>\n<ul>\n<li>在k索引树上找到k=3的记录，取得 ID = 300；</li>\n<li>再到ID索引树查到ID=300对应的R3；</li>\n<li>在k索引树取下一个值k=5，取得ID=500；</li>\n<li>再回到ID索引树查到ID=500对应的R4；</li>\n<li>在k索引树取下一个值k=6，不满足条件，循环结束。</li>\n<li>在这个过程中，回到主键索引树搜索的过程，我们称为回表。可以看到，这个查询过程读了k索引树的3条记录，回表了两次。在这个例子中，由于查询结果所需要的数据只在主键索引上有，所以不得不回表。</li>\n</ul>\n<p><strong>优化方式</strong></p>\n<ul>\n<li>sql语句修改为<code>select ID from T where k between 3 and 5</code>，这时只需要查ID的值，而ID的值已经在k索引树上了，因此可以直接提供查询结果，不需要回表。也就是说，在这个查询里面，索引k已经“覆盖了”我们的查询需求，我们称为<code>覆盖索引</code>。</li>\n<li>由于<code>覆盖索引</code>可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。</li>\n</ul>\n<h4 id=\"总结-2\"><a href=\"#总结-2\" class=\"headerlink\" title=\"总结\"></a>总结</h4><ul>\n<li><code>覆盖索引</code>：如果查询条件使用的是普通索引（或是联合索引的最左原则字段），查询结果是联合索引的字段或是主键，不用回表操作，直接返回结果，减少IO磁盘读写读取正行数据</li>\n<li><code>最左前缀</code>：联合索引的最左 N 个字段，也可以是字符串索引的最左 M 个字符</li>\n<li><code>联合索引</code>：根据创建联合索引的顺序，以最左原则进行where检索，比如（age，name）以age=1 或 age= 1 and name=‘张三’可以使用索引，单以name=‘张三’ 不会使用索引，考虑到存储空间的问题，还请根据业务需求，将查找频繁的数据进行靠左创建索引。</li>\n<li>索引下推：<code>like &#39;hello%’and age &gt;10</code> 检索，MySQL5.6版本之前，会对匹配的数据进行回表查询。5.6版本后，会先过滤掉age&lt;10的数据，再进行回表查询，减少回表率，提升检索速度</li>\n</ul>\n<h3 id=\"讲全局锁和表锁：给表加个字段怎么有这么多阻碍\"><a href=\"#讲全局锁和表锁：给表加个字段怎么有这么多阻碍\" class=\"headerlink\" title=\"讲全局锁和表锁：给表加个字段怎么有这么多阻碍\"></a>讲全局锁和表锁：给表加个字段怎么有这么多阻碍</h3><blockquote>\n<p>根据加锁的范围，MySQL里面的锁大致可以分成全局锁、表级锁和行锁三类</p>\n</blockquote>\n<p><strong>全局锁</strong></p>\n<ul>\n<li>对整个数据库实例加锁。MySQL提供加全局读锁的方法：<code>Flush tables with read lock(FTWRL)</code>。这个命令可以使整个库处于只读状态。使用该命令之后，数据更新语句、数据定义语句和更新类事务的提交语句等操作都会被阻塞。使用场景：<code>全库逻辑备份</code>。</li>\n<li>风险是如果在主库备份，在备份期间不能更新，业务停摆。如果在从库备份，备份期间不能执行主库同步的binlog，导致主从延迟。官方自带的逻辑备份工具<code>mysqldump</code>，当mysqldump使用参数<code>--single-transaction</code>的时候，会启动一个事务，确保拿到一致性视图。而由于<code>MVCC</code>的支持，这个过程中数据是可以正常更新的。</li>\n<li>一致性读是好，但是前提是引擎要支持这个隔离级别。如果要全库只读，为什么不使用<code>set global readonly=true</code>的方式？在有些系统中，<code>readonly</code>的值会被用来做其他逻辑，比如判断主备库。所以修改global变量的方式影响太大。</li>\n<li>在异常处理机制上有差异。如果执行<code>FTWRL</code>命令之后由于客户端发生异常断开，那么MySQL会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为<code>readonly</code>之后，如果客户端发生异常，则数据库就会一直保持<code>readonly</code>状态，这样会导致整个库长时间处于不可写状态，风险较高。</li>\n</ul>\n<p><strong>表级锁</strong></p>\n<ul>\n<li>MySQL里面表级锁有两种，一种是表锁，一种是元数据所(meta data lock,MDL)。表锁的语法是:l<code>ock tables ... read/write</code></li>\n<li>可以用<code>unlock tables</code>主动释放锁，也可以在客户端断开的时候自动释放。<code>lock tables</code>语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。</li>\n<li>对于<code>InnoDB</code>这种支持<code>行锁</code>的引擎，一般不使用<code>lock tables</code>命令来控制并发，毕竟锁住整个表的影响面还是太大。</li>\n<li>另一类表级的锁是<code>MDL</code>（metadata lock)。<code>MDL不需要显式使用</code>，在访问一个表的时候会被<code>自动加上</code>。MDL的作用是，<code>保证读写的正确性</code>。当对一个表做增删改查操作的时候，加<code>MDL读锁</code>；当要对表做结构变更操作的时候，加<code>MDL写锁</code>。<code>读锁之间不互斥</code>，因此你可以有多个线程同时对一张表增删改查。<code>读写锁之间、写锁之间是互斥的</code>，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。</li>\n<li><code>MDL</code> 会直到事务提交才会释放，在做表结构变更的时候，一定要小心不要导致锁住线上查询和更新。</li>\n</ul>\n<p><strong>如何安全地给表加字段</strong></p>\n<ul>\n<li>给一个表加字段，或者修改字段，或者加索引，需要扫描全表的数据。首先我们要解决长事务，事务不提交，就会一直占着MDL锁。在MySQL的<code>information_schema</code> 库的 <code>innodb_trx</code> 表中，你可以查到当前执行中的事务。如果你要做<code>DDL</code>变更的表刚好有<code>长事务</code>在执行，要考虑先暂停DDL，或者<code>kill</code>掉这个长事务。</li>\n<li>如果你要变更的表是一个<code>热点表</code>，虽然数据量不大，但是上面的请求很频繁，这时候kill可能未必管用，因为新的请求马上就来了。比较理想的机制是，在<code>alter table</code>语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到<code>MDL写锁</code>最好，拿不到也不要阻塞后面的业务语句，先放弃。之后开发人员或者DBA再通过重试命令重复这个过程。</li>\n</ul>\n<h3 id=\"讲行锁功过：怎么减少行锁对性能的影响\"><a href=\"#讲行锁功过：怎么减少行锁对性能的影响\" class=\"headerlink\" title=\"讲行锁功过：怎么减少行锁对性能的影响\"></a>讲行锁功过：怎么减少行锁对性能的影响</h3><ul>\n<li>MySQL的<code>行锁</code>是在引擎层由各个<code>引擎自己实现</code>的。但并不是所有的引擎都支持行锁，比<code>如MyISAM引擎就不支持行锁</code>。不支持行锁意味着并发控制只能使用表锁，对于这种引擎的表，同一张表上任何时刻只能有一个更新在执行，这就会影响到业务并发度。<code>InnoDB是支持行锁</code>的，这也是<code>MyISAM</code>被<code>InnoDB</code>替代的重要原因之一。</li>\n<li><code>两阶段锁协议</code>：在<code>InnoDB</code>事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。</li>\n<li><code>死锁</code>：当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁</li>\n</ul>\n<p><img src=\"https://img-blog.csdnimg.cn/20190412161554856.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=Enkur&originHeight=585&originWidth=948&originalType=binary&ratio=1&status=done&style=none\"></p>\n<ul>\n<li><code>事务A</code>在等待<code>事务B</code>释放id=2的行锁，而<code>事务B在等待事务A</code>释放id=1的行锁。 事务A和事务B在互相等待对方的资源释放，就是进入了<code>死锁状态</code></li>\n</ul>\n<p><strong>出现死锁以后，有两种策略：</strong></p>\n<ul>\n<li>一种策略是，<code>直接进入等待，直到超时</code>。这个超时时间可以通过参数<code>innodb_lock_wait_timeout</code>来设置。在InnoDB中，默认值是<code>50s</code></li>\n<li>另一种策略是，<code>发起死锁检测</code>，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数<code>innodb_deadlock_detect设置为on</code>，表示开启这个逻辑。默认值本身就是on</li>\n<li>正常情况下选择第二种策略，但是它也是有额外负担的，如果瞬间有大量线程请求会消耗消耗大量的CPU资源，但是每秒却执行不了几个事务，因为每次都要检测。</li>\n</ul>\n<p><strong>怎么解决由这种热点行更新导致的性能问题?</strong></p>\n<ul>\n<li>问题的症结在于，死锁检测要耗费大量的CPU资源</li>\n<li>如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉。 一般不建议采用</li>\n<li>控制并发度，对应相同行的更新，在进入引擎之前排队。这样在InnoDB内部就不会有大量的死锁检测工作了。</li>\n<li>将热更新的行数据拆分成逻辑上的多行来减少锁冲突，但是业务复杂度可能会大大提高。</li>\n<li><code>innodb行级锁是通过锁索引记录实现的，如果更新的列没建索引是会锁住整个表的。</code></li>\n</ul>\n<h4 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a>小结</h4><p>如果你要删除一个表里面的前10000行数据，有以下三种方法可以做到：</p>\n<ul>\n<li>第一种，直接执行     <code>delete from T limit 10000;</code></li>\n<li>第二种，在一个连接中循环执行20次 <code>delete from T limit 500;</code></li>\n<li>第三种，在20个连接中同时执行    <code>delete from T limit 500</code></li>\n</ul>\n<p><strong>三种方案分析</strong></p>\n<ul>\n<li>方案一，事务相对较长，则占用锁的时间较长，会导致其他客户端等待资源时间较长。</li>\n<li>方案二，串行化执行，将相对长的事务分成多次相对短的事务，则每次事务占用锁的时间相对较短，其他客户端在等待相应资源的时间也较短。这样的操作，同时也意味着将资源分片使用（每次执行使用不同片段的资源），可以提高并发性。</li>\n<li>方案三，人为自己制造锁竞争，加剧并发量。</li>\n</ul>\n<h3 id=\"事务到底是隔离的还是不隔离的\"><a href=\"#事务到底是隔离的还是不隔离的\" class=\"headerlink\" title=\"事务到底是隔离的还是不隔离的\"></a>事务到底是隔离的还是不隔离的</h3><ul>\n<li><code>innodb</code>支持<code>RC(读提交)</code>和<code>RR(可重复读)</code>隔离级别实现是用的一致性视图(consistent read view)</li>\n<li>.事务在启动时会拍一个快照,这个快照是基于整个库的。基于整个库的意思就是说一个事务内,整个库的修改对于该事务都是不可见的(对于快照读的情况)。如果在事务内<code>select t</code>表,另外的事务执行了<code>DDL t</code>表,根据发生时间,<code>要吗锁住要嘛报错</code></li>\n</ul>\n<p><strong>事务是如何实现的MVCC呢?</strong></p>\n<ul>\n<li>每个事务都有一个事务ID,叫做<code>transaction id</code>(严格递增)</li>\n<li>事务在启动时,找到已提交的最大事务ID记为up_limit_id。</li>\n<li>事务在更新一条语句时,比如id=1改为了id=2.会把id=1和该行之前的<code>row trx_id</code>写到<code>undo log</code>里。并且在数据页上把id的值改为2,并且把修改这条语句的<code>transaction id</code>记在该行行头。</li>\n<li>再定一个规矩,一个事务要查看一条数据时,必须先用该事务的<code>up_limit_id</code>与该行的<code>transaction id</code>做比对</li>\n<li>如果<code>up_limit_id&gt;=transaction id</code>,那么可以看.如果<code>up_limit_id&lt;transaction id</code>,则只能去<code>undo log</code>里去取。去undo log查找数据的时候,也需要做比对,必须<code>up_limit_id&gt;transaction id</code>,才返回数据</li>\n</ul>\n<p><strong>什么是当前读,</strong></p>\n<ul>\n<li>由于当前读都是先读后写,只能读当前的值,所以认为当前读.会更新事务内的up_limit_id为该事务的transaction id</li>\n</ul>\n<p><strong>为什么</strong><code>**RR**</code><strong>能实现可重复读而</strong><code>**RC**</code><strong>不能,分两种情况</strong></p>\n<ul>\n<li>快照读的情况下,rr(可重复读)不能更新事务内的up_limit_id,而<code>rc(读提交)</code>每次会把<code>up_limit_id</code>更新为快照读之前最新已提交事务的<code>transaction id</code>,则<code>rc(读提交)</code>不能可重复读</li>\n<li>当前读的情况下,<code>rr(可重复读)</code>是利用<code>record lock+gap lock</code>来实现的,而<code>rc(读提交)</code>没有gap,所以rc不能可重复读</li>\n</ul>\n<h3 id=\"MySQL为什么有时候会选错索引\"><a href=\"#MySQL为什么有时候会选错索引\" class=\"headerlink\" title=\"MySQL为什么有时候会选错索引\"></a>MySQL为什么有时候会选错索引</h3><ul>\n<li>在MySQL中一张表其实是可以支持多个索引的。但是，你写SQL语句的时候，并没有主动指定使用哪个索引。也就是说，使用哪个索引是由MySQL来确定的。所以有时候由于MySQL选错了索引，而导致执行速度变得很慢</li>\n</ul>\n<p>测试代码</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">CREATE</span> <span class=\"keyword\">TABLE</span> `t` (</span><br><span class=\"line\">  `id` <span class=\"type\">int</span>(<span class=\"number\">11</span>) <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  `a` <span class=\"type\">int</span>(<span class=\"number\">11</span>) <span class=\"keyword\">DEFAULT</span> <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  `b` <span class=\"type\">int</span>(<span class=\"number\">11</span>) <span class=\"keyword\">DEFAULT</span> <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  <span class=\"keyword\">PRIMARY</span> KEY (`id`),</span><br><span class=\"line\">  KEY `a` (`a`),</span><br><span class=\"line\">  KEY `b` (`b`)</span><br><span class=\"line\">) ENGINE<span class=\"operator\">=</span>InnoDB；</span><br></pre></td></tr></table></figure>\n\n\n<p>然后，我们往表t中插入10万行记录，取值按整数递增，即：(1,1,1)，(2,2,2)，(3,3,3) 直到(100000,100000,100000)。</p>\n<p>分析一条SQL语句：</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql<span class=\"operator\">&gt;</span> <span class=\"keyword\">select</span> <span class=\"operator\">*</span> <span class=\"keyword\">from</span> t <span class=\"keyword\">where</span> a <span class=\"keyword\">between</span> <span class=\"number\">10000</span> <span class=\"keyword\">and</span> <span class=\"number\">20000</span>;</span><br></pre></td></tr></table></figure>\n\n\n<p>正常情况下，a上有索引，肯定是要使用索引a的。</p>\n<p><img src=\"https://img-blog.csdnimg.cn/20190414141306715.png#id=OG5aI&originHeight=97&originWidth=1077&originalType=binary&ratio=1&status=done&style=none\"><br>但是特许情况下如果同时有两个以下下操作执行：</p>\n<ul>\n<li>如果一个A请求首先开启了事物，随后，B请求把数据都删除后，又插入了10万行数据。</li>\n<li>这时候， B操作的查询语句<code>select * from t where a between 10000 and 20000</code>就不会再选择索引a了，会执行全表扫描，执行时间会比之前慢很多。<code>为什么会出现这样情况？</code>因为选择索引是优化器的工作，而优化器选择索引的目的，是找到一个最优的执行方案，并用最小的代价去执行语句。</li>\n<li>MySQL在真正开始执行语句之前，并不能精确地知道满足这个条件的记录有多少条，而只能根据统计信息来估算记录数。这个统计信息就是索引的“<code>区分度</code>”。一个索引上不同的值越多，这个索引的区分度就越好。而一个索引上不同的值的个数，我们称之为<code>“基数”</code>（cardinality）。也就是说，这个基数越大，索引的区分度越好。</li>\n<li>可以使用<code>show index table</code>方法，看到一个索引的基数</li>\n<li>MySQL是怎样得到索引的基数的呢？MySQL通过采样统计的方法得到基数</li>\n<li>如果使用索引a，每次从索引a上拿到一个值，都要回到主键索引上查出整行数据，这个代价优化器也要算进去的。而如果选择扫描10万行，是直接在主键索引上扫描的，没有额外的代价。优化器会估算这两个选择的代价，从结果看来，优化器认为直接扫描主键索引更快。当然，从执行时间看来，这个选择并不是最优的。</li>\n<li><code>analyze table t</code> 命令可以用来重新统计索引信息</li>\n<li>采用<code>force index</code>强行选择一个索引。如果force index指定的索引在候选索引列表中，就直接选择这个索引，不再评估其他索引的执行代价。</li>\n</ul>\n<p><img src=\"https://img-blog.csdnimg.cn/20190414141504344.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=LVEvh&originHeight=321&originWidth=921&originalType=binary&ratio=1&status=done&style=none\"></p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">set</span> long_query_time<span class=\"operator\">=</span><span class=\"number\">0</span>;</span><br><span class=\"line\"><span class=\"keyword\">select</span> <span class=\"operator\">*</span> <span class=\"keyword\">from</span> t <span class=\"keyword\">where</span> a <span class=\"keyword\">between</span> <span class=\"number\">10000</span> <span class=\"keyword\">and</span> <span class=\"number\">20000</span>; <span class=\"comment\">/*Q1*/</span></span><br><span class=\"line\"><span class=\"keyword\">select</span> <span class=\"operator\">*</span> <span class=\"keyword\">from</span> t force index(a) <span class=\"keyword\">where</span> a <span class=\"keyword\">between</span> <span class=\"number\">10000</span> <span class=\"keyword\">and</span> <span class=\"number\">20000</span>;<span class=\"comment\">/*Q2*/</span></span><br><span class=\"line\"></span><br><span class=\"line\">第一句，是将慢查询日志的阈值设置为<span class=\"number\">0</span>，表示这个线程接下来的语句都会被记录入慢查询日志中；</span><br><span class=\"line\">第二句，Q1是session B原来的查询；</span><br><span class=\"line\">第三句，Q2是加了force index(a)来和session B原来的查询语句执行情况对比。</span><br></pre></td></tr></table></figure>\n\n\n<ul>\n<li>delete 语句删掉了所有的数据，然后再通过call idata()插入了10万行数据，看上去是覆盖了原来的10万行。</li>\n<li>但是，session A开启了事务并没有提交，所以之前插入的10万行数据是不能删除的。这样，之前的数据每一行数据都有两个版本，旧版本是delete之前的数据，新版本是标记为deleted的数据。这样，索引a上的数据其实就有两份</li>\n</ul>\n<h3 id=\"怎么给字符串字段加索引\"><a href=\"#怎么给字符串字段加索引\" class=\"headerlink\" title=\"怎么给字符串字段加索引\"></a>怎么给字符串字段加索引</h3><ul>\n<li>假设，你现在维护一个支持邮箱登录的系统，用户表是这么定义的：</li>\n</ul>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql<span class=\"operator\">&gt;</span> <span class=\"keyword\">create</span> <span class=\"keyword\">table</span> SUser(</span><br><span class=\"line\">ID <span class=\"type\">bigint</span> unsigned <span class=\"keyword\">primary</span> key,</span><br><span class=\"line\">email <span class=\"type\">varchar</span>(<span class=\"number\">64</span>), </span><br><span class=\"line\">... </span><br><span class=\"line\">)engine<span class=\"operator\">=</span>innodb;</span><br></pre></td></tr></table></figure>\n\n\n<p>由于要使用邮箱登录，所以业务代码中一定会出现类似于这样的语句：</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql<span class=\"operator\">&gt;</span> <span class=\"keyword\">select</span> f1, f2 <span class=\"keyword\">from</span> SUser <span class=\"keyword\">where</span> email<span class=\"operator\">=</span><span class=\"string\">&#x27;xxx&#x27;</span>;</span><br></pre></td></tr></table></figure>\n\n\n<ul>\n<li>如果email这个字段上没有索引，那么这个语句就只能做全表扫描。同时，MySQL是支持前缀索引的，也就是说，你可以定义字符串的一部分作为索引。默认地，如果你创建索引的语句不指定前缀长度，那么索引就会包含整个字符串。</li>\n</ul>\n<p>比如，这两个在email字段上创建索引的语句：</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql<span class=\"operator\">&gt;</span> <span class=\"keyword\">alter</span> <span class=\"keyword\">table</span> SUser <span class=\"keyword\">add</span> index index1(email);</span><br><span class=\"line\">或</span><br><span class=\"line\">mysql<span class=\"operator\">&gt;</span> <span class=\"keyword\">alter</span> <span class=\"keyword\">table</span> SUser <span class=\"keyword\">add</span> index index2(email(<span class=\"number\">6</span>));</span><br></pre></td></tr></table></figure>\n\n\n<p><img src=\"https://img-blog.csdnimg.cn/201904142351118.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=FFfQd&originHeight=468&originWidth=1000&originalType=binary&ratio=1&status=done&style=none\"><br><img src=\"https://img-blog.csdnimg.cn/20190414235147183.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=XF7LV&originHeight=449&originWidth=640&originalType=binary&ratio=1&status=done&style=none\"></p>\n<ul>\n<li>第一个语句创建的index1索引里面，包含了每个记录的整个字符串；</li>\n<li>第二个语句创建的index2索引里面，对于每个记录都是只取前6个字节。由于email(6)这个索引结构中每个邮箱字段都只取前6个字节,所以占用的空间会更小，这就是使用前缀索引的优势。但是 可能会增加额外的记录扫描次数。</li>\n</ul>\n<p><strong>使用的是index1的执行流程</strong></p>\n<ul>\n<li>从<code>index1</code>索引树找到满足索引值是’<a href=\"mailto:&#x7a;&#104;&#x61;&#110;&#103;&#115;&#115;&#120;&#x79;&#122;&#x40;&#120;&#120;&#x78;&#x2e;&#99;&#x6f;&#x6d;\">&#x7a;&#104;&#x61;&#110;&#103;&#115;&#115;&#120;&#x79;&#122;&#x40;&#120;&#120;&#x78;&#x2e;&#99;&#x6f;&#x6d;</a>’的这条记录，取得ID2的值；</li>\n<li>到主键上查到主键值是ID2的行，判断email的值是正确的，将这行记录加入结果集；</li>\n<li>取index1索引树上刚刚查到的位置的下一条记录，发现已经不满足email=‘<a href=\"mailto:&#122;&#104;&#97;&#x6e;&#x67;&#x73;&#x73;&#120;&#x79;&#x7a;&#x40;&#120;&#120;&#120;&#46;&#99;&#x6f;&#x6d;\">&#122;&#104;&#97;&#x6e;&#x67;&#x73;&#x73;&#120;&#x79;&#x7a;&#x40;&#120;&#120;&#120;&#46;&#99;&#x6f;&#x6d;</a>’的条件了，循环结束</li>\n<li>这个过程中，只需要回主键索引取一次数据，所以系统认为只扫描了一行。</li>\n</ul>\n<p><strong>使用的是index2的执行流程</strong></p>\n<ul>\n<li>从<code>index2</code>索引树找到满足索引值是’zhangs’的记录，找到的第一个是ID1；</li>\n<li>到主键上查到主键值是ID1的行，判断出email的值不是’<a href=\"mailto:&#x7a;&#x68;&#97;&#110;&#x67;&#115;&#115;&#x78;&#121;&#122;&#64;&#x78;&#x78;&#120;&#46;&#x63;&#x6f;&#x6d;\">&#x7a;&#x68;&#97;&#110;&#x67;&#115;&#115;&#x78;&#121;&#122;&#64;&#x78;&#x78;&#120;&#46;&#x63;&#x6f;&#x6d;</a>’，这行记录丢弃；</li>\n<li>取index2上刚刚查到的位置的下一条记录，发现仍然是’zhangs’，取出ID2，再到ID索引上取整行然后判断，这次值对了，将这行记录加入结果集；</li>\n<li>重复上一步，直到在idxe2上取到的值不是’zhangs’时，循环结束。</li>\n<li>在这个过程中，要回主键索引取4次数据，也就是扫描了4行。</li>\n<li>但是  对于这个查询语句来说，如果你定义的<code>index2</code>不是email(6)而是email(7），也就是说取email字段的前7个字节来构建索引的话，即满足前缀’zhangss’的记录只有一个，也能够直接查到ID2，只扫描一行就结束了。</li>\n<li>也就是说<code>使用前缀索引，定义好长度，就可以做到既节省空间，又不用额外增加太多的查询成本</code>。</li>\n</ul>\n<p><strong>前缀索引对覆盖索引的影响</strong></p>\n<ul>\n<li>使用前缀索引可能会增加扫描行数，这会影响到性能。其实，前缀索引的影响不止如此</li>\n</ul>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#查询<span class=\"number\">1</span> </span><br><span class=\"line\"><span class=\"keyword\">select</span> id,email <span class=\"keyword\">from</span> SUser <span class=\"keyword\">where</span> email<span class=\"operator\">=</span><span class=\"string\">&#x27;zhangssxyz@xxx.com&#x27;</span>;</span><br><span class=\"line\"># 查询<span class=\"number\">2</span></span><br><span class=\"line\"><span class=\"keyword\">select</span> id,name,email <span class=\"keyword\">from</span> SUser <span class=\"keyword\">where</span> email<span class=\"operator\">=</span><span class=\"string\">&#x27;zhangssxyz@xxx.com&#x27;</span>;</span><br></pre></td></tr></table></figure>\n\n\n<ul>\n<li>如果使用index1（即email整个字符串的索引结构）的话，可以利用覆盖索引，从index1查到结果后直接就返回了，不需要回到ID索引再去查一次。而如果使用index2（即email(6)索引结构）的话，就不得不回到ID索引再去判断email字段的值。</li>\n<li>即使你将index2的定义修改为email(18)的前缀索引，这时候虽然index2已经包含了所有的信息，但InnoDB还是要回到id索引再查一下，因为系统并不确定前缀索引的定义是否截断了完整信息。</li>\n<li>使用前缀索引就用不上覆盖索引对查询性能的优化了</li>\n</ul>\n<h4 id=\"小结-1\"><a href=\"#小结-1\" class=\"headerlink\" title=\"小结\"></a>小结</h4><p>对于类似于邮箱这样的字段来说，使用前缀索引的效果可能还不错。但是，遇到前缀的区分度不够好的情况时。比如，我们国家的身份证号，一共18位，其中前6位是地址码，所以同一个县的人的身份证号前6位一般会是相同的。</p>\n<p>假设你维护的数据库是一个市的公民信息系统，这时候如果对身份证号做长度为6的前缀索引的话，这个索引的区分度就非常低了。可能你需要创建长度为12以上的前缀索引，才能够满足区分度要求。但是，<code>索引选取的越长，占用的磁盘空间就越大，相同的数据页能放下的索引值就越少，搜索的效率也就会越低</code>。</p>\n<p>那么，如果我们能够确定业务需求里面只有按照身份证进行等值查询的需求，还有没有别的处理方法呢？这种方法，既可以占用更小的空间，也能达到相同的查询效率。</p>\n<p>第一种方式是使用<code>倒序存储</code>。如果你存储身份证号的时候把它倒过来存，每次查询的时候，你可以这么写：</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql<span class=\"operator\">&gt;</span> <span class=\"keyword\">select</span> field_list <span class=\"keyword\">from</span> t <span class=\"keyword\">where</span> id_card <span class=\"operator\">=</span> reverse(<span class=\"string\">&#x27;input_id_card_string&#x27;</span>);</span><br></pre></td></tr></table></figure>\n\n\n<p>由于身份证号的最后6位没有地址码这样的重复逻辑，所以最后这6位很可能就提供了足够的区分度。</p>\n<p>第二种方式是<code>使用hash字段</code>。你可以在表上再创建一个整数字段，来保存身份证的校验码，同时在这个字段上创建索引。</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql<span class=\"operator\">&gt;</span> <span class=\"keyword\">alter</span> <span class=\"keyword\">table</span> t <span class=\"keyword\">add</span> id_card_crc <span class=\"type\">int</span> unsigned, <span class=\"keyword\">add</span> index(id_card_crc);</span><br></pre></td></tr></table></figure>\n\n\n<p>然后每次插入新记录的时候，都同时用crc32()这个函数得到校验码填到这个新字段。由于校验码可能存在冲突，也就是说两个不同的身份证号通过crc32()函数得到的结果可能是相同的，所以你的查询语句where部分要判断id_card的值是否精确相同。</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql<span class=\"operator\">&gt;</span> <span class=\"keyword\">select</span> field_list <span class=\"keyword\">from</span> t <span class=\"keyword\">where</span> id_card_crc<span class=\"operator\">=</span>crc32(<span class=\"string\">&#x27;input_id_card_string&#x27;</span>) <span class=\"keyword\">and</span> id_card<span class=\"operator\">=</span><span class=\"string\">&#x27;input_id_card_string&#x27;</span></span><br></pre></td></tr></table></figure>\n\n\n<p>这样，索引的长度变成了4个字节，比原来小了很多。</p>\n<p><strong>使用倒序存储和使用hash字段这两种方法的异同点</strong></p>\n<ul>\n<li>首先，它们的相同点是，都不支持范围查询。</li>\n<li><code>从占用的额外空间来看</code>，倒序存储方式在主键索引上，不会消耗额外的存储空间，而hash字段方法需要增加一个字段</li>\n<li><code>在CPU消耗方面</code>，倒序方式每次写和读的时候，都需要额外调用一次reverse函数，而hash字段的方式需要额外调用一次crc32()函数</li>\n<li><code>从查询效率上看</code>，使用hash字段方式的查询性能相对更稳定一些。因为crc32算出来的值虽然有冲突的概率，但是概率非常小，可以认为每次查询的平均扫描行数接近1。而倒序存储方式毕竟还是用的前缀索引的方式，也就是说还是会增加扫描行数。</li>\n</ul>\n<p><strong>字符串字段创建索引的场景你可以使用的方式有：</strong></p>\n<ul>\n<li>直接创建完整索引，这样可能比较占用空间；</li>\n<li>创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引；</li>\n<li>倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题；</li>\n<li>创建hash字段索引，查询性能稳定，有额外的存储和计算消耗，跟第三种方式一样，都不支持范围扫描。</li>\n</ul>\n<p><strong>利用学号作为登录名索引设计问题？</strong></p>\n<blockquote>\n<p>如果你在维护一个学校的学生信息数据库，学生登录名的统一格式是”学号@gmail.com”, 而学号的规则是：十五位的数字，其中前三位是所在城市编号、第四到第六位是学校编号、第七位到第十位是入学年份、最后五位是顺序编号。<br>系统登录的时候都需要学生输入登录名和密码，验证正确后才能继续使用系统。就只考虑登录验证这个行为的话，你会怎么设计这个登录名的索引呢？</p>\n</blockquote>\n<p><code>**设计思路：**</code></p>\n<ul>\n<li>由于这个学号的规则，无论是正向还是反向的前缀索引，重复度都比较高。因为维护的只是一个学校的，因此前面6位（其中，前三位是所在城市编号、第四到第六位是学校编号）其实是固定的，邮箱后缀都是@gamil.com，因此可以只存入学年份加顺序编号，它们的长度是9位。</li>\n<li>而其实在此基础上，可以用数字类型来存这9位数字。比如201100001，这样只需要占4个字节。其实这个就是一种hash，只是它用了最简单的转换规则：字符串转数字的规则，而刚好我们设定的这个背景，可以保证这个转换后结果的唯一性。</li>\n</ul>\n<h3 id=\"为什么我的MySQL会“抖”一下\"><a href=\"#为什么我的MySQL会“抖”一下\" class=\"headerlink\" title=\"为什么我的MySQL会“抖”一下\"></a>为什么我的MySQL会“抖”一下</h3><ul>\n<li>一条SQL语句，正常执行的时候特别快，但是有时也不知道怎么回事，它就会变得特别慢，并且这样的场景很难复现，它不只随机，而且持续时间还很短。看上去，这就像是数据库“抖”了一下</li>\n<li>在MySQL里，如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程IO成本、查找成本都很高。为了解决这个问题，MySQL的设计者使用了<code>WAL技术</code>，WAL的全称是Write-Ahead Logging，它的关键点就是<code>先写日志，再写磁盘</code>。</li>\n<li>利用WAL技术，数据库将随机写转换成了顺序写，大大提升了数据库的性能。但是，由此也带来了内存脏页的问题。脏页会被后台线程自动flush，也会由于数据页淘汰而触发flush，而刷脏页的过程由于会占用资源，可能会让你的更新和查询语句的响应时间长一些</li>\n<li>当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”。</li>\n<li>平时执行很快的更新操作，其实就是在写内存和日志，而MySQL偶尔“抖”一下的那个瞬间，可能就是在刷脏页（<code>flush</code>）。</li>\n</ul>\n<p><strong>什么情况会引发数据库的flush过程呢？</strong></p>\n<ul>\n<li><code>InnoDB</code>在处理更新语句的时候，只做了写日志这一个磁盘操作。这个日志叫作redo log（重做日志）。在更新内存写完<code>redo log</code>后，就返回给客户端，本次更新成功。</li>\n<li><code>InnoDB</code>的<code>redo log</code>(重做日志)写满了。这时候系统会停止所有更新操作，把<code>checkpoint(检查点)</code>往前推进，<code>redo log</code>留出空间可以继续写</li>\n<li>第二种场景是：对应的就是系统内存不足。当需要新的内存页，而内存不够用的时候，就要淘汰一些数据页，空出内存给别的数据页使用。如果淘汰的是“脏页”，就要先将脏页写到磁盘。</li>\n<li>第三种场景就是<code>MySQL</code>认为系统<code>“空闲”</code>的时候。也要见缝插针地找时间，只要有机会就刷一点<code>“脏页”</code></li>\n<li>第四种场景就是<code>MySQL正常关闭的情况</code>。这时候，MySQL会把内存的脏页都flush到磁盘上，这样下次MySQL启动的时候，就可以直接从磁盘上读数据，启动速度会很快。</li>\n</ul>\n<p><strong>分析一下上面四种场景对性能的影响</strong></p>\n<ul>\n<li><code>第一种是“redo log写满了，要flush脏页”</code>，这种情况是InnoDB要尽量避免的。因为出现这种情况的时候，整个系统就不能再接受更新了，所有的更新都必须堵住。如果你从监控上看，这时候更新数会跌为0。</li>\n<li><code>第二种是“内存不够用了，要先将脏页写到磁盘”</code>，这种情况其实是常态。InnoDB用缓冲池（buffer pool）管理内存，缓冲池中的内存页有三种状态：第一种是，还没有使用的；第二种是，使用了并且是干净页；第三种是，使用了并且是脏页。InnoDB的策略是尽量使用内存，因此对于一个长时间运行的库来说，未被使用的页面很少。</li>\n<li>而当要读入的数据页没有在内存的时候，就必须到缓冲池中申请一个数据页。这时候只能把最久不使用的数据页从内存中淘汰掉：如果要淘汰的是一个干净页，就直接释放出来复用；但如果是脏页呢，就必须将脏页先刷到磁盘，变成干净页后才能复用。</li>\n<li>所以，刷脏页虽然是常态，但是出现以下这两种情况，都是会明显影响性能的：一个查询要淘汰的脏页个数太多，会导致查询的响应时间明显变长；日志写满，更新全部堵住，写性能跌为0，这种情况对敏感业务来说，是不能接受的。</li>\n</ul>\n<p><strong>InnoDB刷脏页的控制策略</strong></p>\n<ul>\n<li>首先，你要正确地告诉<code>InnoDB</code>所在主机的<code>IO能力</code>，这样<code>InnoDB</code>才能知道需要全力刷脏页的时候，可以刷多快。这就要用到<code>innodb_io_capacity</code>这个参数了，它会告诉<code>InnoDB</code>你的磁盘能力。这个值我建议你设置成<code>磁盘的IOPS</code>。</li>\n<li>假设有这样一个场景：<code>MySQL的写入速度很慢，TPS很低</code>，但是数据库主机的<code>IO压力并不大</code>。主机磁盘用的是SSD，但是<code>innodb_io_capacity</code>的值设置的是<code>300</code>。于是，InnoDB认为这个系统的能力就这么差，所以刷脏页刷得特别慢，甚至比脏页生成的速度还慢，这样就造成了脏页累积，影响了查询和更新性能。</li>\n<li><code>InnoDB</code>的刷盘速度就是要参考这两个因素：一个是<code>脏页比例</code>，一个是<code>redo log写盘速度</code>。</li>\n<li>参数<code>innodb_max_dirty_pages_pct</code>是<code>脏页比例上限</code>，默认值是<code>75%</code>。InnoDB会根据当前的脏页比例（假设为M），算出一个范围在0到100之间的数字。<code>InnoDB</code>每次写入的日志<code>都有一个序号</code>，当前写入的序号跟<code>checkpoint</code>对应的序号之间的差值。我们假设为N。InnoDB会根据这个N算出一个范围在0到100之间的数字，这个计算公式可以记为F2(N)。F2(N)算法比较复杂，你只要知道N越大，算出来的值越大就好了。</li>\n<li>然后，根据上述算得的F1(M)和F2(N)两个值，取其中较大的值记为R，之后引擎就可以按照<code>innodb_io_capacity</code>定义的能力乘以<code>R%</code>来控制刷脏页的速度。</li>\n</ul>\n<p><img src=\"https://img-blog.csdnimg.cn/2019041513510966.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=GVQMh&originHeight=1522&originWidth=1142&originalType=binary&ratio=1&status=done&style=none\"></p>\n<ul>\n<li>InnoDB会在后台刷脏页，而刷脏页的过程是要将内存页写入磁盘。所以，无论是你的查询语句在需要内存的时候可能要求淘汰一个脏页，还是由于刷脏页的逻辑会占用IO资源并可能影响到了你的更新语句，都可能是造成你从业务端感知到MySQL“抖”了一下的原因。</li>\n<li>要尽量避免这种情况，你就要合理地设置<code>innodb_io_capacity的值</code>，并且平时要多关注脏页比例，不要让它经常接近<code>75%</code>。</li>\n</ul>\n<blockquote>\n<p>脏页比例是通过Innodb_buffer_pool_pages_dirty/Innodb_buffer_pool_pages_total得到的</p>\n</blockquote>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql<span class=\"operator\">&gt;</span> <span class=\"keyword\">select</span> VARIABLE_VALUE <span class=\"keyword\">into</span> <span class=\"variable\">@a</span> <span class=\"keyword\">from</span> global_status <span class=\"keyword\">where</span> VARIABLE_NAME <span class=\"operator\">=</span> <span class=\"string\">&#x27;Innodb_buffer_pool_pages_dirty&#x27;</span>;</span><br><span class=\"line\"><span class=\"keyword\">select</span> VARIABLE_VALUE <span class=\"keyword\">into</span> <span class=\"variable\">@b</span> <span class=\"keyword\">from</span> global_status <span class=\"keyword\">where</span> VARIABLE_NAME <span class=\"operator\">=</span> <span class=\"string\">&#x27;Innodb_buffer_pool_pages_total&#x27;</span>;</span><br><span class=\"line\"><span class=\"keyword\">select</span> <span class=\"variable\">@a</span><span class=\"operator\">/</span><span class=\"variable\">@b</span>;</span><br></pre></td></tr></table></figure>\n\n\n<ul>\n<li>一旦一个查询请求需要在执行过程中先flush掉一个脏页时，这个查询就可能要比平时慢了。而MySQL中的一个机制，可能让你的查询会更慢：在准备刷一个脏页的时候，如果这个数据页旁边的数据页刚好是脏页，就会把这个“邻居”也带着一起刷掉；而且这个把“邻居”拖下水的逻辑还可以继续蔓延，也就是对于每个邻居数据页，如果跟它相邻的数据页也还是脏页的话，也会被放到一起刷。</li>\n<li>在InnoDB中，<code>innodb_flush_neighbors</code> 参数就是用来控制这个行为的，<code>值为1</code>的时候会有上述的<code>“连坐”机制</code>，<code>值为0时</code>表示不找邻居，自己刷自己的。</li>\n<li>找<code>“邻居”</code>这个优化在<code>机械硬盘时代是很有意义</code>的，可以<code>减少很多随机IO</code>。机械硬盘的随机<code>IOPS</code>一般只有几百，相同的逻辑操作减少随机IO就意味着系统性能的大幅度提升。</li>\n<li>而如果使用的是<code>SSD这类IOPS比较高的设备</code>的话，我就建议你把<code>innodb_flush_neighbors</code>的值设置成0。因为这时候<code>IOPS</code>往往不是瓶颈，而<code>“只刷自己”</code>，就能更快地执行完必要的刷脏页操作，减少SQL语句响应时间。</li>\n<li>在MySQL 8.0中<code>，innodb_flush_neighbors参数的默认值已经是0</code>了。</li>\n</ul>\n<h3 id=\"为什么表数据删掉一半，表文件大小不变\"><a href=\"#为什么表数据删掉一半，表文件大小不变\" class=\"headerlink\" title=\"为什么表数据删掉一半，表文件大小不变\"></a>为什么表数据删掉一半，表文件大小不变</h3><ul>\n<li>一个InnoDB表包含两部分，即：表结构定义和数据。在MySQL 8.0版本以前，表结构是存在以.frm为后缀的文件里。</li>\n<li>表数据既可以存在共享表空间里，也可以是单独的文件。这个行为是由参数<code>innodb_file_per_table</code>控制的，设置为<code>OFF</code>表示的是，表的数据放在<code>系统共享表空间</code>，也就是跟数据字典放在一起；设置为<code>ON</code>表示的是，每个InnoDB表数据存储在一个以 <code>.ibd</code>为后缀的文件中。从<code>MySQL 5.6.6</code>版本开始，它的<code>默认值就是ON</code>了</li>\n<li>建议你不论使用MySQL的哪个版本，都将这个值设置为ON。因为，一个表单独存储为一个文件更容易管理，而且在你不需要这个表的时候，通过<code>drop table</code>命令，系统就会直接删除这个文件。而如果是放在共享表空间中，即使表删掉了，空间也是不会回收的。</li>\n<li>我们在删除整个表的时候，可以使用drop table命令回收表空间。但是，我们遇到的更多的删除数据的场景是删除某些行，表中的数据被删除了，但是表空间却没有被回收。</li>\n</ul>\n<p><strong>数据删除流程</strong></p>\n<p><img src=\"https://img-blog.csdnimg.cn/20190416104535458.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=roWLU&originHeight=478&originWidth=603&originalType=binary&ratio=1&status=done&style=none\"></p>\n<ul>\n<li>假设，我们要删掉R4这个记录，InnoDB引擎只会把R4这个记录标记为删除。如果之后要再插入一个ID在300和600之间的记录时，可能会复用这个位置。但是，磁盘文件的大小并不会缩小。</li>\n<li>InnoDB的数据是按页存储的，那么如果我们删掉了一个数据页上的所有记录，整个数据页就可以被复用了。</li>\n<li>但是，数据页的复用跟记录的复用是不同的。记录的复用，只限于符合范围条件的数据，比如R4这条记录被删除后，如果插入一个ID是400的行，可以直接复用这个空间。但如果插入的是一个ID是800的行，就不能复用这个位置了。</li>\n<li>而当整个页从B+树里面摘掉以后，可以复用到任何位置。如果相邻的两个数据页利用率都很小，系统就会把这两个页上的数据合到其中一个页上，另外一个数据页就被标记为可复用。</li>\n<li>所以如果我们用delete命令把整个表的数据删除，结果就是，所有的数据页都会被标记为可复用。但是磁盘上，文件不会变小。也就是说，通过delete命令是不能回收表空间的。这些可以复用，而没有被使用的空间，看起来就像是<code>“空洞”</code>。</li>\n<li>实际上，不止是删除数据会造成空洞，插入数据也会。如果数据是按照索引递增顺序插入的，那么索引是紧凑的。但如果数据是随机插入的，就可能造成索引的数据页分裂。另外，更新索引上的值，可以理解为删除一个旧的值，再插入一个新值。不难理解，这也是会造成空洞的。</li>\n</ul>\n<p><strong>重建表</strong></p>\n<ul>\n<li>重建表就是新建一个与表A结构相同的表B，然后按照主键ID递增的顺序，把数据一行一行地从表A里读出来再插入到表B中。由于表B是新建的表，所以表A主键索引上的空洞，在表B中就都不存在了。</li>\n<li>可以使用<code>alter table A engine=InnoDB</code>命令来重建表。MySQL 5.5之后会自动完成转存数据、交换表名、删除旧表的操作。</li>\n<li>重建表的过程中，如果中途有新的数据要写入，就会造成数据丢失。所以在整个<code>DDL</code>过程中，表A中不能有更新。也就是说，这个DDL不是<code>Online</code>的。在MySQL 5.6版本开始引入的<code>Online DDL</code>，对这个操作流程做了优化。</li>\n<li>对于很大的表来说，这个操作是很消耗IO和CPU资源的。想要比较安全的操作的话，推荐使用<code>GitHub</code>开源的<a href=\"https://github.com/github/gh-ost\">gh-ost</a>来做。</li>\n</ul>\n<p><strong>MySQL执行DDL()原理</strong></p>\n<ul>\n<li><code>DML</code>：它们是SELECT、UPDATE、INSERT、DELETE，就象它的名字一样，这4条命令是用来对数据库里的数据进行操作的语言</li>\n<li><code>DDL</code>：DDL比DML要多，主要的命令有CREATE、ALTER、DROP等，DDL主要是用在定义或改变表(TABLE)的结构，数据类型，表之间的链接和约束等初始化工作上，他们大多在建立表时使用</li>\n<li><code>DCL</code>：是数据库控制功能。是用来设置或更改数据库用户或角色权限的语句</li>\n<li>MySQL各版本，对于DDL的处理方式是不同的，主要有三种：</li>\n<li><code>Copy Table</code>方式：这是InnoDB最早支持的方式。通过临时表拷贝的方式实现的。新建一个带有新结构的临时表，将原表数据全部拷贝到临时表，然后Rename，完成创建操作。这个方式过程中，<code>原表是可读的，不可写</code>。但是<code>会消耗一倍的存储空间</code>。</li>\n<li><code>Inplace</code>方式：这是原生MySQL 5.5，以及<code>innodb_plugin</code>中提供的方式。所谓Inplace，也就是在<code>原表上直接进行，不会拷贝临时表</code>。相对于Copy Table方式，这比较高效率。<code>原表同样可读的，但是不可写</code>。</li>\n<li><code>Online方式</code>：MySQL 5.6以上版本中提供的方式，无论是Copy Table方式，还是Inplace方式，<code>原表只能允许读取，不可写</code>。对应用有较大的限制，因此MySQL最新版本中，InnoDB支持了所谓的<code>Online方式DDL</code>。与以上两种方式相比，<code>online方式支持DDL时不仅可以读，还可以写</code></li>\n</ul>\n<h3 id=\"count-语句到底是怎样实现的\"><a href=\"#count-语句到底是怎样实现的\" class=\"headerlink\" title=\"count(*)语句到底是怎样实现的\"></a>count(*)语句到底是怎样实现的</h3><ul>\n<li>在不同的MySQL引擎中，count(*)有不同的实现方式。</li>\n<li><code>MyISAM引擎</code>把一个表的总行数存在了磁盘上，因此执行<code>count(*)</code>的时候会直接返回这个数，效率很高。这里讨论的是没有过滤条件的count(*)，如果加了where 条件的话，MyISAM表也是不能返回得这么快的。</li>\n<li><code>InnoDB引擎</code>就麻烦了，它执行count(*)的时候，需要把数据一行一行地从引擎里面读出来，然后累积计数。</li>\n</ul>\n<p><strong>为什么InnoDB不跟MyISAM一样，也把数字存起来呢？</strong></p>\n<ul>\n<li>这是因为即使是在同一个时刻的多个查询，由于<code>多版本并发控制</code>（MVCC）的原因，InnoDB表“应该返回多少行”也是不确定的。</li>\n<li>这和InnoDB的事务设计有关系，<code>可重复读是它默认的隔离级别</code>，在代码上就是通过多版本并发控制，也就是MVCC来实现的。每一行记录都要判断自己是否对这个会话可见，因此对于count(*)请求来说，InnoDB只好把数据一行一行地读出依次判断，可见的行才能够用于计算“基于这个查询”的表的总行数。</li>\n<li><code>InnoDB是索引组织表</code>，<code>主键索引树的叶子节点是数据</code>，而<code>普通索引树的叶子节点是主键值</code>。所以，普通索引树比主键索引树小很多。对于count(*)这样的操作，遍历哪个索引树得到的结果逻辑上都是一样的。因此，MySQL优化器会找到最小的那棵树来遍历。在保证逻辑正确的前提下，尽量减少扫描的数据量，是数据库系统设计的通用法则之一。</li>\n<li>MyISAM表虽然count(<em>)很快，但是不支持事务；show table status命令虽然返回很快，但是不准确；InnoDB表直接count(</em>)会遍历全表，虽然结果准确，但会导致性能问题。</li>\n</ul>\n<h3 id=\"不同的count用法\"><a href=\"#不同的count用法\" class=\"headerlink\" title=\"不同的count用法\"></a>不同的count用法</h3><p><code>select count(?) from t</code>这样的查询语句里面，<code>count(*)、count(主键id)、count(字段)和count(1)</code>等不同用法的性能，有哪些差别。</p>\n<ul>\n<li>count()是一个聚合函数，对于返回的结果集，一行行地判断，如果count函数的参数不是NULL，累计值就加1，否则不加。最后返回累计值。</li>\n<li>所以，count(*)、count(主键id)和count(1) 都表示返回满足条件的结果集的总行数；而count(字段），则表示返回满足条件的数据行里面，参数“字段”不为NULL的总个数。</li>\n<li><code>对于count(主键id)来说</code>，InnoDB引擎会遍历整张表，把每一行的id值都取出来，返回给server层。server层拿到id后，判断是不可能为空的，就按行累加。</li>\n<li><code>对于count(1)来说</code>，InnoDB引擎遍历整张表，但不取值。server层对于返回的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加。</li>\n<li><code>对于count(字段)来说</code>：如果这个“字段”是定义为not null的话，一行行地从记录里面读出这个字段，判断不能为null，按行累加；如果这个“字段”定义允许为null，那么执行的时候，判断到有可能是null，还要把值取出来再判断一下，不是null才累加。</li>\n<li>count(<em>)是例外：并不会把全部字段取出来，而是专门做了优化，不取值。count(</em>)肯定不是null，按行累加。</li>\n<li>所以结论是：按照效率排序的话，count(字段)&lt;count(主键id)&lt;count(1)≈count(<em>)，所以我建议你，尽量使用count(</em>)。</li>\n</ul>\n<h3 id=\"order-by是怎么工作的\"><a href=\"#order-by是怎么工作的\" class=\"headerlink\" title=\"order by是怎么工作的\"></a>order by是怎么工作的</h3><p>首先创建一个测试表  <code>t_city</code></p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">CREATE</span> <span class=\"keyword\">TABLE</span> `t_city` (</span><br><span class=\"line\">  `id` <span class=\"type\">int</span>(<span class=\"number\">11</span>) <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  `city` <span class=\"type\">varchar</span>(<span class=\"number\">16</span>) <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  `name` <span class=\"type\">varchar</span>(<span class=\"number\">16</span>) <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  `age` <span class=\"type\">int</span>(<span class=\"number\">11</span>) <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  `addr` <span class=\"type\">varchar</span>(<span class=\"number\">128</span>) <span class=\"keyword\">DEFAULT</span> <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  <span class=\"keyword\">PRIMARY</span> KEY (`id`),</span><br><span class=\"line\">  KEY `city` (`city`)</span><br><span class=\"line\">) ENGINE<span class=\"operator\">=</span>InnoDB <span class=\"keyword\">DEFAULT</span> CHARSET<span class=\"operator\">=</span>utf8;</span><br></pre></td></tr></table></figure>\n\n\n<p>使用存储过程 添加10W条测试数据</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">delimiter ;;</span><br><span class=\"line\"><span class=\"keyword\">create</span> <span class=\"keyword\">procedure</span> idata2()</span><br><span class=\"line\"><span class=\"keyword\">begin</span></span><br><span class=\"line\">  <span class=\"keyword\">declare</span> i <span class=\"type\">int</span>;</span><br><span class=\"line\">  <span class=\"keyword\">set</span> i<span class=\"operator\">=</span><span class=\"number\">1</span>;</span><br><span class=\"line\">  while(i<span class=\"operator\">&lt;=</span><span class=\"number\">10000</span>)do</span><br><span class=\"line\">    <span class=\"keyword\">insert</span> <span class=\"keyword\">into</span> t_city <span class=\"keyword\">values</span>(i,<span class=\"string\">&#x27;广州&#x27;</span>, i,i,i);</span><br><span class=\"line\">    <span class=\"keyword\">set</span> i<span class=\"operator\">=</span>i<span class=\"operator\">+</span><span class=\"number\">1</span>;</span><br><span class=\"line\">  <span class=\"keyword\">end</span> while;</span><br><span class=\"line\"><span class=\"keyword\">end</span>;;</span><br><span class=\"line\">delimiter ;</span><br><span class=\"line\"><span class=\"keyword\">call</span> idata2();</span><br></pre></td></tr></table></figure>\n\n\n<p>比如有如下sql语句，为避免全表扫描，已经在city字段加上索引</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">select</span> city,name,age <span class=\"keyword\">from</span> t_city <span class=\"keyword\">where</span> city<span class=\"operator\">=</span><span class=\"string\">&#x27;广州&#x27;</span> <span class=\"keyword\">order</span> <span class=\"keyword\">by</span> name limit <span class=\"number\">1000</span>;</span><br></pre></td></tr></table></figure>\n\n\n<p>这个语句看上去逻辑很清晰， 那吗数据库内部到底是怎样执行的了？</p>\n<p>首先先用<code>explain</code>看看执行计划</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">explain <span class=\"keyword\">select</span> city,name,age <span class=\"keyword\">from</span> t_city <span class=\"keyword\">where</span> city<span class=\"operator\">=</span><span class=\"string\">&#x27;广州&#x27;</span> <span class=\"keyword\">order</span> <span class=\"keyword\">by</span> name limit <span class=\"number\">1000</span>;</span><br></pre></td></tr></table></figure>\n\n\n<p><img src=\"https://img-blog.csdnimg.cn/20190416172638203.png#id=J8vpw&originHeight=52&originWidth=981&originalType=binary&ratio=1&status=done&style=none\"><br><strong>先看下个执行计划各参数的含义：</strong></p>\n<ul>\n<li><code>select_type</code>：显 示查询中每个select子句的类型</li>\n<li><code>table</code>： 显示这一行的数据是关于哪张表的，有时不是真实的表名字</li>\n<li><code>type</code>：在表中找到所需行的方式，又称“访问类型”。常用的类型有： ALL, index,  range, ref, eq_ref, const, system, NULL（从左到右，性能从差到好）</li>\n<li><code>possible_keys</code>：指出MySQL能使用哪个索引在表中找到记录，查询涉及到的字段上若存在索引，则该索引将被列出，但不一定被查询使用</li>\n<li><code>Key</code>：key列显示MySQL实际决定使用的键（索引）</li>\n<li><code>key_len</code>：表示索引中使用的字节数，可通过该列计算查询中使用的索引的长度，key_len显示的值为索引字段的最大可能长度，并非实际使用长度，不损失精确性的情况下，长度越短越好</li>\n<li><code>ref</code>：表示上述表的连接匹配条件，即哪些列或常量被用于查找索引列上的值</li>\n<li><code>rows</code>： 表示MySQL根据表统计信息及索引选用情况，估算的找到所需的记录所需要读取的行数</li>\n<li><code>Extra</code>：该列包含MySQL解决查询的详细信息。Extra这个字段中的<code>“Using filesort”表示的就是需要排序</code>，MySQL会给每个线程分配一块内存用于排序，称为<code>sort_buffer</code>。</li>\n</ul>\n<p><img src=\"https://img-blog.csdnimg.cn/20190416174643103.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=qZTfO&originHeight=642&originWidth=655&originalType=binary&ratio=1&status=done&style=none\"></p>\n<ul>\n<li>按name排序”这个动作，可能在内存中完成，也可能需要使用外部排序，这取决于排序所需的内存和参数<code>sort_buffer_size</code>。</li>\n<li><code>sort_buffer_size</code>就是MySQL为排序开辟的内存（<code>sort_buffer</code>）的大小。如果要排序的数据量小于sort_buffer_size，排序就在内存中完成。但如果排序数据量太大，内存放不下，则不得不利用磁盘临时文件辅助排序。</li>\n</ul>\n<blockquote>\n<p>确定一个排序语句是否使用了临时文件</p>\n</blockquote>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/* 打开optimizer_trace，只对本线程有效 */</span></span><br><span class=\"line\"><span class=\"keyword\">SET</span> optimizer_trace<span class=\"operator\">=</span><span class=\"string\">&#x27;enabled=on&#x27;</span>; </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/* @a保存Innodb_rows_read的初始值 */</span></span><br><span class=\"line\"><span class=\"keyword\">select</span> VARIABLE_VALUE <span class=\"keyword\">into</span> <span class=\"variable\">@a</span> <span class=\"keyword\">from</span>  performance_schema.session_status <span class=\"keyword\">where</span> variable_name <span class=\"operator\">=</span> <span class=\"string\">&#x27;Innodb_rows_read&#x27;</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/* 执行语句 */</span></span><br><span class=\"line\"><span class=\"keyword\">select</span> city, name,age <span class=\"keyword\">from</span> t <span class=\"keyword\">where</span> city<span class=\"operator\">=</span><span class=\"string\">&#x27;杭州&#x27;</span> <span class=\"keyword\">order</span> <span class=\"keyword\">by</span> name limit <span class=\"number\">1000</span>; </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/* 查看 OPTIMIZER_TRACE 输出 */</span></span><br><span class=\"line\"><span class=\"keyword\">SELECT</span> <span class=\"operator\">*</span> <span class=\"keyword\">FROM</span> `information_schema`.`OPTIMIZER_TRACE`</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/* @b保存Innodb_rows_read的当前值 */</span></span><br><span class=\"line\"><span class=\"keyword\">select</span> VARIABLE_VALUE <span class=\"keyword\">into</span> <span class=\"variable\">@b</span> <span class=\"keyword\">from</span> performance_schema.session_status <span class=\"keyword\">where</span> variable_name <span class=\"operator\">=</span> <span class=\"string\">&#x27;Innodb_rows_read&#x27;</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/* 计算Innodb_rows_read差值 */</span></span><br><span class=\"line\"><span class=\"keyword\">select</span> <span class=\"variable\">@b</span><span class=\"operator\">-</span><span class=\"variable\">@a</span>;</span><br></pre></td></tr></table></figure>\n\n\n<p>这个方法是通过查看 OPTIMIZER_TRACE 的结果来确认的，你可以从 number_of_tmp_files中看到是否使用了临时文件。</p>\n<p><img src=\"https://img-blog.csdnimg.cn/2019041617592518.png#id=ZWOG8&originHeight=180&originWidth=712&originalType=binary&ratio=1&status=done&style=none\"></p>\n<ul>\n<li><code>number_of_tmp_files</code>表示的是，排序过程中使用的临时文件数。内存放不下时，就需要使用外部排序，外部排序一般使用归并排序算法。，MySQL将需要排序的数据分成12份，每一份单独排序后存在这些临时文件中。然后把这12个有序文件再合并成一个有序的大文件。</li>\n<li>如果<code>sort_buffer_size</code>超过了需要排序的数据量的大小，<code>number_of_tmp_files</code>就是0，表示排序可以直接在内存中完成。否则就需要放在临时文件中排序。</li>\n<li><code>sort_buffer_size</code>越小，需要分成的份数越多，<code>number_of_tmp_files</code>的值就越大。</li>\n<li><code>sort_mode</code> 里面的<code>packed_additional_fields</code>的意思是，排序过程对字符串做了<code>“紧凑”</code>处理。即使name字段的定义是varchar(16)，在排序过程中还是要按照实际长度来分配空间的。</li>\n<li>同时，最后一个查询语句select @b-@a 的返回结果是4000，表示整个执行过程只扫描了4000行。</li>\n<li>这里需要注意的是，为了避免对结论造成干扰，我把internal_tmp_disk_storage_engine设置成MyISAM。否则，select @b-@a的结果会大于4000</li>\n<li>在上面这个算法过程里面，只对原表的数据读了一遍，剩下的操作都是在sort_buffer和临时文件中执行的。但这个算法有一个问题，就是如果查询要返回的字段很多的话，那么sort_buffer里面要放的字段数太多，这样内存里能够同时放下的行数很少，要分成很多个临时文件，排序的性能会很差。</li>\n</ul>\n<p><strong>如果MySQL认为排序的单行长度太大会怎么做呢？</strong></p>\n<ul>\n<li><code>max_length_for_sort_data</code>，是MySQL中专门控制用于排序的行数据的长度的一个参数。它的意思是，如果单行的长度超过这个值，MySQL就认为单行太大，要换一个算法。</li>\n</ul>\n<h3 id=\"如何正确地显示随机消息\"><a href=\"#如何正确地显示随机消息\" class=\"headerlink\" title=\"如何正确地显示随机消息\"></a>如何正确地显示随机消息</h3><p>从一个单词表中随机选出三个单词</p>\n<p>创建测试表</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"> <span class=\"keyword\">CREATE</span> <span class=\"keyword\">TABLE</span> `words` (</span><br><span class=\"line\">  `id` <span class=\"type\">int</span>(<span class=\"number\">11</span>) <span class=\"keyword\">NOT</span> <span class=\"keyword\">NULL</span> AUTO_INCREMENT,</span><br><span class=\"line\">  `word` <span class=\"type\">varchar</span>(<span class=\"number\">64</span>) <span class=\"keyword\">DEFAULT</span> <span class=\"keyword\">NULL</span>,</span><br><span class=\"line\">  <span class=\"keyword\">PRIMARY</span> KEY (`id`)</span><br><span class=\"line\">) ENGINE<span class=\"operator\">=</span>InnoDB;</span><br></pre></td></tr></table></figure>\n\n\n<p>添加测试数据</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">delimiter ;;</span><br><span class=\"line\"><span class=\"keyword\">create</span> <span class=\"keyword\">procedure</span> idata3()</span><br><span class=\"line\"><span class=\"keyword\">begin</span></span><br><span class=\"line\">  <span class=\"keyword\">declare</span> i <span class=\"type\">int</span>;</span><br><span class=\"line\">  <span class=\"keyword\">set</span> i<span class=\"operator\">=</span><span class=\"number\">0</span>;</span><br><span class=\"line\">  while i<span class=\"operator\">&lt;</span><span class=\"number\">10000</span> do</span><br><span class=\"line\">    <span class=\"keyword\">insert</span> <span class=\"keyword\">into</span> words(word) <span class=\"keyword\">values</span>(concat(<span class=\"type\">char</span>(<span class=\"number\">97</span><span class=\"operator\">+</span>(i div <span class=\"number\">1000</span>)), <span class=\"type\">char</span>(<span class=\"number\">97</span><span class=\"operator\">+</span>(i <span class=\"operator\">%</span> <span class=\"number\">1000</span> div <span class=\"number\">100</span>)), <span class=\"type\">char</span>(<span class=\"number\">97</span><span class=\"operator\">+</span>(i <span class=\"operator\">%</span> <span class=\"number\">100</span> div <span class=\"number\">10</span>)), <span class=\"type\">char</span>(<span class=\"number\">97</span><span class=\"operator\">+</span>(i <span class=\"operator\">%</span> <span class=\"number\">10</span>))));</span><br><span class=\"line\">    <span class=\"keyword\">set</span> i<span class=\"operator\">=</span>i<span class=\"operator\">+</span><span class=\"number\">1</span>;</span><br><span class=\"line\">  <span class=\"keyword\">end</span> while;</span><br><span class=\"line\"><span class=\"keyword\">end</span>;;</span><br><span class=\"line\">delimiter ;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">call</span> idata3();</span><br></pre></td></tr></table></figure>\n\n\n<p><strong>首先，会想到用order by rand()来实现这个逻辑</strong></p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">EXPLAIN <span class=\"keyword\">select</span> word <span class=\"keyword\">from</span> words <span class=\"keyword\">order</span> <span class=\"keyword\">by</span> rand() limit <span class=\"number\">3</span>;</span><br></pre></td></tr></table></figure>\n\n\n<p><img src=\"https://img-blog.csdnimg.cn/20190416182846114.png#id=IcAaX&originHeight=98&originWidth=1076&originalType=binary&ratio=1&status=done&style=none\"></p>\n<ul>\n<li>Extra字段显示<code>Using temporary</code>，表示的是需要使用临时表；<code>Using filesort</code>，表示的是需要执行排序操作。因此这个Extra的意思就是，需要临时表，并且需要在临时表上排序</li>\n<li>order by rand()使用了内存临时表，内存临时表排序的时候使用了rowid排序方法。</li>\n<li>tmp_table_size这个配置限制了内存临时表的大小，默认值是16M。如果临时表大小超过了tmp_table_size，那么内存临时表就会转成磁盘临时表。</li>\n<li>磁盘临时表使用的引擎默认是InnoDB，是由参数internal_tmp_disk_storage_engine控制的。当使用磁盘临时表的时候，对应的就是一个没有显式索引的InnoDB表的排序过程。</li>\n</ul>\n<h3 id=\"幻读是什么，幻读有什么问题\"><a href=\"#幻读是什么，幻读有什么问题\" class=\"headerlink\" title=\"幻读是什么，幻读有什么问题\"></a>幻读是什么，幻读有什么问题</h3><ul>\n<li>幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。</li>\n<li>在可重复读隔离级别下，普通的查询是快照读，是不会看到别的事务插入的数据的。因此，幻读在“当前读”下才会出现。</li>\n</ul>\n<p><strong>创建测试数据</strong></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CREATE TABLE `t` (</span><br><span class=\"line\">  `id` int(11) NOT NULL,</span><br><span class=\"line\">  `c` int(11) DEFAULT NULL,</span><br><span class=\"line\">  `d` int(11) DEFAULT NULL,</span><br><span class=\"line\">  PRIMARY KEY (`id`),</span><br><span class=\"line\">  KEY `c` (`c`)</span><br><span class=\"line\">) ENGINE=InnoDB;</span><br><span class=\"line\"></span><br><span class=\"line\">insert into t values(0,0,0),(5,5,5),</span><br><span class=\"line\">(10,10,10),(15,15,15),(20,20,20),(25,25,25);</span><br></pre></td></tr></table></figure>\n\n\n<p><strong>下面的语句序列，是怎么加锁的，加的锁又是什么时候释放的呢？</strong></p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">begin</span>;</span><br><span class=\"line\"><span class=\"keyword\">select</span> <span class=\"operator\">*</span> <span class=\"keyword\">from</span> t <span class=\"keyword\">where</span> d<span class=\"operator\">=</span><span class=\"number\">5</span> <span class=\"keyword\">for</span> update;</span><br><span class=\"line\"><span class=\"keyword\">commit</span>;</span><br></pre></td></tr></table></figure>\n\n\n<ul>\n<li>这个语句会命中d=5的这一行，对应的主键id=5，因此在select 语句执行完成后，id=5这一行会加一个写锁，而且由于两阶段锁协议，这个写锁会在执行commit语句的时候释放。</li>\n<li>由于字段d上没有索引，因此这条查询语句会做全表扫描。那么，其他被扫描到的，但是不满足条件的5行记录上，会不会被加锁呢？</li>\n</ul>\n<p><img src=\"https://img-blog.csdnimg.cn/20190418165218311.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=GPJCV&originHeight=688&originWidth=984&originalType=binary&ratio=1&status=done&style=none\"></p>\n<ul>\n<li>可以看到，session A里执行了三次查询，分别是Q1、Q2和Q3。它们的SQL语句相同，都是select * from t where d=5 for update。这个语句的意思你应该很清楚了，查所有d=5的行，而且使用的是当前读，并且加上写锁</li>\n</ul>\n<p><strong>图中SQL执行流程</strong></p>\n<ul>\n<li>Q1只返回id=5这一行；</li>\n<li>在T2时刻，session B把id=0这一行的d值改成了5，因此T3时刻Q2查出来的是id=0和id=5这两行；</li>\n<li>在T4时刻，session C又插入一行（1,1,5），因此T5时刻Q3查出来的是id=0、id=1和id=5的这三行。</li>\n<li>其中，Q3读到id=1这一行的现象，被称为<code>“幻读”</code>。</li>\n<li>在<code>可重复读</code>(InnoDB的默认)隔离级别下，普通的查询是快照读，是不会看到别的事务插入的数据的。因此，<code>幻读在“当前读”下才会出现。</code></li>\n<li>上面session B的修改结果，被session A之后的select语句用“当前读”看到，不能称为幻读。幻读仅专指“新插入的行”</li>\n</ul>\n<p>从事务可见性规则来分析的话，上面这三条SQL语句的返回结果都没有问题。因为这三个查询都是加了for update，都是当前读。而当前读的规则，就是要能读到所有已经提交的记录的最新值。并且，session B和sessionC的两条语句，执行后就会提交，所以Q2和Q3就是应该看到这两个事务的操作效果，而且也看到了，这跟事务的可见性规则并不矛盾。但是，这是不是真的没问题呢？</p>\n<p><strong>幻读有什么问题？</strong></p>\n<ul>\n<li>首先是语义上的。session A在T1时刻就声明了，“我要把所有d=5的行锁住，不准别的事务进行读写操作”。而实际上，这个语义被破坏了。</li>\n</ul>\n<p><strong>其次，是数据一致性的问题。</strong></p>\n<ul>\n<li>我们知道，锁的设计是为了保证数据的一致性。而这个一致性，不止是数据库内部数据状态在此刻的一致性，还包含了数据和日志在逻辑上的一致性</li>\n<li>为了说明这个问题，我给session A在T1时刻再加一个更新语句，即：update t set d=100 where d=5。<br><img src=\"https://img-blog.csdnimg.cn/20190418171046246.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=Wyaze&originHeight=551&originWidth=929&originalType=binary&ratio=1&status=done&style=none\"><br><strong>上面的执行流程</strong></li>\n<li>经过T1时刻，id=5这一行变成 (5,5,100)，当然这个结果最终是在T6时刻正式提交的;</li>\n<li>经过T2时刻，id=0这一行变成(0,5,5);</li>\n<li>经过T4时刻，表里面多了一行(1,5,5);</li>\n</ul>\n<p>这样看，这些数据也没啥问题，但是我们再来看看这时候binlog里面的内容。</p>\n<ul>\n<li>T2时刻，session B事务提交，写入了两条语句；</li>\n<li>T4时刻，session C事务提交，写入了两条语句；</li>\n<li>T6时刻，session A事务提交，写入了update t set d=100 where d=5 这条语句。</li>\n</ul>\n<p>放到一起的话，就是这样的：</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">update t <span class=\"keyword\">set</span> d<span class=\"operator\">=</span><span class=\"number\">5</span> <span class=\"keyword\">where</span> id<span class=\"operator\">=</span><span class=\"number\">0</span>; <span class=\"comment\">/*(0,0,5)*/</span></span><br><span class=\"line\">update t <span class=\"keyword\">set</span> c<span class=\"operator\">=</span><span class=\"number\">5</span> <span class=\"keyword\">where</span> id<span class=\"operator\">=</span><span class=\"number\">0</span>; <span class=\"comment\">/*(0,5,5)*/</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">insert</span> <span class=\"keyword\">into</span> t <span class=\"keyword\">values</span>(<span class=\"number\">1</span>,<span class=\"number\">1</span>,<span class=\"number\">5</span>); <span class=\"comment\">/*(1,1,5)*/</span></span><br><span class=\"line\">update t <span class=\"keyword\">set</span> c<span class=\"operator\">=</span><span class=\"number\">5</span> <span class=\"keyword\">where</span> id<span class=\"operator\">=</span><span class=\"number\">1</span>; <span class=\"comment\">/*(1,5,5)*/</span></span><br><span class=\"line\"></span><br><span class=\"line\">update t <span class=\"keyword\">set</span> d<span class=\"operator\">=</span><span class=\"number\">100</span> <span class=\"keyword\">where</span> d<span class=\"operator\">=</span><span class=\"number\">5</span>;<span class=\"comment\">/*所有d=5的行，d改成100*/</span></span><br></pre></td></tr></table></figure>\n\n\n<blockquote>\n<p>这个语句序列，不论是拿到备库去执行，还是以后用binlog来克隆一个库，这三行的结果，都变成了 (0,5,100)、(1,5,100)和(5,5,100)。也就是说，id=0和id=1这两行，发生了数据不一致。这个问题很严重，是不行的。</p>\n</blockquote>\n<p><strong>如何解决幻读？</strong></p>\n<ul>\n<li>产生幻读的原因是，行锁只能锁住行，但是新插入记录这个动作，要更新的是记录之间的“间隙”。因此，为了解决幻读问题，InnoDB只好引入新的锁，也就是间隙锁(Gap Lock)。</li>\n<li>间隙锁，锁的就是两个值之间的空隙。比如文章开头的表t，初始化插入了6个记录，这就产生了7个间隙。</li>\n<li>这样，当你执行 select * from t where d=5 for update的时候，就不止是给数据库中已有的6个记录加上了行锁，还同时加了7个间隙锁。这样就确保了无法再插入新的记录。</li>\n<li>也就是说这时候，在一行行扫描的过程中，不仅将给行加上了行锁，还给行两边的空隙，也加上了间隙锁。</li>\n<li>间隙锁存在冲突关系的，是“往这个间隙中插入一个记录”这个操作。间隙锁之间都不存在冲突关系。</li>\n<li>间隙锁和next-key lock的引入，帮我们解决了幻读的问题，但同时也带来了一些“困扰”</li>\n</ul>\n<blockquote>\n<p>比如现在有这样一个场景 业务逻辑这样的：任意锁住一行，如果这一行不存在的话就插入，如果存在这一行就更新它的数据，代码如下：</p>\n</blockquote>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">begin</span>;</span><br><span class=\"line\"><span class=\"keyword\">select</span> <span class=\"operator\">*</span> <span class=\"keyword\">from</span> t <span class=\"keyword\">where</span> id<span class=\"operator\">=</span>N <span class=\"keyword\">for</span> update;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/*如果行不存在*/</span></span><br><span class=\"line\"><span class=\"keyword\">insert</span> <span class=\"keyword\">into</span> t <span class=\"keyword\">values</span>(N,N,N);</span><br><span class=\"line\"><span class=\"comment\">/*如果行存在*/</span></span><br><span class=\"line\">update t <span class=\"keyword\">set</span> d<span class=\"operator\">=</span>N <span class=\"keyword\">set</span> id<span class=\"operator\">=</span>N;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">commit</span>;</span><br></pre></td></tr></table></figure>\n\n\n<blockquote>\n<p>可能你会说，这个不是<code>insert ... on duplicate key update</code> 就能解决吗？但其实在有多个唯一键的时候,这个方法是不能满足要求的。这个逻辑一旦有并发，就会碰到死锁。你一定也觉得奇怪，这个逻辑每次操作前用for update锁起来，已经是最严格的模式了，怎么还会有死锁呢？</p>\n</blockquote>\n<p><img src=\"https://img-blog.csdnimg.cn/20190418172853342.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzOTEzNDI=,size_16,color_FFFFFF,t_70#id=n7URX&originHeight=372&originWidth=982&originalType=binary&ratio=1&status=done&style=none\"><br>你看到了，其实都不需要用到后面的update语句，就已经形成死锁了。我们按语句执行顺序来分析一下：</p>\n<ul>\n<li>session A 执行select … for update语句，由于id=9这一行并不存在，因此会加上间隙锁(5,10);</li>\n<li>session B 执行select … for update语句，同样会加上间隙锁(5,10)，间隙锁之间不会冲突，因此这个语句可以执行成功；</li>\n<li>session B 试图插入一行(9,9,9)，被session A的间隙锁挡住了，只好进入等待；</li>\n<li>session A试图插入一行(9,9,9)，被session B的间隙锁挡住了。</li>\n<li>至此，两个session进入互相等待状态，形成死锁。当然，InnoDB的死锁检测马上就发现了这对死锁关系，让session A的insert语句报错返回了。</li>\n</ul>\n<blockquote>\n<p><code>间隙锁是在可重复读隔离级别下才会生效的</code>。所以，你如果把隔离级别设置为读提交的话，就没有间隙锁了。但同时，你要解决可能出现的数据和日志不一致问题，需要把<code>binlog</code>格式设置为row。这，也是现在不少公司使用的配置组合。</p>\n</blockquote>\n"},{"title":"八股文系列（四）—— RabbitMQ","date":"2021-09-21T06:15:58.000Z","updated":"2021-09-21T06:16:01.000Z","description":null,"_content":"\n这是八股文系列的第四篇文章，主要是关于RabbitMQ的面试常问问题。\n\n本文仅仅列举问题的部分常见解答，详细回答需结合官方文档和日常工作使用经验。😉\n    \n<!-- more -->\n\n## 1.RabbitMQ是什么？\n\n\nRabbitMQ是实现了高级消息队列协议（AMQP）的开源消息代理软件（亦称面向消息的中间件）。RabbitMQ服务器是用Erlang语言编写的，而群集和故障转移是构建在开放电信平台框架上的。所有主要的编程语言均有与代理接口通讯的客户端库。\nPS:也可能直接问什么是消息队列？消息队列就是一个使用队列来通信的组件\n\n\n## 2.RabbitMQ特点?\n可靠性: RabbitMQ使用一些机制来保证可靠性， 如持久化、传输确认及发布确认等。\n灵活的路由 : 在消息进入队列之前，通过交换器来路由消息。对于典型的路由功能， RabbitMQ 己经提供了一些内置的交换器来实现。针对更复杂的路由功能，可以将多个 交换器绑定在一起， 也可以通过插件机制来实现自己的交换器。\n扩展性: 多个RabbitMQ节点可以组成一个集群，也可以根据实际业务情况动态地扩展 集群中节点。\n高可用性 : 队列可以在集群中的机器上设置镜像，使得在部分节点出现问题的情况下队 列仍然可用。\n多种协议: RabbitMQ除了原生支持AMQP协议，还支持STOMP， MQTT等多种消息 中间件协议。\n多语言客户端 :RabbitMQ 几乎支持所有常用语言，比如 Java、 Python、 Ruby、 PHP、 C#、 JavaScript 等。\n管理界面 : RabbitMQ 提供了一个易用的用户界面，使得用户可以监控和管理消息、集 群中的节点等。\n令插件机制 : RabbitMQ 提供了许多插件 ， 以实现从多方面进行扩展，当然也可以编写自 己的插件。\n\n\n## 3.AMQP是什么?\nRabbitMQ就是 AMQP 协议的 Erlang 的实现(当然 RabbitMQ 还支持 STOMP2、 MQTT3 等协议 ) AMQP 的模型架构 和 RabbitMQ 的模型架构是一样的，生产者将消息发送给交换器，交换器和队列绑定 。\nRabbitMQ 中的交换器、交换器类型、队列、绑定、路由键等都是遵循的 AMQP 协议中相 应的概念。目前 RabbitMQ 最新版本默认支持的是 AMQP 0-9-1。\n\n## 4.AMQP协议3层？\nModule Layer:协议最高层，主要定义了一些客户端调用的命令，客户端可以用这些命令实现自己的业务逻辑。\nSession Layer:中间层，主要负责客户端命令发送给服务器，再将服务端应答返回客户端，提供可靠性同步机制和错误处理。\nTransportLayer:最底层，主要传输二进制数据流，提供帧的处理、信道服用、错误检测和数据表示等。\n\n## 5.AMQP模型的几大组件？\n\n- 交换器 (Exchange)：消息代理服务器中用于把消息路由到队列的组件。\n- 队列 (Queue)：用来存储消息的数据结构，位于硬盘或内存中。\n- 绑定 (Binding)：一套规则，告知交换器消息应该将消息投递给哪个队列。\n\n## 6.说说生产者Producer和消费者Consumer?\n生产者\n- 消息生产者，就是投递消息的一方。\n- 消息一般包含两个部分：消息体（payload)和标签(Label)。\n\n消费者\n- 消费消息，也就是接收消息的一方。\n- 消费者连接到RabbitMQ服务器，并订阅到队列上。消费消息时只消费消息体，丢弃标签。\n\n## 7.为什么需要消息队列？\n从本质上来说是因为互联网的快速发展，业务不断扩张，促使技术架构需要不断的演进。\n从以前的单体架构到现在的微服务架构，成百上千的服务之间相互调用和依赖。从互联网初期一个服务器上有 100 个在线用户已经很了不得，到现在坐拥10亿日活的微信。此时，我们需要有一个「工具」来解耦服务之间的关系、控制资源合理合时的使用以及缓冲流量洪峰等等。因此，消息队列就应运而生了。\n它常用来实现：异步处理、服务解耦、流量控制（削峰）。\n\n\n## 8.说说Broker服务节点、Queue队列、Exchange交换器？\n- Broker可以看做RabbitMQ的服务节点。一般请下一个Broker可以看做一个RabbitMQ服务器。\n- Queue:RabbitMQ的内部对象，用于存储消息。多个消费者可以订阅同一队列，这时队列中的消息会被平摊（轮询）给多个消费者进行处理。\n- Exchange:生产者将消息发送到交换器，由交换器将消息路由到一个或者多个队列中。当路由不到时，或返回给生产者或直接丢弃。\n\n## 9.消息队列有什么优缺点\n优点上面已经说了，就是在特殊场景下有其对应的好处，解耦、异步、削峰。缺点有以下几个：\n\n- 系统可用性降低 系统引入的外部依赖越多，越容易挂掉。万一 MQ 挂了，MQ 一挂，整套系统崩 溃，你不就完了？\n- 系统复杂度提高 硬生生加个 MQ 进来，你怎么保证消息没有重复消费？怎么处理消息丢失的情况？\n- 怎么保证消息传递的顺序性？问题一大堆。\n- 一致性问题 A 系统处理完了直接返回成功了，人都以为你这个请求就成功了；但是问题是，要是 BCD 三个系统那里，BD 两个系统写库成功了，结果 C 系统写库失败了，咋整？你这数据就不一致 了。\n\n## 10.如何保证消息的可靠性？\n消息到MQ的过程中搞丢，MQ自己搞丢，MQ到消费过程中搞丢。\n生产者到RabbitMQ：事务机制和Confirm机制，注意：事务机制和 Confirm 机制是互斥的，两者不能共存，会导致 RabbitMQ 报错。\nRabbitMQ自身：持久化、集群、普通模式、镜像模式。\nRabbitMQ到消费者：basicAck机制、死信队列、消息补偿机制。\n\n## 11.什么是RoutingKey路由键？\n生产者将消息发送给交换器的时候，会指定一个RoutingKey,用来指定这个消息的路由规则，这个RoutingKey需要与交换器类型和绑定键(BindingKey)联合使用才能最终生效。\n\n## 12.Binding绑定？\n通过绑定将交换器和队列关联起来，一般会指定一个BindingKey,这样RabbitMq就知道如何正确路由消息到队列了。\n\n## 13.交换器4种类型？\n主要有以下4种。\n- fanout:把所有发送到该交换器的消息路由到所有与该交换器绑定的队列中。\n- direct:把消息路由到BindingKey和RoutingKey完全匹配的队列中。\n- topic:\n- 匹配规则： \n    - RoutingKey：为一个 点号'.': 分隔的字符串。比如: java.xiaoka.show \n    - BindingKey：和RoutingKey一样也是点号“.“分隔的字符串。BindingKey可使用 * 和 # 用于做模糊匹配，*匹配一个单词，#匹配多个或者0个 \n    - headers：不依赖路由键匹配规则路由消息。是根据发送消息内容中的headers属性进行匹配。性能差，基本用不到。\n    \n## 14.生产者消息运转？\n1. Producer先连接到Broker,建立连接Connection,开启一个信道(Channel)。\n2. Producer声明一个交换器并设置好相关属性。\n3. Producer声明一个队列并设置好相关属性。\n4. Producer通过路由键将交换器和队列绑定起来。\n5. Producer发送消息到Broker,其中包含路由键、交换器等信息。\n6. 相应的交换器根据接收到的路由键查找匹配的队列。\n7. 如果找到，将消息存入对应的队列，如果没有找到，会根据生产者的配置丢弃或者退回给生产者。\n8. 关闭信道。\n9. 管理连接。\n\n## 15.消费者接收消息过程？\n1. Producer先连接到Broker,建立连接Connection,开启一个信道(Channel)。\n2. 向Broker请求消费响应的队列中消息，可能会设置响应的回调函数。\n3. 等待Broker回应并投递相应队列中的消息，接收消息。\n4. 消费者确认收到的消息,ack。\n5. RabbitMq从队列中删除已经确定的消息。\n6. 关闭信道。\n7. 关闭连接。\n\n## 16.交换器无法根据自身类型和路由键找到符合条件队列时，有哪些处理？\n- mandatory：true 返回消息给生产者。\n- mandatory: false 直接丢弃。\n\n## 17.死信队列？\nDLX，全称为 Dead-Letter-Exchange，死信交换器，死信邮箱。当消息在一个队列中变成死信 (dead message) 之后，它能被重新被发送到另一个交换器中，这个交换器就是 DLX，绑定 DLX 的队列就称之为死信队列。\n\n## 18.导致的死信的几种原因？\n- 消息被拒（Basic.Reject /Basic.Nack) 且 requeue = false。\n- 消息TTL过期。\n- 队列满了，无法再添加。\n\n## 19.延迟队列？\n存储对应的延迟消息，指当消息被发送以后，并不想让消费者立刻拿到消息，而是等待特定时间后，消费者才能拿到这个消息进行消费。\n\n## 20.优先级队列？\n- 优先级高的队列会先被消费。\n- 可以通过x-max-priority参数来实现。\n- 当消费速度大于生产速度且Broker没有堆积的情况下，优先级显得没有意义。\n\n## 21.事务机制？\nRabbitMQ 客户端中与事务机制相关的方法有三个:\n1. channel.txSelect 用于将当前的信道设置成事务模式。\n2. channel . txCommit 用于提交事务 。\n3. channel . txRollback 用于事务回滚,如果在事务提交执行之前由于 RabbitMQ 异常崩溃或者其他原因抛出异常,通过txRollback来回滚。\n\n## 22.发送确认机制？\n生产者把信道设置为confirm确认模式,设置后，所有再改信道发布的消息都会被指定一个唯一的ID，一旦消息被投递到所有匹配的队列之后，RabbitMQ就会发送一个确认（Basic.Ack)给生产者（包含消息的唯一ID)，这样生产者就知道消息到达对应的目的地了。\n\n## 23.消费者获取消息的方式？\n- 推\n- 拉\n\n## 24.消费者某些原因无法处理当前接受的消息如何来拒绝？\nchannel .basicNack channel .basicReject\n\n## 25.消息传输保证层级？\nAt most once:最多一次。消息可能会丢失，但不会重复传输。\nAt least once：最少一次。消息绝不会丢失，但可能会重复传输。\nExactly once: 恰好一次，每条消息肯定仅传输一次。\n\n## 26.了解Virtual Host吗?\n每一个RabbitMQ服务器都能创建虚拟的消息服务器，也叫虚拟主机(virtual host)，简称vhost。\n默认为“/”。\n\n## 27.集群中的节点类型？\n1. 内存节点：ram,将变更写入内存。\n2. 磁盘节点：disc,磁盘写入操作。\n3. RabbitMQ要求最少有一个磁盘节点。\n\n## 28.队列结构？\n通常由以下两部分组成：\n\n1. rabbit_amqqueue_process:负责协议相关的消息处理，即接收生产者发布的消息、向消费者交付消息、处理消息的确认(包括生产端的 confirm 和消费端的 ack) 等。\n2. backing_queue:是消息存储的具体形式和引擎，并向 rabbit amqqueue process提供相关的接口以供调用。\n\n## 29.RabbitMQ中消息可能有的几种状态?\n1. alpha: 消息内容(包括消息体、属性和 headers) 和消息索引都存储在内存中 。\n2. beta: 消息内容保存在磁盘中，消息索引保存在内存中。\n3. gamma: 消息内容保存在磁盘中，消息索引在磁盘和内存中都有 。\n4. delta: 消息内容和索引都在磁盘中 。\n\n## 30.在何种场景下使用了消息中间件？\n- 接口之间耦合比较严重\n- 面对大流量并发时，容易被冲垮\n- 存在性能问题\n\n## 31.生产者如何将消息可靠投递到MQ？\n1. Client发送消息给MQ\n2. MQ将消息持久化后，发送Ack消息给Client，此处有可能因为网络问题导致Ack消息无法发送到Client，那么Client在等待超时后，会重传消息；\n3. Client收到Ack消息后，认为消息已经投递成功。\n\n## 32 . MQ如何将消息可靠投递到消费者？\n1. MQ将消息push给Client（或Client来pull消息）\n2. Client得到消息并做完业务逻辑\n3. Client发送Ack消息给MQ，通知MQ删除该消息，此处有可能因为网络问题导致Ack失败，那么Client会重复消息，这里就引出消费幂等的问题；\n4. MQ将已消费的消息删除\n\n## 33.如何保证RabbitMQ消息队列的高可用?\nRabbitMQ 有三种模式：单机模式，普通集群模式，镜像集群模式。\n1. 单机模式：就是demo级别的，一般就是你本地启动了玩玩儿的，没人生产用单机模式\n2. 普通集群模式：意思就是在多台机器上启动多个RabbitMQ实例，每个机器启动一个。\n3. 镜像集群模式：这种模式，才是所谓的RabbitMQ的高可用模式，跟普通集群模式不一样的是，你创建的queue，无论元数据(元数据指RabbitMQ的配置数据)还是queue里的消息都会存在于多个实例上，然后每次你写消息到queue的时候，都会自动把消息到多个实例的queue里进行消息同步。\n\n## 34.如何快速处理挤压过多的消息？\n情景：消费者挂掉后再重启，这时会有很多已经挤压了的消息在MQ中，所以需要快速的处理之前已经挤压了的消息。\n解决方案：可以将原由的消费者进行修改，不再直接对数据库进行操作，只对MQ的数据进行并将处理得到的数据再发给新的partition（可以创建很多来进行过度），然后再由很多消费者进行同时的消费，并写入数据库。这是处理速度就会很快。因为第一次的消费者处理之后并不用写入数据库就可以给MQ反馈已经消费了；后续的消费者继续处理需要消费的数据并不会影响之前的消费者处理的速度。\n\n\n## 35.如果消息队列满了怎么处理？\n类似上述问题：修改消费者消费方式（不直接进行消费，转发给另外的MQ），然后再由其他消费者进行消费。\n\n\n## 36.如果让你开发消息队列中间件，如何来设计？\n1. 考虑mq的伸缩性，就是需要的时候快速扩容，就可以增加吞吐量和容量，那怎么搞？设计个分布式的系统呗，参照一下kafka的设计理念，broker -> topic -> partition，每个partition放一个机器，就存一部分数据。如果现在资源不够了，简单啊，给topic增加partition，然后做数据迁移，增加机器，这样就可以存放更多数据，提供更高的吞吐量了。\n2. 考虑mq数据要不要持久化？需要写入磁盘，这样才能保证挂了之后不会造成数据的丢失。写入时怎么进行写入磁盘？顺序写入，这样既保证了消息的顺序性，还减少了寻址的开销，达到提高性能的目的。\n3. 考虑mq的可用性？参考kafka的高可用的保障机制。多副本--》leader&follwer--》broker挂了重新选举leader即可。\n","source":"_posts/RabbitMQ.md","raw":"---\ntitle: 八股文系列（四）—— RabbitMQ\ndate: 2021-09-21 14:15:58\nupdated: 2021-09-21 14:16:01\ntags: [八股文,rabbitmq,mq]\ncategories: rabbitmq\ndescription:\n---\n\n这是八股文系列的第四篇文章，主要是关于RabbitMQ的面试常问问题。\n\n本文仅仅列举问题的部分常见解答，详细回答需结合官方文档和日常工作使用经验。😉\n    \n<!-- more -->\n\n## 1.RabbitMQ是什么？\n\n\nRabbitMQ是实现了高级消息队列协议（AMQP）的开源消息代理软件（亦称面向消息的中间件）。RabbitMQ服务器是用Erlang语言编写的，而群集和故障转移是构建在开放电信平台框架上的。所有主要的编程语言均有与代理接口通讯的客户端库。\nPS:也可能直接问什么是消息队列？消息队列就是一个使用队列来通信的组件\n\n\n## 2.RabbitMQ特点?\n可靠性: RabbitMQ使用一些机制来保证可靠性， 如持久化、传输确认及发布确认等。\n灵活的路由 : 在消息进入队列之前，通过交换器来路由消息。对于典型的路由功能， RabbitMQ 己经提供了一些内置的交换器来实现。针对更复杂的路由功能，可以将多个 交换器绑定在一起， 也可以通过插件机制来实现自己的交换器。\n扩展性: 多个RabbitMQ节点可以组成一个集群，也可以根据实际业务情况动态地扩展 集群中节点。\n高可用性 : 队列可以在集群中的机器上设置镜像，使得在部分节点出现问题的情况下队 列仍然可用。\n多种协议: RabbitMQ除了原生支持AMQP协议，还支持STOMP， MQTT等多种消息 中间件协议。\n多语言客户端 :RabbitMQ 几乎支持所有常用语言，比如 Java、 Python、 Ruby、 PHP、 C#、 JavaScript 等。\n管理界面 : RabbitMQ 提供了一个易用的用户界面，使得用户可以监控和管理消息、集 群中的节点等。\n令插件机制 : RabbitMQ 提供了许多插件 ， 以实现从多方面进行扩展，当然也可以编写自 己的插件。\n\n\n## 3.AMQP是什么?\nRabbitMQ就是 AMQP 协议的 Erlang 的实现(当然 RabbitMQ 还支持 STOMP2、 MQTT3 等协议 ) AMQP 的模型架构 和 RabbitMQ 的模型架构是一样的，生产者将消息发送给交换器，交换器和队列绑定 。\nRabbitMQ 中的交换器、交换器类型、队列、绑定、路由键等都是遵循的 AMQP 协议中相 应的概念。目前 RabbitMQ 最新版本默认支持的是 AMQP 0-9-1。\n\n## 4.AMQP协议3层？\nModule Layer:协议最高层，主要定义了一些客户端调用的命令，客户端可以用这些命令实现自己的业务逻辑。\nSession Layer:中间层，主要负责客户端命令发送给服务器，再将服务端应答返回客户端，提供可靠性同步机制和错误处理。\nTransportLayer:最底层，主要传输二进制数据流，提供帧的处理、信道服用、错误检测和数据表示等。\n\n## 5.AMQP模型的几大组件？\n\n- 交换器 (Exchange)：消息代理服务器中用于把消息路由到队列的组件。\n- 队列 (Queue)：用来存储消息的数据结构，位于硬盘或内存中。\n- 绑定 (Binding)：一套规则，告知交换器消息应该将消息投递给哪个队列。\n\n## 6.说说生产者Producer和消费者Consumer?\n生产者\n- 消息生产者，就是投递消息的一方。\n- 消息一般包含两个部分：消息体（payload)和标签(Label)。\n\n消费者\n- 消费消息，也就是接收消息的一方。\n- 消费者连接到RabbitMQ服务器，并订阅到队列上。消费消息时只消费消息体，丢弃标签。\n\n## 7.为什么需要消息队列？\n从本质上来说是因为互联网的快速发展，业务不断扩张，促使技术架构需要不断的演进。\n从以前的单体架构到现在的微服务架构，成百上千的服务之间相互调用和依赖。从互联网初期一个服务器上有 100 个在线用户已经很了不得，到现在坐拥10亿日活的微信。此时，我们需要有一个「工具」来解耦服务之间的关系、控制资源合理合时的使用以及缓冲流量洪峰等等。因此，消息队列就应运而生了。\n它常用来实现：异步处理、服务解耦、流量控制（削峰）。\n\n\n## 8.说说Broker服务节点、Queue队列、Exchange交换器？\n- Broker可以看做RabbitMQ的服务节点。一般请下一个Broker可以看做一个RabbitMQ服务器。\n- Queue:RabbitMQ的内部对象，用于存储消息。多个消费者可以订阅同一队列，这时队列中的消息会被平摊（轮询）给多个消费者进行处理。\n- Exchange:生产者将消息发送到交换器，由交换器将消息路由到一个或者多个队列中。当路由不到时，或返回给生产者或直接丢弃。\n\n## 9.消息队列有什么优缺点\n优点上面已经说了，就是在特殊场景下有其对应的好处，解耦、异步、削峰。缺点有以下几个：\n\n- 系统可用性降低 系统引入的外部依赖越多，越容易挂掉。万一 MQ 挂了，MQ 一挂，整套系统崩 溃，你不就完了？\n- 系统复杂度提高 硬生生加个 MQ 进来，你怎么保证消息没有重复消费？怎么处理消息丢失的情况？\n- 怎么保证消息传递的顺序性？问题一大堆。\n- 一致性问题 A 系统处理完了直接返回成功了，人都以为你这个请求就成功了；但是问题是，要是 BCD 三个系统那里，BD 两个系统写库成功了，结果 C 系统写库失败了，咋整？你这数据就不一致 了。\n\n## 10.如何保证消息的可靠性？\n消息到MQ的过程中搞丢，MQ自己搞丢，MQ到消费过程中搞丢。\n生产者到RabbitMQ：事务机制和Confirm机制，注意：事务机制和 Confirm 机制是互斥的，两者不能共存，会导致 RabbitMQ 报错。\nRabbitMQ自身：持久化、集群、普通模式、镜像模式。\nRabbitMQ到消费者：basicAck机制、死信队列、消息补偿机制。\n\n## 11.什么是RoutingKey路由键？\n生产者将消息发送给交换器的时候，会指定一个RoutingKey,用来指定这个消息的路由规则，这个RoutingKey需要与交换器类型和绑定键(BindingKey)联合使用才能最终生效。\n\n## 12.Binding绑定？\n通过绑定将交换器和队列关联起来，一般会指定一个BindingKey,这样RabbitMq就知道如何正确路由消息到队列了。\n\n## 13.交换器4种类型？\n主要有以下4种。\n- fanout:把所有发送到该交换器的消息路由到所有与该交换器绑定的队列中。\n- direct:把消息路由到BindingKey和RoutingKey完全匹配的队列中。\n- topic:\n- 匹配规则： \n    - RoutingKey：为一个 点号'.': 分隔的字符串。比如: java.xiaoka.show \n    - BindingKey：和RoutingKey一样也是点号“.“分隔的字符串。BindingKey可使用 * 和 # 用于做模糊匹配，*匹配一个单词，#匹配多个或者0个 \n    - headers：不依赖路由键匹配规则路由消息。是根据发送消息内容中的headers属性进行匹配。性能差，基本用不到。\n    \n## 14.生产者消息运转？\n1. Producer先连接到Broker,建立连接Connection,开启一个信道(Channel)。\n2. Producer声明一个交换器并设置好相关属性。\n3. Producer声明一个队列并设置好相关属性。\n4. Producer通过路由键将交换器和队列绑定起来。\n5. Producer发送消息到Broker,其中包含路由键、交换器等信息。\n6. 相应的交换器根据接收到的路由键查找匹配的队列。\n7. 如果找到，将消息存入对应的队列，如果没有找到，会根据生产者的配置丢弃或者退回给生产者。\n8. 关闭信道。\n9. 管理连接。\n\n## 15.消费者接收消息过程？\n1. Producer先连接到Broker,建立连接Connection,开启一个信道(Channel)。\n2. 向Broker请求消费响应的队列中消息，可能会设置响应的回调函数。\n3. 等待Broker回应并投递相应队列中的消息，接收消息。\n4. 消费者确认收到的消息,ack。\n5. RabbitMq从队列中删除已经确定的消息。\n6. 关闭信道。\n7. 关闭连接。\n\n## 16.交换器无法根据自身类型和路由键找到符合条件队列时，有哪些处理？\n- mandatory：true 返回消息给生产者。\n- mandatory: false 直接丢弃。\n\n## 17.死信队列？\nDLX，全称为 Dead-Letter-Exchange，死信交换器，死信邮箱。当消息在一个队列中变成死信 (dead message) 之后，它能被重新被发送到另一个交换器中，这个交换器就是 DLX，绑定 DLX 的队列就称之为死信队列。\n\n## 18.导致的死信的几种原因？\n- 消息被拒（Basic.Reject /Basic.Nack) 且 requeue = false。\n- 消息TTL过期。\n- 队列满了，无法再添加。\n\n## 19.延迟队列？\n存储对应的延迟消息，指当消息被发送以后，并不想让消费者立刻拿到消息，而是等待特定时间后，消费者才能拿到这个消息进行消费。\n\n## 20.优先级队列？\n- 优先级高的队列会先被消费。\n- 可以通过x-max-priority参数来实现。\n- 当消费速度大于生产速度且Broker没有堆积的情况下，优先级显得没有意义。\n\n## 21.事务机制？\nRabbitMQ 客户端中与事务机制相关的方法有三个:\n1. channel.txSelect 用于将当前的信道设置成事务模式。\n2. channel . txCommit 用于提交事务 。\n3. channel . txRollback 用于事务回滚,如果在事务提交执行之前由于 RabbitMQ 异常崩溃或者其他原因抛出异常,通过txRollback来回滚。\n\n## 22.发送确认机制？\n生产者把信道设置为confirm确认模式,设置后，所有再改信道发布的消息都会被指定一个唯一的ID，一旦消息被投递到所有匹配的队列之后，RabbitMQ就会发送一个确认（Basic.Ack)给生产者（包含消息的唯一ID)，这样生产者就知道消息到达对应的目的地了。\n\n## 23.消费者获取消息的方式？\n- 推\n- 拉\n\n## 24.消费者某些原因无法处理当前接受的消息如何来拒绝？\nchannel .basicNack channel .basicReject\n\n## 25.消息传输保证层级？\nAt most once:最多一次。消息可能会丢失，但不会重复传输。\nAt least once：最少一次。消息绝不会丢失，但可能会重复传输。\nExactly once: 恰好一次，每条消息肯定仅传输一次。\n\n## 26.了解Virtual Host吗?\n每一个RabbitMQ服务器都能创建虚拟的消息服务器，也叫虚拟主机(virtual host)，简称vhost。\n默认为“/”。\n\n## 27.集群中的节点类型？\n1. 内存节点：ram,将变更写入内存。\n2. 磁盘节点：disc,磁盘写入操作。\n3. RabbitMQ要求最少有一个磁盘节点。\n\n## 28.队列结构？\n通常由以下两部分组成：\n\n1. rabbit_amqqueue_process:负责协议相关的消息处理，即接收生产者发布的消息、向消费者交付消息、处理消息的确认(包括生产端的 confirm 和消费端的 ack) 等。\n2. backing_queue:是消息存储的具体形式和引擎，并向 rabbit amqqueue process提供相关的接口以供调用。\n\n## 29.RabbitMQ中消息可能有的几种状态?\n1. alpha: 消息内容(包括消息体、属性和 headers) 和消息索引都存储在内存中 。\n2. beta: 消息内容保存在磁盘中，消息索引保存在内存中。\n3. gamma: 消息内容保存在磁盘中，消息索引在磁盘和内存中都有 。\n4. delta: 消息内容和索引都在磁盘中 。\n\n## 30.在何种场景下使用了消息中间件？\n- 接口之间耦合比较严重\n- 面对大流量并发时，容易被冲垮\n- 存在性能问题\n\n## 31.生产者如何将消息可靠投递到MQ？\n1. Client发送消息给MQ\n2. MQ将消息持久化后，发送Ack消息给Client，此处有可能因为网络问题导致Ack消息无法发送到Client，那么Client在等待超时后，会重传消息；\n3. Client收到Ack消息后，认为消息已经投递成功。\n\n## 32 . MQ如何将消息可靠投递到消费者？\n1. MQ将消息push给Client（或Client来pull消息）\n2. Client得到消息并做完业务逻辑\n3. Client发送Ack消息给MQ，通知MQ删除该消息，此处有可能因为网络问题导致Ack失败，那么Client会重复消息，这里就引出消费幂等的问题；\n4. MQ将已消费的消息删除\n\n## 33.如何保证RabbitMQ消息队列的高可用?\nRabbitMQ 有三种模式：单机模式，普通集群模式，镜像集群模式。\n1. 单机模式：就是demo级别的，一般就是你本地启动了玩玩儿的，没人生产用单机模式\n2. 普通集群模式：意思就是在多台机器上启动多个RabbitMQ实例，每个机器启动一个。\n3. 镜像集群模式：这种模式，才是所谓的RabbitMQ的高可用模式，跟普通集群模式不一样的是，你创建的queue，无论元数据(元数据指RabbitMQ的配置数据)还是queue里的消息都会存在于多个实例上，然后每次你写消息到queue的时候，都会自动把消息到多个实例的queue里进行消息同步。\n\n## 34.如何快速处理挤压过多的消息？\n情景：消费者挂掉后再重启，这时会有很多已经挤压了的消息在MQ中，所以需要快速的处理之前已经挤压了的消息。\n解决方案：可以将原由的消费者进行修改，不再直接对数据库进行操作，只对MQ的数据进行并将处理得到的数据再发给新的partition（可以创建很多来进行过度），然后再由很多消费者进行同时的消费，并写入数据库。这是处理速度就会很快。因为第一次的消费者处理之后并不用写入数据库就可以给MQ反馈已经消费了；后续的消费者继续处理需要消费的数据并不会影响之前的消费者处理的速度。\n\n\n## 35.如果消息队列满了怎么处理？\n类似上述问题：修改消费者消费方式（不直接进行消费，转发给另外的MQ），然后再由其他消费者进行消费。\n\n\n## 36.如果让你开发消息队列中间件，如何来设计？\n1. 考虑mq的伸缩性，就是需要的时候快速扩容，就可以增加吞吐量和容量，那怎么搞？设计个分布式的系统呗，参照一下kafka的设计理念，broker -> topic -> partition，每个partition放一个机器，就存一部分数据。如果现在资源不够了，简单啊，给topic增加partition，然后做数据迁移，增加机器，这样就可以存放更多数据，提供更高的吞吐量了。\n2. 考虑mq数据要不要持久化？需要写入磁盘，这样才能保证挂了之后不会造成数据的丢失。写入时怎么进行写入磁盘？顺序写入，这样既保证了消息的顺序性，还减少了寻址的开销，达到提高性能的目的。\n3. 考虑mq的可用性？参考kafka的高可用的保障机制。多副本--》leader&follwer--》broker挂了重新选举leader即可。\n","slug":"RabbitMQ","published":1,"_id":"ckttosy8j0000y0vub3d8dbxb","comments":1,"layout":"post","photos":[],"link":"","content":"<p>这是八股文系列的第四篇文章，主要是关于RabbitMQ的面试常问问题。</p>\n<p>本文仅仅列举问题的部分常见解答，详细回答需结合官方文档和日常工作使用经验。😉</p>\n<span id=\"more\"></span>\n\n<h2 id=\"1-RabbitMQ是什么？\"><a href=\"#1-RabbitMQ是什么？\" class=\"headerlink\" title=\"1.RabbitMQ是什么？\"></a>1.RabbitMQ是什么？</h2><p>RabbitMQ是实现了高级消息队列协议（AMQP）的开源消息代理软件（亦称面向消息的中间件）。RabbitMQ服务器是用Erlang语言编写的，而群集和故障转移是构建在开放电信平台框架上的。所有主要的编程语言均有与代理接口通讯的客户端库。<br>PS:也可能直接问什么是消息队列？消息队列就是一个使用队列来通信的组件</p>\n<h2 id=\"2-RabbitMQ特点\"><a href=\"#2-RabbitMQ特点\" class=\"headerlink\" title=\"2.RabbitMQ特点?\"></a>2.RabbitMQ特点?</h2><p>可靠性: RabbitMQ使用一些机制来保证可靠性， 如持久化、传输确认及发布确认等。<br>灵活的路由 : 在消息进入队列之前，通过交换器来路由消息。对于典型的路由功能， RabbitMQ 己经提供了一些内置的交换器来实现。针对更复杂的路由功能，可以将多个 交换器绑定在一起， 也可以通过插件机制来实现自己的交换器。<br>扩展性: 多个RabbitMQ节点可以组成一个集群，也可以根据实际业务情况动态地扩展 集群中节点。<br>高可用性 : 队列可以在集群中的机器上设置镜像，使得在部分节点出现问题的情况下队 列仍然可用。<br>多种协议: RabbitMQ除了原生支持AMQP协议，还支持STOMP， MQTT等多种消息 中间件协议。<br>多语言客户端 :RabbitMQ 几乎支持所有常用语言，比如 Java、 Python、 Ruby、 PHP、 C#、 JavaScript 等。<br>管理界面 : RabbitMQ 提供了一个易用的用户界面，使得用户可以监控和管理消息、集 群中的节点等。<br>令插件机制 : RabbitMQ 提供了许多插件 ， 以实现从多方面进行扩展，当然也可以编写自 己的插件。</p>\n<h2 id=\"3-AMQP是什么\"><a href=\"#3-AMQP是什么\" class=\"headerlink\" title=\"3.AMQP是什么?\"></a>3.AMQP是什么?</h2><p>RabbitMQ就是 AMQP 协议的 Erlang 的实现(当然 RabbitMQ 还支持 STOMP2、 MQTT3 等协议 ) AMQP 的模型架构 和 RabbitMQ 的模型架构是一样的，生产者将消息发送给交换器，交换器和队列绑定 。<br>RabbitMQ 中的交换器、交换器类型、队列、绑定、路由键等都是遵循的 AMQP 协议中相 应的概念。目前 RabbitMQ 最新版本默认支持的是 AMQP 0-9-1。</p>\n<h2 id=\"4-AMQP协议3层？\"><a href=\"#4-AMQP协议3层？\" class=\"headerlink\" title=\"4.AMQP协议3层？\"></a>4.AMQP协议3层？</h2><p>Module Layer:协议最高层，主要定义了一些客户端调用的命令，客户端可以用这些命令实现自己的业务逻辑。<br>Session Layer:中间层，主要负责客户端命令发送给服务器，再将服务端应答返回客户端，提供可靠性同步机制和错误处理。<br>TransportLayer:最底层，主要传输二进制数据流，提供帧的处理、信道服用、错误检测和数据表示等。</p>\n<h2 id=\"5-AMQP模型的几大组件？\"><a href=\"#5-AMQP模型的几大组件？\" class=\"headerlink\" title=\"5.AMQP模型的几大组件？\"></a>5.AMQP模型的几大组件？</h2><ul>\n<li>交换器 (Exchange)：消息代理服务器中用于把消息路由到队列的组件。</li>\n<li>队列 (Queue)：用来存储消息的数据结构，位于硬盘或内存中。</li>\n<li>绑定 (Binding)：一套规则，告知交换器消息应该将消息投递给哪个队列。</li>\n</ul>\n<h2 id=\"6-说说生产者Producer和消费者Consumer\"><a href=\"#6-说说生产者Producer和消费者Consumer\" class=\"headerlink\" title=\"6.说说生产者Producer和消费者Consumer?\"></a>6.说说生产者Producer和消费者Consumer?</h2><p>生产者</p>\n<ul>\n<li>消息生产者，就是投递消息的一方。</li>\n<li>消息一般包含两个部分：消息体（payload)和标签(Label)。</li>\n</ul>\n<p>消费者</p>\n<ul>\n<li>消费消息，也就是接收消息的一方。</li>\n<li>消费者连接到RabbitMQ服务器，并订阅到队列上。消费消息时只消费消息体，丢弃标签。</li>\n</ul>\n<h2 id=\"7-为什么需要消息队列？\"><a href=\"#7-为什么需要消息队列？\" class=\"headerlink\" title=\"7.为什么需要消息队列？\"></a>7.为什么需要消息队列？</h2><p>从本质上来说是因为互联网的快速发展，业务不断扩张，促使技术架构需要不断的演进。<br>从以前的单体架构到现在的微服务架构，成百上千的服务之间相互调用和依赖。从互联网初期一个服务器上有 100 个在线用户已经很了不得，到现在坐拥10亿日活的微信。此时，我们需要有一个「工具」来解耦服务之间的关系、控制资源合理合时的使用以及缓冲流量洪峰等等。因此，消息队列就应运而生了。<br>它常用来实现：异步处理、服务解耦、流量控制（削峰）。</p>\n<h2 id=\"8-说说Broker服务节点、Queue队列、Exchange交换器？\"><a href=\"#8-说说Broker服务节点、Queue队列、Exchange交换器？\" class=\"headerlink\" title=\"8.说说Broker服务节点、Queue队列、Exchange交换器？\"></a>8.说说Broker服务节点、Queue队列、Exchange交换器？</h2><ul>\n<li>Broker可以看做RabbitMQ的服务节点。一般请下一个Broker可以看做一个RabbitMQ服务器。</li>\n<li>Queue:RabbitMQ的内部对象，用于存储消息。多个消费者可以订阅同一队列，这时队列中的消息会被平摊（轮询）给多个消费者进行处理。</li>\n<li>Exchange:生产者将消息发送到交换器，由交换器将消息路由到一个或者多个队列中。当路由不到时，或返回给生产者或直接丢弃。</li>\n</ul>\n<h2 id=\"9-消息队列有什么优缺点\"><a href=\"#9-消息队列有什么优缺点\" class=\"headerlink\" title=\"9.消息队列有什么优缺点\"></a>9.消息队列有什么优缺点</h2><p>优点上面已经说了，就是在特殊场景下有其对应的好处，解耦、异步、削峰。缺点有以下几个：</p>\n<ul>\n<li>系统可用性降低 系统引入的外部依赖越多，越容易挂掉。万一 MQ 挂了，MQ 一挂，整套系统崩 溃，你不就完了？</li>\n<li>系统复杂度提高 硬生生加个 MQ 进来，你怎么保证消息没有重复消费？怎么处理消息丢失的情况？</li>\n<li>怎么保证消息传递的顺序性？问题一大堆。</li>\n<li>一致性问题 A 系统处理完了直接返回成功了，人都以为你这个请求就成功了；但是问题是，要是 BCD 三个系统那里，BD 两个系统写库成功了，结果 C 系统写库失败了，咋整？你这数据就不一致 了。</li>\n</ul>\n<h2 id=\"10-如何保证消息的可靠性？\"><a href=\"#10-如何保证消息的可靠性？\" class=\"headerlink\" title=\"10.如何保证消息的可靠性？\"></a>10.如何保证消息的可靠性？</h2><p>消息到MQ的过程中搞丢，MQ自己搞丢，MQ到消费过程中搞丢。<br>生产者到RabbitMQ：事务机制和Confirm机制，注意：事务机制和 Confirm 机制是互斥的，两者不能共存，会导致 RabbitMQ 报错。<br>RabbitMQ自身：持久化、集群、普通模式、镜像模式。<br>RabbitMQ到消费者：basicAck机制、死信队列、消息补偿机制。</p>\n<h2 id=\"11-什么是RoutingKey路由键？\"><a href=\"#11-什么是RoutingKey路由键？\" class=\"headerlink\" title=\"11.什么是RoutingKey路由键？\"></a>11.什么是RoutingKey路由键？</h2><p>生产者将消息发送给交换器的时候，会指定一个RoutingKey,用来指定这个消息的路由规则，这个RoutingKey需要与交换器类型和绑定键(BindingKey)联合使用才能最终生效。</p>\n<h2 id=\"12-Binding绑定？\"><a href=\"#12-Binding绑定？\" class=\"headerlink\" title=\"12.Binding绑定？\"></a>12.Binding绑定？</h2><p>通过绑定将交换器和队列关联起来，一般会指定一个BindingKey,这样RabbitMq就知道如何正确路由消息到队列了。</p>\n<h2 id=\"13-交换器4种类型？\"><a href=\"#13-交换器4种类型？\" class=\"headerlink\" title=\"13.交换器4种类型？\"></a>13.交换器4种类型？</h2><p>主要有以下4种。</p>\n<ul>\n<li>fanout:把所有发送到该交换器的消息路由到所有与该交换器绑定的队列中。</li>\n<li>direct:把消息路由到BindingKey和RoutingKey完全匹配的队列中。</li>\n<li>topic:</li>\n<li>匹配规则： <ul>\n<li>RoutingKey：为一个 点号’.’: 分隔的字符串。比如: java.xiaoka.show </li>\n<li>BindingKey：和RoutingKey一样也是点号“.“分隔的字符串。BindingKey可使用 * 和 # 用于做模糊匹配，*匹配一个单词，#匹配多个或者0个 </li>\n<li>headers：不依赖路由键匹配规则路由消息。是根据发送消息内容中的headers属性进行匹配。性能差，基本用不到。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"14-生产者消息运转？\"><a href=\"#14-生产者消息运转？\" class=\"headerlink\" title=\"14.生产者消息运转？\"></a>14.生产者消息运转？</h2><ol>\n<li>Producer先连接到Broker,建立连接Connection,开启一个信道(Channel)。</li>\n<li>Producer声明一个交换器并设置好相关属性。</li>\n<li>Producer声明一个队列并设置好相关属性。</li>\n<li>Producer通过路由键将交换器和队列绑定起来。</li>\n<li>Producer发送消息到Broker,其中包含路由键、交换器等信息。</li>\n<li>相应的交换器根据接收到的路由键查找匹配的队列。</li>\n<li>如果找到，将消息存入对应的队列，如果没有找到，会根据生产者的配置丢弃或者退回给生产者。</li>\n<li>关闭信道。</li>\n<li>管理连接。</li>\n</ol>\n<h2 id=\"15-消费者接收消息过程？\"><a href=\"#15-消费者接收消息过程？\" class=\"headerlink\" title=\"15.消费者接收消息过程？\"></a>15.消费者接收消息过程？</h2><ol>\n<li>Producer先连接到Broker,建立连接Connection,开启一个信道(Channel)。</li>\n<li>向Broker请求消费响应的队列中消息，可能会设置响应的回调函数。</li>\n<li>等待Broker回应并投递相应队列中的消息，接收消息。</li>\n<li>消费者确认收到的消息,ack。</li>\n<li>RabbitMq从队列中删除已经确定的消息。</li>\n<li>关闭信道。</li>\n<li>关闭连接。</li>\n</ol>\n<h2 id=\"16-交换器无法根据自身类型和路由键找到符合条件队列时，有哪些处理？\"><a href=\"#16-交换器无法根据自身类型和路由键找到符合条件队列时，有哪些处理？\" class=\"headerlink\" title=\"16.交换器无法根据自身类型和路由键找到符合条件队列时，有哪些处理？\"></a>16.交换器无法根据自身类型和路由键找到符合条件队列时，有哪些处理？</h2><ul>\n<li>mandatory：true 返回消息给生产者。</li>\n<li>mandatory: false 直接丢弃。</li>\n</ul>\n<h2 id=\"17-死信队列？\"><a href=\"#17-死信队列？\" class=\"headerlink\" title=\"17.死信队列？\"></a>17.死信队列？</h2><p>DLX，全称为 Dead-Letter-Exchange，死信交换器，死信邮箱。当消息在一个队列中变成死信 (dead message) 之后，它能被重新被发送到另一个交换器中，这个交换器就是 DLX，绑定 DLX 的队列就称之为死信队列。</p>\n<h2 id=\"18-导致的死信的几种原因？\"><a href=\"#18-导致的死信的几种原因？\" class=\"headerlink\" title=\"18.导致的死信的几种原因？\"></a>18.导致的死信的几种原因？</h2><ul>\n<li>消息被拒（Basic.Reject /Basic.Nack) 且 requeue = false。</li>\n<li>消息TTL过期。</li>\n<li>队列满了，无法再添加。</li>\n</ul>\n<h2 id=\"19-延迟队列？\"><a href=\"#19-延迟队列？\" class=\"headerlink\" title=\"19.延迟队列？\"></a>19.延迟队列？</h2><p>存储对应的延迟消息，指当消息被发送以后，并不想让消费者立刻拿到消息，而是等待特定时间后，消费者才能拿到这个消息进行消费。</p>\n<h2 id=\"20-优先级队列？\"><a href=\"#20-优先级队列？\" class=\"headerlink\" title=\"20.优先级队列？\"></a>20.优先级队列？</h2><ul>\n<li>优先级高的队列会先被消费。</li>\n<li>可以通过x-max-priority参数来实现。</li>\n<li>当消费速度大于生产速度且Broker没有堆积的情况下，优先级显得没有意义。</li>\n</ul>\n<h2 id=\"21-事务机制？\"><a href=\"#21-事务机制？\" class=\"headerlink\" title=\"21.事务机制？\"></a>21.事务机制？</h2><p>RabbitMQ 客户端中与事务机制相关的方法有三个:</p>\n<ol>\n<li>channel.txSelect 用于将当前的信道设置成事务模式。</li>\n<li>channel . txCommit 用于提交事务 。</li>\n<li>channel . txRollback 用于事务回滚,如果在事务提交执行之前由于 RabbitMQ 异常崩溃或者其他原因抛出异常,通过txRollback来回滚。</li>\n</ol>\n<h2 id=\"22-发送确认机制？\"><a href=\"#22-发送确认机制？\" class=\"headerlink\" title=\"22.发送确认机制？\"></a>22.发送确认机制？</h2><p>生产者把信道设置为confirm确认模式,设置后，所有再改信道发布的消息都会被指定一个唯一的ID，一旦消息被投递到所有匹配的队列之后，RabbitMQ就会发送一个确认（Basic.Ack)给生产者（包含消息的唯一ID)，这样生产者就知道消息到达对应的目的地了。</p>\n<h2 id=\"23-消费者获取消息的方式？\"><a href=\"#23-消费者获取消息的方式？\" class=\"headerlink\" title=\"23.消费者获取消息的方式？\"></a>23.消费者获取消息的方式？</h2><ul>\n<li>推</li>\n<li>拉</li>\n</ul>\n<h2 id=\"24-消费者某些原因无法处理当前接受的消息如何来拒绝？\"><a href=\"#24-消费者某些原因无法处理当前接受的消息如何来拒绝？\" class=\"headerlink\" title=\"24.消费者某些原因无法处理当前接受的消息如何来拒绝？\"></a>24.消费者某些原因无法处理当前接受的消息如何来拒绝？</h2><p>channel .basicNack channel .basicReject</p>\n<h2 id=\"25-消息传输保证层级？\"><a href=\"#25-消息传输保证层级？\" class=\"headerlink\" title=\"25.消息传输保证层级？\"></a>25.消息传输保证层级？</h2><p>At most once:最多一次。消息可能会丢失，但不会重复传输。<br>At least once：最少一次。消息绝不会丢失，但可能会重复传输。<br>Exactly once: 恰好一次，每条消息肯定仅传输一次。</p>\n<h2 id=\"26-了解Virtual-Host吗\"><a href=\"#26-了解Virtual-Host吗\" class=\"headerlink\" title=\"26.了解Virtual Host吗?\"></a>26.了解Virtual Host吗?</h2><p>每一个RabbitMQ服务器都能创建虚拟的消息服务器，也叫虚拟主机(virtual host)，简称vhost。<br>默认为“/”。</p>\n<h2 id=\"27-集群中的节点类型？\"><a href=\"#27-集群中的节点类型？\" class=\"headerlink\" title=\"27.集群中的节点类型？\"></a>27.集群中的节点类型？</h2><ol>\n<li>内存节点：ram,将变更写入内存。</li>\n<li>磁盘节点：disc,磁盘写入操作。</li>\n<li>RabbitMQ要求最少有一个磁盘节点。</li>\n</ol>\n<h2 id=\"28-队列结构？\"><a href=\"#28-队列结构？\" class=\"headerlink\" title=\"28.队列结构？\"></a>28.队列结构？</h2><p>通常由以下两部分组成：</p>\n<ol>\n<li>rabbit_amqqueue_process:负责协议相关的消息处理，即接收生产者发布的消息、向消费者交付消息、处理消息的确认(包括生产端的 confirm 和消费端的 ack) 等。</li>\n<li>backing_queue:是消息存储的具体形式和引擎，并向 rabbit amqqueue process提供相关的接口以供调用。</li>\n</ol>\n<h2 id=\"29-RabbitMQ中消息可能有的几种状态\"><a href=\"#29-RabbitMQ中消息可能有的几种状态\" class=\"headerlink\" title=\"29.RabbitMQ中消息可能有的几种状态?\"></a>29.RabbitMQ中消息可能有的几种状态?</h2><ol>\n<li>alpha: 消息内容(包括消息体、属性和 headers) 和消息索引都存储在内存中 。</li>\n<li>beta: 消息内容保存在磁盘中，消息索引保存在内存中。</li>\n<li>gamma: 消息内容保存在磁盘中，消息索引在磁盘和内存中都有 。</li>\n<li>delta: 消息内容和索引都在磁盘中 。</li>\n</ol>\n<h2 id=\"30-在何种场景下使用了消息中间件？\"><a href=\"#30-在何种场景下使用了消息中间件？\" class=\"headerlink\" title=\"30.在何种场景下使用了消息中间件？\"></a>30.在何种场景下使用了消息中间件？</h2><ul>\n<li>接口之间耦合比较严重</li>\n<li>面对大流量并发时，容易被冲垮</li>\n<li>存在性能问题</li>\n</ul>\n<h2 id=\"31-生产者如何将消息可靠投递到MQ？\"><a href=\"#31-生产者如何将消息可靠投递到MQ？\" class=\"headerlink\" title=\"31.生产者如何将消息可靠投递到MQ？\"></a>31.生产者如何将消息可靠投递到MQ？</h2><ol>\n<li>Client发送消息给MQ</li>\n<li>MQ将消息持久化后，发送Ack消息给Client，此处有可能因为网络问题导致Ack消息无法发送到Client，那么Client在等待超时后，会重传消息；</li>\n<li>Client收到Ack消息后，认为消息已经投递成功。</li>\n</ol>\n<h2 id=\"32-MQ如何将消息可靠投递到消费者？\"><a href=\"#32-MQ如何将消息可靠投递到消费者？\" class=\"headerlink\" title=\"32 . MQ如何将消息可靠投递到消费者？\"></a>32 . MQ如何将消息可靠投递到消费者？</h2><ol>\n<li>MQ将消息push给Client（或Client来pull消息）</li>\n<li>Client得到消息并做完业务逻辑</li>\n<li>Client发送Ack消息给MQ，通知MQ删除该消息，此处有可能因为网络问题导致Ack失败，那么Client会重复消息，这里就引出消费幂等的问题；</li>\n<li>MQ将已消费的消息删除</li>\n</ol>\n<h2 id=\"33-如何保证RabbitMQ消息队列的高可用\"><a href=\"#33-如何保证RabbitMQ消息队列的高可用\" class=\"headerlink\" title=\"33.如何保证RabbitMQ消息队列的高可用?\"></a>33.如何保证RabbitMQ消息队列的高可用?</h2><p>RabbitMQ 有三种模式：单机模式，普通集群模式，镜像集群模式。</p>\n<ol>\n<li>单机模式：就是demo级别的，一般就是你本地启动了玩玩儿的，没人生产用单机模式</li>\n<li>普通集群模式：意思就是在多台机器上启动多个RabbitMQ实例，每个机器启动一个。</li>\n<li>镜像集群模式：这种模式，才是所谓的RabbitMQ的高可用模式，跟普通集群模式不一样的是，你创建的queue，无论元数据(元数据指RabbitMQ的配置数据)还是queue里的消息都会存在于多个实例上，然后每次你写消息到queue的时候，都会自动把消息到多个实例的queue里进行消息同步。</li>\n</ol>\n<h2 id=\"34-如何快速处理挤压过多的消息？\"><a href=\"#34-如何快速处理挤压过多的消息？\" class=\"headerlink\" title=\"34.如何快速处理挤压过多的消息？\"></a>34.如何快速处理挤压过多的消息？</h2><p>情景：消费者挂掉后再重启，这时会有很多已经挤压了的消息在MQ中，所以需要快速的处理之前已经挤压了的消息。<br>解决方案：可以将原由的消费者进行修改，不再直接对数据库进行操作，只对MQ的数据进行并将处理得到的数据再发给新的partition（可以创建很多来进行过度），然后再由很多消费者进行同时的消费，并写入数据库。这是处理速度就会很快。因为第一次的消费者处理之后并不用写入数据库就可以给MQ反馈已经消费了；后续的消费者继续处理需要消费的数据并不会影响之前的消费者处理的速度。</p>\n<h2 id=\"35-如果消息队列满了怎么处理？\"><a href=\"#35-如果消息队列满了怎么处理？\" class=\"headerlink\" title=\"35.如果消息队列满了怎么处理？\"></a>35.如果消息队列满了怎么处理？</h2><p>类似上述问题：修改消费者消费方式（不直接进行消费，转发给另外的MQ），然后再由其他消费者进行消费。</p>\n<h2 id=\"36-如果让你开发消息队列中间件，如何来设计？\"><a href=\"#36-如果让你开发消息队列中间件，如何来设计？\" class=\"headerlink\" title=\"36.如果让你开发消息队列中间件，如何来设计？\"></a>36.如果让你开发消息队列中间件，如何来设计？</h2><ol>\n<li>考虑mq的伸缩性，就是需要的时候快速扩容，就可以增加吞吐量和容量，那怎么搞？设计个分布式的系统呗，参照一下kafka的设计理念，broker -&gt; topic -&gt; partition，每个partition放一个机器，就存一部分数据。如果现在资源不够了，简单啊，给topic增加partition，然后做数据迁移，增加机器，这样就可以存放更多数据，提供更高的吞吐量了。</li>\n<li>考虑mq数据要不要持久化？需要写入磁盘，这样才能保证挂了之后不会造成数据的丢失。写入时怎么进行写入磁盘？顺序写入，这样既保证了消息的顺序性，还减少了寻址的开销，达到提高性能的目的。</li>\n<li>考虑mq的可用性？参考kafka的高可用的保障机制。多副本–》leader&amp;follwer–》broker挂了重新选举leader即可。</li>\n</ol>\n","site":{"data":{}},"length":5777,"excerpt":"<p>这是八股文系列的第四篇文章，主要是关于RabbitMQ的面试常问问题。</p>\n<p>本文仅仅列举问题的部分常见解答，详细回答需结合官方文档和日常工作使用经验。😉</p>","more":"<h2 id=\"1-RabbitMQ是什么？\"><a href=\"#1-RabbitMQ是什么？\" class=\"headerlink\" title=\"1.RabbitMQ是什么？\"></a>1.RabbitMQ是什么？</h2><p>RabbitMQ是实现了高级消息队列协议（AMQP）的开源消息代理软件（亦称面向消息的中间件）。RabbitMQ服务器是用Erlang语言编写的，而群集和故障转移是构建在开放电信平台框架上的。所有主要的编程语言均有与代理接口通讯的客户端库。<br>PS:也可能直接问什么是消息队列？消息队列就是一个使用队列来通信的组件</p>\n<h2 id=\"2-RabbitMQ特点\"><a href=\"#2-RabbitMQ特点\" class=\"headerlink\" title=\"2.RabbitMQ特点?\"></a>2.RabbitMQ特点?</h2><p>可靠性: RabbitMQ使用一些机制来保证可靠性， 如持久化、传输确认及发布确认等。<br>灵活的路由 : 在消息进入队列之前，通过交换器来路由消息。对于典型的路由功能， RabbitMQ 己经提供了一些内置的交换器来实现。针对更复杂的路由功能，可以将多个 交换器绑定在一起， 也可以通过插件机制来实现自己的交换器。<br>扩展性: 多个RabbitMQ节点可以组成一个集群，也可以根据实际业务情况动态地扩展 集群中节点。<br>高可用性 : 队列可以在集群中的机器上设置镜像，使得在部分节点出现问题的情况下队 列仍然可用。<br>多种协议: RabbitMQ除了原生支持AMQP协议，还支持STOMP， MQTT等多种消息 中间件协议。<br>多语言客户端 :RabbitMQ 几乎支持所有常用语言，比如 Java、 Python、 Ruby、 PHP、 C#、 JavaScript 等。<br>管理界面 : RabbitMQ 提供了一个易用的用户界面，使得用户可以监控和管理消息、集 群中的节点等。<br>令插件机制 : RabbitMQ 提供了许多插件 ， 以实现从多方面进行扩展，当然也可以编写自 己的插件。</p>\n<h2 id=\"3-AMQP是什么\"><a href=\"#3-AMQP是什么\" class=\"headerlink\" title=\"3.AMQP是什么?\"></a>3.AMQP是什么?</h2><p>RabbitMQ就是 AMQP 协议的 Erlang 的实现(当然 RabbitMQ 还支持 STOMP2、 MQTT3 等协议 ) AMQP 的模型架构 和 RabbitMQ 的模型架构是一样的，生产者将消息发送给交换器，交换器和队列绑定 。<br>RabbitMQ 中的交换器、交换器类型、队列、绑定、路由键等都是遵循的 AMQP 协议中相 应的概念。目前 RabbitMQ 最新版本默认支持的是 AMQP 0-9-1。</p>\n<h2 id=\"4-AMQP协议3层？\"><a href=\"#4-AMQP协议3层？\" class=\"headerlink\" title=\"4.AMQP协议3层？\"></a>4.AMQP协议3层？</h2><p>Module Layer:协议最高层，主要定义了一些客户端调用的命令，客户端可以用这些命令实现自己的业务逻辑。<br>Session Layer:中间层，主要负责客户端命令发送给服务器，再将服务端应答返回客户端，提供可靠性同步机制和错误处理。<br>TransportLayer:最底层，主要传输二进制数据流，提供帧的处理、信道服用、错误检测和数据表示等。</p>\n<h2 id=\"5-AMQP模型的几大组件？\"><a href=\"#5-AMQP模型的几大组件？\" class=\"headerlink\" title=\"5.AMQP模型的几大组件？\"></a>5.AMQP模型的几大组件？</h2><ul>\n<li>交换器 (Exchange)：消息代理服务器中用于把消息路由到队列的组件。</li>\n<li>队列 (Queue)：用来存储消息的数据结构，位于硬盘或内存中。</li>\n<li>绑定 (Binding)：一套规则，告知交换器消息应该将消息投递给哪个队列。</li>\n</ul>\n<h2 id=\"6-说说生产者Producer和消费者Consumer\"><a href=\"#6-说说生产者Producer和消费者Consumer\" class=\"headerlink\" title=\"6.说说生产者Producer和消费者Consumer?\"></a>6.说说生产者Producer和消费者Consumer?</h2><p>生产者</p>\n<ul>\n<li>消息生产者，就是投递消息的一方。</li>\n<li>消息一般包含两个部分：消息体（payload)和标签(Label)。</li>\n</ul>\n<p>消费者</p>\n<ul>\n<li>消费消息，也就是接收消息的一方。</li>\n<li>消费者连接到RabbitMQ服务器，并订阅到队列上。消费消息时只消费消息体，丢弃标签。</li>\n</ul>\n<h2 id=\"7-为什么需要消息队列？\"><a href=\"#7-为什么需要消息队列？\" class=\"headerlink\" title=\"7.为什么需要消息队列？\"></a>7.为什么需要消息队列？</h2><p>从本质上来说是因为互联网的快速发展，业务不断扩张，促使技术架构需要不断的演进。<br>从以前的单体架构到现在的微服务架构，成百上千的服务之间相互调用和依赖。从互联网初期一个服务器上有 100 个在线用户已经很了不得，到现在坐拥10亿日活的微信。此时，我们需要有一个「工具」来解耦服务之间的关系、控制资源合理合时的使用以及缓冲流量洪峰等等。因此，消息队列就应运而生了。<br>它常用来实现：异步处理、服务解耦、流量控制（削峰）。</p>\n<h2 id=\"8-说说Broker服务节点、Queue队列、Exchange交换器？\"><a href=\"#8-说说Broker服务节点、Queue队列、Exchange交换器？\" class=\"headerlink\" title=\"8.说说Broker服务节点、Queue队列、Exchange交换器？\"></a>8.说说Broker服务节点、Queue队列、Exchange交换器？</h2><ul>\n<li>Broker可以看做RabbitMQ的服务节点。一般请下一个Broker可以看做一个RabbitMQ服务器。</li>\n<li>Queue:RabbitMQ的内部对象，用于存储消息。多个消费者可以订阅同一队列，这时队列中的消息会被平摊（轮询）给多个消费者进行处理。</li>\n<li>Exchange:生产者将消息发送到交换器，由交换器将消息路由到一个或者多个队列中。当路由不到时，或返回给生产者或直接丢弃。</li>\n</ul>\n<h2 id=\"9-消息队列有什么优缺点\"><a href=\"#9-消息队列有什么优缺点\" class=\"headerlink\" title=\"9.消息队列有什么优缺点\"></a>9.消息队列有什么优缺点</h2><p>优点上面已经说了，就是在特殊场景下有其对应的好处，解耦、异步、削峰。缺点有以下几个：</p>\n<ul>\n<li>系统可用性降低 系统引入的外部依赖越多，越容易挂掉。万一 MQ 挂了，MQ 一挂，整套系统崩 溃，你不就完了？</li>\n<li>系统复杂度提高 硬生生加个 MQ 进来，你怎么保证消息没有重复消费？怎么处理消息丢失的情况？</li>\n<li>怎么保证消息传递的顺序性？问题一大堆。</li>\n<li>一致性问题 A 系统处理完了直接返回成功了，人都以为你这个请求就成功了；但是问题是，要是 BCD 三个系统那里，BD 两个系统写库成功了，结果 C 系统写库失败了，咋整？你这数据就不一致 了。</li>\n</ul>\n<h2 id=\"10-如何保证消息的可靠性？\"><a href=\"#10-如何保证消息的可靠性？\" class=\"headerlink\" title=\"10.如何保证消息的可靠性？\"></a>10.如何保证消息的可靠性？</h2><p>消息到MQ的过程中搞丢，MQ自己搞丢，MQ到消费过程中搞丢。<br>生产者到RabbitMQ：事务机制和Confirm机制，注意：事务机制和 Confirm 机制是互斥的，两者不能共存，会导致 RabbitMQ 报错。<br>RabbitMQ自身：持久化、集群、普通模式、镜像模式。<br>RabbitMQ到消费者：basicAck机制、死信队列、消息补偿机制。</p>\n<h2 id=\"11-什么是RoutingKey路由键？\"><a href=\"#11-什么是RoutingKey路由键？\" class=\"headerlink\" title=\"11.什么是RoutingKey路由键？\"></a>11.什么是RoutingKey路由键？</h2><p>生产者将消息发送给交换器的时候，会指定一个RoutingKey,用来指定这个消息的路由规则，这个RoutingKey需要与交换器类型和绑定键(BindingKey)联合使用才能最终生效。</p>\n<h2 id=\"12-Binding绑定？\"><a href=\"#12-Binding绑定？\" class=\"headerlink\" title=\"12.Binding绑定？\"></a>12.Binding绑定？</h2><p>通过绑定将交换器和队列关联起来，一般会指定一个BindingKey,这样RabbitMq就知道如何正确路由消息到队列了。</p>\n<h2 id=\"13-交换器4种类型？\"><a href=\"#13-交换器4种类型？\" class=\"headerlink\" title=\"13.交换器4种类型？\"></a>13.交换器4种类型？</h2><p>主要有以下4种。</p>\n<ul>\n<li>fanout:把所有发送到该交换器的消息路由到所有与该交换器绑定的队列中。</li>\n<li>direct:把消息路由到BindingKey和RoutingKey完全匹配的队列中。</li>\n<li>topic:</li>\n<li>匹配规则： <ul>\n<li>RoutingKey：为一个 点号’.’: 分隔的字符串。比如: java.xiaoka.show </li>\n<li>BindingKey：和RoutingKey一样也是点号“.“分隔的字符串。BindingKey可使用 * 和 # 用于做模糊匹配，*匹配一个单词，#匹配多个或者0个 </li>\n<li>headers：不依赖路由键匹配规则路由消息。是根据发送消息内容中的headers属性进行匹配。性能差，基本用不到。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"14-生产者消息运转？\"><a href=\"#14-生产者消息运转？\" class=\"headerlink\" title=\"14.生产者消息运转？\"></a>14.生产者消息运转？</h2><ol>\n<li>Producer先连接到Broker,建立连接Connection,开启一个信道(Channel)。</li>\n<li>Producer声明一个交换器并设置好相关属性。</li>\n<li>Producer声明一个队列并设置好相关属性。</li>\n<li>Producer通过路由键将交换器和队列绑定起来。</li>\n<li>Producer发送消息到Broker,其中包含路由键、交换器等信息。</li>\n<li>相应的交换器根据接收到的路由键查找匹配的队列。</li>\n<li>如果找到，将消息存入对应的队列，如果没有找到，会根据生产者的配置丢弃或者退回给生产者。</li>\n<li>关闭信道。</li>\n<li>管理连接。</li>\n</ol>\n<h2 id=\"15-消费者接收消息过程？\"><a href=\"#15-消费者接收消息过程？\" class=\"headerlink\" title=\"15.消费者接收消息过程？\"></a>15.消费者接收消息过程？</h2><ol>\n<li>Producer先连接到Broker,建立连接Connection,开启一个信道(Channel)。</li>\n<li>向Broker请求消费响应的队列中消息，可能会设置响应的回调函数。</li>\n<li>等待Broker回应并投递相应队列中的消息，接收消息。</li>\n<li>消费者确认收到的消息,ack。</li>\n<li>RabbitMq从队列中删除已经确定的消息。</li>\n<li>关闭信道。</li>\n<li>关闭连接。</li>\n</ol>\n<h2 id=\"16-交换器无法根据自身类型和路由键找到符合条件队列时，有哪些处理？\"><a href=\"#16-交换器无法根据自身类型和路由键找到符合条件队列时，有哪些处理？\" class=\"headerlink\" title=\"16.交换器无法根据自身类型和路由键找到符合条件队列时，有哪些处理？\"></a>16.交换器无法根据自身类型和路由键找到符合条件队列时，有哪些处理？</h2><ul>\n<li>mandatory：true 返回消息给生产者。</li>\n<li>mandatory: false 直接丢弃。</li>\n</ul>\n<h2 id=\"17-死信队列？\"><a href=\"#17-死信队列？\" class=\"headerlink\" title=\"17.死信队列？\"></a>17.死信队列？</h2><p>DLX，全称为 Dead-Letter-Exchange，死信交换器，死信邮箱。当消息在一个队列中变成死信 (dead message) 之后，它能被重新被发送到另一个交换器中，这个交换器就是 DLX，绑定 DLX 的队列就称之为死信队列。</p>\n<h2 id=\"18-导致的死信的几种原因？\"><a href=\"#18-导致的死信的几种原因？\" class=\"headerlink\" title=\"18.导致的死信的几种原因？\"></a>18.导致的死信的几种原因？</h2><ul>\n<li>消息被拒（Basic.Reject /Basic.Nack) 且 requeue = false。</li>\n<li>消息TTL过期。</li>\n<li>队列满了，无法再添加。</li>\n</ul>\n<h2 id=\"19-延迟队列？\"><a href=\"#19-延迟队列？\" class=\"headerlink\" title=\"19.延迟队列？\"></a>19.延迟队列？</h2><p>存储对应的延迟消息，指当消息被发送以后，并不想让消费者立刻拿到消息，而是等待特定时间后，消费者才能拿到这个消息进行消费。</p>\n<h2 id=\"20-优先级队列？\"><a href=\"#20-优先级队列？\" class=\"headerlink\" title=\"20.优先级队列？\"></a>20.优先级队列？</h2><ul>\n<li>优先级高的队列会先被消费。</li>\n<li>可以通过x-max-priority参数来实现。</li>\n<li>当消费速度大于生产速度且Broker没有堆积的情况下，优先级显得没有意义。</li>\n</ul>\n<h2 id=\"21-事务机制？\"><a href=\"#21-事务机制？\" class=\"headerlink\" title=\"21.事务机制？\"></a>21.事务机制？</h2><p>RabbitMQ 客户端中与事务机制相关的方法有三个:</p>\n<ol>\n<li>channel.txSelect 用于将当前的信道设置成事务模式。</li>\n<li>channel . txCommit 用于提交事务 。</li>\n<li>channel . txRollback 用于事务回滚,如果在事务提交执行之前由于 RabbitMQ 异常崩溃或者其他原因抛出异常,通过txRollback来回滚。</li>\n</ol>\n<h2 id=\"22-发送确认机制？\"><a href=\"#22-发送确认机制？\" class=\"headerlink\" title=\"22.发送确认机制？\"></a>22.发送确认机制？</h2><p>生产者把信道设置为confirm确认模式,设置后，所有再改信道发布的消息都会被指定一个唯一的ID，一旦消息被投递到所有匹配的队列之后，RabbitMQ就会发送一个确认（Basic.Ack)给生产者（包含消息的唯一ID)，这样生产者就知道消息到达对应的目的地了。</p>\n<h2 id=\"23-消费者获取消息的方式？\"><a href=\"#23-消费者获取消息的方式？\" class=\"headerlink\" title=\"23.消费者获取消息的方式？\"></a>23.消费者获取消息的方式？</h2><ul>\n<li>推</li>\n<li>拉</li>\n</ul>\n<h2 id=\"24-消费者某些原因无法处理当前接受的消息如何来拒绝？\"><a href=\"#24-消费者某些原因无法处理当前接受的消息如何来拒绝？\" class=\"headerlink\" title=\"24.消费者某些原因无法处理当前接受的消息如何来拒绝？\"></a>24.消费者某些原因无法处理当前接受的消息如何来拒绝？</h2><p>channel .basicNack channel .basicReject</p>\n<h2 id=\"25-消息传输保证层级？\"><a href=\"#25-消息传输保证层级？\" class=\"headerlink\" title=\"25.消息传输保证层级？\"></a>25.消息传输保证层级？</h2><p>At most once:最多一次。消息可能会丢失，但不会重复传输。<br>At least once：最少一次。消息绝不会丢失，但可能会重复传输。<br>Exactly once: 恰好一次，每条消息肯定仅传输一次。</p>\n<h2 id=\"26-了解Virtual-Host吗\"><a href=\"#26-了解Virtual-Host吗\" class=\"headerlink\" title=\"26.了解Virtual Host吗?\"></a>26.了解Virtual Host吗?</h2><p>每一个RabbitMQ服务器都能创建虚拟的消息服务器，也叫虚拟主机(virtual host)，简称vhost。<br>默认为“/”。</p>\n<h2 id=\"27-集群中的节点类型？\"><a href=\"#27-集群中的节点类型？\" class=\"headerlink\" title=\"27.集群中的节点类型？\"></a>27.集群中的节点类型？</h2><ol>\n<li>内存节点：ram,将变更写入内存。</li>\n<li>磁盘节点：disc,磁盘写入操作。</li>\n<li>RabbitMQ要求最少有一个磁盘节点。</li>\n</ol>\n<h2 id=\"28-队列结构？\"><a href=\"#28-队列结构？\" class=\"headerlink\" title=\"28.队列结构？\"></a>28.队列结构？</h2><p>通常由以下两部分组成：</p>\n<ol>\n<li>rabbit_amqqueue_process:负责协议相关的消息处理，即接收生产者发布的消息、向消费者交付消息、处理消息的确认(包括生产端的 confirm 和消费端的 ack) 等。</li>\n<li>backing_queue:是消息存储的具体形式和引擎，并向 rabbit amqqueue process提供相关的接口以供调用。</li>\n</ol>\n<h2 id=\"29-RabbitMQ中消息可能有的几种状态\"><a href=\"#29-RabbitMQ中消息可能有的几种状态\" class=\"headerlink\" title=\"29.RabbitMQ中消息可能有的几种状态?\"></a>29.RabbitMQ中消息可能有的几种状态?</h2><ol>\n<li>alpha: 消息内容(包括消息体、属性和 headers) 和消息索引都存储在内存中 。</li>\n<li>beta: 消息内容保存在磁盘中，消息索引保存在内存中。</li>\n<li>gamma: 消息内容保存在磁盘中，消息索引在磁盘和内存中都有 。</li>\n<li>delta: 消息内容和索引都在磁盘中 。</li>\n</ol>\n<h2 id=\"30-在何种场景下使用了消息中间件？\"><a href=\"#30-在何种场景下使用了消息中间件？\" class=\"headerlink\" title=\"30.在何种场景下使用了消息中间件？\"></a>30.在何种场景下使用了消息中间件？</h2><ul>\n<li>接口之间耦合比较严重</li>\n<li>面对大流量并发时，容易被冲垮</li>\n<li>存在性能问题</li>\n</ul>\n<h2 id=\"31-生产者如何将消息可靠投递到MQ？\"><a href=\"#31-生产者如何将消息可靠投递到MQ？\" class=\"headerlink\" title=\"31.生产者如何将消息可靠投递到MQ？\"></a>31.生产者如何将消息可靠投递到MQ？</h2><ol>\n<li>Client发送消息给MQ</li>\n<li>MQ将消息持久化后，发送Ack消息给Client，此处有可能因为网络问题导致Ack消息无法发送到Client，那么Client在等待超时后，会重传消息；</li>\n<li>Client收到Ack消息后，认为消息已经投递成功。</li>\n</ol>\n<h2 id=\"32-MQ如何将消息可靠投递到消费者？\"><a href=\"#32-MQ如何将消息可靠投递到消费者？\" class=\"headerlink\" title=\"32 . MQ如何将消息可靠投递到消费者？\"></a>32 . MQ如何将消息可靠投递到消费者？</h2><ol>\n<li>MQ将消息push给Client（或Client来pull消息）</li>\n<li>Client得到消息并做完业务逻辑</li>\n<li>Client发送Ack消息给MQ，通知MQ删除该消息，此处有可能因为网络问题导致Ack失败，那么Client会重复消息，这里就引出消费幂等的问题；</li>\n<li>MQ将已消费的消息删除</li>\n</ol>\n<h2 id=\"33-如何保证RabbitMQ消息队列的高可用\"><a href=\"#33-如何保证RabbitMQ消息队列的高可用\" class=\"headerlink\" title=\"33.如何保证RabbitMQ消息队列的高可用?\"></a>33.如何保证RabbitMQ消息队列的高可用?</h2><p>RabbitMQ 有三种模式：单机模式，普通集群模式，镜像集群模式。</p>\n<ol>\n<li>单机模式：就是demo级别的，一般就是你本地启动了玩玩儿的，没人生产用单机模式</li>\n<li>普通集群模式：意思就是在多台机器上启动多个RabbitMQ实例，每个机器启动一个。</li>\n<li>镜像集群模式：这种模式，才是所谓的RabbitMQ的高可用模式，跟普通集群模式不一样的是，你创建的queue，无论元数据(元数据指RabbitMQ的配置数据)还是queue里的消息都会存在于多个实例上，然后每次你写消息到queue的时候，都会自动把消息到多个实例的queue里进行消息同步。</li>\n</ol>\n<h2 id=\"34-如何快速处理挤压过多的消息？\"><a href=\"#34-如何快速处理挤压过多的消息？\" class=\"headerlink\" title=\"34.如何快速处理挤压过多的消息？\"></a>34.如何快速处理挤压过多的消息？</h2><p>情景：消费者挂掉后再重启，这时会有很多已经挤压了的消息在MQ中，所以需要快速的处理之前已经挤压了的消息。<br>解决方案：可以将原由的消费者进行修改，不再直接对数据库进行操作，只对MQ的数据进行并将处理得到的数据再发给新的partition（可以创建很多来进行过度），然后再由很多消费者进行同时的消费，并写入数据库。这是处理速度就会很快。因为第一次的消费者处理之后并不用写入数据库就可以给MQ反馈已经消费了；后续的消费者继续处理需要消费的数据并不会影响之前的消费者处理的速度。</p>\n<h2 id=\"35-如果消息队列满了怎么处理？\"><a href=\"#35-如果消息队列满了怎么处理？\" class=\"headerlink\" title=\"35.如果消息队列满了怎么处理？\"></a>35.如果消息队列满了怎么处理？</h2><p>类似上述问题：修改消费者消费方式（不直接进行消费，转发给另外的MQ），然后再由其他消费者进行消费。</p>\n<h2 id=\"36-如果让你开发消息队列中间件，如何来设计？\"><a href=\"#36-如果让你开发消息队列中间件，如何来设计？\" class=\"headerlink\" title=\"36.如果让你开发消息队列中间件，如何来设计？\"></a>36.如果让你开发消息队列中间件，如何来设计？</h2><ol>\n<li>考虑mq的伸缩性，就是需要的时候快速扩容，就可以增加吞吐量和容量，那怎么搞？设计个分布式的系统呗，参照一下kafka的设计理念，broker -&gt; topic -&gt; partition，每个partition放一个机器，就存一部分数据。如果现在资源不够了，简单啊，给topic增加partition，然后做数据迁移，增加机器，这样就可以存放更多数据，提供更高的吞吐量了。</li>\n<li>考虑mq数据要不要持久化？需要写入磁盘，这样才能保证挂了之后不会造成数据的丢失。写入时怎么进行写入磁盘？顺序写入，这样既保证了消息的顺序性，还减少了寻址的开销，达到提高性能的目的。</li>\n<li>考虑mq的可用性？参考kafka的高可用的保障机制。多副本–》leader&amp;follwer–》broker挂了重新选举leader即可。</li>\n</ol>"},{"title":"LeetCode刷题指南","date":"2021-09-22T14:09:54.000Z","updated":"2021-09-22T14:09:56.000Z","description":"本人LeetCode刷题近400道后，总结出来的算法小抄。包括了回溯、双指针，滑动窗口和动态规划等常见算法的做题思路和模板。","_content":"\n# 回溯\n\n\n如何判断该使用回溯：感觉如果不穷举一下就没法知道答案。\n\n\n一般回溯的问题有三种：\n\n\n1.  Find a path to success 有没有解\n1.  Find all paths to success 求所有解\n1.  求所有解的个数\n1.  求所有解的具体信息\n3.  Find the best path to success 求最优解\n\n\n\n```python\ndef backtrack(新区域, res, path):\n    if 结束:# 一般是最小值最大值\n        res.add(path) # \n        return\n    for 选择 in 新区域:\n        if 符合要求:\n            path.add(当前选择)\n            backtrack(新区域, res, path)\n            path.pop()\n```\n\n\n# 滑动窗口\n\n\n### 思路1：\n\n\n1.  定义两个指针 left 和 right 分别指向区间的开头和结尾，注意是闭区间；定义 sums 用来统计该区间内的各个字符出现次数；\n1.  第一重 while 循环是为了判断 right 指针的位置是否超出了数组边界；当 right 每次到了新位置，需要增加 right 指针的求和/计数；\n1.  第二重 while 循环是让 left 指针向右移动到 [left, right] 区间符合题意的位置；\n    当 left 每次移动到了新位置，需要减少 left 指针的求和/计数；\n1.  在第二重 while 循环之后，成功找到了一个符合题意的 [left, right] 区间，题目要求\n    最大的区间长度，因此更新 res 为 max(res, 当前区间的长度) 。\n1.  right 指针每次向右移动一步，开始探索新的区间。\n\n\n\n```python\ndef findSubArray(nums):\n    N = len(nums) # 数组/字符串长度\n    left, right = 0, 0 # 双指针，表示当前遍历的区间[left, right]，闭区间\n    sums = 0 # 用于统计 子数组/子区间 是否有效，根据题目可能会改成求和/计数\n    res = 0 # 保存最大的满足题目要求的 子数组/子串 长度\n    while right < N: # 当右边的指针没有搜索到 数组/字符串 的结尾\n        sums += nums[right] # 增加当前右边指针的数字/字符的求和/计数\n        while 区间[left, right]不符合题意：# 此时需要一直移动左指针，直至找到一个符合题意的区间\n            sums -= nums[left] # 移动左指针前需要从counter中减少left位置字符的求和/计数\n            left += 1 # 真正的移动左指针，注意不能跟上面一行代码写反\n        # 到 while 结束时，我们找到了一个符合题意要求的 子数组/子串\n        res = max(res, right - left + 1) # 需要更新结果\n        right += 1 # 移动右指针，去探索新的区间\n    return res\n```\n\n\n### 思路2：\n\n\n1.  当移动 right 扩大窗口，即加入字符时，应该更新哪些数据？\n1.  什么条件下，窗口应该暂停扩大，开始移动 left 缩小窗口？\n1.  当移动 left 缩小窗口，即移出字符时，应该更新哪些数据？\n1.  我们要的结果应该在扩大窗口时还是缩小窗口时进行更新？\n\n\n\n```python\n# s为匹配串，t为模式串\ndef slideWindow(s, t):\n    needs, window = collections.defaultdict(int), collections.defaultdict(int)\n    # 计录模式串中每个字符分别有多少个\n    for i in t:\n        needs[i] += 1\n\n    left, right = 0, 0\n    # 记录窗口中满足模式串字符的个数\n    valid = 0\n    while right < len(s):\n        # 进入窗口的字符\n        c = s[right]\n        # 更新窗口内数据\n        do something\n\n        # debug 位置\n        print(left, right)\n\n        # 窗口收缩操作\n        while left need to shrink:\n            d = s[left]\n            left += 1\n            # 更新窗口内数据\n            do something\n        \n        # 窗口右移\n        right += 1\n```\n\n\n# BFS\n\n\n问题的本质就是让你在一幅「图」中找到从起点 _start_ 到终点 _target_ 的最近距离\n\n\n```python\ndef bfs(start, target):\n    queue = collections.deque()\n    # 记录是否经过该节点\n    visited = set()\n    step = 0\n    # 初始化第一个节点\n    queue.apped(start)\n    visited.add(start)\n    while queue:\n        # 从当前节点向四周扩散\n        for i in range(len(queue)):\n            temp = queue.popleft()\n            # 是否到达终点\n            if temp == target:\n                return step\n            # 添加相邻节点\n            for node in temp.相邻节点:\n                if node not in visited:\n                    queue.apped(node)\n                    visited.add(node)\n        step += 1\n```\n\n\n# 二分查找\n\n\n二分查找场景：寻找一个数、寻找左侧边界、寻找右侧边界。\n\n\n```python\ndef binarySeaech(nums):\n    left, right = 0, len(nums)\n    \n    while condition:\n        mid = lefg + (right -left) / 2\n        if nums[mid] == target:\n            do something\n        elif nums[mid] < target:\n            left = something\n        elif nums[mid] > target:\n            right = something\n    return something\n```\n\n\n# 背包问题：\n\n\n定义 dp 数组的作用十分关键！！！\n\n\n必须明确dp[i][j]，i，j，分别代表什么，并为dp数组正确初始化。\n\n\n然后是定义状态转移方程，之后就可以愉快地套模板了~\n\n\n### 通用转移方程\n\n\n1. 最值问题:\n\n\n\n```python\ndp[i] = max/min(dp[i], dp[i - nums] + 1) 或者 dp[i] = max/min(dp[i], dp[i - num] + num)\n```\n\n\n2. 存在问题(bool)：\n\n\n\n```python\ndp[i] = dp[i] or dp[i - num]\n```\n\n\n3. 组合问题：\n\n\n\n```python\ndp[i] += dp[i - num]\n```\n\n\n### 二维dp\n\n\n```python\ndef bags(nums, target):\n    n = len(nums)\n    dp = [[0] * (target + 1) for _ in range(n + 1)]\n\n    for i in range(n + 1):\n        # 设定所需的初始状态\n        dp[i][0] = [1]\n    \n    for i in range(1, n + 1):\n        for j in range(target + 1):\n            if condition:\n                转移方程1\n            else:\n                转移方程2\n    \n    return dp[-1][-1]\n```\n\n\n### 一维dp\n\n\n1. 如果是0-1背包，即数组中的元素不可重复使用，nums放在外循环，target在内循环，且内循环倒序；\n\n\n\n```python\nfor num in nums:\n    for i in range(target, num - 1, -1):\n```\n\n\n2. 如果是完全背包，即数组中的元素可重复使用，nums放在外循环，target在内循环。且内循环正序。\n\n\n\n```python\nfor num in nums:\n    for i in range(num, target + 1):\n```\n\n\n3. 如果组合问题需考虑元素之间的顺序，需将target放在外循环，将nums放在内循环。\n\n\n\n```python\nfor i in range(1, target+1):\n    for num in nums:\n```\n\n\n整体代码如下\n\n\n```python\ndef bags(nums, target):\n    n = len(nums)\n    dp = [0] * (target + 1)\n\n    # 设定所需的初始状态\n    dp[0] = 1\n    \n    for num in nums:\n        for j in range(target, num - 1, -1):\n            转移方程\n    \n    return dp[-1]\n```\n\n\n# 手撸LRU\n\n\n1. 新加入的节点放在链表末尾，`addNodeToLast(node)`\n1. 若容量达到上限，去除最久未使用的数据，`removeHeadNode(head.next)`\n1. 若数据新被访问过，比如被`get`了或被`put`了新值，把该节点挪到链表末尾，`moveNodeToLast(node)`\n\n\n\n下图为lru的基本数据结构，用hashmap存储`{value: node}`\n\n\n![](https://cdn.nlark.com/yuque/0/2021/jpeg/1431305/1628497262413-769ddb04-b2b2-4d59-95ad-2e79bcc8d57f.jpeg#height=256&id=LiL9J&originHeight=511&originWidth=997&originalType=binary&ratio=1&status=done&style=none&width=499)\n\n`put`操作的逻辑\n\n![](https://cdn.nlark.com/yuque/0/2021/jpeg/1431305/1628497265751-aa1e3cc8-aefa-49ef-914b-d4094dd429a9.jpeg#height=406&id=BFC0S&originHeight=811&originWidth=955&originalType=binary&ratio=1&status=done&style=none&width=478)\n\n\n```python\nclass TreeNode:\n\n    def __init__(self, key=0, val=0):\n        self.pre = None\n        self.next = None\n        self.key = key\n        self.val = val\n\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.hashmap = {}\n        self.head = TreeNode()\n        self.tail = TreeNode()\n        self.head.next = self.tail\n        self.tail.pre = self.head\n\n    def remove_node(self, node):\n        node.pre.next = node.next\n        node.next.pre = node.pre\n\n    def add_node(self, node):\n        self.tail.pre.next = node\n        node.pre = self.tail.pre\n        node.next = self.tail\n        self.tail.pre = node\n\n    def move_node_to_last(self, node):\n        self.remove_node(node)\n        self.add_node(node)\n\n    def get(self, key: int) -> int:\n        if key not in self.hashmap:\n            return -1\n        node = self.hashmap[key]\n        self.move_node_to_last(node)\n        return node.val\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.hashmap:\n            node = self.hashmap[key]\n            node.val = value\n            self.move_node_to_last(node)\n            return\n        if len(self.hashmap) == self.capacity:\n            self.hashmap.pop(self.head.next.key)\n            self.remove_node(self.head.next)\n        node = TreeNode(key, value)\n        self.add_node(node)\n        self.hashmap[key] = node\n```\n\n","source":"_posts/LeetCode刷题指南.md","raw":"---\ntitle: LeetCode刷题指南\ndate: 2021-09-22 22:09:54\nupdated: 2021-09-22 22:09:56\ntags: ['leetcode','算法']\ncategories: leetcode\ndescription: 本人LeetCode刷题近400道后，总结出来的算法小抄。包括了回溯、双指针，滑动窗口和动态规划等常见算法的做题思路和模板。\n---\n\n# 回溯\n\n\n如何判断该使用回溯：感觉如果不穷举一下就没法知道答案。\n\n\n一般回溯的问题有三种：\n\n\n1.  Find a path to success 有没有解\n1.  Find all paths to success 求所有解\n1.  求所有解的个数\n1.  求所有解的具体信息\n3.  Find the best path to success 求最优解\n\n\n\n```python\ndef backtrack(新区域, res, path):\n    if 结束:# 一般是最小值最大值\n        res.add(path) # \n        return\n    for 选择 in 新区域:\n        if 符合要求:\n            path.add(当前选择)\n            backtrack(新区域, res, path)\n            path.pop()\n```\n\n\n# 滑动窗口\n\n\n### 思路1：\n\n\n1.  定义两个指针 left 和 right 分别指向区间的开头和结尾，注意是闭区间；定义 sums 用来统计该区间内的各个字符出现次数；\n1.  第一重 while 循环是为了判断 right 指针的位置是否超出了数组边界；当 right 每次到了新位置，需要增加 right 指针的求和/计数；\n1.  第二重 while 循环是让 left 指针向右移动到 [left, right] 区间符合题意的位置；\n    当 left 每次移动到了新位置，需要减少 left 指针的求和/计数；\n1.  在第二重 while 循环之后，成功找到了一个符合题意的 [left, right] 区间，题目要求\n    最大的区间长度，因此更新 res 为 max(res, 当前区间的长度) 。\n1.  right 指针每次向右移动一步，开始探索新的区间。\n\n\n\n```python\ndef findSubArray(nums):\n    N = len(nums) # 数组/字符串长度\n    left, right = 0, 0 # 双指针，表示当前遍历的区间[left, right]，闭区间\n    sums = 0 # 用于统计 子数组/子区间 是否有效，根据题目可能会改成求和/计数\n    res = 0 # 保存最大的满足题目要求的 子数组/子串 长度\n    while right < N: # 当右边的指针没有搜索到 数组/字符串 的结尾\n        sums += nums[right] # 增加当前右边指针的数字/字符的求和/计数\n        while 区间[left, right]不符合题意：# 此时需要一直移动左指针，直至找到一个符合题意的区间\n            sums -= nums[left] # 移动左指针前需要从counter中减少left位置字符的求和/计数\n            left += 1 # 真正的移动左指针，注意不能跟上面一行代码写反\n        # 到 while 结束时，我们找到了一个符合题意要求的 子数组/子串\n        res = max(res, right - left + 1) # 需要更新结果\n        right += 1 # 移动右指针，去探索新的区间\n    return res\n```\n\n\n### 思路2：\n\n\n1.  当移动 right 扩大窗口，即加入字符时，应该更新哪些数据？\n1.  什么条件下，窗口应该暂停扩大，开始移动 left 缩小窗口？\n1.  当移动 left 缩小窗口，即移出字符时，应该更新哪些数据？\n1.  我们要的结果应该在扩大窗口时还是缩小窗口时进行更新？\n\n\n\n```python\n# s为匹配串，t为模式串\ndef slideWindow(s, t):\n    needs, window = collections.defaultdict(int), collections.defaultdict(int)\n    # 计录模式串中每个字符分别有多少个\n    for i in t:\n        needs[i] += 1\n\n    left, right = 0, 0\n    # 记录窗口中满足模式串字符的个数\n    valid = 0\n    while right < len(s):\n        # 进入窗口的字符\n        c = s[right]\n        # 更新窗口内数据\n        do something\n\n        # debug 位置\n        print(left, right)\n\n        # 窗口收缩操作\n        while left need to shrink:\n            d = s[left]\n            left += 1\n            # 更新窗口内数据\n            do something\n        \n        # 窗口右移\n        right += 1\n```\n\n\n# BFS\n\n\n问题的本质就是让你在一幅「图」中找到从起点 _start_ 到终点 _target_ 的最近距离\n\n\n```python\ndef bfs(start, target):\n    queue = collections.deque()\n    # 记录是否经过该节点\n    visited = set()\n    step = 0\n    # 初始化第一个节点\n    queue.apped(start)\n    visited.add(start)\n    while queue:\n        # 从当前节点向四周扩散\n        for i in range(len(queue)):\n            temp = queue.popleft()\n            # 是否到达终点\n            if temp == target:\n                return step\n            # 添加相邻节点\n            for node in temp.相邻节点:\n                if node not in visited:\n                    queue.apped(node)\n                    visited.add(node)\n        step += 1\n```\n\n\n# 二分查找\n\n\n二分查找场景：寻找一个数、寻找左侧边界、寻找右侧边界。\n\n\n```python\ndef binarySeaech(nums):\n    left, right = 0, len(nums)\n    \n    while condition:\n        mid = lefg + (right -left) / 2\n        if nums[mid] == target:\n            do something\n        elif nums[mid] < target:\n            left = something\n        elif nums[mid] > target:\n            right = something\n    return something\n```\n\n\n# 背包问题：\n\n\n定义 dp 数组的作用十分关键！！！\n\n\n必须明确dp[i][j]，i，j，分别代表什么，并为dp数组正确初始化。\n\n\n然后是定义状态转移方程，之后就可以愉快地套模板了~\n\n\n### 通用转移方程\n\n\n1. 最值问题:\n\n\n\n```python\ndp[i] = max/min(dp[i], dp[i - nums] + 1) 或者 dp[i] = max/min(dp[i], dp[i - num] + num)\n```\n\n\n2. 存在问题(bool)：\n\n\n\n```python\ndp[i] = dp[i] or dp[i - num]\n```\n\n\n3. 组合问题：\n\n\n\n```python\ndp[i] += dp[i - num]\n```\n\n\n### 二维dp\n\n\n```python\ndef bags(nums, target):\n    n = len(nums)\n    dp = [[0] * (target + 1) for _ in range(n + 1)]\n\n    for i in range(n + 1):\n        # 设定所需的初始状态\n        dp[i][0] = [1]\n    \n    for i in range(1, n + 1):\n        for j in range(target + 1):\n            if condition:\n                转移方程1\n            else:\n                转移方程2\n    \n    return dp[-1][-1]\n```\n\n\n### 一维dp\n\n\n1. 如果是0-1背包，即数组中的元素不可重复使用，nums放在外循环，target在内循环，且内循环倒序；\n\n\n\n```python\nfor num in nums:\n    for i in range(target, num - 1, -1):\n```\n\n\n2. 如果是完全背包，即数组中的元素可重复使用，nums放在外循环，target在内循环。且内循环正序。\n\n\n\n```python\nfor num in nums:\n    for i in range(num, target + 1):\n```\n\n\n3. 如果组合问题需考虑元素之间的顺序，需将target放在外循环，将nums放在内循环。\n\n\n\n```python\nfor i in range(1, target+1):\n    for num in nums:\n```\n\n\n整体代码如下\n\n\n```python\ndef bags(nums, target):\n    n = len(nums)\n    dp = [0] * (target + 1)\n\n    # 设定所需的初始状态\n    dp[0] = 1\n    \n    for num in nums:\n        for j in range(target, num - 1, -1):\n            转移方程\n    \n    return dp[-1]\n```\n\n\n# 手撸LRU\n\n\n1. 新加入的节点放在链表末尾，`addNodeToLast(node)`\n1. 若容量达到上限，去除最久未使用的数据，`removeHeadNode(head.next)`\n1. 若数据新被访问过，比如被`get`了或被`put`了新值，把该节点挪到链表末尾，`moveNodeToLast(node)`\n\n\n\n下图为lru的基本数据结构，用hashmap存储`{value: node}`\n\n\n![](https://cdn.nlark.com/yuque/0/2021/jpeg/1431305/1628497262413-769ddb04-b2b2-4d59-95ad-2e79bcc8d57f.jpeg#height=256&id=LiL9J&originHeight=511&originWidth=997&originalType=binary&ratio=1&status=done&style=none&width=499)\n\n`put`操作的逻辑\n\n![](https://cdn.nlark.com/yuque/0/2021/jpeg/1431305/1628497265751-aa1e3cc8-aefa-49ef-914b-d4094dd429a9.jpeg#height=406&id=BFC0S&originHeight=811&originWidth=955&originalType=binary&ratio=1&status=done&style=none&width=478)\n\n\n```python\nclass TreeNode:\n\n    def __init__(self, key=0, val=0):\n        self.pre = None\n        self.next = None\n        self.key = key\n        self.val = val\n\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.hashmap = {}\n        self.head = TreeNode()\n        self.tail = TreeNode()\n        self.head.next = self.tail\n        self.tail.pre = self.head\n\n    def remove_node(self, node):\n        node.pre.next = node.next\n        node.next.pre = node.pre\n\n    def add_node(self, node):\n        self.tail.pre.next = node\n        node.pre = self.tail.pre\n        node.next = self.tail\n        self.tail.pre = node\n\n    def move_node_to_last(self, node):\n        self.remove_node(node)\n        self.add_node(node)\n\n    def get(self, key: int) -> int:\n        if key not in self.hashmap:\n            return -1\n        node = self.hashmap[key]\n        self.move_node_to_last(node)\n        return node.val\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.hashmap:\n            node = self.hashmap[key]\n            node.val = value\n            self.move_node_to_last(node)\n            return\n        if len(self.hashmap) == self.capacity:\n            self.hashmap.pop(self.head.next.key)\n            self.remove_node(self.head.next)\n        node = TreeNode(key, value)\n        self.add_node(node)\n        self.hashmap[key] = node\n```\n\n","slug":"LeetCode刷题指南","published":1,"comments":1,"layout":"post","photos":[],"link":"","_id":"cktvosie100012svu1hay76ev","content":"<h1 id=\"回溯\"><a href=\"#回溯\" class=\"headerlink\" title=\"回溯\"></a>回溯</h1><p>如何判断该使用回溯：感觉如果不穷举一下就没法知道答案。</p>\n<p>一般回溯的问题有三种：</p>\n<ol>\n<li> Find a path to success 有没有解</li>\n<li> Find all paths to success 求所有解</li>\n<li> 求所有解的个数</li>\n<li> 求所有解的具体信息</li>\n<li> Find the best path to success 求最优解</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">backtrack</span>(<span class=\"params\">新区域, res, path</span>):</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> 结束:<span class=\"comment\"># 一般是最小值最大值</span></span><br><span class=\"line\">        res.add(path) <span class=\"comment\"># </span></span><br><span class=\"line\">        <span class=\"keyword\">return</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> 选择 <span class=\"keyword\">in</span> 新区域:</span><br><span class=\"line\">        <span class=\"keyword\">if</span> 符合要求:</span><br><span class=\"line\">            path.add(当前选择)</span><br><span class=\"line\">            backtrack(新区域, res, path)</span><br><span class=\"line\">            path.pop()</span><br></pre></td></tr></table></figure>\n\n\n<h1 id=\"滑动窗口\"><a href=\"#滑动窗口\" class=\"headerlink\" title=\"滑动窗口\"></a>滑动窗口</h1><h3 id=\"思路1：\"><a href=\"#思路1：\" class=\"headerlink\" title=\"思路1：\"></a>思路1：</h3><ol>\n<li> 定义两个指针 left 和 right 分别指向区间的开头和结尾，注意是闭区间；定义 sums 用来统计该区间内的各个字符出现次数；</li>\n<li> 第一重 while 循环是为了判断 right 指针的位置是否超出了数组边界；当 right 每次到了新位置，需要增加 right 指针的求和/计数；</li>\n<li>第二重 while 循环是让 left 指针向右移动到 [left, right] 区间符合题意的位置；<br> 当 left 每次移动到了新位置，需要减少 left 指针的求和/计数；</li>\n<li>在第二重 while 循环之后，成功找到了一个符合题意的 [left, right] 区间，题目要求<br> 最大的区间长度，因此更新 res 为 max(res, 当前区间的长度) 。</li>\n<li> right 指针每次向右移动一步，开始探索新的区间。</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">findSubArray</span>(<span class=\"params\">nums</span>):</span></span><br><span class=\"line\">    N = <span class=\"built_in\">len</span>(nums) <span class=\"comment\"># 数组/字符串长度</span></span><br><span class=\"line\">    left, right = <span class=\"number\">0</span>, <span class=\"number\">0</span> <span class=\"comment\"># 双指针，表示当前遍历的区间[left, right]，闭区间</span></span><br><span class=\"line\">    sums = <span class=\"number\">0</span> <span class=\"comment\"># 用于统计 子数组/子区间 是否有效，根据题目可能会改成求和/计数</span></span><br><span class=\"line\">    res = <span class=\"number\">0</span> <span class=\"comment\"># 保存最大的满足题目要求的 子数组/子串 长度</span></span><br><span class=\"line\">    <span class=\"keyword\">while</span> right &lt; N: <span class=\"comment\"># 当右边的指针没有搜索到 数组/字符串 的结尾</span></span><br><span class=\"line\">        sums += nums[right] <span class=\"comment\"># 增加当前右边指针的数字/字符的求和/计数</span></span><br><span class=\"line\">        <span class=\"keyword\">while</span> 区间[left, right]不符合题意：<span class=\"comment\"># 此时需要一直移动左指针，直至找到一个符合题意的区间</span></span><br><span class=\"line\">            sums -= nums[left] <span class=\"comment\"># 移动左指针前需要从counter中减少left位置字符的求和/计数</span></span><br><span class=\"line\">            left += <span class=\"number\">1</span> <span class=\"comment\"># 真正的移动左指针，注意不能跟上面一行代码写反</span></span><br><span class=\"line\">        <span class=\"comment\"># 到 while 结束时，我们找到了一个符合题意要求的 子数组/子串</span></span><br><span class=\"line\">        res = <span class=\"built_in\">max</span>(res, right - left + <span class=\"number\">1</span>) <span class=\"comment\"># 需要更新结果</span></span><br><span class=\"line\">        right += <span class=\"number\">1</span> <span class=\"comment\"># 移动右指针，去探索新的区间</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> res</span><br></pre></td></tr></table></figure>\n\n\n<h3 id=\"思路2：\"><a href=\"#思路2：\" class=\"headerlink\" title=\"思路2：\"></a>思路2：</h3><ol>\n<li> 当移动 right 扩大窗口，即加入字符时，应该更新哪些数据？</li>\n<li> 什么条件下，窗口应该暂停扩大，开始移动 left 缩小窗口？</li>\n<li> 当移动 left 缩小窗口，即移出字符时，应该更新哪些数据？</li>\n<li> 我们要的结果应该在扩大窗口时还是缩小窗口时进行更新？</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># s为匹配串，t为模式串</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">slideWindow</span>(<span class=\"params\">s, t</span>):</span></span><br><span class=\"line\">    needs, window = collections.defaultdict(<span class=\"built_in\">int</span>), collections.defaultdict(<span class=\"built_in\">int</span>)</span><br><span class=\"line\">    <span class=\"comment\"># 计录模式串中每个字符分别有多少个</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> t:</span><br><span class=\"line\">        needs[i] += <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\">    left, right = <span class=\"number\">0</span>, <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"comment\"># 记录窗口中满足模式串字符的个数</span></span><br><span class=\"line\">    valid = <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"keyword\">while</span> right &lt; <span class=\"built_in\">len</span>(s):</span><br><span class=\"line\">        <span class=\"comment\"># 进入窗口的字符</span></span><br><span class=\"line\">        c = s[right]</span><br><span class=\"line\">        <span class=\"comment\"># 更新窗口内数据</span></span><br><span class=\"line\">        do something</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># debug 位置</span></span><br><span class=\"line\">        <span class=\"built_in\">print</span>(left, right)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 窗口收缩操作</span></span><br><span class=\"line\">        <span class=\"keyword\">while</span> left need to shrink:</span><br><span class=\"line\">            d = s[left]</span><br><span class=\"line\">            left += <span class=\"number\">1</span></span><br><span class=\"line\">            <span class=\"comment\"># 更新窗口内数据</span></span><br><span class=\"line\">            do something</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 窗口右移</span></span><br><span class=\"line\">        right += <span class=\"number\">1</span></span><br></pre></td></tr></table></figure>\n\n\n<h1 id=\"BFS\"><a href=\"#BFS\" class=\"headerlink\" title=\"BFS\"></a>BFS</h1><p>问题的本质就是让你在一幅「图」中找到从起点 <em>start</em> 到终点 <em>target</em> 的最近距离</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">bfs</span>(<span class=\"params\">start, target</span>):</span></span><br><span class=\"line\">    queue = collections.deque()</span><br><span class=\"line\">    <span class=\"comment\"># 记录是否经过该节点</span></span><br><span class=\"line\">    visited = <span class=\"built_in\">set</span>()</span><br><span class=\"line\">    step = <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"comment\"># 初始化第一个节点</span></span><br><span class=\"line\">    queue.apped(start)</span><br><span class=\"line\">    visited.add(start)</span><br><span class=\"line\">    <span class=\"keyword\">while</span> queue:</span><br><span class=\"line\">        <span class=\"comment\"># 从当前节点向四周扩散</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(queue)):</span><br><span class=\"line\">            temp = queue.popleft()</span><br><span class=\"line\">            <span class=\"comment\"># 是否到达终点</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> temp == target:</span><br><span class=\"line\">                <span class=\"keyword\">return</span> step</span><br><span class=\"line\">            <span class=\"comment\"># 添加相邻节点</span></span><br><span class=\"line\">            <span class=\"keyword\">for</span> node <span class=\"keyword\">in</span> temp.相邻节点:</span><br><span class=\"line\">                <span class=\"keyword\">if</span> node <span class=\"keyword\">not</span> <span class=\"keyword\">in</span> visited:</span><br><span class=\"line\">                    queue.apped(node)</span><br><span class=\"line\">                    visited.add(node)</span><br><span class=\"line\">        step += <span class=\"number\">1</span></span><br></pre></td></tr></table></figure>\n\n\n<h1 id=\"二分查找\"><a href=\"#二分查找\" class=\"headerlink\" title=\"二分查找\"></a>二分查找</h1><p>二分查找场景：寻找一个数、寻找左侧边界、寻找右侧边界。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">binarySeaech</span>(<span class=\"params\">nums</span>):</span></span><br><span class=\"line\">    left, right = <span class=\"number\">0</span>, <span class=\"built_in\">len</span>(nums)</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">while</span> condition:</span><br><span class=\"line\">        mid = lefg + (right -left) / <span class=\"number\">2</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> nums[mid] == target:</span><br><span class=\"line\">            do something</span><br><span class=\"line\">        <span class=\"keyword\">elif</span> nums[mid] &lt; target:</span><br><span class=\"line\">            left = something</span><br><span class=\"line\">        <span class=\"keyword\">elif</span> nums[mid] &gt; target:</span><br><span class=\"line\">            right = something</span><br><span class=\"line\">    <span class=\"keyword\">return</span> something</span><br></pre></td></tr></table></figure>\n\n\n<h1 id=\"背包问题：\"><a href=\"#背包问题：\" class=\"headerlink\" title=\"背包问题：\"></a>背包问题：</h1><p>定义 dp 数组的作用十分关键！！！</p>\n<p>必须明确dp[i][j]，i，j，分别代表什么，并为dp数组正确初始化。</p>\n<p>然后是定义状态转移方程，之后就可以愉快地套模板了~</p>\n<h3 id=\"通用转移方程\"><a href=\"#通用转移方程\" class=\"headerlink\" title=\"通用转移方程\"></a>通用转移方程</h3><ol>\n<li>最值问题:</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dp[i] = <span class=\"built_in\">max</span>/<span class=\"built_in\">min</span>(dp[i], dp[i - nums] + <span class=\"number\">1</span>) 或者 dp[i] = <span class=\"built_in\">max</span>/<span class=\"built_in\">min</span>(dp[i], dp[i - num] + num)</span><br></pre></td></tr></table></figure>\n\n\n<ol start=\"2\">\n<li>存在问题(bool)：</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dp[i] = dp[i] <span class=\"keyword\">or</span> dp[i - num]</span><br></pre></td></tr></table></figure>\n\n\n<ol start=\"3\">\n<li>组合问题：</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dp[i] += dp[i - num]</span><br></pre></td></tr></table></figure>\n\n\n<h3 id=\"二维dp\"><a href=\"#二维dp\" class=\"headerlink\" title=\"二维dp\"></a>二维dp</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">bags</span>(<span class=\"params\">nums, target</span>):</span></span><br><span class=\"line\">    n = <span class=\"built_in\">len</span>(nums)</span><br><span class=\"line\">    dp = [[<span class=\"number\">0</span>] * (target + <span class=\"number\">1</span>) <span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(n + <span class=\"number\">1</span>)]</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(n + <span class=\"number\">1</span>):</span><br><span class=\"line\">        <span class=\"comment\"># 设定所需的初始状态</span></span><br><span class=\"line\">        dp[i][<span class=\"number\">0</span>] = [<span class=\"number\">1</span>]</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">1</span>, n + <span class=\"number\">1</span>):</span><br><span class=\"line\">        <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(target + <span class=\"number\">1</span>):</span><br><span class=\"line\">            <span class=\"keyword\">if</span> condition:</span><br><span class=\"line\">                转移方程<span class=\"number\">1</span></span><br><span class=\"line\">            <span class=\"keyword\">else</span>:</span><br><span class=\"line\">                转移方程<span class=\"number\">2</span></span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">return</span> dp[-<span class=\"number\">1</span>][-<span class=\"number\">1</span>]</span><br></pre></td></tr></table></figure>\n\n\n<h3 id=\"一维dp\"><a href=\"#一维dp\" class=\"headerlink\" title=\"一维dp\"></a>一维dp</h3><ol>\n<li>如果是0-1背包，即数组中的元素不可重复使用，nums放在外循环，target在内循环，且内循环倒序；</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> num <span class=\"keyword\">in</span> nums:</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(target, num - <span class=\"number\">1</span>, -<span class=\"number\">1</span>):</span><br></pre></td></tr></table></figure>\n\n\n<ol start=\"2\">\n<li>如果是完全背包，即数组中的元素可重复使用，nums放在外循环，target在内循环。且内循环正序。</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> num <span class=\"keyword\">in</span> nums:</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(num, target + <span class=\"number\">1</span>):</span><br></pre></td></tr></table></figure>\n\n\n<ol start=\"3\">\n<li>如果组合问题需考虑元素之间的顺序，需将target放在外循环，将nums放在内循环。</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">1</span>, target+<span class=\"number\">1</span>):</span><br><span class=\"line\">    <span class=\"keyword\">for</span> num <span class=\"keyword\">in</span> nums:</span><br></pre></td></tr></table></figure>\n\n\n<p>整体代码如下</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">bags</span>(<span class=\"params\">nums, target</span>):</span></span><br><span class=\"line\">    n = <span class=\"built_in\">len</span>(nums)</span><br><span class=\"line\">    dp = [<span class=\"number\">0</span>] * (target + <span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 设定所需的初始状态</span></span><br><span class=\"line\">    dp[<span class=\"number\">0</span>] = <span class=\"number\">1</span></span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">for</span> num <span class=\"keyword\">in</span> nums:</span><br><span class=\"line\">        <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(target, num - <span class=\"number\">1</span>, -<span class=\"number\">1</span>):</span><br><span class=\"line\">            转移方程</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">return</span> dp[-<span class=\"number\">1</span>]</span><br></pre></td></tr></table></figure>\n\n\n<h1 id=\"手撸LRU\"><a href=\"#手撸LRU\" class=\"headerlink\" title=\"手撸LRU\"></a>手撸LRU</h1><ol>\n<li>新加入的节点放在链表末尾，<code>addNodeToLast(node)</code></li>\n<li>若容量达到上限，去除最久未使用的数据，<code>removeHeadNode(head.next)</code></li>\n<li>若数据新被访问过，比如被<code>get</code>了或被<code>put</code>了新值，把该节点挪到链表末尾，<code>moveNodeToLast(node)</code></li>\n</ol>\n<p>下图为lru的基本数据结构，用hashmap存储<code>&#123;value: node&#125;</code></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2021/jpeg/1431305/1628497262413-769ddb04-b2b2-4d59-95ad-2e79bcc8d57f.jpeg#height=256&id=LiL9J&originHeight=511&originWidth=997&originalType=binary&ratio=1&status=done&style=none&width=499\"></p>\n<p><code>put</code>操作的逻辑</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2021/jpeg/1431305/1628497265751-aa1e3cc8-aefa-49ef-914b-d4094dd429a9.jpeg#height=406&id=BFC0S&originHeight=811&originWidth=955&originalType=binary&ratio=1&status=done&style=none&width=478\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">TreeNode</span>:</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span>(<span class=\"params\">self, key=<span class=\"number\">0</span>, val=<span class=\"number\">0</span></span>):</span></span><br><span class=\"line\">        self.pre = <span class=\"literal\">None</span></span><br><span class=\"line\">        self.<span class=\"built_in\">next</span> = <span class=\"literal\">None</span></span><br><span class=\"line\">        self.key = key</span><br><span class=\"line\">        self.val = val</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">LRUCache</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span>(<span class=\"params\">self, capacity: <span class=\"built_in\">int</span></span>):</span></span><br><span class=\"line\">        self.capacity = capacity</span><br><span class=\"line\">        self.hashmap = &#123;&#125;</span><br><span class=\"line\">        self.head = TreeNode()</span><br><span class=\"line\">        self.tail = TreeNode()</span><br><span class=\"line\">        self.head.<span class=\"built_in\">next</span> = self.tail</span><br><span class=\"line\">        self.tail.pre = self.head</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">remove_node</span>(<span class=\"params\">self, node</span>):</span></span><br><span class=\"line\">        node.pre.<span class=\"built_in\">next</span> = node.<span class=\"built_in\">next</span></span><br><span class=\"line\">        node.<span class=\"built_in\">next</span>.pre = node.pre</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">add_node</span>(<span class=\"params\">self, node</span>):</span></span><br><span class=\"line\">        self.tail.pre.<span class=\"built_in\">next</span> = node</span><br><span class=\"line\">        node.pre = self.tail.pre</span><br><span class=\"line\">        node.<span class=\"built_in\">next</span> = self.tail</span><br><span class=\"line\">        self.tail.pre = node</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">move_node_to_last</span>(<span class=\"params\">self, node</span>):</span></span><br><span class=\"line\">        self.remove_node(node)</span><br><span class=\"line\">        self.add_node(node)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">get</span>(<span class=\"params\">self, key: <span class=\"built_in\">int</span></span>) -&gt; <span class=\"built_in\">int</span>:</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> key <span class=\"keyword\">not</span> <span class=\"keyword\">in</span> self.hashmap:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> -<span class=\"number\">1</span></span><br><span class=\"line\">        node = self.hashmap[key]</span><br><span class=\"line\">        self.move_node_to_last(node)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> node.val</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">put</span>(<span class=\"params\">self, key: <span class=\"built_in\">int</span>, value: <span class=\"built_in\">int</span></span>) -&gt; <span class=\"literal\">None</span>:</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> key <span class=\"keyword\">in</span> self.hashmap:</span><br><span class=\"line\">            node = self.hashmap[key]</span><br><span class=\"line\">            node.val = value</span><br><span class=\"line\">            self.move_node_to_last(node)</span><br><span class=\"line\">            <span class=\"keyword\">return</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(self.hashmap) == self.capacity:</span><br><span class=\"line\">            self.hashmap.pop(self.head.<span class=\"built_in\">next</span>.key)</span><br><span class=\"line\">            self.remove_node(self.head.<span class=\"built_in\">next</span>)</span><br><span class=\"line\">        node = TreeNode(key, value)</span><br><span class=\"line\">        self.add_node(node)</span><br><span class=\"line\">        self.hashmap[key] = node</span><br></pre></td></tr></table></figure>\n\n","site":{"data":{}},"length":4258,"excerpt":"","more":"<h1 id=\"回溯\"><a href=\"#回溯\" class=\"headerlink\" title=\"回溯\"></a>回溯</h1><p>如何判断该使用回溯：感觉如果不穷举一下就没法知道答案。</p>\n<p>一般回溯的问题有三种：</p>\n<ol>\n<li> Find a path to success 有没有解</li>\n<li> Find all paths to success 求所有解</li>\n<li> 求所有解的个数</li>\n<li> 求所有解的具体信息</li>\n<li> Find the best path to success 求最优解</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">backtrack</span>(<span class=\"params\">新区域, res, path</span>):</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> 结束:<span class=\"comment\"># 一般是最小值最大值</span></span><br><span class=\"line\">        res.add(path) <span class=\"comment\"># </span></span><br><span class=\"line\">        <span class=\"keyword\">return</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> 选择 <span class=\"keyword\">in</span> 新区域:</span><br><span class=\"line\">        <span class=\"keyword\">if</span> 符合要求:</span><br><span class=\"line\">            path.add(当前选择)</span><br><span class=\"line\">            backtrack(新区域, res, path)</span><br><span class=\"line\">            path.pop()</span><br></pre></td></tr></table></figure>\n\n\n<h1 id=\"滑动窗口\"><a href=\"#滑动窗口\" class=\"headerlink\" title=\"滑动窗口\"></a>滑动窗口</h1><h3 id=\"思路1：\"><a href=\"#思路1：\" class=\"headerlink\" title=\"思路1：\"></a>思路1：</h3><ol>\n<li> 定义两个指针 left 和 right 分别指向区间的开头和结尾，注意是闭区间；定义 sums 用来统计该区间内的各个字符出现次数；</li>\n<li> 第一重 while 循环是为了判断 right 指针的位置是否超出了数组边界；当 right 每次到了新位置，需要增加 right 指针的求和/计数；</li>\n<li>第二重 while 循环是让 left 指针向右移动到 [left, right] 区间符合题意的位置；<br> 当 left 每次移动到了新位置，需要减少 left 指针的求和/计数；</li>\n<li>在第二重 while 循环之后，成功找到了一个符合题意的 [left, right] 区间，题目要求<br> 最大的区间长度，因此更新 res 为 max(res, 当前区间的长度) 。</li>\n<li> right 指针每次向右移动一步，开始探索新的区间。</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">findSubArray</span>(<span class=\"params\">nums</span>):</span></span><br><span class=\"line\">    N = <span class=\"built_in\">len</span>(nums) <span class=\"comment\"># 数组/字符串长度</span></span><br><span class=\"line\">    left, right = <span class=\"number\">0</span>, <span class=\"number\">0</span> <span class=\"comment\"># 双指针，表示当前遍历的区间[left, right]，闭区间</span></span><br><span class=\"line\">    sums = <span class=\"number\">0</span> <span class=\"comment\"># 用于统计 子数组/子区间 是否有效，根据题目可能会改成求和/计数</span></span><br><span class=\"line\">    res = <span class=\"number\">0</span> <span class=\"comment\"># 保存最大的满足题目要求的 子数组/子串 长度</span></span><br><span class=\"line\">    <span class=\"keyword\">while</span> right &lt; N: <span class=\"comment\"># 当右边的指针没有搜索到 数组/字符串 的结尾</span></span><br><span class=\"line\">        sums += nums[right] <span class=\"comment\"># 增加当前右边指针的数字/字符的求和/计数</span></span><br><span class=\"line\">        <span class=\"keyword\">while</span> 区间[left, right]不符合题意：<span class=\"comment\"># 此时需要一直移动左指针，直至找到一个符合题意的区间</span></span><br><span class=\"line\">            sums -= nums[left] <span class=\"comment\"># 移动左指针前需要从counter中减少left位置字符的求和/计数</span></span><br><span class=\"line\">            left += <span class=\"number\">1</span> <span class=\"comment\"># 真正的移动左指针，注意不能跟上面一行代码写反</span></span><br><span class=\"line\">        <span class=\"comment\"># 到 while 结束时，我们找到了一个符合题意要求的 子数组/子串</span></span><br><span class=\"line\">        res = <span class=\"built_in\">max</span>(res, right - left + <span class=\"number\">1</span>) <span class=\"comment\"># 需要更新结果</span></span><br><span class=\"line\">        right += <span class=\"number\">1</span> <span class=\"comment\"># 移动右指针，去探索新的区间</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> res</span><br></pre></td></tr></table></figure>\n\n\n<h3 id=\"思路2：\"><a href=\"#思路2：\" class=\"headerlink\" title=\"思路2：\"></a>思路2：</h3><ol>\n<li> 当移动 right 扩大窗口，即加入字符时，应该更新哪些数据？</li>\n<li> 什么条件下，窗口应该暂停扩大，开始移动 left 缩小窗口？</li>\n<li> 当移动 left 缩小窗口，即移出字符时，应该更新哪些数据？</li>\n<li> 我们要的结果应该在扩大窗口时还是缩小窗口时进行更新？</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># s为匹配串，t为模式串</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">slideWindow</span>(<span class=\"params\">s, t</span>):</span></span><br><span class=\"line\">    needs, window = collections.defaultdict(<span class=\"built_in\">int</span>), collections.defaultdict(<span class=\"built_in\">int</span>)</span><br><span class=\"line\">    <span class=\"comment\"># 计录模式串中每个字符分别有多少个</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> t:</span><br><span class=\"line\">        needs[i] += <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\">    left, right = <span class=\"number\">0</span>, <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"comment\"># 记录窗口中满足模式串字符的个数</span></span><br><span class=\"line\">    valid = <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"keyword\">while</span> right &lt; <span class=\"built_in\">len</span>(s):</span><br><span class=\"line\">        <span class=\"comment\"># 进入窗口的字符</span></span><br><span class=\"line\">        c = s[right]</span><br><span class=\"line\">        <span class=\"comment\"># 更新窗口内数据</span></span><br><span class=\"line\">        do something</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># debug 位置</span></span><br><span class=\"line\">        <span class=\"built_in\">print</span>(left, right)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 窗口收缩操作</span></span><br><span class=\"line\">        <span class=\"keyword\">while</span> left need to shrink:</span><br><span class=\"line\">            d = s[left]</span><br><span class=\"line\">            left += <span class=\"number\">1</span></span><br><span class=\"line\">            <span class=\"comment\"># 更新窗口内数据</span></span><br><span class=\"line\">            do something</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 窗口右移</span></span><br><span class=\"line\">        right += <span class=\"number\">1</span></span><br></pre></td></tr></table></figure>\n\n\n<h1 id=\"BFS\"><a href=\"#BFS\" class=\"headerlink\" title=\"BFS\"></a>BFS</h1><p>问题的本质就是让你在一幅「图」中找到从起点 <em>start</em> 到终点 <em>target</em> 的最近距离</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">bfs</span>(<span class=\"params\">start, target</span>):</span></span><br><span class=\"line\">    queue = collections.deque()</span><br><span class=\"line\">    <span class=\"comment\"># 记录是否经过该节点</span></span><br><span class=\"line\">    visited = <span class=\"built_in\">set</span>()</span><br><span class=\"line\">    step = <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"comment\"># 初始化第一个节点</span></span><br><span class=\"line\">    queue.apped(start)</span><br><span class=\"line\">    visited.add(start)</span><br><span class=\"line\">    <span class=\"keyword\">while</span> queue:</span><br><span class=\"line\">        <span class=\"comment\"># 从当前节点向四周扩散</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(queue)):</span><br><span class=\"line\">            temp = queue.popleft()</span><br><span class=\"line\">            <span class=\"comment\"># 是否到达终点</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> temp == target:</span><br><span class=\"line\">                <span class=\"keyword\">return</span> step</span><br><span class=\"line\">            <span class=\"comment\"># 添加相邻节点</span></span><br><span class=\"line\">            <span class=\"keyword\">for</span> node <span class=\"keyword\">in</span> temp.相邻节点:</span><br><span class=\"line\">                <span class=\"keyword\">if</span> node <span class=\"keyword\">not</span> <span class=\"keyword\">in</span> visited:</span><br><span class=\"line\">                    queue.apped(node)</span><br><span class=\"line\">                    visited.add(node)</span><br><span class=\"line\">        step += <span class=\"number\">1</span></span><br></pre></td></tr></table></figure>\n\n\n<h1 id=\"二分查找\"><a href=\"#二分查找\" class=\"headerlink\" title=\"二分查找\"></a>二分查找</h1><p>二分查找场景：寻找一个数、寻找左侧边界、寻找右侧边界。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">binarySeaech</span>(<span class=\"params\">nums</span>):</span></span><br><span class=\"line\">    left, right = <span class=\"number\">0</span>, <span class=\"built_in\">len</span>(nums)</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">while</span> condition:</span><br><span class=\"line\">        mid = lefg + (right -left) / <span class=\"number\">2</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> nums[mid] == target:</span><br><span class=\"line\">            do something</span><br><span class=\"line\">        <span class=\"keyword\">elif</span> nums[mid] &lt; target:</span><br><span class=\"line\">            left = something</span><br><span class=\"line\">        <span class=\"keyword\">elif</span> nums[mid] &gt; target:</span><br><span class=\"line\">            right = something</span><br><span class=\"line\">    <span class=\"keyword\">return</span> something</span><br></pre></td></tr></table></figure>\n\n\n<h1 id=\"背包问题：\"><a href=\"#背包问题：\" class=\"headerlink\" title=\"背包问题：\"></a>背包问题：</h1><p>定义 dp 数组的作用十分关键！！！</p>\n<p>必须明确dp[i][j]，i，j，分别代表什么，并为dp数组正确初始化。</p>\n<p>然后是定义状态转移方程，之后就可以愉快地套模板了~</p>\n<h3 id=\"通用转移方程\"><a href=\"#通用转移方程\" class=\"headerlink\" title=\"通用转移方程\"></a>通用转移方程</h3><ol>\n<li>最值问题:</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dp[i] = <span class=\"built_in\">max</span>/<span class=\"built_in\">min</span>(dp[i], dp[i - nums] + <span class=\"number\">1</span>) 或者 dp[i] = <span class=\"built_in\">max</span>/<span class=\"built_in\">min</span>(dp[i], dp[i - num] + num)</span><br></pre></td></tr></table></figure>\n\n\n<ol start=\"2\">\n<li>存在问题(bool)：</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dp[i] = dp[i] <span class=\"keyword\">or</span> dp[i - num]</span><br></pre></td></tr></table></figure>\n\n\n<ol start=\"3\">\n<li>组合问题：</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dp[i] += dp[i - num]</span><br></pre></td></tr></table></figure>\n\n\n<h3 id=\"二维dp\"><a href=\"#二维dp\" class=\"headerlink\" title=\"二维dp\"></a>二维dp</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">bags</span>(<span class=\"params\">nums, target</span>):</span></span><br><span class=\"line\">    n = <span class=\"built_in\">len</span>(nums)</span><br><span class=\"line\">    dp = [[<span class=\"number\">0</span>] * (target + <span class=\"number\">1</span>) <span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(n + <span class=\"number\">1</span>)]</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(n + <span class=\"number\">1</span>):</span><br><span class=\"line\">        <span class=\"comment\"># 设定所需的初始状态</span></span><br><span class=\"line\">        dp[i][<span class=\"number\">0</span>] = [<span class=\"number\">1</span>]</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">1</span>, n + <span class=\"number\">1</span>):</span><br><span class=\"line\">        <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(target + <span class=\"number\">1</span>):</span><br><span class=\"line\">            <span class=\"keyword\">if</span> condition:</span><br><span class=\"line\">                转移方程<span class=\"number\">1</span></span><br><span class=\"line\">            <span class=\"keyword\">else</span>:</span><br><span class=\"line\">                转移方程<span class=\"number\">2</span></span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">return</span> dp[-<span class=\"number\">1</span>][-<span class=\"number\">1</span>]</span><br></pre></td></tr></table></figure>\n\n\n<h3 id=\"一维dp\"><a href=\"#一维dp\" class=\"headerlink\" title=\"一维dp\"></a>一维dp</h3><ol>\n<li>如果是0-1背包，即数组中的元素不可重复使用，nums放在外循环，target在内循环，且内循环倒序；</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> num <span class=\"keyword\">in</span> nums:</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(target, num - <span class=\"number\">1</span>, -<span class=\"number\">1</span>):</span><br></pre></td></tr></table></figure>\n\n\n<ol start=\"2\">\n<li>如果是完全背包，即数组中的元素可重复使用，nums放在外循环，target在内循环。且内循环正序。</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> num <span class=\"keyword\">in</span> nums:</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(num, target + <span class=\"number\">1</span>):</span><br></pre></td></tr></table></figure>\n\n\n<ol start=\"3\">\n<li>如果组合问题需考虑元素之间的顺序，需将target放在外循环，将nums放在内循环。</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">1</span>, target+<span class=\"number\">1</span>):</span><br><span class=\"line\">    <span class=\"keyword\">for</span> num <span class=\"keyword\">in</span> nums:</span><br></pre></td></tr></table></figure>\n\n\n<p>整体代码如下</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">bags</span>(<span class=\"params\">nums, target</span>):</span></span><br><span class=\"line\">    n = <span class=\"built_in\">len</span>(nums)</span><br><span class=\"line\">    dp = [<span class=\"number\">0</span>] * (target + <span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 设定所需的初始状态</span></span><br><span class=\"line\">    dp[<span class=\"number\">0</span>] = <span class=\"number\">1</span></span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">for</span> num <span class=\"keyword\">in</span> nums:</span><br><span class=\"line\">        <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(target, num - <span class=\"number\">1</span>, -<span class=\"number\">1</span>):</span><br><span class=\"line\">            转移方程</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">return</span> dp[-<span class=\"number\">1</span>]</span><br></pre></td></tr></table></figure>\n\n\n<h1 id=\"手撸LRU\"><a href=\"#手撸LRU\" class=\"headerlink\" title=\"手撸LRU\"></a>手撸LRU</h1><ol>\n<li>新加入的节点放在链表末尾，<code>addNodeToLast(node)</code></li>\n<li>若容量达到上限，去除最久未使用的数据，<code>removeHeadNode(head.next)</code></li>\n<li>若数据新被访问过，比如被<code>get</code>了或被<code>put</code>了新值，把该节点挪到链表末尾，<code>moveNodeToLast(node)</code></li>\n</ol>\n<p>下图为lru的基本数据结构，用hashmap存储<code>&#123;value: node&#125;</code></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2021/jpeg/1431305/1628497262413-769ddb04-b2b2-4d59-95ad-2e79bcc8d57f.jpeg#height=256&id=LiL9J&originHeight=511&originWidth=997&originalType=binary&ratio=1&status=done&style=none&width=499\"></p>\n<p><code>put</code>操作的逻辑</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2021/jpeg/1431305/1628497265751-aa1e3cc8-aefa-49ef-914b-d4094dd429a9.jpeg#height=406&id=BFC0S&originHeight=811&originWidth=955&originalType=binary&ratio=1&status=done&style=none&width=478\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">TreeNode</span>:</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span>(<span class=\"params\">self, key=<span class=\"number\">0</span>, val=<span class=\"number\">0</span></span>):</span></span><br><span class=\"line\">        self.pre = <span class=\"literal\">None</span></span><br><span class=\"line\">        self.<span class=\"built_in\">next</span> = <span class=\"literal\">None</span></span><br><span class=\"line\">        self.key = key</span><br><span class=\"line\">        self.val = val</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">LRUCache</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span>(<span class=\"params\">self, capacity: <span class=\"built_in\">int</span></span>):</span></span><br><span class=\"line\">        self.capacity = capacity</span><br><span class=\"line\">        self.hashmap = &#123;&#125;</span><br><span class=\"line\">        self.head = TreeNode()</span><br><span class=\"line\">        self.tail = TreeNode()</span><br><span class=\"line\">        self.head.<span class=\"built_in\">next</span> = self.tail</span><br><span class=\"line\">        self.tail.pre = self.head</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">remove_node</span>(<span class=\"params\">self, node</span>):</span></span><br><span class=\"line\">        node.pre.<span class=\"built_in\">next</span> = node.<span class=\"built_in\">next</span></span><br><span class=\"line\">        node.<span class=\"built_in\">next</span>.pre = node.pre</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">add_node</span>(<span class=\"params\">self, node</span>):</span></span><br><span class=\"line\">        self.tail.pre.<span class=\"built_in\">next</span> = node</span><br><span class=\"line\">        node.pre = self.tail.pre</span><br><span class=\"line\">        node.<span class=\"built_in\">next</span> = self.tail</span><br><span class=\"line\">        self.tail.pre = node</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">move_node_to_last</span>(<span class=\"params\">self, node</span>):</span></span><br><span class=\"line\">        self.remove_node(node)</span><br><span class=\"line\">        self.add_node(node)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">get</span>(<span class=\"params\">self, key: <span class=\"built_in\">int</span></span>) -&gt; <span class=\"built_in\">int</span>:</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> key <span class=\"keyword\">not</span> <span class=\"keyword\">in</span> self.hashmap:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> -<span class=\"number\">1</span></span><br><span class=\"line\">        node = self.hashmap[key]</span><br><span class=\"line\">        self.move_node_to_last(node)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> node.val</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">put</span>(<span class=\"params\">self, key: <span class=\"built_in\">int</span>, value: <span class=\"built_in\">int</span></span>) -&gt; <span class=\"literal\">None</span>:</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> key <span class=\"keyword\">in</span> self.hashmap:</span><br><span class=\"line\">            node = self.hashmap[key]</span><br><span class=\"line\">            node.val = value</span><br><span class=\"line\">            self.move_node_to_last(node)</span><br><span class=\"line\">            <span class=\"keyword\">return</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(self.hashmap) == self.capacity:</span><br><span class=\"line\">            self.hashmap.pop(self.head.<span class=\"built_in\">next</span>.key)</span><br><span class=\"line\">            self.remove_node(self.head.<span class=\"built_in\">next</span>)</span><br><span class=\"line\">        node = TreeNode(key, value)</span><br><span class=\"line\">        self.add_node(node)</span><br><span class=\"line\">        self.hashmap[key] = node</span><br></pre></td></tr></table></figure>\n\n"},{"title":"面试八股文（一）—— 计算机网络","date":"2021-09-22T14:22:04.000Z","updated":"2021-09-22T15:24:11.000Z","description":"根据我多年（其实就一年）复习备考408和春招的经验，总结出来的面试八股文第一篇，也是基础篇之一——计算机网络相关的常见问题。如果文章中有看不懂的知识点，强力推荐王道考研的计网相关课程，讲的巨清晰无比。如果觉得本文介绍内容过于浅显，大佬请移步机工出版社黑皮书之《计算机网络自顶向下》。","_content":" \n<meta name=\"referrer\" content=\"no-referrer\" />\n \n# 计算机网络体系结构\n\n![](https://cdn.nlark.com/yuque/0/2021/png/1431305/1628084581427-ad52128d-5d7c-4304-8fb3-8f8c6b59dc15.png)\n\n- Physical, Data Link, Network, Transport, Application\n- 应用层：常见协议：\n    - FTP(21端口)：文件传输协议\n    - SSH(22端口)：远程登陆\n    - TELNET(23端口)：远程登录\n    - SMTP(25端口)：发送邮件\n    - POP3(110端口)：接收邮件\n    - HTTP(80端口)：超文本传输协议\n    - DNS(53端口)：运行在UDP上，域名解析服务\n- 传输层：TCP/UDP\n- 网络层：IP、ARP、NAT、RIP...\n- 路由器网络层，根据IP地址进行寻址；\n\n[](#%E4%BB%80%E4%B9%88%E6%98%AFNAT-Network-Address-Translation-%E7%BD%91%E7%BB%9C%E5%9C%B0%E5%9D%80%E8%BD%AC%E6%8D%A2)\n# 传输层：TCP和UDP\n\n### 什么是三次握手 (three-way handshake)？\n![](https://cdn.nlark.com/yuque/0/2021/png/1431305/1628083612400-05353867-b677-449d-bc87-378dc2ac5fbd.png)\n- 第一次握手：Client将SYN置1，随机产生一个初始序列号seq发送给Server，进入SYN_SENT状态；\n- 第二次握手：Server收到Client的SYN=1之后，知道客户端请求建立连接，将自己的SYN置1，ACK置1，产生一个acknowledge number=sequence number+1，并随机产生一个自己的初始序列号，发送给客户端；进入SYN_RCVD状态；\n- 第三次握手：客户端检查acknowledge number是否为序列号+1，ACK是否为1，检查正确之后将自己的ACK置为1，产生一个acknowledge number=服务器发的序列号+1，发送给服务器；进入ESTABLISHED状态；服务器检查ACK为1和acknowledge number为序列号+1之后，也进入ESTABLISHED状态；完成三次握手，连接建立。\n\n##### TCP建立连接可以两次握手吗？为什么?\n不可以。有两个原因：\n首先，可能会出现**已失效的连接请求报文段又传到了服务器端**。\n> client 发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达 server。本来这是一个早已失效的报文段。但 server 收到此失效的连接请求报文段后，就误认为是 client 再次发出的一个新的连接请求。于是就向 client 发出确认报文段，同意建立连接。假设不采用 “三次握手”，那么只要 server 发出确认，新的连接就建立了。由于现在 client 并没有发出建立连接的请求，因此不会理睬 server 的确认，也不会向 server 发送数据。但 server 却以为新的运输连接已经建立，并一直等待 client 发来数据。这样，server 的很多资源就白白浪费掉了。采用 “三次握手” 的办法可以防止上述现象发生。例如刚才那种情况，client 不会向 server 的确认发出确认。server 由于收不到确认，就知道 client 并没有要求建立连接。\n\n其次，两次握手无法保证Client正确接收第二次握手的报文（Server无法确认Client是否收到），也无法保证Client和Server之间成功互换初始序列号。\n\n##### 可以采用四次握手吗？为什么？\n可以。但是会降低传输的效率。\n四次握手是指：第二次握手：Server只发送ACK和acknowledge number；而Server的SYN和初始序列号在第三次握手时发送；原来协议中的第三次握手变为第四次握手。出于优化目的，四次握手中的二、三可以合并。\n\n##### 第三次握手中，如果客户端的ACK未送达服务器，会怎样？\nServer端：\n由于Server没有收到ACK确认，因此会重发之前的SYN+ACK（默认重发五次，之后自动关闭连接进入CLOSED状态），Client收到后会重新传ACK给Server。\nClient端，两种情况：\n\n1. 在Server进行超时重发的过程中，如果Client向服务器发送数据，数据头部的ACK是为1的，所以服务器收到数据之后会读取 ACK number，进入 establish 状态 \n2. 在Server进入CLOSED状态之后，如果Client向服务器发送数据，服务器会以RST包应答。\n\n##### 如果已经建立了连接，但客户端出现了故障怎么办？\n服务器每收到一次客户端的请求后都会重新复位一个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75秒钟发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。\n\n##### 初始序列号是什么？\nTCP连接的一方A，随机选择一个32位的序列号（Sequence Number）作为发送数据的初始序列号（Initial Sequence Number，ISN），比如为1000，以该序列号为原点，对要传送的数据进行编号：1001、1002...三次握手时，把这个初始序列号传送给另一方B，以便在传输数据时，B可以确认什么样的数据编号是合法的；同时在进行数据传输时，A还可以确认B收到的每一个字节，如果A收到了B的确认编号（acknowledge number）是2001，就说明编号为1001-2000的数据已经被B成功接受。\n\n### 什么是四次挥手？\n![](https://cdn.nlark.com/yuque/0/2021/png/1431305/1628083644967-a1117a3a-ad00-494a-bdf5-f357adfef3b9.png)\n\n- 第一次挥手：Client将FIN置为1，发送一个序列号seq给Server；进入FIN_WAIT_1状态；\n- 第二次挥手：Server收到FIN之后，发送一个ACK=1，acknowledge number=收到的序列号+1；进入CLOSE_WAIT状态。此时客户端已经没有要发送的数据了，但仍可以接受服务器发来的数据。\n- 第三次挥手：Server将FIN置1，发送一个序列号给Client；进入LAST_ACK状态；\n- 第四次挥手：Client收到服务器的FIN后，进入TIME_WAIT状态；接着将ACK置1，发送一个acknowledge number=序列号+1给服务器；服务器收到后，确认acknowledge number后，变为CLOSED状态，不再向客户端发送数据。客户端等待2*MSL（报文段最长寿命）时间后，也进入CLOSED状态。完成四次挥手。\n\n##### 为什么不能把服务器发送的ACK和FIN合并起来，变成三次挥手（CLOSE_WAIT状态意义是什么）？\n因为服务器收到客户端断开连接的请求时，可能还有一些数据没有发完，这时先回复ACK，表示接收到了断开连接的请求。等到数据发完之后再发FIN，断开服务器到客户端的数据传送。\n\n##### 如果第二次挥手时服务器的ACK没有送达客户端，会怎样？\n客户端没有收到ACK确认，会重新发送FIN请求。\n\n\n##### 客户端TIME_WAIT状态的意义是什么？\n第四次挥手时，客户端发送给服务器的ACK有可能丢失，TIME_WAIT状态就是用来重发可能丢失的ACK报文。如果Server没有收到ACK，就会重发FIN，如果Client在2*MSL的时间内收到了FIN，就会重新发送ACK并再次等待2MSL，防止Server没有收到ACK而不断重发FIN。\nMSL(Maximum Segment Lifetime)，指一个片段在网络中最大的存活时间，2MSL就是一个发送和一个回复所需的最大时间。如果直到2MSL，Client都没有再次收到FIN，那么Client推断ACK已经被成功接收，则结束TCP连接。\n\n### TCP如何实现流量控制？\n![](https://cdn.nlark.com/yuque/0/2021/png/1431305/1628083671501-2d938176-eced-4414-b6aa-fbc32d323ae9.png)\n\n使用滑动窗口协议实现流量控制。防止发送方发送速率太快，接收方缓存区不够导致溢出。接收方会维护一个接收窗口 receiver window（窗口大小单位是字节），接受窗口的大小是根据自己的资源情况动态调整的，在返回ACK时将接受窗口大小放在TCP报文中的窗口字段告知发送方。发送窗口的大小不能超过接受窗口的大小，只有当发送方发送并收到确认之后，才能将发送窗口右移。\n\n发送窗口的上限为接受窗口和拥塞窗口中的较小值。接受窗口表明了接收方的接收能力，拥塞窗口表明了网络的传送能力。\n\n![](https://cdn.nlark.com/yuque/0/2021/gif/1431305/1628083685654-29996960-ed15-47f4-99bf-246b8ac30214.gif)\n\n##### 什么是零窗口（接收窗口为0时会怎样）？\n\n如果接收方没有能力接收数据，就会将接收窗口设置为0，这时发送方必须暂停发送数据，但是会启动一个持续计时器(persistence timer)，到期后发送一个大小为1字节的探测数据包，以查看接收窗口状态。如果接收方能够接收数据，就会在返回的报文中更新接收窗口大小，恢复数据传送。\n\n### TCP的拥塞控制是怎么实现的？\n![](https://cdn.nlark.com/yuque/0/2021/png/1431305/1628083709929-6e2bfba1-63ca-4742-a80a-256a93b0f159.png)\n\n拥塞控制主要由四个算法组成：**慢启动（Slow Start）、拥塞避免（Congestion voidance）、快重传 （Fast Retransmit）、快恢复（Fast Recovery）**\n1. 慢启动：刚开始发送数据时，先把拥塞窗口（congestion window）设置为一个最大报文段MSS的数值，每收到一个新的确认报文之后，就把拥塞窗口加1个MSS。这样每经过一个传输轮次（或者说是每经过一个往返时间RTT），拥塞窗口的大小就会加倍\n![](https://cdn.nlark.com/yuque/0/2021/png/1431305/1628083774060-71278d40-0b39-4e15-9dd1-22534e2c90d8.png)\n\n\n2. 拥塞避免：当拥塞窗口的大小达到慢开始门限(slow start threshold)时，开始执行拥塞避免算法，拥塞窗口大小不再指数增加，而是线性增加，即每经过一个传输轮次只增加1MSS.\n\n> 无论在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞（其根据就是没有收到确认），就要把慢开始门限ssthresh设置为出现拥塞时的发送方窗口值的一半（但不能小于2）。然后把拥塞窗口cwnd重新设置为1，执行慢开始算法。**（这是不使用快重传的情况）**\n\n3. 快重传：快重传要求接收方在收到一个失序的报文段后就立即发出**重复确认**（为的是使发送方及早知道有报文段没有到达对方）而不要等到自己发送数据时捎带确认。快重传算法规定，发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段，而不必继续等待设置的重传计时器时间到期。\n\n![](https://cdn.nlark.com/yuque/0/2021/png/1431305/1628083866222-2e727029-b6f2-495e-97f2-e4b7b49cd16e.png)\n\n4. 快恢复：当发送方连续收到三个重复确认时，就把慢开始门限减半，然后执行拥塞避免算法。不执行慢开始算法的原因：因为如果网络出现拥塞的话就不会收到好几个重复的确认，所以发送方认为现在网络可能没有出现拥塞。\n   也有的快重传是把开始时的拥塞窗口cwnd值再增大一点，即等于 ssthresh + 3*MSS 。这样做的理由是：既然发送方收到三个重复的确认，就表明有三个分组已经离开了网络。这三个分组不再消耗网络的资源而是停留在接收方的缓存中。可见现在网络中减少了三个分组。因此可以适当把拥塞窗口扩大些。\n### TCP如何最大利用带宽？\nTCP速率受到三个因素影响\n- 窗口：即滑动窗口大小，见[TCP如何实现流量控制？](#TCP%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6)\n- 带宽：这里带宽是指单位时间内从发送端到接收端所能通过的“最高数据率”，是一种硬件限制。TCP发送端和接收端的数据传输数不可能超过两点间的带宽限制。发送端和接收端之间带宽取所通过线路的带宽最小值（如通过互联网连接）。\n- RTT：即Round Trip Time，表示从发送端到接收端的一去一回需要的时间，TCP在数据传输过程中会对RTT进行采样（即对发送的数据包及其ACK的时间差进行测量，并根据测量值更新RTT值），TCP根据得到的RTT值更新RTO值，即Retransmission TimeOut，就是重传间隔，发送端对每个发出的数据包进行计时，如果在RTO时间内没有收到所发出的数据包的对应ACK，则任务数据包丢失，将重传数据。一般RTO值都比采样得到的RTT值要大。\n\n带宽时延乘积=带宽*RTT，实际上等于发送端到接收端单向通道的数据容积的两倍，这里单向通道的数据容积可以这样来理解，单向通道看成是一条单行道马路，带宽就是马路的车道数，路上跑的汽车就是数据（不过这里所有汽车的速率都是一样的，且不会有人想超车，大家齐头并进），那么单向通道的数据容积就是这条单行道上摆满车，一共可以摆多少辆。带宽就是马路的车道数，带宽数乘以单向通道的数据容积就是路面上所能容纳的全部数据量。当路面上已经摆满的时候，就不能再往里面放了。\n![](https://cdn.nlark.com/yuque/0/2021/png/1431305/1628084389045-9ba4652e-2456-424e-b530-bd95b496004d.png)\n\n\n### TCP与UDP的区别\n1. TCP是面向连接的，UDP是无连接的；\n2. UDP发送数据之前不需要建立连接\n3. TCP是可靠的，UDP不可靠； \n4. UDP接收方收到报文后，不需要给出任何确认\n5. TCP只支持点对点通信，UDP支持一对一、一对多、多对一、多对多；\n6. TCP是面向字节流的，UDP是面向报文的； \n7. 面向字节流是指发送数据时以字节为单位，一个数据包可以拆分成若干组进行发送，而UDP一个报文只能一次发完。\n8. TCP有拥塞控制机制，UDP没有。网络出现的拥塞不会使源主机的发送速率降低，这对某些实时应用是很重要的，比如媒体通信，游戏；\n9. TCP首部开销（20字节）比UDP首部开销（8字节）要大\n10. UDP 的主机不需要维持复杂的连接状态表\n\n##### 什么时候选择TCP，什么时候选UDP？\n\n##### HTTP可以使用UDP吗？\n\n注：**http 3.0 使用udp实现**\n[https://zh.wikipedia.org/wiki/HTTP/3](https://zh.wikipedia.org/wiki/HTTP/3)\n\n##### 面向连接和无连接的区别\n无连接的网络服务（数据报服务）-- 面向连接的网络服务（虚电路服务）\n虚电路服务：首先建立连接，所有的数据包经过相同的路径，服务质量有较好的保证；\n数据报服务：每个数据包含目的地址，数据路由相互独立（路径可能变化）；网络尽最大努力交付数据，但不保证不丢失、不保证先后顺序、不保证在时限内交付；网络发生拥塞时，可能会将一些分组丢弃；\n\n![](https://cdn.nlark.com/yuque/0/2021/png/1431305/1628084520127-fb51536c-1fee-4fa4-a450-684dab556f9e.png#height=494&id=HncLV&originHeight=659&originWidth=769&originalType=binary&ratio=1&status=done&style=none&width=577)\n\n### TCP如何保证传输的可靠性\n1. 数据包校验\n2. 对失序数据包重新排序（TCP报文具有序列号）\n3. 丢弃重复数据\n4. 应答机制：接收方收到数据之后，会发送一个确认（通常延迟几分之一秒）；\n5. 超时重发：发送方发出数据之后，启动一个定时器，超时未收到接收方的确认，则重新发送这个数据；\n6. 流量控制：确保接收端能够接收发送方的数据而不会缓冲区溢出\n# 应用层：HTTP和HTTPS\n\n### HTTP和HTTPS有什么区别？\n1. 端口不同：HTTP使用的是80端口，HTTPS使用443端口；\n2. HTTP（超文本传输协议）信息是明文传输，HTTPS运行在SSL(Secure Socket Layer)之上，添加了加密和认证机制，更加安全；\n3. HTTPS由于加密解密会带来更大的CPU和内存开销；\n4. HTTPS通信需要证书，一般需要向证书颁发机构（CA）购买\n\n##### Https的连接过程？\n1. 客户端向服务器发送请求，同时发送客户端支持的一套加密规则（包括对称加密、非对称加密、摘要算法）；\n2. 服务器从中选出一组加密算法与HASH算法，并将自己的身份信息以证书的形式发回给浏览器。证书里面包含了网站地址，**加密公钥**（用于非对称加密），以及证书的颁发机构等信息（证书中的私钥只能用于服务器端进行解密）；\n3. 客户端验证服务器的合法性，包括：证书是否过期，CA 是否可靠，发行者证书的公钥能否正确解开服务器证书的“发行者的数字签名”，服务器证书上的域名是否和服务器的实际域名相匹配；\n4. 如果证书受信任，或者用户接收了不受信任的证书，浏览器会生成一个**随机密钥**（用于对称算法），并用服务器提供的公钥加密（采用非对称算法对密钥加密）；使用Hash算法对握手消息进行**摘要**计算，并对摘要使用之前产生的密钥加密（对称算法）；将加密后的随机密钥和摘要一起发送给服务器；\n5. 服务器使用自己的私钥解密，得到对称加密的密钥，用这个密钥解密出Hash摘要值，并验证握手消息是否一致；如果一致，服务器使用对称加密的密钥加密握手消息发给浏览器；\n6. 浏览器解密并验证摘要，若一致，则握手结束。之后的数据传送都使用对称加密的密钥进行加密\n\n总结：非对称加密算法用于在握手过程中加密生成的密码；对称加密算法用于对真正传输的数据进行加密；HASH算法用于验证数据的完整性。\n\n##### 输入 www.baidu.com，怎么变成 [https://www.baidu.com](https://www.baidu.com) 的，怎么确定用HTTP还是HTTPS？\n\n[你访问的网站是如何自动切换到 HTTPS 的？](https://www.sohu.com/a/136637876_487516)\n一种是原始的302跳转，服务器把所有的HTTp流量跳转到HTTPS。但这样有一个漏洞，就是中间人可能在第一次访问站点的时候就劫持。\n解决方法是引入HSTS机制，用户浏览器在访问站点的时候强制使用HTTPS。\n\n##### HTTPS连接的时候，怎么确定收到的包是服务器发来的（中间人攻击）？\n\n##### 什么是对称加密、非对称加密？区别是什么？\n- 对称加密：加密和解密采用相同的密钥。如：DES、RC2、RC4\n- 非对称加密：需要两个密钥：公钥和私钥。如果用公钥加密，需要用私钥才能解密。如：RSA\n- 区别：对称加密速度更快，通常用于大量数据的加密；非对称加密安全性更高（不需要传送私钥）\n\n##### 数字签名、报文摘要的原理\n- 发送者A用私钥进行签名，接收者B用公钥验证签名。因为除A外没有人有私钥，所以B相信签名是来自A。A不可抵赖，B也不能伪造报文。\n- 摘要算法:MD5、SHA\n\n### GET与POST的区别？\n1. GET是幂等的，即读取同一个资源，总是得到相同的数据，POST不是幂等的；\n2. GET一般用于从服务器获取资源，而POST有可能改变服务器上的资源；\n3. 请求形式上：GET请求的数据附在URL之后，在HTTP请求头中；POST请求的数据在请求体中；\n4. 安全性：GET请求可被缓存、收藏、保留到历史记录，且其请求数据明文出现在URL中。POST的参数不会被保存，安全性相对较高；\n5. GET只允许ASCII字符，POST对数据类型没有要求，也允许二进制数据；\n6. GET的长度有限制（操作系统或者浏览器），而POST数据大小无限制\n\n### Session与Cookie的区别？\nSession是服务器端保持状态的方案，Cookie是客户端保持状态的方案\nCookie保存在客户端本地，客户端请求服务器时会将Cookie一起提交；Session保存在服务端，通过检索Sessionid查看状态。保存Sessionid的方式可以采用Cookie，如果禁用了Cookie，可以使用URL重写机制（把会话ID保存在URL中）。\n\n### 从输入网址到获得页面的过程 (越详细越好)？\n1. 浏览器查询 DNS，获取域名对应的IP地址:具体过程包括浏览器搜索自身的DNS缓存、搜索操作系统的DNS缓存、读取本地的Host文件和向本地DNS服务器进行查询等。对于向本地DNS服务器进行查询，如果要查询的域名包含在本地配置区域资源中，则返回解析结果给客户机，完成域名解析(此解析具有权威性)；如果要查询的域名不由本地DNS服务器区域解析，但该服务器已缓存了此网址映射关系，则调用这个IP地址映射，完成域名解析（此解析不具有权威性）。如果本地域名服务器并未缓存该网址映射关系，那么将根据其设置发起递归查询或者迭代查询；\n2. 浏览器获得域名对应的IP地址以后，浏览器向服务器请求建立链接，发起三次握手；\n3. TCP/IP链接建立起来后，浏览器向服务器发送HTTP请求；\n4. 服务器接收到这个请求，并根据路径参数映射到特定的请求处理器进行处理，并将处理结果及相应的视图返回给浏览器；\n5. 浏览器解析并渲染视图，若遇到对js文件、css文件及图片等静态资源的引用，则重复上述步骤并向服务器请求这些资源；\n6. 浏览器根据其请求到的资源、数据渲染页面，最终向用户呈现一个完整的页面。\n\n### HTTP请求有哪些常见状态码？\n1. 2xx状态码：操作成功。200 OK\n2. 3xx状态码：重定向。301 永久重定向；302暂时重定向\n3. 4xx状态码：客户端错误。400 Bad Request；401 Unauthorized；403 Forbidden；404 Not Found；\n4. 5xx状态码：服务端错误。500服务器内部错误；501服务不可用\n\n### 什么是RIP (Routing Information Protocol, 距离矢量路由协议)? 算法是什么？\n每个路由器维护一张表，记录该路由器到其它网络的”跳数“，路由器到与其直接连接的网络的跳数是1，每多经过一个路由器跳数就加1；更新该表时和相邻路由器交换路由信息；路由器允许一个路径最多包含15个路由器，如果跳数为16，则不可达。交付数据报时优先选取距离最短的路径。\n\n（PS：RIP是应用层协议：[https://www.zhihu.com/question/19645407](https://www.zhihu.com/question/19645407)）\n\n- 实现简单，开销小\n- 随着网络规模扩大开销也会增大；\n- 最大距离为15，限制了网络的规模；\n- 当网络出现故障时，要经过较长的时间才能将此信息传递到所有路由器\n- 交换机数据链路层，根据MAC地址进行寻址\n\n# 网络层协议\n\n### IP地址的分类？\n![](https://cdn.nlark.com/yuque/0/2021/png/1431305/1628084593202-102c8a14-99c6-463c-8bde-866b86d19613.png)\n\n路由器仅根据网络号net-id来转发分组，当分组到达目的网络的路由器之后，再按照主机号host-id将分组交付给主机；同一网络上的所有主机的网络号相同。\n\n### 什么叫划分子网？\n\n从主机号host-id借用若干个比特作为子网号subnet-id；子网掩码：网络号和子网号都为1，主机号为0；数据报仍然先按照网络号找到目的网络，发送到路由器，路由器再按照网络号和子网号找到目的子网：将子网掩码与目标地址逐比特与操作，若结果为某个子网的网络地址，则送到该子网。\n\n### 什么是ARP协议 (Address Resolution Protocol)？\n\n\n**ARP协议完成了IP地址与物理地址的映射**。每一个主机都设有一个 ARP 高速缓存，里面有**所在的局域网**上的各主机和路由器的 IP 地址到硬件地址的映射表。当源主机要发送数据包到目的主机时，会先检查自己的ARP高速缓存中有没有目的主机的MAC地址，如果有，就直接将数据包发到这个MAC地址，如果没有，就向**所在的局域网**发起一个ARP请求的广播包（在发送自己的 ARP 请求时，同时会带上自己的 IP 地址到硬件地址的映射），收到请求的主机检查自己的IP地址和目的主机的IP地址是否一致，如果一致，则先保存源主机的映射到自己的ARP缓存，然后给源主机发送一个ARP响应数据包。源主机收到响应数据包之后，先添加目的主机的IP地址与MAC地址的映射，再进行数据传送。如果源主机一直没有收到响应，表示ARP查询失败。\n\n\n如果所要找的主机和源主机不在同一个局域网上，那么就要通过 ARP 找到一个位于本局域网上的某个路由器的硬件地址，然后把分组发送给这个路由器，让这个路由器把分组转发给下一个网络。剩下的工作就由下一个网络来做。\n\n\n### 什么是NAT (Network Address Translation, 网络地址转换)？\n\n\n用于解决内网中的主机要和因特网上的主机通信。由NAT路由器将主机的本地IP地址转换为全球IP地址，分为静态转换（转换得到的全球IP地址固定不变）和动态NAT转换。\n\n文章内容搬运自本人[语雀](https://www.yuque.com/docs/share/5b2ba306-5030-4cff-8c82-19ecb35b4f40)\n","source":"_posts/面试八股文（一）——-计算机网络.md","raw":"---\ntitle: 面试八股文（一）—— 计算机网络\ndate: 2021-09-22 22:22:04\nupdated: 2021-09-22 23:24:11\ntags: ['八股文', '计算机网络']\ncategories: \n - 计算机网络\n - 八股文\ndescription: 根据我多年（其实就一年）复习备考408和春招的经验，总结出来的面试八股文第一篇，也是基础篇之一——计算机网络相关的常见问题。如果文章中有看不懂的知识点，强力推荐王道考研的计网相关课程，讲的巨清晰无比。如果觉得本文介绍内容过于浅显，大佬请移步机工出版社黑皮书之《计算机网络自顶向下》。\n---\n \n<meta name=\"referrer\" content=\"no-referrer\" />\n \n# 计算机网络体系结构\n\n![](https://cdn.nlark.com/yuque/0/2021/png/1431305/1628084581427-ad52128d-5d7c-4304-8fb3-8f8c6b59dc15.png)\n\n- Physical, Data Link, Network, Transport, Application\n- 应用层：常见协议：\n    - FTP(21端口)：文件传输协议\n    - SSH(22端口)：远程登陆\n    - TELNET(23端口)：远程登录\n    - SMTP(25端口)：发送邮件\n    - POP3(110端口)：接收邮件\n    - HTTP(80端口)：超文本传输协议\n    - DNS(53端口)：运行在UDP上，域名解析服务\n- 传输层：TCP/UDP\n- 网络层：IP、ARP、NAT、RIP...\n- 路由器网络层，根据IP地址进行寻址；\n\n[](#%E4%BB%80%E4%B9%88%E6%98%AFNAT-Network-Address-Translation-%E7%BD%91%E7%BB%9C%E5%9C%B0%E5%9D%80%E8%BD%AC%E6%8D%A2)\n# 传输层：TCP和UDP\n\n### 什么是三次握手 (three-way handshake)？\n![](https://cdn.nlark.com/yuque/0/2021/png/1431305/1628083612400-05353867-b677-449d-bc87-378dc2ac5fbd.png)\n- 第一次握手：Client将SYN置1，随机产生一个初始序列号seq发送给Server，进入SYN_SENT状态；\n- 第二次握手：Server收到Client的SYN=1之后，知道客户端请求建立连接，将自己的SYN置1，ACK置1，产生一个acknowledge number=sequence number+1，并随机产生一个自己的初始序列号，发送给客户端；进入SYN_RCVD状态；\n- 第三次握手：客户端检查acknowledge number是否为序列号+1，ACK是否为1，检查正确之后将自己的ACK置为1，产生一个acknowledge number=服务器发的序列号+1，发送给服务器；进入ESTABLISHED状态；服务器检查ACK为1和acknowledge number为序列号+1之后，也进入ESTABLISHED状态；完成三次握手，连接建立。\n\n##### TCP建立连接可以两次握手吗？为什么?\n不可以。有两个原因：\n首先，可能会出现**已失效的连接请求报文段又传到了服务器端**。\n> client 发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达 server。本来这是一个早已失效的报文段。但 server 收到此失效的连接请求报文段后，就误认为是 client 再次发出的一个新的连接请求。于是就向 client 发出确认报文段，同意建立连接。假设不采用 “三次握手”，那么只要 server 发出确认，新的连接就建立了。由于现在 client 并没有发出建立连接的请求，因此不会理睬 server 的确认，也不会向 server 发送数据。但 server 却以为新的运输连接已经建立，并一直等待 client 发来数据。这样，server 的很多资源就白白浪费掉了。采用 “三次握手” 的办法可以防止上述现象发生。例如刚才那种情况，client 不会向 server 的确认发出确认。server 由于收不到确认，就知道 client 并没有要求建立连接。\n\n其次，两次握手无法保证Client正确接收第二次握手的报文（Server无法确认Client是否收到），也无法保证Client和Server之间成功互换初始序列号。\n\n##### 可以采用四次握手吗？为什么？\n可以。但是会降低传输的效率。\n四次握手是指：第二次握手：Server只发送ACK和acknowledge number；而Server的SYN和初始序列号在第三次握手时发送；原来协议中的第三次握手变为第四次握手。出于优化目的，四次握手中的二、三可以合并。\n\n##### 第三次握手中，如果客户端的ACK未送达服务器，会怎样？\nServer端：\n由于Server没有收到ACK确认，因此会重发之前的SYN+ACK（默认重发五次，之后自动关闭连接进入CLOSED状态），Client收到后会重新传ACK给Server。\nClient端，两种情况：\n\n1. 在Server进行超时重发的过程中，如果Client向服务器发送数据，数据头部的ACK是为1的，所以服务器收到数据之后会读取 ACK number，进入 establish 状态 \n2. 在Server进入CLOSED状态之后，如果Client向服务器发送数据，服务器会以RST包应答。\n\n##### 如果已经建立了连接，但客户端出现了故障怎么办？\n服务器每收到一次客户端的请求后都会重新复位一个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75秒钟发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。\n\n##### 初始序列号是什么？\nTCP连接的一方A，随机选择一个32位的序列号（Sequence Number）作为发送数据的初始序列号（Initial Sequence Number，ISN），比如为1000，以该序列号为原点，对要传送的数据进行编号：1001、1002...三次握手时，把这个初始序列号传送给另一方B，以便在传输数据时，B可以确认什么样的数据编号是合法的；同时在进行数据传输时，A还可以确认B收到的每一个字节，如果A收到了B的确认编号（acknowledge number）是2001，就说明编号为1001-2000的数据已经被B成功接受。\n\n### 什么是四次挥手？\n![](https://cdn.nlark.com/yuque/0/2021/png/1431305/1628083644967-a1117a3a-ad00-494a-bdf5-f357adfef3b9.png)\n\n- 第一次挥手：Client将FIN置为1，发送一个序列号seq给Server；进入FIN_WAIT_1状态；\n- 第二次挥手：Server收到FIN之后，发送一个ACK=1，acknowledge number=收到的序列号+1；进入CLOSE_WAIT状态。此时客户端已经没有要发送的数据了，但仍可以接受服务器发来的数据。\n- 第三次挥手：Server将FIN置1，发送一个序列号给Client；进入LAST_ACK状态；\n- 第四次挥手：Client收到服务器的FIN后，进入TIME_WAIT状态；接着将ACK置1，发送一个acknowledge number=序列号+1给服务器；服务器收到后，确认acknowledge number后，变为CLOSED状态，不再向客户端发送数据。客户端等待2*MSL（报文段最长寿命）时间后，也进入CLOSED状态。完成四次挥手。\n\n##### 为什么不能把服务器发送的ACK和FIN合并起来，变成三次挥手（CLOSE_WAIT状态意义是什么）？\n因为服务器收到客户端断开连接的请求时，可能还有一些数据没有发完，这时先回复ACK，表示接收到了断开连接的请求。等到数据发完之后再发FIN，断开服务器到客户端的数据传送。\n\n##### 如果第二次挥手时服务器的ACK没有送达客户端，会怎样？\n客户端没有收到ACK确认，会重新发送FIN请求。\n\n\n##### 客户端TIME_WAIT状态的意义是什么？\n第四次挥手时，客户端发送给服务器的ACK有可能丢失，TIME_WAIT状态就是用来重发可能丢失的ACK报文。如果Server没有收到ACK，就会重发FIN，如果Client在2*MSL的时间内收到了FIN，就会重新发送ACK并再次等待2MSL，防止Server没有收到ACK而不断重发FIN。\nMSL(Maximum Segment Lifetime)，指一个片段在网络中最大的存活时间，2MSL就是一个发送和一个回复所需的最大时间。如果直到2MSL，Client都没有再次收到FIN，那么Client推断ACK已经被成功接收，则结束TCP连接。\n\n### TCP如何实现流量控制？\n![](https://cdn.nlark.com/yuque/0/2021/png/1431305/1628083671501-2d938176-eced-4414-b6aa-fbc32d323ae9.png)\n\n使用滑动窗口协议实现流量控制。防止发送方发送速率太快，接收方缓存区不够导致溢出。接收方会维护一个接收窗口 receiver window（窗口大小单位是字节），接受窗口的大小是根据自己的资源情况动态调整的，在返回ACK时将接受窗口大小放在TCP报文中的窗口字段告知发送方。发送窗口的大小不能超过接受窗口的大小，只有当发送方发送并收到确认之后，才能将发送窗口右移。\n\n发送窗口的上限为接受窗口和拥塞窗口中的较小值。接受窗口表明了接收方的接收能力，拥塞窗口表明了网络的传送能力。\n\n![](https://cdn.nlark.com/yuque/0/2021/gif/1431305/1628083685654-29996960-ed15-47f4-99bf-246b8ac30214.gif)\n\n##### 什么是零窗口（接收窗口为0时会怎样）？\n\n如果接收方没有能力接收数据，就会将接收窗口设置为0，这时发送方必须暂停发送数据，但是会启动一个持续计时器(persistence timer)，到期后发送一个大小为1字节的探测数据包，以查看接收窗口状态。如果接收方能够接收数据，就会在返回的报文中更新接收窗口大小，恢复数据传送。\n\n### TCP的拥塞控制是怎么实现的？\n![](https://cdn.nlark.com/yuque/0/2021/png/1431305/1628083709929-6e2bfba1-63ca-4742-a80a-256a93b0f159.png)\n\n拥塞控制主要由四个算法组成：**慢启动（Slow Start）、拥塞避免（Congestion voidance）、快重传 （Fast Retransmit）、快恢复（Fast Recovery）**\n1. 慢启动：刚开始发送数据时，先把拥塞窗口（congestion window）设置为一个最大报文段MSS的数值，每收到一个新的确认报文之后，就把拥塞窗口加1个MSS。这样每经过一个传输轮次（或者说是每经过一个往返时间RTT），拥塞窗口的大小就会加倍\n![](https://cdn.nlark.com/yuque/0/2021/png/1431305/1628083774060-71278d40-0b39-4e15-9dd1-22534e2c90d8.png)\n\n\n2. 拥塞避免：当拥塞窗口的大小达到慢开始门限(slow start threshold)时，开始执行拥塞避免算法，拥塞窗口大小不再指数增加，而是线性增加，即每经过一个传输轮次只增加1MSS.\n\n> 无论在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞（其根据就是没有收到确认），就要把慢开始门限ssthresh设置为出现拥塞时的发送方窗口值的一半（但不能小于2）。然后把拥塞窗口cwnd重新设置为1，执行慢开始算法。**（这是不使用快重传的情况）**\n\n3. 快重传：快重传要求接收方在收到一个失序的报文段后就立即发出**重复确认**（为的是使发送方及早知道有报文段没有到达对方）而不要等到自己发送数据时捎带确认。快重传算法规定，发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段，而不必继续等待设置的重传计时器时间到期。\n\n![](https://cdn.nlark.com/yuque/0/2021/png/1431305/1628083866222-2e727029-b6f2-495e-97f2-e4b7b49cd16e.png)\n\n4. 快恢复：当发送方连续收到三个重复确认时，就把慢开始门限减半，然后执行拥塞避免算法。不执行慢开始算法的原因：因为如果网络出现拥塞的话就不会收到好几个重复的确认，所以发送方认为现在网络可能没有出现拥塞。\n   也有的快重传是把开始时的拥塞窗口cwnd值再增大一点，即等于 ssthresh + 3*MSS 。这样做的理由是：既然发送方收到三个重复的确认，就表明有三个分组已经离开了网络。这三个分组不再消耗网络的资源而是停留在接收方的缓存中。可见现在网络中减少了三个分组。因此可以适当把拥塞窗口扩大些。\n### TCP如何最大利用带宽？\nTCP速率受到三个因素影响\n- 窗口：即滑动窗口大小，见[TCP如何实现流量控制？](#TCP%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6)\n- 带宽：这里带宽是指单位时间内从发送端到接收端所能通过的“最高数据率”，是一种硬件限制。TCP发送端和接收端的数据传输数不可能超过两点间的带宽限制。发送端和接收端之间带宽取所通过线路的带宽最小值（如通过互联网连接）。\n- RTT：即Round Trip Time，表示从发送端到接收端的一去一回需要的时间，TCP在数据传输过程中会对RTT进行采样（即对发送的数据包及其ACK的时间差进行测量，并根据测量值更新RTT值），TCP根据得到的RTT值更新RTO值，即Retransmission TimeOut，就是重传间隔，发送端对每个发出的数据包进行计时，如果在RTO时间内没有收到所发出的数据包的对应ACK，则任务数据包丢失，将重传数据。一般RTO值都比采样得到的RTT值要大。\n\n带宽时延乘积=带宽*RTT，实际上等于发送端到接收端单向通道的数据容积的两倍，这里单向通道的数据容积可以这样来理解，单向通道看成是一条单行道马路，带宽就是马路的车道数，路上跑的汽车就是数据（不过这里所有汽车的速率都是一样的，且不会有人想超车，大家齐头并进），那么单向通道的数据容积就是这条单行道上摆满车，一共可以摆多少辆。带宽就是马路的车道数，带宽数乘以单向通道的数据容积就是路面上所能容纳的全部数据量。当路面上已经摆满的时候，就不能再往里面放了。\n![](https://cdn.nlark.com/yuque/0/2021/png/1431305/1628084389045-9ba4652e-2456-424e-b530-bd95b496004d.png)\n\n\n### TCP与UDP的区别\n1. TCP是面向连接的，UDP是无连接的；\n2. UDP发送数据之前不需要建立连接\n3. TCP是可靠的，UDP不可靠； \n4. UDP接收方收到报文后，不需要给出任何确认\n5. TCP只支持点对点通信，UDP支持一对一、一对多、多对一、多对多；\n6. TCP是面向字节流的，UDP是面向报文的； \n7. 面向字节流是指发送数据时以字节为单位，一个数据包可以拆分成若干组进行发送，而UDP一个报文只能一次发完。\n8. TCP有拥塞控制机制，UDP没有。网络出现的拥塞不会使源主机的发送速率降低，这对某些实时应用是很重要的，比如媒体通信，游戏；\n9. TCP首部开销（20字节）比UDP首部开销（8字节）要大\n10. UDP 的主机不需要维持复杂的连接状态表\n\n##### 什么时候选择TCP，什么时候选UDP？\n\n##### HTTP可以使用UDP吗？\n\n注：**http 3.0 使用udp实现**\n[https://zh.wikipedia.org/wiki/HTTP/3](https://zh.wikipedia.org/wiki/HTTP/3)\n\n##### 面向连接和无连接的区别\n无连接的网络服务（数据报服务）-- 面向连接的网络服务（虚电路服务）\n虚电路服务：首先建立连接，所有的数据包经过相同的路径，服务质量有较好的保证；\n数据报服务：每个数据包含目的地址，数据路由相互独立（路径可能变化）；网络尽最大努力交付数据，但不保证不丢失、不保证先后顺序、不保证在时限内交付；网络发生拥塞时，可能会将一些分组丢弃；\n\n![](https://cdn.nlark.com/yuque/0/2021/png/1431305/1628084520127-fb51536c-1fee-4fa4-a450-684dab556f9e.png#height=494&id=HncLV&originHeight=659&originWidth=769&originalType=binary&ratio=1&status=done&style=none&width=577)\n\n### TCP如何保证传输的可靠性\n1. 数据包校验\n2. 对失序数据包重新排序（TCP报文具有序列号）\n3. 丢弃重复数据\n4. 应答机制：接收方收到数据之后，会发送一个确认（通常延迟几分之一秒）；\n5. 超时重发：发送方发出数据之后，启动一个定时器，超时未收到接收方的确认，则重新发送这个数据；\n6. 流量控制：确保接收端能够接收发送方的数据而不会缓冲区溢出\n# 应用层：HTTP和HTTPS\n\n### HTTP和HTTPS有什么区别？\n1. 端口不同：HTTP使用的是80端口，HTTPS使用443端口；\n2. HTTP（超文本传输协议）信息是明文传输，HTTPS运行在SSL(Secure Socket Layer)之上，添加了加密和认证机制，更加安全；\n3. HTTPS由于加密解密会带来更大的CPU和内存开销；\n4. HTTPS通信需要证书，一般需要向证书颁发机构（CA）购买\n\n##### Https的连接过程？\n1. 客户端向服务器发送请求，同时发送客户端支持的一套加密规则（包括对称加密、非对称加密、摘要算法）；\n2. 服务器从中选出一组加密算法与HASH算法，并将自己的身份信息以证书的形式发回给浏览器。证书里面包含了网站地址，**加密公钥**（用于非对称加密），以及证书的颁发机构等信息（证书中的私钥只能用于服务器端进行解密）；\n3. 客户端验证服务器的合法性，包括：证书是否过期，CA 是否可靠，发行者证书的公钥能否正确解开服务器证书的“发行者的数字签名”，服务器证书上的域名是否和服务器的实际域名相匹配；\n4. 如果证书受信任，或者用户接收了不受信任的证书，浏览器会生成一个**随机密钥**（用于对称算法），并用服务器提供的公钥加密（采用非对称算法对密钥加密）；使用Hash算法对握手消息进行**摘要**计算，并对摘要使用之前产生的密钥加密（对称算法）；将加密后的随机密钥和摘要一起发送给服务器；\n5. 服务器使用自己的私钥解密，得到对称加密的密钥，用这个密钥解密出Hash摘要值，并验证握手消息是否一致；如果一致，服务器使用对称加密的密钥加密握手消息发给浏览器；\n6. 浏览器解密并验证摘要，若一致，则握手结束。之后的数据传送都使用对称加密的密钥进行加密\n\n总结：非对称加密算法用于在握手过程中加密生成的密码；对称加密算法用于对真正传输的数据进行加密；HASH算法用于验证数据的完整性。\n\n##### 输入 www.baidu.com，怎么变成 [https://www.baidu.com](https://www.baidu.com) 的，怎么确定用HTTP还是HTTPS？\n\n[你访问的网站是如何自动切换到 HTTPS 的？](https://www.sohu.com/a/136637876_487516)\n一种是原始的302跳转，服务器把所有的HTTp流量跳转到HTTPS。但这样有一个漏洞，就是中间人可能在第一次访问站点的时候就劫持。\n解决方法是引入HSTS机制，用户浏览器在访问站点的时候强制使用HTTPS。\n\n##### HTTPS连接的时候，怎么确定收到的包是服务器发来的（中间人攻击）？\n\n##### 什么是对称加密、非对称加密？区别是什么？\n- 对称加密：加密和解密采用相同的密钥。如：DES、RC2、RC4\n- 非对称加密：需要两个密钥：公钥和私钥。如果用公钥加密，需要用私钥才能解密。如：RSA\n- 区别：对称加密速度更快，通常用于大量数据的加密；非对称加密安全性更高（不需要传送私钥）\n\n##### 数字签名、报文摘要的原理\n- 发送者A用私钥进行签名，接收者B用公钥验证签名。因为除A外没有人有私钥，所以B相信签名是来自A。A不可抵赖，B也不能伪造报文。\n- 摘要算法:MD5、SHA\n\n### GET与POST的区别？\n1. GET是幂等的，即读取同一个资源，总是得到相同的数据，POST不是幂等的；\n2. GET一般用于从服务器获取资源，而POST有可能改变服务器上的资源；\n3. 请求形式上：GET请求的数据附在URL之后，在HTTP请求头中；POST请求的数据在请求体中；\n4. 安全性：GET请求可被缓存、收藏、保留到历史记录，且其请求数据明文出现在URL中。POST的参数不会被保存，安全性相对较高；\n5. GET只允许ASCII字符，POST对数据类型没有要求，也允许二进制数据；\n6. GET的长度有限制（操作系统或者浏览器），而POST数据大小无限制\n\n### Session与Cookie的区别？\nSession是服务器端保持状态的方案，Cookie是客户端保持状态的方案\nCookie保存在客户端本地，客户端请求服务器时会将Cookie一起提交；Session保存在服务端，通过检索Sessionid查看状态。保存Sessionid的方式可以采用Cookie，如果禁用了Cookie，可以使用URL重写机制（把会话ID保存在URL中）。\n\n### 从输入网址到获得页面的过程 (越详细越好)？\n1. 浏览器查询 DNS，获取域名对应的IP地址:具体过程包括浏览器搜索自身的DNS缓存、搜索操作系统的DNS缓存、读取本地的Host文件和向本地DNS服务器进行查询等。对于向本地DNS服务器进行查询，如果要查询的域名包含在本地配置区域资源中，则返回解析结果给客户机，完成域名解析(此解析具有权威性)；如果要查询的域名不由本地DNS服务器区域解析，但该服务器已缓存了此网址映射关系，则调用这个IP地址映射，完成域名解析（此解析不具有权威性）。如果本地域名服务器并未缓存该网址映射关系，那么将根据其设置发起递归查询或者迭代查询；\n2. 浏览器获得域名对应的IP地址以后，浏览器向服务器请求建立链接，发起三次握手；\n3. TCP/IP链接建立起来后，浏览器向服务器发送HTTP请求；\n4. 服务器接收到这个请求，并根据路径参数映射到特定的请求处理器进行处理，并将处理结果及相应的视图返回给浏览器；\n5. 浏览器解析并渲染视图，若遇到对js文件、css文件及图片等静态资源的引用，则重复上述步骤并向服务器请求这些资源；\n6. 浏览器根据其请求到的资源、数据渲染页面，最终向用户呈现一个完整的页面。\n\n### HTTP请求有哪些常见状态码？\n1. 2xx状态码：操作成功。200 OK\n2. 3xx状态码：重定向。301 永久重定向；302暂时重定向\n3. 4xx状态码：客户端错误。400 Bad Request；401 Unauthorized；403 Forbidden；404 Not Found；\n4. 5xx状态码：服务端错误。500服务器内部错误；501服务不可用\n\n### 什么是RIP (Routing Information Protocol, 距离矢量路由协议)? 算法是什么？\n每个路由器维护一张表，记录该路由器到其它网络的”跳数“，路由器到与其直接连接的网络的跳数是1，每多经过一个路由器跳数就加1；更新该表时和相邻路由器交换路由信息；路由器允许一个路径最多包含15个路由器，如果跳数为16，则不可达。交付数据报时优先选取距离最短的路径。\n\n（PS：RIP是应用层协议：[https://www.zhihu.com/question/19645407](https://www.zhihu.com/question/19645407)）\n\n- 实现简单，开销小\n- 随着网络规模扩大开销也会增大；\n- 最大距离为15，限制了网络的规模；\n- 当网络出现故障时，要经过较长的时间才能将此信息传递到所有路由器\n- 交换机数据链路层，根据MAC地址进行寻址\n\n# 网络层协议\n\n### IP地址的分类？\n![](https://cdn.nlark.com/yuque/0/2021/png/1431305/1628084593202-102c8a14-99c6-463c-8bde-866b86d19613.png)\n\n路由器仅根据网络号net-id来转发分组，当分组到达目的网络的路由器之后，再按照主机号host-id将分组交付给主机；同一网络上的所有主机的网络号相同。\n\n### 什么叫划分子网？\n\n从主机号host-id借用若干个比特作为子网号subnet-id；子网掩码：网络号和子网号都为1，主机号为0；数据报仍然先按照网络号找到目的网络，发送到路由器，路由器再按照网络号和子网号找到目的子网：将子网掩码与目标地址逐比特与操作，若结果为某个子网的网络地址，则送到该子网。\n\n### 什么是ARP协议 (Address Resolution Protocol)？\n\n\n**ARP协议完成了IP地址与物理地址的映射**。每一个主机都设有一个 ARP 高速缓存，里面有**所在的局域网**上的各主机和路由器的 IP 地址到硬件地址的映射表。当源主机要发送数据包到目的主机时，会先检查自己的ARP高速缓存中有没有目的主机的MAC地址，如果有，就直接将数据包发到这个MAC地址，如果没有，就向**所在的局域网**发起一个ARP请求的广播包（在发送自己的 ARP 请求时，同时会带上自己的 IP 地址到硬件地址的映射），收到请求的主机检查自己的IP地址和目的主机的IP地址是否一致，如果一致，则先保存源主机的映射到自己的ARP缓存，然后给源主机发送一个ARP响应数据包。源主机收到响应数据包之后，先添加目的主机的IP地址与MAC地址的映射，再进行数据传送。如果源主机一直没有收到响应，表示ARP查询失败。\n\n\n如果所要找的主机和源主机不在同一个局域网上，那么就要通过 ARP 找到一个位于本局域网上的某个路由器的硬件地址，然后把分组发送给这个路由器，让这个路由器把分组转发给下一个网络。剩下的工作就由下一个网络来做。\n\n\n### 什么是NAT (Network Address Translation, 网络地址转换)？\n\n\n用于解决内网中的主机要和因特网上的主机通信。由NAT路由器将主机的本地IP地址转换为全球IP地址，分为静态转换（转换得到的全球IP地址固定不变）和动态NAT转换。\n\n文章内容搬运自本人[语雀](https://www.yuque.com/docs/share/5b2ba306-5030-4cff-8c82-19ecb35b4f40)\n","slug":"面试八股文（一）——-计算机网络","published":1,"comments":1,"layout":"post","photos":[],"link":"","_id":"cktvosie900082svuc1lf6su1","content":"<meta name=\"referrer\" content=\"no-referrer\" />\n \n<h1 id=\"计算机网络体系结构\"><a href=\"#计算机网络体系结构\" class=\"headerlink\" title=\"计算机网络体系结构\"></a>计算机网络体系结构</h1><p><img src=\"https://cdn.nlark.com/yuque/0/2021/png/1431305/1628084581427-ad52128d-5d7c-4304-8fb3-8f8c6b59dc15.png\"></p>\n<ul>\n<li>Physical, Data Link, Network, Transport, Application</li>\n<li>应用层：常见协议：<ul>\n<li>FTP(21端口)：文件传输协议</li>\n<li>SSH(22端口)：远程登陆</li>\n<li>TELNET(23端口)：远程登录</li>\n<li>SMTP(25端口)：发送邮件</li>\n<li>POP3(110端口)：接收邮件</li>\n<li>HTTP(80端口)：超文本传输协议</li>\n<li>DNS(53端口)：运行在UDP上，域名解析服务</li>\n</ul>\n</li>\n<li>传输层：TCP/UDP</li>\n<li>网络层：IP、ARP、NAT、RIP…</li>\n<li>路由器网络层，根据IP地址进行寻址；</li>\n</ul>\n<p><a href=\"#%E4%BB%80%E4%B9%88%E6%98%AFNAT-Network-Address-Translation-%E7%BD%91%E7%BB%9C%E5%9C%B0%E5%9D%80%E8%BD%AC%E6%8D%A2\"></a></p>\n<h1 id=\"传输层：TCP和UDP\"><a href=\"#传输层：TCP和UDP\" class=\"headerlink\" title=\"传输层：TCP和UDP\"></a>传输层：TCP和UDP</h1><h3 id=\"什么是三次握手-three-way-handshake-？\"><a href=\"#什么是三次握手-three-way-handshake-？\" class=\"headerlink\" title=\"什么是三次握手 (three-way handshake)？\"></a>什么是三次握手 (three-way handshake)？</h3><p><img src=\"https://cdn.nlark.com/yuque/0/2021/png/1431305/1628083612400-05353867-b677-449d-bc87-378dc2ac5fbd.png\"></p>\n<ul>\n<li>第一次握手：Client将SYN置1，随机产生一个初始序列号seq发送给Server，进入SYN_SENT状态；</li>\n<li>第二次握手：Server收到Client的SYN=1之后，知道客户端请求建立连接，将自己的SYN置1，ACK置1，产生一个acknowledge number=sequence number+1，并随机产生一个自己的初始序列号，发送给客户端；进入SYN_RCVD状态；</li>\n<li>第三次握手：客户端检查acknowledge number是否为序列号+1，ACK是否为1，检查正确之后将自己的ACK置为1，产生一个acknowledge number=服务器发的序列号+1，发送给服务器；进入ESTABLISHED状态；服务器检查ACK为1和acknowledge number为序列号+1之后，也进入ESTABLISHED状态；完成三次握手，连接建立。</li>\n</ul>\n<h5 id=\"TCP建立连接可以两次握手吗？为什么\"><a href=\"#TCP建立连接可以两次握手吗？为什么\" class=\"headerlink\" title=\"TCP建立连接可以两次握手吗？为什么?\"></a>TCP建立连接可以两次握手吗？为什么?</h5><p>不可以。有两个原因：<br>首先，可能会出现<strong>已失效的连接请求报文段又传到了服务器端</strong>。</p>\n<blockquote>\n<p>client 发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达 server。本来这是一个早已失效的报文段。但 server 收到此失效的连接请求报文段后，就误认为是 client 再次发出的一个新的连接请求。于是就向 client 发出确认报文段，同意建立连接。假设不采用 “三次握手”，那么只要 server 发出确认，新的连接就建立了。由于现在 client 并没有发出建立连接的请求，因此不会理睬 server 的确认，也不会向 server 发送数据。但 server 却以为新的运输连接已经建立，并一直等待 client 发来数据。这样，server 的很多资源就白白浪费掉了。采用 “三次握手” 的办法可以防止上述现象发生。例如刚才那种情况，client 不会向 server 的确认发出确认。server 由于收不到确认，就知道 client 并没有要求建立连接。</p>\n</blockquote>\n<p>其次，两次握手无法保证Client正确接收第二次握手的报文（Server无法确认Client是否收到），也无法保证Client和Server之间成功互换初始序列号。</p>\n<h5 id=\"可以采用四次握手吗？为什么？\"><a href=\"#可以采用四次握手吗？为什么？\" class=\"headerlink\" title=\"可以采用四次握手吗？为什么？\"></a>可以采用四次握手吗？为什么？</h5><p>可以。但是会降低传输的效率。<br>四次握手是指：第二次握手：Server只发送ACK和acknowledge number；而Server的SYN和初始序列号在第三次握手时发送；原来协议中的第三次握手变为第四次握手。出于优化目的，四次握手中的二、三可以合并。</p>\n<h5 id=\"第三次握手中，如果客户端的ACK未送达服务器，会怎样？\"><a href=\"#第三次握手中，如果客户端的ACK未送达服务器，会怎样？\" class=\"headerlink\" title=\"第三次握手中，如果客户端的ACK未送达服务器，会怎样？\"></a>第三次握手中，如果客户端的ACK未送达服务器，会怎样？</h5><p>Server端：<br>由于Server没有收到ACK确认，因此会重发之前的SYN+ACK（默认重发五次，之后自动关闭连接进入CLOSED状态），Client收到后会重新传ACK给Server。<br>Client端，两种情况：</p>\n<ol>\n<li>在Server进行超时重发的过程中，如果Client向服务器发送数据，数据头部的ACK是为1的，所以服务器收到数据之后会读取 ACK number，进入 establish 状态 </li>\n<li>在Server进入CLOSED状态之后，如果Client向服务器发送数据，服务器会以RST包应答。</li>\n</ol>\n<h5 id=\"如果已经建立了连接，但客户端出现了故障怎么办？\"><a href=\"#如果已经建立了连接，但客户端出现了故障怎么办？\" class=\"headerlink\" title=\"如果已经建立了连接，但客户端出现了故障怎么办？\"></a>如果已经建立了连接，但客户端出现了故障怎么办？</h5><p>服务器每收到一次客户端的请求后都会重新复位一个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75秒钟发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。</p>\n<h5 id=\"初始序列号是什么？\"><a href=\"#初始序列号是什么？\" class=\"headerlink\" title=\"初始序列号是什么？\"></a>初始序列号是什么？</h5><p>TCP连接的一方A，随机选择一个32位的序列号（Sequence Number）作为发送数据的初始序列号（Initial Sequence Number，ISN），比如为1000，以该序列号为原点，对要传送的数据进行编号：1001、1002…三次握手时，把这个初始序列号传送给另一方B，以便在传输数据时，B可以确认什么样的数据编号是合法的；同时在进行数据传输时，A还可以确认B收到的每一个字节，如果A收到了B的确认编号（acknowledge number）是2001，就说明编号为1001-2000的数据已经被B成功接受。</p>\n<h3 id=\"什么是四次挥手？\"><a href=\"#什么是四次挥手？\" class=\"headerlink\" title=\"什么是四次挥手？\"></a>什么是四次挥手？</h3><p><img src=\"https://cdn.nlark.com/yuque/0/2021/png/1431305/1628083644967-a1117a3a-ad00-494a-bdf5-f357adfef3b9.png\"></p>\n<ul>\n<li>第一次挥手：Client将FIN置为1，发送一个序列号seq给Server；进入FIN_WAIT_1状态；</li>\n<li>第二次挥手：Server收到FIN之后，发送一个ACK=1，acknowledge number=收到的序列号+1；进入CLOSE_WAIT状态。此时客户端已经没有要发送的数据了，但仍可以接受服务器发来的数据。</li>\n<li>第三次挥手：Server将FIN置1，发送一个序列号给Client；进入LAST_ACK状态；</li>\n<li>第四次挥手：Client收到服务器的FIN后，进入TIME_WAIT状态；接着将ACK置1，发送一个acknowledge number=序列号+1给服务器；服务器收到后，确认acknowledge number后，变为CLOSED状态，不再向客户端发送数据。客户端等待2*MSL（报文段最长寿命）时间后，也进入CLOSED状态。完成四次挥手。</li>\n</ul>\n<h5 id=\"为什么不能把服务器发送的ACK和FIN合并起来，变成三次挥手（CLOSE-WAIT状态意义是什么）？\"><a href=\"#为什么不能把服务器发送的ACK和FIN合并起来，变成三次挥手（CLOSE-WAIT状态意义是什么）？\" class=\"headerlink\" title=\"为什么不能把服务器发送的ACK和FIN合并起来，变成三次挥手（CLOSE_WAIT状态意义是什么）？\"></a>为什么不能把服务器发送的ACK和FIN合并起来，变成三次挥手（CLOSE_WAIT状态意义是什么）？</h5><p>因为服务器收到客户端断开连接的请求时，可能还有一些数据没有发完，这时先回复ACK，表示接收到了断开连接的请求。等到数据发完之后再发FIN，断开服务器到客户端的数据传送。</p>\n<h5 id=\"如果第二次挥手时服务器的ACK没有送达客户端，会怎样？\"><a href=\"#如果第二次挥手时服务器的ACK没有送达客户端，会怎样？\" class=\"headerlink\" title=\"如果第二次挥手时服务器的ACK没有送达客户端，会怎样？\"></a>如果第二次挥手时服务器的ACK没有送达客户端，会怎样？</h5><p>客户端没有收到ACK确认，会重新发送FIN请求。</p>\n<h5 id=\"客户端TIME-WAIT状态的意义是什么？\"><a href=\"#客户端TIME-WAIT状态的意义是什么？\" class=\"headerlink\" title=\"客户端TIME_WAIT状态的意义是什么？\"></a>客户端TIME_WAIT状态的意义是什么？</h5><p>第四次挥手时，客户端发送给服务器的ACK有可能丢失，TIME_WAIT状态就是用来重发可能丢失的ACK报文。如果Server没有收到ACK，就会重发FIN，如果Client在2*MSL的时间内收到了FIN，就会重新发送ACK并再次等待2MSL，防止Server没有收到ACK而不断重发FIN。<br>MSL(Maximum Segment Lifetime)，指一个片段在网络中最大的存活时间，2MSL就是一个发送和一个回复所需的最大时间。如果直到2MSL，Client都没有再次收到FIN，那么Client推断ACK已经被成功接收，则结束TCP连接。</p>\n<h3 id=\"TCP如何实现流量控制？\"><a href=\"#TCP如何实现流量控制？\" class=\"headerlink\" title=\"TCP如何实现流量控制？\"></a>TCP如何实现流量控制？</h3><p><img src=\"https://cdn.nlark.com/yuque/0/2021/png/1431305/1628083671501-2d938176-eced-4414-b6aa-fbc32d323ae9.png\"></p>\n<p>使用滑动窗口协议实现流量控制。防止发送方发送速率太快，接收方缓存区不够导致溢出。接收方会维护一个接收窗口 receiver window（窗口大小单位是字节），接受窗口的大小是根据自己的资源情况动态调整的，在返回ACK时将接受窗口大小放在TCP报文中的窗口字段告知发送方。发送窗口的大小不能超过接受窗口的大小，只有当发送方发送并收到确认之后，才能将发送窗口右移。</p>\n<p>发送窗口的上限为接受窗口和拥塞窗口中的较小值。接受窗口表明了接收方的接收能力，拥塞窗口表明了网络的传送能力。</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2021/gif/1431305/1628083685654-29996960-ed15-47f4-99bf-246b8ac30214.gif\"></p>\n<h5 id=\"什么是零窗口（接收窗口为0时会怎样）？\"><a href=\"#什么是零窗口（接收窗口为0时会怎样）？\" class=\"headerlink\" title=\"什么是零窗口（接收窗口为0时会怎样）？\"></a>什么是零窗口（接收窗口为0时会怎样）？</h5><p>如果接收方没有能力接收数据，就会将接收窗口设置为0，这时发送方必须暂停发送数据，但是会启动一个持续计时器(persistence timer)，到期后发送一个大小为1字节的探测数据包，以查看接收窗口状态。如果接收方能够接收数据，就会在返回的报文中更新接收窗口大小，恢复数据传送。</p>\n<h3 id=\"TCP的拥塞控制是怎么实现的？\"><a href=\"#TCP的拥塞控制是怎么实现的？\" class=\"headerlink\" title=\"TCP的拥塞控制是怎么实现的？\"></a>TCP的拥塞控制是怎么实现的？</h3><p><img src=\"https://cdn.nlark.com/yuque/0/2021/png/1431305/1628083709929-6e2bfba1-63ca-4742-a80a-256a93b0f159.png\"></p>\n<p>拥塞控制主要由四个算法组成：<strong>慢启动（Slow Start）、拥塞避免（Congestion voidance）、快重传 （Fast Retransmit）、快恢复（Fast Recovery）</strong></p>\n<ol>\n<li>慢启动：刚开始发送数据时，先把拥塞窗口（congestion window）设置为一个最大报文段MSS的数值，每收到一个新的确认报文之后，就把拥塞窗口加1个MSS。这样每经过一个传输轮次（或者说是每经过一个往返时间RTT），拥塞窗口的大小就会加倍<br><img src=\"https://cdn.nlark.com/yuque/0/2021/png/1431305/1628083774060-71278d40-0b39-4e15-9dd1-22534e2c90d8.png\"></li>\n</ol>\n<ol start=\"2\">\n<li>拥塞避免：当拥塞窗口的大小达到慢开始门限(slow start threshold)时，开始执行拥塞避免算法，拥塞窗口大小不再指数增加，而是线性增加，即每经过一个传输轮次只增加1MSS.</li>\n</ol>\n<blockquote>\n<p>无论在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞（其根据就是没有收到确认），就要把慢开始门限ssthresh设置为出现拥塞时的发送方窗口值的一半（但不能小于2）。然后把拥塞窗口cwnd重新设置为1，执行慢开始算法。<strong>（这是不使用快重传的情况）</strong></p>\n</blockquote>\n<ol start=\"3\">\n<li>快重传：快重传要求接收方在收到一个失序的报文段后就立即发出<strong>重复确认</strong>（为的是使发送方及早知道有报文段没有到达对方）而不要等到自己发送数据时捎带确认。快重传算法规定，发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段，而不必继续等待设置的重传计时器时间到期。</li>\n</ol>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2021/png/1431305/1628083866222-2e727029-b6f2-495e-97f2-e4b7b49cd16e.png\"></p>\n<ol start=\"4\">\n<li>快恢复：当发送方连续收到三个重复确认时，就把慢开始门限减半，然后执行拥塞避免算法。不执行慢开始算法的原因：因为如果网络出现拥塞的话就不会收到好几个重复的确认，所以发送方认为现在网络可能没有出现拥塞。<br>也有的快重传是把开始时的拥塞窗口cwnd值再增大一点，即等于 ssthresh + 3*MSS 。这样做的理由是：既然发送方收到三个重复的确认，就表明有三个分组已经离开了网络。这三个分组不再消耗网络的资源而是停留在接收方的缓存中。可见现在网络中减少了三个分组。因此可以适当把拥塞窗口扩大些。<h3 id=\"TCP如何最大利用带宽？\"><a href=\"#TCP如何最大利用带宽？\" class=\"headerlink\" title=\"TCP如何最大利用带宽？\"></a>TCP如何最大利用带宽？</h3>TCP速率受到三个因素影响</li>\n</ol>\n<ul>\n<li>窗口：即滑动窗口大小，见<a href=\"#TCP%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6\">TCP如何实现流量控制？</a></li>\n<li>带宽：这里带宽是指单位时间内从发送端到接收端所能通过的“最高数据率”，是一种硬件限制。TCP发送端和接收端的数据传输数不可能超过两点间的带宽限制。发送端和接收端之间带宽取所通过线路的带宽最小值（如通过互联网连接）。</li>\n<li>RTT：即Round Trip Time，表示从发送端到接收端的一去一回需要的时间，TCP在数据传输过程中会对RTT进行采样（即对发送的数据包及其ACK的时间差进行测量，并根据测量值更新RTT值），TCP根据得到的RTT值更新RTO值，即Retransmission TimeOut，就是重传间隔，发送端对每个发出的数据包进行计时，如果在RTO时间内没有收到所发出的数据包的对应ACK，则任务数据包丢失，将重传数据。一般RTO值都比采样得到的RTT值要大。</li>\n</ul>\n<p>带宽时延乘积=带宽*RTT，实际上等于发送端到接收端单向通道的数据容积的两倍，这里单向通道的数据容积可以这样来理解，单向通道看成是一条单行道马路，带宽就是马路的车道数，路上跑的汽车就是数据（不过这里所有汽车的速率都是一样的，且不会有人想超车，大家齐头并进），那么单向通道的数据容积就是这条单行道上摆满车，一共可以摆多少辆。带宽就是马路的车道数，带宽数乘以单向通道的数据容积就是路面上所能容纳的全部数据量。当路面上已经摆满的时候，就不能再往里面放了。<br><img src=\"https://cdn.nlark.com/yuque/0/2021/png/1431305/1628084389045-9ba4652e-2456-424e-b530-bd95b496004d.png\"></p>\n<h3 id=\"TCP与UDP的区别\"><a href=\"#TCP与UDP的区别\" class=\"headerlink\" title=\"TCP与UDP的区别\"></a>TCP与UDP的区别</h3><ol>\n<li>TCP是面向连接的，UDP是无连接的；</li>\n<li>UDP发送数据之前不需要建立连接</li>\n<li>TCP是可靠的，UDP不可靠； </li>\n<li>UDP接收方收到报文后，不需要给出任何确认</li>\n<li>TCP只支持点对点通信，UDP支持一对一、一对多、多对一、多对多；</li>\n<li>TCP是面向字节流的，UDP是面向报文的； </li>\n<li>面向字节流是指发送数据时以字节为单位，一个数据包可以拆分成若干组进行发送，而UDP一个报文只能一次发完。</li>\n<li>TCP有拥塞控制机制，UDP没有。网络出现的拥塞不会使源主机的发送速率降低，这对某些实时应用是很重要的，比如媒体通信，游戏；</li>\n<li>TCP首部开销（20字节）比UDP首部开销（8字节）要大</li>\n<li>UDP 的主机不需要维持复杂的连接状态表</li>\n</ol>\n<h5 id=\"什么时候选择TCP，什么时候选UDP？\"><a href=\"#什么时候选择TCP，什么时候选UDP？\" class=\"headerlink\" title=\"什么时候选择TCP，什么时候选UDP？\"></a>什么时候选择TCP，什么时候选UDP？</h5><h5 id=\"HTTP可以使用UDP吗？\"><a href=\"#HTTP可以使用UDP吗？\" class=\"headerlink\" title=\"HTTP可以使用UDP吗？\"></a>HTTP可以使用UDP吗？</h5><p>注：<strong>http 3.0 使用udp实现</strong><br><a href=\"https://zh.wikipedia.org/wiki/HTTP/3\">https://zh.wikipedia.org/wiki/HTTP/3</a></p>\n<h5 id=\"面向连接和无连接的区别\"><a href=\"#面向连接和无连接的区别\" class=\"headerlink\" title=\"面向连接和无连接的区别\"></a>面向连接和无连接的区别</h5><p>无连接的网络服务（数据报服务）– 面向连接的网络服务（虚电路服务）<br>虚电路服务：首先建立连接，所有的数据包经过相同的路径，服务质量有较好的保证；<br>数据报服务：每个数据包含目的地址，数据路由相互独立（路径可能变化）；网络尽最大努力交付数据，但不保证不丢失、不保证先后顺序、不保证在时限内交付；网络发生拥塞时，可能会将一些分组丢弃；</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2021/png/1431305/1628084520127-fb51536c-1fee-4fa4-a450-684dab556f9e.png#height=494&id=HncLV&originHeight=659&originWidth=769&originalType=binary&ratio=1&status=done&style=none&width=577\"></p>\n<h3 id=\"TCP如何保证传输的可靠性\"><a href=\"#TCP如何保证传输的可靠性\" class=\"headerlink\" title=\"TCP如何保证传输的可靠性\"></a>TCP如何保证传输的可靠性</h3><ol>\n<li>数据包校验</li>\n<li>对失序数据包重新排序（TCP报文具有序列号）</li>\n<li>丢弃重复数据</li>\n<li>应答机制：接收方收到数据之后，会发送一个确认（通常延迟几分之一秒）；</li>\n<li>超时重发：发送方发出数据之后，启动一个定时器，超时未收到接收方的确认，则重新发送这个数据；</li>\n<li>流量控制：确保接收端能够接收发送方的数据而不会缓冲区溢出<h1 id=\"应用层：HTTP和HTTPS\"><a href=\"#应用层：HTTP和HTTPS\" class=\"headerlink\" title=\"应用层：HTTP和HTTPS\"></a>应用层：HTTP和HTTPS</h1></li>\n</ol>\n<h3 id=\"HTTP和HTTPS有什么区别？\"><a href=\"#HTTP和HTTPS有什么区别？\" class=\"headerlink\" title=\"HTTP和HTTPS有什么区别？\"></a>HTTP和HTTPS有什么区别？</h3><ol>\n<li>端口不同：HTTP使用的是80端口，HTTPS使用443端口；</li>\n<li>HTTP（超文本传输协议）信息是明文传输，HTTPS运行在SSL(Secure Socket Layer)之上，添加了加密和认证机制，更加安全；</li>\n<li>HTTPS由于加密解密会带来更大的CPU和内存开销；</li>\n<li>HTTPS通信需要证书，一般需要向证书颁发机构（CA）购买</li>\n</ol>\n<h5 id=\"Https的连接过程？\"><a href=\"#Https的连接过程？\" class=\"headerlink\" title=\"Https的连接过程？\"></a>Https的连接过程？</h5><ol>\n<li>客户端向服务器发送请求，同时发送客户端支持的一套加密规则（包括对称加密、非对称加密、摘要算法）；</li>\n<li>服务器从中选出一组加密算法与HASH算法，并将自己的身份信息以证书的形式发回给浏览器。证书里面包含了网站地址，<strong>加密公钥</strong>（用于非对称加密），以及证书的颁发机构等信息（证书中的私钥只能用于服务器端进行解密）；</li>\n<li>客户端验证服务器的合法性，包括：证书是否过期，CA 是否可靠，发行者证书的公钥能否正确解开服务器证书的“发行者的数字签名”，服务器证书上的域名是否和服务器的实际域名相匹配；</li>\n<li>如果证书受信任，或者用户接收了不受信任的证书，浏览器会生成一个<strong>随机密钥</strong>（用于对称算法），并用服务器提供的公钥加密（采用非对称算法对密钥加密）；使用Hash算法对握手消息进行<strong>摘要</strong>计算，并对摘要使用之前产生的密钥加密（对称算法）；将加密后的随机密钥和摘要一起发送给服务器；</li>\n<li>服务器使用自己的私钥解密，得到对称加密的密钥，用这个密钥解密出Hash摘要值，并验证握手消息是否一致；如果一致，服务器使用对称加密的密钥加密握手消息发给浏览器；</li>\n<li>浏览器解密并验证摘要，若一致，则握手结束。之后的数据传送都使用对称加密的密钥进行加密</li>\n</ol>\n<p>总结：非对称加密算法用于在握手过程中加密生成的密码；对称加密算法用于对真正传输的数据进行加密；HASH算法用于验证数据的完整性。</p>\n<h5 id=\"输入-www-baidu-com，怎么变成-https-www-baidu-com-的，怎么确定用HTTP还是HTTPS？\"><a href=\"#输入-www-baidu-com，怎么变成-https-www-baidu-com-的，怎么确定用HTTP还是HTTPS？\" class=\"headerlink\" title=\"输入 www.baidu.com，怎么变成 https://www.baidu.com 的，怎么确定用HTTP还是HTTPS？\"></a>输入 <a href=\"http://www.baidu.com,怎么变成/\">www.baidu.com，怎么变成</a> <a href=\"https://www.baidu.com/\">https://www.baidu.com</a> 的，怎么确定用HTTP还是HTTPS？</h5><p><a href=\"https://www.sohu.com/a/136637876_487516\">你访问的网站是如何自动切换到 HTTPS 的？</a><br>一种是原始的302跳转，服务器把所有的HTTp流量跳转到HTTPS。但这样有一个漏洞，就是中间人可能在第一次访问站点的时候就劫持。<br>解决方法是引入HSTS机制，用户浏览器在访问站点的时候强制使用HTTPS。</p>\n<h5 id=\"HTTPS连接的时候，怎么确定收到的包是服务器发来的（中间人攻击）？\"><a href=\"#HTTPS连接的时候，怎么确定收到的包是服务器发来的（中间人攻击）？\" class=\"headerlink\" title=\"HTTPS连接的时候，怎么确定收到的包是服务器发来的（中间人攻击）？\"></a>HTTPS连接的时候，怎么确定收到的包是服务器发来的（中间人攻击）？</h5><h5 id=\"什么是对称加密、非对称加密？区别是什么？\"><a href=\"#什么是对称加密、非对称加密？区别是什么？\" class=\"headerlink\" title=\"什么是对称加密、非对称加密？区别是什么？\"></a>什么是对称加密、非对称加密？区别是什么？</h5><ul>\n<li>对称加密：加密和解密采用相同的密钥。如：DES、RC2、RC4</li>\n<li>非对称加密：需要两个密钥：公钥和私钥。如果用公钥加密，需要用私钥才能解密。如：RSA</li>\n<li>区别：对称加密速度更快，通常用于大量数据的加密；非对称加密安全性更高（不需要传送私钥）</li>\n</ul>\n<h5 id=\"数字签名、报文摘要的原理\"><a href=\"#数字签名、报文摘要的原理\" class=\"headerlink\" title=\"数字签名、报文摘要的原理\"></a>数字签名、报文摘要的原理</h5><ul>\n<li>发送者A用私钥进行签名，接收者B用公钥验证签名。因为除A外没有人有私钥，所以B相信签名是来自A。A不可抵赖，B也不能伪造报文。</li>\n<li>摘要算法:MD5、SHA</li>\n</ul>\n<h3 id=\"GET与POST的区别？\"><a href=\"#GET与POST的区别？\" class=\"headerlink\" title=\"GET与POST的区别？\"></a>GET与POST的区别？</h3><ol>\n<li>GET是幂等的，即读取同一个资源，总是得到相同的数据，POST不是幂等的；</li>\n<li>GET一般用于从服务器获取资源，而POST有可能改变服务器上的资源；</li>\n<li>请求形式上：GET请求的数据附在URL之后，在HTTP请求头中；POST请求的数据在请求体中；</li>\n<li>安全性：GET请求可被缓存、收藏、保留到历史记录，且其请求数据明文出现在URL中。POST的参数不会被保存，安全性相对较高；</li>\n<li>GET只允许ASCII字符，POST对数据类型没有要求，也允许二进制数据；</li>\n<li>GET的长度有限制（操作系统或者浏览器），而POST数据大小无限制</li>\n</ol>\n<h3 id=\"Session与Cookie的区别？\"><a href=\"#Session与Cookie的区别？\" class=\"headerlink\" title=\"Session与Cookie的区别？\"></a>Session与Cookie的区别？</h3><p>Session是服务器端保持状态的方案，Cookie是客户端保持状态的方案<br>Cookie保存在客户端本地，客户端请求服务器时会将Cookie一起提交；Session保存在服务端，通过检索Sessionid查看状态。保存Sessionid的方式可以采用Cookie，如果禁用了Cookie，可以使用URL重写机制（把会话ID保存在URL中）。</p>\n<h3 id=\"从输入网址到获得页面的过程-越详细越好-？\"><a href=\"#从输入网址到获得页面的过程-越详细越好-？\" class=\"headerlink\" title=\"从输入网址到获得页面的过程 (越详细越好)？\"></a>从输入网址到获得页面的过程 (越详细越好)？</h3><ol>\n<li>浏览器查询 DNS，获取域名对应的IP地址:具体过程包括浏览器搜索自身的DNS缓存、搜索操作系统的DNS缓存、读取本地的Host文件和向本地DNS服务器进行查询等。对于向本地DNS服务器进行查询，如果要查询的域名包含在本地配置区域资源中，则返回解析结果给客户机，完成域名解析(此解析具有权威性)；如果要查询的域名不由本地DNS服务器区域解析，但该服务器已缓存了此网址映射关系，则调用这个IP地址映射，完成域名解析（此解析不具有权威性）。如果本地域名服务器并未缓存该网址映射关系，那么将根据其设置发起递归查询或者迭代查询；</li>\n<li>浏览器获得域名对应的IP地址以后，浏览器向服务器请求建立链接，发起三次握手；</li>\n<li>TCP/IP链接建立起来后，浏览器向服务器发送HTTP请求；</li>\n<li>服务器接收到这个请求，并根据路径参数映射到特定的请求处理器进行处理，并将处理结果及相应的视图返回给浏览器；</li>\n<li>浏览器解析并渲染视图，若遇到对js文件、css文件及图片等静态资源的引用，则重复上述步骤并向服务器请求这些资源；</li>\n<li>浏览器根据其请求到的资源、数据渲染页面，最终向用户呈现一个完整的页面。</li>\n</ol>\n<h3 id=\"HTTP请求有哪些常见状态码？\"><a href=\"#HTTP请求有哪些常见状态码？\" class=\"headerlink\" title=\"HTTP请求有哪些常见状态码？\"></a>HTTP请求有哪些常见状态码？</h3><ol>\n<li>2xx状态码：操作成功。200 OK</li>\n<li>3xx状态码：重定向。301 永久重定向；302暂时重定向</li>\n<li>4xx状态码：客户端错误。400 Bad Request；401 Unauthorized；403 Forbidden；404 Not Found；</li>\n<li>5xx状态码：服务端错误。500服务器内部错误；501服务不可用</li>\n</ol>\n<h3 id=\"什么是RIP-Routing-Information-Protocol-距离矢量路由协议-算法是什么？\"><a href=\"#什么是RIP-Routing-Information-Protocol-距离矢量路由协议-算法是什么？\" class=\"headerlink\" title=\"什么是RIP (Routing Information Protocol, 距离矢量路由协议)? 算法是什么？\"></a>什么是RIP (Routing Information Protocol, 距离矢量路由协议)? 算法是什么？</h3><p>每个路由器维护一张表，记录该路由器到其它网络的”跳数“，路由器到与其直接连接的网络的跳数是1，每多经过一个路由器跳数就加1；更新该表时和相邻路由器交换路由信息；路由器允许一个路径最多包含15个路由器，如果跳数为16，则不可达。交付数据报时优先选取距离最短的路径。</p>\n<p>（PS：RIP是应用层协议：<a href=\"https://www.zhihu.com/question/19645407\">https://www.zhihu.com/question/19645407</a>）</p>\n<ul>\n<li>实现简单，开销小</li>\n<li>随着网络规模扩大开销也会增大；</li>\n<li>最大距离为15，限制了网络的规模；</li>\n<li>当网络出现故障时，要经过较长的时间才能将此信息传递到所有路由器</li>\n<li>交换机数据链路层，根据MAC地址进行寻址</li>\n</ul>\n<h1 id=\"网络层协议\"><a href=\"#网络层协议\" class=\"headerlink\" title=\"网络层协议\"></a>网络层协议</h1><h3 id=\"IP地址的分类？\"><a href=\"#IP地址的分类？\" class=\"headerlink\" title=\"IP地址的分类？\"></a>IP地址的分类？</h3><p><img src=\"https://cdn.nlark.com/yuque/0/2021/png/1431305/1628084593202-102c8a14-99c6-463c-8bde-866b86d19613.png\"></p>\n<p>路由器仅根据网络号net-id来转发分组，当分组到达目的网络的路由器之后，再按照主机号host-id将分组交付给主机；同一网络上的所有主机的网络号相同。</p>\n<h3 id=\"什么叫划分子网？\"><a href=\"#什么叫划分子网？\" class=\"headerlink\" title=\"什么叫划分子网？\"></a>什么叫划分子网？</h3><p>从主机号host-id借用若干个比特作为子网号subnet-id；子网掩码：网络号和子网号都为1，主机号为0；数据报仍然先按照网络号找到目的网络，发送到路由器，路由器再按照网络号和子网号找到目的子网：将子网掩码与目标地址逐比特与操作，若结果为某个子网的网络地址，则送到该子网。</p>\n<h3 id=\"什么是ARP协议-Address-Resolution-Protocol-？\"><a href=\"#什么是ARP协议-Address-Resolution-Protocol-？\" class=\"headerlink\" title=\"什么是ARP协议 (Address Resolution Protocol)？\"></a>什么是ARP协议 (Address Resolution Protocol)？</h3><p><strong>ARP协议完成了IP地址与物理地址的映射</strong>。每一个主机都设有一个 ARP 高速缓存，里面有<strong>所在的局域网</strong>上的各主机和路由器的 IP 地址到硬件地址的映射表。当源主机要发送数据包到目的主机时，会先检查自己的ARP高速缓存中有没有目的主机的MAC地址，如果有，就直接将数据包发到这个MAC地址，如果没有，就向<strong>所在的局域网</strong>发起一个ARP请求的广播包（在发送自己的 ARP 请求时，同时会带上自己的 IP 地址到硬件地址的映射），收到请求的主机检查自己的IP地址和目的主机的IP地址是否一致，如果一致，则先保存源主机的映射到自己的ARP缓存，然后给源主机发送一个ARP响应数据包。源主机收到响应数据包之后，先添加目的主机的IP地址与MAC地址的映射，再进行数据传送。如果源主机一直没有收到响应，表示ARP查询失败。</p>\n<p>如果所要找的主机和源主机不在同一个局域网上，那么就要通过 ARP 找到一个位于本局域网上的某个路由器的硬件地址，然后把分组发送给这个路由器，让这个路由器把分组转发给下一个网络。剩下的工作就由下一个网络来做。</p>\n<h3 id=\"什么是NAT-Network-Address-Translation-网络地址转换-？\"><a href=\"#什么是NAT-Network-Address-Translation-网络地址转换-？\" class=\"headerlink\" title=\"什么是NAT (Network Address Translation, 网络地址转换)？\"></a>什么是NAT (Network Address Translation, 网络地址转换)？</h3><p>用于解决内网中的主机要和因特网上的主机通信。由NAT路由器将主机的本地IP地址转换为全球IP地址，分为静态转换（转换得到的全球IP地址固定不变）和动态NAT转换。</p>\n<p>文章内容搬运自本人<a href=\"https://www.yuque.com/docs/share/5b2ba306-5030-4cff-8c82-19ecb35b4f40\">语雀</a></p>\n","site":{"data":{}},"length":8852,"excerpt":"","more":"<meta name=\"referrer\" content=\"no-referrer\" />\n \n<h1 id=\"计算机网络体系结构\"><a href=\"#计算机网络体系结构\" class=\"headerlink\" title=\"计算机网络体系结构\"></a>计算机网络体系结构</h1><p><img src=\"https://cdn.nlark.com/yuque/0/2021/png/1431305/1628084581427-ad52128d-5d7c-4304-8fb3-8f8c6b59dc15.png\"></p>\n<ul>\n<li>Physical, Data Link, Network, Transport, Application</li>\n<li>应用层：常见协议：<ul>\n<li>FTP(21端口)：文件传输协议</li>\n<li>SSH(22端口)：远程登陆</li>\n<li>TELNET(23端口)：远程登录</li>\n<li>SMTP(25端口)：发送邮件</li>\n<li>POP3(110端口)：接收邮件</li>\n<li>HTTP(80端口)：超文本传输协议</li>\n<li>DNS(53端口)：运行在UDP上，域名解析服务</li>\n</ul>\n</li>\n<li>传输层：TCP/UDP</li>\n<li>网络层：IP、ARP、NAT、RIP…</li>\n<li>路由器网络层，根据IP地址进行寻址；</li>\n</ul>\n<p><a href=\"#%E4%BB%80%E4%B9%88%E6%98%AFNAT-Network-Address-Translation-%E7%BD%91%E7%BB%9C%E5%9C%B0%E5%9D%80%E8%BD%AC%E6%8D%A2\"></a></p>\n<h1 id=\"传输层：TCP和UDP\"><a href=\"#传输层：TCP和UDP\" class=\"headerlink\" title=\"传输层：TCP和UDP\"></a>传输层：TCP和UDP</h1><h3 id=\"什么是三次握手-three-way-handshake-？\"><a href=\"#什么是三次握手-three-way-handshake-？\" class=\"headerlink\" title=\"什么是三次握手 (three-way handshake)？\"></a>什么是三次握手 (three-way handshake)？</h3><p><img src=\"https://cdn.nlark.com/yuque/0/2021/png/1431305/1628083612400-05353867-b677-449d-bc87-378dc2ac5fbd.png\"></p>\n<ul>\n<li>第一次握手：Client将SYN置1，随机产生一个初始序列号seq发送给Server，进入SYN_SENT状态；</li>\n<li>第二次握手：Server收到Client的SYN=1之后，知道客户端请求建立连接，将自己的SYN置1，ACK置1，产生一个acknowledge number=sequence number+1，并随机产生一个自己的初始序列号，发送给客户端；进入SYN_RCVD状态；</li>\n<li>第三次握手：客户端检查acknowledge number是否为序列号+1，ACK是否为1，检查正确之后将自己的ACK置为1，产生一个acknowledge number=服务器发的序列号+1，发送给服务器；进入ESTABLISHED状态；服务器检查ACK为1和acknowledge number为序列号+1之后，也进入ESTABLISHED状态；完成三次握手，连接建立。</li>\n</ul>\n<h5 id=\"TCP建立连接可以两次握手吗？为什么\"><a href=\"#TCP建立连接可以两次握手吗？为什么\" class=\"headerlink\" title=\"TCP建立连接可以两次握手吗？为什么?\"></a>TCP建立连接可以两次握手吗？为什么?</h5><p>不可以。有两个原因：<br>首先，可能会出现<strong>已失效的连接请求报文段又传到了服务器端</strong>。</p>\n<blockquote>\n<p>client 发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达 server。本来这是一个早已失效的报文段。但 server 收到此失效的连接请求报文段后，就误认为是 client 再次发出的一个新的连接请求。于是就向 client 发出确认报文段，同意建立连接。假设不采用 “三次握手”，那么只要 server 发出确认，新的连接就建立了。由于现在 client 并没有发出建立连接的请求，因此不会理睬 server 的确认，也不会向 server 发送数据。但 server 却以为新的运输连接已经建立，并一直等待 client 发来数据。这样，server 的很多资源就白白浪费掉了。采用 “三次握手” 的办法可以防止上述现象发生。例如刚才那种情况，client 不会向 server 的确认发出确认。server 由于收不到确认，就知道 client 并没有要求建立连接。</p>\n</blockquote>\n<p>其次，两次握手无法保证Client正确接收第二次握手的报文（Server无法确认Client是否收到），也无法保证Client和Server之间成功互换初始序列号。</p>\n<h5 id=\"可以采用四次握手吗？为什么？\"><a href=\"#可以采用四次握手吗？为什么？\" class=\"headerlink\" title=\"可以采用四次握手吗？为什么？\"></a>可以采用四次握手吗？为什么？</h5><p>可以。但是会降低传输的效率。<br>四次握手是指：第二次握手：Server只发送ACK和acknowledge number；而Server的SYN和初始序列号在第三次握手时发送；原来协议中的第三次握手变为第四次握手。出于优化目的，四次握手中的二、三可以合并。</p>\n<h5 id=\"第三次握手中，如果客户端的ACK未送达服务器，会怎样？\"><a href=\"#第三次握手中，如果客户端的ACK未送达服务器，会怎样？\" class=\"headerlink\" title=\"第三次握手中，如果客户端的ACK未送达服务器，会怎样？\"></a>第三次握手中，如果客户端的ACK未送达服务器，会怎样？</h5><p>Server端：<br>由于Server没有收到ACK确认，因此会重发之前的SYN+ACK（默认重发五次，之后自动关闭连接进入CLOSED状态），Client收到后会重新传ACK给Server。<br>Client端，两种情况：</p>\n<ol>\n<li>在Server进行超时重发的过程中，如果Client向服务器发送数据，数据头部的ACK是为1的，所以服务器收到数据之后会读取 ACK number，进入 establish 状态 </li>\n<li>在Server进入CLOSED状态之后，如果Client向服务器发送数据，服务器会以RST包应答。</li>\n</ol>\n<h5 id=\"如果已经建立了连接，但客户端出现了故障怎么办？\"><a href=\"#如果已经建立了连接，但客户端出现了故障怎么办？\" class=\"headerlink\" title=\"如果已经建立了连接，但客户端出现了故障怎么办？\"></a>如果已经建立了连接，但客户端出现了故障怎么办？</h5><p>服务器每收到一次客户端的请求后都会重新复位一个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75秒钟发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。</p>\n<h5 id=\"初始序列号是什么？\"><a href=\"#初始序列号是什么？\" class=\"headerlink\" title=\"初始序列号是什么？\"></a>初始序列号是什么？</h5><p>TCP连接的一方A，随机选择一个32位的序列号（Sequence Number）作为发送数据的初始序列号（Initial Sequence Number，ISN），比如为1000，以该序列号为原点，对要传送的数据进行编号：1001、1002…三次握手时，把这个初始序列号传送给另一方B，以便在传输数据时，B可以确认什么样的数据编号是合法的；同时在进行数据传输时，A还可以确认B收到的每一个字节，如果A收到了B的确认编号（acknowledge number）是2001，就说明编号为1001-2000的数据已经被B成功接受。</p>\n<h3 id=\"什么是四次挥手？\"><a href=\"#什么是四次挥手？\" class=\"headerlink\" title=\"什么是四次挥手？\"></a>什么是四次挥手？</h3><p><img src=\"https://cdn.nlark.com/yuque/0/2021/png/1431305/1628083644967-a1117a3a-ad00-494a-bdf5-f357adfef3b9.png\"></p>\n<ul>\n<li>第一次挥手：Client将FIN置为1，发送一个序列号seq给Server；进入FIN_WAIT_1状态；</li>\n<li>第二次挥手：Server收到FIN之后，发送一个ACK=1，acknowledge number=收到的序列号+1；进入CLOSE_WAIT状态。此时客户端已经没有要发送的数据了，但仍可以接受服务器发来的数据。</li>\n<li>第三次挥手：Server将FIN置1，发送一个序列号给Client；进入LAST_ACK状态；</li>\n<li>第四次挥手：Client收到服务器的FIN后，进入TIME_WAIT状态；接着将ACK置1，发送一个acknowledge number=序列号+1给服务器；服务器收到后，确认acknowledge number后，变为CLOSED状态，不再向客户端发送数据。客户端等待2*MSL（报文段最长寿命）时间后，也进入CLOSED状态。完成四次挥手。</li>\n</ul>\n<h5 id=\"为什么不能把服务器发送的ACK和FIN合并起来，变成三次挥手（CLOSE-WAIT状态意义是什么）？\"><a href=\"#为什么不能把服务器发送的ACK和FIN合并起来，变成三次挥手（CLOSE-WAIT状态意义是什么）？\" class=\"headerlink\" title=\"为什么不能把服务器发送的ACK和FIN合并起来，变成三次挥手（CLOSE_WAIT状态意义是什么）？\"></a>为什么不能把服务器发送的ACK和FIN合并起来，变成三次挥手（CLOSE_WAIT状态意义是什么）？</h5><p>因为服务器收到客户端断开连接的请求时，可能还有一些数据没有发完，这时先回复ACK，表示接收到了断开连接的请求。等到数据发完之后再发FIN，断开服务器到客户端的数据传送。</p>\n<h5 id=\"如果第二次挥手时服务器的ACK没有送达客户端，会怎样？\"><a href=\"#如果第二次挥手时服务器的ACK没有送达客户端，会怎样？\" class=\"headerlink\" title=\"如果第二次挥手时服务器的ACK没有送达客户端，会怎样？\"></a>如果第二次挥手时服务器的ACK没有送达客户端，会怎样？</h5><p>客户端没有收到ACK确认，会重新发送FIN请求。</p>\n<h5 id=\"客户端TIME-WAIT状态的意义是什么？\"><a href=\"#客户端TIME-WAIT状态的意义是什么？\" class=\"headerlink\" title=\"客户端TIME_WAIT状态的意义是什么？\"></a>客户端TIME_WAIT状态的意义是什么？</h5><p>第四次挥手时，客户端发送给服务器的ACK有可能丢失，TIME_WAIT状态就是用来重发可能丢失的ACK报文。如果Server没有收到ACK，就会重发FIN，如果Client在2*MSL的时间内收到了FIN，就会重新发送ACK并再次等待2MSL，防止Server没有收到ACK而不断重发FIN。<br>MSL(Maximum Segment Lifetime)，指一个片段在网络中最大的存活时间，2MSL就是一个发送和一个回复所需的最大时间。如果直到2MSL，Client都没有再次收到FIN，那么Client推断ACK已经被成功接收，则结束TCP连接。</p>\n<h3 id=\"TCP如何实现流量控制？\"><a href=\"#TCP如何实现流量控制？\" class=\"headerlink\" title=\"TCP如何实现流量控制？\"></a>TCP如何实现流量控制？</h3><p><img src=\"https://cdn.nlark.com/yuque/0/2021/png/1431305/1628083671501-2d938176-eced-4414-b6aa-fbc32d323ae9.png\"></p>\n<p>使用滑动窗口协议实现流量控制。防止发送方发送速率太快，接收方缓存区不够导致溢出。接收方会维护一个接收窗口 receiver window（窗口大小单位是字节），接受窗口的大小是根据自己的资源情况动态调整的，在返回ACK时将接受窗口大小放在TCP报文中的窗口字段告知发送方。发送窗口的大小不能超过接受窗口的大小，只有当发送方发送并收到确认之后，才能将发送窗口右移。</p>\n<p>发送窗口的上限为接受窗口和拥塞窗口中的较小值。接受窗口表明了接收方的接收能力，拥塞窗口表明了网络的传送能力。</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2021/gif/1431305/1628083685654-29996960-ed15-47f4-99bf-246b8ac30214.gif\"></p>\n<h5 id=\"什么是零窗口（接收窗口为0时会怎样）？\"><a href=\"#什么是零窗口（接收窗口为0时会怎样）？\" class=\"headerlink\" title=\"什么是零窗口（接收窗口为0时会怎样）？\"></a>什么是零窗口（接收窗口为0时会怎样）？</h5><p>如果接收方没有能力接收数据，就会将接收窗口设置为0，这时发送方必须暂停发送数据，但是会启动一个持续计时器(persistence timer)，到期后发送一个大小为1字节的探测数据包，以查看接收窗口状态。如果接收方能够接收数据，就会在返回的报文中更新接收窗口大小，恢复数据传送。</p>\n<h3 id=\"TCP的拥塞控制是怎么实现的？\"><a href=\"#TCP的拥塞控制是怎么实现的？\" class=\"headerlink\" title=\"TCP的拥塞控制是怎么实现的？\"></a>TCP的拥塞控制是怎么实现的？</h3><p><img src=\"https://cdn.nlark.com/yuque/0/2021/png/1431305/1628083709929-6e2bfba1-63ca-4742-a80a-256a93b0f159.png\"></p>\n<p>拥塞控制主要由四个算法组成：<strong>慢启动（Slow Start）、拥塞避免（Congestion voidance）、快重传 （Fast Retransmit）、快恢复（Fast Recovery）</strong></p>\n<ol>\n<li>慢启动：刚开始发送数据时，先把拥塞窗口（congestion window）设置为一个最大报文段MSS的数值，每收到一个新的确认报文之后，就把拥塞窗口加1个MSS。这样每经过一个传输轮次（或者说是每经过一个往返时间RTT），拥塞窗口的大小就会加倍<br><img src=\"https://cdn.nlark.com/yuque/0/2021/png/1431305/1628083774060-71278d40-0b39-4e15-9dd1-22534e2c90d8.png\"></li>\n</ol>\n<ol start=\"2\">\n<li>拥塞避免：当拥塞窗口的大小达到慢开始门限(slow start threshold)时，开始执行拥塞避免算法，拥塞窗口大小不再指数增加，而是线性增加，即每经过一个传输轮次只增加1MSS.</li>\n</ol>\n<blockquote>\n<p>无论在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞（其根据就是没有收到确认），就要把慢开始门限ssthresh设置为出现拥塞时的发送方窗口值的一半（但不能小于2）。然后把拥塞窗口cwnd重新设置为1，执行慢开始算法。<strong>（这是不使用快重传的情况）</strong></p>\n</blockquote>\n<ol start=\"3\">\n<li>快重传：快重传要求接收方在收到一个失序的报文段后就立即发出<strong>重复确认</strong>（为的是使发送方及早知道有报文段没有到达对方）而不要等到自己发送数据时捎带确认。快重传算法规定，发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段，而不必继续等待设置的重传计时器时间到期。</li>\n</ol>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2021/png/1431305/1628083866222-2e727029-b6f2-495e-97f2-e4b7b49cd16e.png\"></p>\n<ol start=\"4\">\n<li>快恢复：当发送方连续收到三个重复确认时，就把慢开始门限减半，然后执行拥塞避免算法。不执行慢开始算法的原因：因为如果网络出现拥塞的话就不会收到好几个重复的确认，所以发送方认为现在网络可能没有出现拥塞。<br>也有的快重传是把开始时的拥塞窗口cwnd值再增大一点，即等于 ssthresh + 3*MSS 。这样做的理由是：既然发送方收到三个重复的确认，就表明有三个分组已经离开了网络。这三个分组不再消耗网络的资源而是停留在接收方的缓存中。可见现在网络中减少了三个分组。因此可以适当把拥塞窗口扩大些。<h3 id=\"TCP如何最大利用带宽？\"><a href=\"#TCP如何最大利用带宽？\" class=\"headerlink\" title=\"TCP如何最大利用带宽？\"></a>TCP如何最大利用带宽？</h3>TCP速率受到三个因素影响</li>\n</ol>\n<ul>\n<li>窗口：即滑动窗口大小，见<a href=\"#TCP%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6\">TCP如何实现流量控制？</a></li>\n<li>带宽：这里带宽是指单位时间内从发送端到接收端所能通过的“最高数据率”，是一种硬件限制。TCP发送端和接收端的数据传输数不可能超过两点间的带宽限制。发送端和接收端之间带宽取所通过线路的带宽最小值（如通过互联网连接）。</li>\n<li>RTT：即Round Trip Time，表示从发送端到接收端的一去一回需要的时间，TCP在数据传输过程中会对RTT进行采样（即对发送的数据包及其ACK的时间差进行测量，并根据测量值更新RTT值），TCP根据得到的RTT值更新RTO值，即Retransmission TimeOut，就是重传间隔，发送端对每个发出的数据包进行计时，如果在RTO时间内没有收到所发出的数据包的对应ACK，则任务数据包丢失，将重传数据。一般RTO值都比采样得到的RTT值要大。</li>\n</ul>\n<p>带宽时延乘积=带宽*RTT，实际上等于发送端到接收端单向通道的数据容积的两倍，这里单向通道的数据容积可以这样来理解，单向通道看成是一条单行道马路，带宽就是马路的车道数，路上跑的汽车就是数据（不过这里所有汽车的速率都是一样的，且不会有人想超车，大家齐头并进），那么单向通道的数据容积就是这条单行道上摆满车，一共可以摆多少辆。带宽就是马路的车道数，带宽数乘以单向通道的数据容积就是路面上所能容纳的全部数据量。当路面上已经摆满的时候，就不能再往里面放了。<br><img src=\"https://cdn.nlark.com/yuque/0/2021/png/1431305/1628084389045-9ba4652e-2456-424e-b530-bd95b496004d.png\"></p>\n<h3 id=\"TCP与UDP的区别\"><a href=\"#TCP与UDP的区别\" class=\"headerlink\" title=\"TCP与UDP的区别\"></a>TCP与UDP的区别</h3><ol>\n<li>TCP是面向连接的，UDP是无连接的；</li>\n<li>UDP发送数据之前不需要建立连接</li>\n<li>TCP是可靠的，UDP不可靠； </li>\n<li>UDP接收方收到报文后，不需要给出任何确认</li>\n<li>TCP只支持点对点通信，UDP支持一对一、一对多、多对一、多对多；</li>\n<li>TCP是面向字节流的，UDP是面向报文的； </li>\n<li>面向字节流是指发送数据时以字节为单位，一个数据包可以拆分成若干组进行发送，而UDP一个报文只能一次发完。</li>\n<li>TCP有拥塞控制机制，UDP没有。网络出现的拥塞不会使源主机的发送速率降低，这对某些实时应用是很重要的，比如媒体通信，游戏；</li>\n<li>TCP首部开销（20字节）比UDP首部开销（8字节）要大</li>\n<li>UDP 的主机不需要维持复杂的连接状态表</li>\n</ol>\n<h5 id=\"什么时候选择TCP，什么时候选UDP？\"><a href=\"#什么时候选择TCP，什么时候选UDP？\" class=\"headerlink\" title=\"什么时候选择TCP，什么时候选UDP？\"></a>什么时候选择TCP，什么时候选UDP？</h5><h5 id=\"HTTP可以使用UDP吗？\"><a href=\"#HTTP可以使用UDP吗？\" class=\"headerlink\" title=\"HTTP可以使用UDP吗？\"></a>HTTP可以使用UDP吗？</h5><p>注：<strong>http 3.0 使用udp实现</strong><br><a href=\"https://zh.wikipedia.org/wiki/HTTP/3\">https://zh.wikipedia.org/wiki/HTTP/3</a></p>\n<h5 id=\"面向连接和无连接的区别\"><a href=\"#面向连接和无连接的区别\" class=\"headerlink\" title=\"面向连接和无连接的区别\"></a>面向连接和无连接的区别</h5><p>无连接的网络服务（数据报服务）– 面向连接的网络服务（虚电路服务）<br>虚电路服务：首先建立连接，所有的数据包经过相同的路径，服务质量有较好的保证；<br>数据报服务：每个数据包含目的地址，数据路由相互独立（路径可能变化）；网络尽最大努力交付数据，但不保证不丢失、不保证先后顺序、不保证在时限内交付；网络发生拥塞时，可能会将一些分组丢弃；</p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2021/png/1431305/1628084520127-fb51536c-1fee-4fa4-a450-684dab556f9e.png#height=494&id=HncLV&originHeight=659&originWidth=769&originalType=binary&ratio=1&status=done&style=none&width=577\"></p>\n<h3 id=\"TCP如何保证传输的可靠性\"><a href=\"#TCP如何保证传输的可靠性\" class=\"headerlink\" title=\"TCP如何保证传输的可靠性\"></a>TCP如何保证传输的可靠性</h3><ol>\n<li>数据包校验</li>\n<li>对失序数据包重新排序（TCP报文具有序列号）</li>\n<li>丢弃重复数据</li>\n<li>应答机制：接收方收到数据之后，会发送一个确认（通常延迟几分之一秒）；</li>\n<li>超时重发：发送方发出数据之后，启动一个定时器，超时未收到接收方的确认，则重新发送这个数据；</li>\n<li>流量控制：确保接收端能够接收发送方的数据而不会缓冲区溢出<h1 id=\"应用层：HTTP和HTTPS\"><a href=\"#应用层：HTTP和HTTPS\" class=\"headerlink\" title=\"应用层：HTTP和HTTPS\"></a>应用层：HTTP和HTTPS</h1></li>\n</ol>\n<h3 id=\"HTTP和HTTPS有什么区别？\"><a href=\"#HTTP和HTTPS有什么区别？\" class=\"headerlink\" title=\"HTTP和HTTPS有什么区别？\"></a>HTTP和HTTPS有什么区别？</h3><ol>\n<li>端口不同：HTTP使用的是80端口，HTTPS使用443端口；</li>\n<li>HTTP（超文本传输协议）信息是明文传输，HTTPS运行在SSL(Secure Socket Layer)之上，添加了加密和认证机制，更加安全；</li>\n<li>HTTPS由于加密解密会带来更大的CPU和内存开销；</li>\n<li>HTTPS通信需要证书，一般需要向证书颁发机构（CA）购买</li>\n</ol>\n<h5 id=\"Https的连接过程？\"><a href=\"#Https的连接过程？\" class=\"headerlink\" title=\"Https的连接过程？\"></a>Https的连接过程？</h5><ol>\n<li>客户端向服务器发送请求，同时发送客户端支持的一套加密规则（包括对称加密、非对称加密、摘要算法）；</li>\n<li>服务器从中选出一组加密算法与HASH算法，并将自己的身份信息以证书的形式发回给浏览器。证书里面包含了网站地址，<strong>加密公钥</strong>（用于非对称加密），以及证书的颁发机构等信息（证书中的私钥只能用于服务器端进行解密）；</li>\n<li>客户端验证服务器的合法性，包括：证书是否过期，CA 是否可靠，发行者证书的公钥能否正确解开服务器证书的“发行者的数字签名”，服务器证书上的域名是否和服务器的实际域名相匹配；</li>\n<li>如果证书受信任，或者用户接收了不受信任的证书，浏览器会生成一个<strong>随机密钥</strong>（用于对称算法），并用服务器提供的公钥加密（采用非对称算法对密钥加密）；使用Hash算法对握手消息进行<strong>摘要</strong>计算，并对摘要使用之前产生的密钥加密（对称算法）；将加密后的随机密钥和摘要一起发送给服务器；</li>\n<li>服务器使用自己的私钥解密，得到对称加密的密钥，用这个密钥解密出Hash摘要值，并验证握手消息是否一致；如果一致，服务器使用对称加密的密钥加密握手消息发给浏览器；</li>\n<li>浏览器解密并验证摘要，若一致，则握手结束。之后的数据传送都使用对称加密的密钥进行加密</li>\n</ol>\n<p>总结：非对称加密算法用于在握手过程中加密生成的密码；对称加密算法用于对真正传输的数据进行加密；HASH算法用于验证数据的完整性。</p>\n<h5 id=\"输入-www-baidu-com，怎么变成-https-www-baidu-com-的，怎么确定用HTTP还是HTTPS？\"><a href=\"#输入-www-baidu-com，怎么变成-https-www-baidu-com-的，怎么确定用HTTP还是HTTPS？\" class=\"headerlink\" title=\"输入 www.baidu.com，怎么变成 https://www.baidu.com 的，怎么确定用HTTP还是HTTPS？\"></a>输入 <a href=\"http://www.baidu.com,怎么变成/\">www.baidu.com，怎么变成</a> <a href=\"https://www.baidu.com/\">https://www.baidu.com</a> 的，怎么确定用HTTP还是HTTPS？</h5><p><a href=\"https://www.sohu.com/a/136637876_487516\">你访问的网站是如何自动切换到 HTTPS 的？</a><br>一种是原始的302跳转，服务器把所有的HTTp流量跳转到HTTPS。但这样有一个漏洞，就是中间人可能在第一次访问站点的时候就劫持。<br>解决方法是引入HSTS机制，用户浏览器在访问站点的时候强制使用HTTPS。</p>\n<h5 id=\"HTTPS连接的时候，怎么确定收到的包是服务器发来的（中间人攻击）？\"><a href=\"#HTTPS连接的时候，怎么确定收到的包是服务器发来的（中间人攻击）？\" class=\"headerlink\" title=\"HTTPS连接的时候，怎么确定收到的包是服务器发来的（中间人攻击）？\"></a>HTTPS连接的时候，怎么确定收到的包是服务器发来的（中间人攻击）？</h5><h5 id=\"什么是对称加密、非对称加密？区别是什么？\"><a href=\"#什么是对称加密、非对称加密？区别是什么？\" class=\"headerlink\" title=\"什么是对称加密、非对称加密？区别是什么？\"></a>什么是对称加密、非对称加密？区别是什么？</h5><ul>\n<li>对称加密：加密和解密采用相同的密钥。如：DES、RC2、RC4</li>\n<li>非对称加密：需要两个密钥：公钥和私钥。如果用公钥加密，需要用私钥才能解密。如：RSA</li>\n<li>区别：对称加密速度更快，通常用于大量数据的加密；非对称加密安全性更高（不需要传送私钥）</li>\n</ul>\n<h5 id=\"数字签名、报文摘要的原理\"><a href=\"#数字签名、报文摘要的原理\" class=\"headerlink\" title=\"数字签名、报文摘要的原理\"></a>数字签名、报文摘要的原理</h5><ul>\n<li>发送者A用私钥进行签名，接收者B用公钥验证签名。因为除A外没有人有私钥，所以B相信签名是来自A。A不可抵赖，B也不能伪造报文。</li>\n<li>摘要算法:MD5、SHA</li>\n</ul>\n<h3 id=\"GET与POST的区别？\"><a href=\"#GET与POST的区别？\" class=\"headerlink\" title=\"GET与POST的区别？\"></a>GET与POST的区别？</h3><ol>\n<li>GET是幂等的，即读取同一个资源，总是得到相同的数据，POST不是幂等的；</li>\n<li>GET一般用于从服务器获取资源，而POST有可能改变服务器上的资源；</li>\n<li>请求形式上：GET请求的数据附在URL之后，在HTTP请求头中；POST请求的数据在请求体中；</li>\n<li>安全性：GET请求可被缓存、收藏、保留到历史记录，且其请求数据明文出现在URL中。POST的参数不会被保存，安全性相对较高；</li>\n<li>GET只允许ASCII字符，POST对数据类型没有要求，也允许二进制数据；</li>\n<li>GET的长度有限制（操作系统或者浏览器），而POST数据大小无限制</li>\n</ol>\n<h3 id=\"Session与Cookie的区别？\"><a href=\"#Session与Cookie的区别？\" class=\"headerlink\" title=\"Session与Cookie的区别？\"></a>Session与Cookie的区别？</h3><p>Session是服务器端保持状态的方案，Cookie是客户端保持状态的方案<br>Cookie保存在客户端本地，客户端请求服务器时会将Cookie一起提交；Session保存在服务端，通过检索Sessionid查看状态。保存Sessionid的方式可以采用Cookie，如果禁用了Cookie，可以使用URL重写机制（把会话ID保存在URL中）。</p>\n<h3 id=\"从输入网址到获得页面的过程-越详细越好-？\"><a href=\"#从输入网址到获得页面的过程-越详细越好-？\" class=\"headerlink\" title=\"从输入网址到获得页面的过程 (越详细越好)？\"></a>从输入网址到获得页面的过程 (越详细越好)？</h3><ol>\n<li>浏览器查询 DNS，获取域名对应的IP地址:具体过程包括浏览器搜索自身的DNS缓存、搜索操作系统的DNS缓存、读取本地的Host文件和向本地DNS服务器进行查询等。对于向本地DNS服务器进行查询，如果要查询的域名包含在本地配置区域资源中，则返回解析结果给客户机，完成域名解析(此解析具有权威性)；如果要查询的域名不由本地DNS服务器区域解析，但该服务器已缓存了此网址映射关系，则调用这个IP地址映射，完成域名解析（此解析不具有权威性）。如果本地域名服务器并未缓存该网址映射关系，那么将根据其设置发起递归查询或者迭代查询；</li>\n<li>浏览器获得域名对应的IP地址以后，浏览器向服务器请求建立链接，发起三次握手；</li>\n<li>TCP/IP链接建立起来后，浏览器向服务器发送HTTP请求；</li>\n<li>服务器接收到这个请求，并根据路径参数映射到特定的请求处理器进行处理，并将处理结果及相应的视图返回给浏览器；</li>\n<li>浏览器解析并渲染视图，若遇到对js文件、css文件及图片等静态资源的引用，则重复上述步骤并向服务器请求这些资源；</li>\n<li>浏览器根据其请求到的资源、数据渲染页面，最终向用户呈现一个完整的页面。</li>\n</ol>\n<h3 id=\"HTTP请求有哪些常见状态码？\"><a href=\"#HTTP请求有哪些常见状态码？\" class=\"headerlink\" title=\"HTTP请求有哪些常见状态码？\"></a>HTTP请求有哪些常见状态码？</h3><ol>\n<li>2xx状态码：操作成功。200 OK</li>\n<li>3xx状态码：重定向。301 永久重定向；302暂时重定向</li>\n<li>4xx状态码：客户端错误。400 Bad Request；401 Unauthorized；403 Forbidden；404 Not Found；</li>\n<li>5xx状态码：服务端错误。500服务器内部错误；501服务不可用</li>\n</ol>\n<h3 id=\"什么是RIP-Routing-Information-Protocol-距离矢量路由协议-算法是什么？\"><a href=\"#什么是RIP-Routing-Information-Protocol-距离矢量路由协议-算法是什么？\" class=\"headerlink\" title=\"什么是RIP (Routing Information Protocol, 距离矢量路由协议)? 算法是什么？\"></a>什么是RIP (Routing Information Protocol, 距离矢量路由协议)? 算法是什么？</h3><p>每个路由器维护一张表，记录该路由器到其它网络的”跳数“，路由器到与其直接连接的网络的跳数是1，每多经过一个路由器跳数就加1；更新该表时和相邻路由器交换路由信息；路由器允许一个路径最多包含15个路由器，如果跳数为16，则不可达。交付数据报时优先选取距离最短的路径。</p>\n<p>（PS：RIP是应用层协议：<a href=\"https://www.zhihu.com/question/19645407\">https://www.zhihu.com/question/19645407</a>）</p>\n<ul>\n<li>实现简单，开销小</li>\n<li>随着网络规模扩大开销也会增大；</li>\n<li>最大距离为15，限制了网络的规模；</li>\n<li>当网络出现故障时，要经过较长的时间才能将此信息传递到所有路由器</li>\n<li>交换机数据链路层，根据MAC地址进行寻址</li>\n</ul>\n<h1 id=\"网络层协议\"><a href=\"#网络层协议\" class=\"headerlink\" title=\"网络层协议\"></a>网络层协议</h1><h3 id=\"IP地址的分类？\"><a href=\"#IP地址的分类？\" class=\"headerlink\" title=\"IP地址的分类？\"></a>IP地址的分类？</h3><p><img src=\"https://cdn.nlark.com/yuque/0/2021/png/1431305/1628084593202-102c8a14-99c6-463c-8bde-866b86d19613.png\"></p>\n<p>路由器仅根据网络号net-id来转发分组，当分组到达目的网络的路由器之后，再按照主机号host-id将分组交付给主机；同一网络上的所有主机的网络号相同。</p>\n<h3 id=\"什么叫划分子网？\"><a href=\"#什么叫划分子网？\" class=\"headerlink\" title=\"什么叫划分子网？\"></a>什么叫划分子网？</h3><p>从主机号host-id借用若干个比特作为子网号subnet-id；子网掩码：网络号和子网号都为1，主机号为0；数据报仍然先按照网络号找到目的网络，发送到路由器，路由器再按照网络号和子网号找到目的子网：将子网掩码与目标地址逐比特与操作，若结果为某个子网的网络地址，则送到该子网。</p>\n<h3 id=\"什么是ARP协议-Address-Resolution-Protocol-？\"><a href=\"#什么是ARP协议-Address-Resolution-Protocol-？\" class=\"headerlink\" title=\"什么是ARP协议 (Address Resolution Protocol)？\"></a>什么是ARP协议 (Address Resolution Protocol)？</h3><p><strong>ARP协议完成了IP地址与物理地址的映射</strong>。每一个主机都设有一个 ARP 高速缓存，里面有<strong>所在的局域网</strong>上的各主机和路由器的 IP 地址到硬件地址的映射表。当源主机要发送数据包到目的主机时，会先检查自己的ARP高速缓存中有没有目的主机的MAC地址，如果有，就直接将数据包发到这个MAC地址，如果没有，就向<strong>所在的局域网</strong>发起一个ARP请求的广播包（在发送自己的 ARP 请求时，同时会带上自己的 IP 地址到硬件地址的映射），收到请求的主机检查自己的IP地址和目的主机的IP地址是否一致，如果一致，则先保存源主机的映射到自己的ARP缓存，然后给源主机发送一个ARP响应数据包。源主机收到响应数据包之后，先添加目的主机的IP地址与MAC地址的映射，再进行数据传送。如果源主机一直没有收到响应，表示ARP查询失败。</p>\n<p>如果所要找的主机和源主机不在同一个局域网上，那么就要通过 ARP 找到一个位于本局域网上的某个路由器的硬件地址，然后把分组发送给这个路由器，让这个路由器把分组转发给下一个网络。剩下的工作就由下一个网络来做。</p>\n<h3 id=\"什么是NAT-Network-Address-Translation-网络地址转换-？\"><a href=\"#什么是NAT-Network-Address-Translation-网络地址转换-？\" class=\"headerlink\" title=\"什么是NAT (Network Address Translation, 网络地址转换)？\"></a>什么是NAT (Network Address Translation, 网络地址转换)？</h3><p>用于解决内网中的主机要和因特网上的主机通信。由NAT路由器将主机的本地IP地址转换为全球IP地址，分为静态转换（转换得到的全球IP地址固定不变）和动态NAT转换。</p>\n<p>文章内容搬运自本人<a href=\"https://www.yuque.com/docs/share/5b2ba306-5030-4cff-8c82-19ecb35b4f40\">语雀</a></p>\n"},{"title":"面试八股文（三）—— 数据库","date":"2021-09-22T14:48:25.000Z","updated":"2021-09-22T15:24:26.000Z","description":"根据我多年（其实就一年）复习备考408和春招的经验，总结出来的面试八股文第三篇，也是基础篇之三——计算机网络相关的常见问题。如果文章中有看不懂的知识点，强力推荐极客时间的MySQL45讲相关课程，讲的巨清晰无比。","_content":"\n<meta name=\"referrer\" content=\"no-referrer\" />\n\n# 数据库基础\n### 事务的概念和特性？\n概念：事务（Transaction）是一个操作序列，不可分割的工作单位，以BEGIN TRANSACTION开始，以ROLLBACK/COMMIT结束\n特性（ACID）：\n- **原子性**（Atomicity）：逻辑上是不可分割的操作单元，事务的所有操作要么全部提交成功，要么全部失败回滚（用回滚日志实现，反向执行日志中的操作）；\n- **一致性**（Consistency）：事务的执行必须使数据库保持一致性状态。在一致性状态下，所有事务对一个数据的读取结果都是相同的；\n- **隔离性**（Isolation）：一个事务所做的修改在最终提交以前，对其它事务是不可见的（并发执行的事务之间不能相互影响）；\n- **持久性**（Durability）：一旦事务提交成功，对数据的修改是永久性的\n\n### 会出现哪些并发一致性问题？\n- **丢失修改**：一个事务对数据进行了修改，在事务提交之前，另一个事务对同一个数据进行了修改，覆盖了之前的修改；\n- **脏读**（Dirty Read）：一个事务读取了被另一个事务修改、但未提交（进行了回滚）的数据，造成两个事务得到的数据不一致；\n- **不可重复读**（Nonrepeatable Read）：在同一个事务中，某查询操作在一个时间读取某一行数据和之后一个时间读取该行数据，发现数据已经发生修改（针对**update**操作）；\n- **幻读**（Phantom Read）：当同一查询多次执行时，由于其它事务在这个数据范围内执行了插入操作，会导致每次返回不同的结果集（和不可重复读的区别：针对的是一个数据整体/范围；并且针对**insert/delete**操作）\n\n### 数据库的四种隔离级别？\n- **未提交读**（Read Uncommited）：在一个事务提交之前，它的执行结果对其它事务也是可见的。会导致脏读、不可重复读、幻读；\n- **提交读**（Read Commited）：一个事务只能看见已经提交的事务所作的改变。可避免脏读问题；\n- **可重复读**（Repeatable Read）：可以确保同一个事务在多次读取同样的数据时得到相同的结果。（MySQL的默认隔离级别）。可避免不可重复读；\n- **可串行化**（Serializable）：强制事务串行执行，使之不可能相互冲突，从而解决幻读问题。可能导致大量的超时现象和锁竞争，实际很少使用。\n\n### 什么是乐观锁和悲观锁？\n- 悲观锁：认为数据随时会被修改，因此每次读取数据之前都会上锁，防止其它事务读取或修改数据；应用于**数据更新比较频繁**的场景；\n- 乐观锁：操作数据时不会上锁，但是更新时会判断在此期间有没有别的事务更新这个数据，若被更新过，则失败重试；适用于**读多写少**的场景。乐观锁的实现方式有：\n    - 加一个版本号或者时间戳字段，每次数据更新时同时更新这个字段；\n    - 先读取想要更新的字段或者所有字段，更新的时候比较一下，只有字段没有变化才进行更新\n\n### 常见的封锁类型？\n意向锁是 InnoDB 自动加的， 不需用户干预。\n对于 UPDATE、 DELETE 和 INSERT 语句， InnoDB\n会自动给涉及数据集加排他锁（X)；\n对于普通 SELECT 语句，InnoDB 不会加任何锁；\n事务可以通过以下语句显式给记录集加共享锁或排他锁：\n共享锁（S）：SELECT * FROM table_name WHERE ... LOCK IN SHARE MODE。 其他 session 仍然可以查询记录，并也可以对该记录加 share mode 的共享锁。但是如果当前事务需要对该记录进行更新操作，则很有可能造成死锁。\n排他锁（X)：SELECT * FROM table_name WHERE ... FOR UPDATE。其他 session 可以查询该记录，但是不能对该记录加共享锁或排他锁，而是等待获得锁\n\n- **排它锁**（Exclusive Lock）/ X锁：事务对数据加上X锁时，只允许此事务读取和修改此数据，并且其它事务不能对该数据加任何锁；\n- **共享锁**（Shared Lock）/ S锁：加了S锁后，该事务只能对数据进行读取而不能修改，并且其它事务只能加S锁，不能加X锁\n- **意向锁**（Intention Locks）：\n    - 一个事务在获得某个**数据行**对象的 S 锁之前，必须先获得**整个表**的 IS 锁或更强的锁；\n    - 一个事务在获得某个数据行对象的 X 锁之前，必须先获得整个表的 IX 锁；\n    - IS/IX 锁之间都是兼容的；\n    - 好处：如果一个事务想要对整个表加X锁，就需要先检测是否有其它事务对该表或者该表中的某一行加了锁，这种检测非常耗时。有了意向锁之后，只需要检测整个表是否存在IX/IS/X/S锁就行了\n\n锁的作用：用于管理对共享资源的并发访问，保证数据库的完整性和一致性\n\nMySQL 中提供了两种封锁粒度：**行级锁**以及**表级锁**。\n封锁粒度小：\n\n- 好处：锁定的数据量越少，发生锁争用的可能就越小，系统的**并发程度**就越高；\n- 坏处：**系统开销**大（加锁、释放锁、检查锁的状态都需要消耗资源）\n\n```\nSELECT ... LOCK In SHARE MODE;\nSELECT ... FOR UPDATE;\n```\n\n### 什么是三级封锁协议？\n- 一级封锁协议：事务在修改数据之前必须先对其加X锁，直到事务结束才释放。可以解决丢失修改问题（两个事务不能同时对一个数据加X锁，避免了修改被覆盖）；\n- 二级封锁协议：在一级的基础上，事务在读取数据之前必须先加S锁，读完后释放。可以解决脏读问题（如果已经有事务在修改数据，就意味着已经加了X锁，此时想要读取数据的事务并不能加S锁，也就无法进行读取，避免了读取脏数据）；\n- 三级封锁协议：在二级的基础上，事务在读取数据之前必须先加S锁，直到事务结束才能释放。可以解决不可重复读问题（避免了在事务结束前其它事务对数据加X锁进行修改，保证了事务期间数据不会被其它事务更新）\n\n### 什么是两段锁协议？\n事务必须严格分为两个阶段对数据进行**加锁和解锁**的操作，第一阶段加锁，第二阶段解锁。也就是说一个事务中一旦释放了锁，就不能再申请新锁了。\n\n**可串行化调度**是指，通过并发控制，使得并发执行的事务结果与某个串行执行的事务结果相同。事务遵循两段锁协议是保证可串行化调度的充分条件。\n\n### 什么是 MVCC？\n多版本并发控制（Multi-Version Concurrency Control, MVCC），MVCC在每行记录后面都保存有两个隐藏的列，用来存储**创建版本号**和**删除版本号**。\n\n- 创建版本号：创建一个数据行时的事务版本号（**事务版本号**：事务开始时的系统版本号；系统版本号：每开始一个新的事务，系统版本号就会自动递增）；\n- 删除版本号：删除操作时的事务版本号；\n- 各种操作：\n    - 插入操作时，记录创建版本号；\n    - 删除操作时，记录删除版本号；\n    - 更新操作时，先记录删除版本号，再新增一行记录创建版本号；\n    - 查询操作时，要符合以下条件才能被查询出来：删除版本号未定义或大于当前事务版本号（删除操作是在当前事务启动之后做的）；创建版本号小于或等于当前事务版本号（创建操作是事务完成或者在事务启动之前完成）\n\n通过版本号减少了锁的争用，**提高了系统性能**；可以实现**提交读**和**可重复读**两种隔离级别，未提交读无需使用MVCC\n\n使用 MVCC 读取的是快照中的数据，这样可以减少加锁所带来的开销：\n```\nselect * from table ...;\n```\n当前读读取的是最新的数据，需要加锁。以下第一个语句需要加 S 锁，其它都需要加 X 锁：\n```\nselect * from table where ? lock in share mode;\nselect * from table where ? for update;\ninsert;\nupdate;\ndelete;\n```\n\n### 数据库的范式？\n- **第一范式**（1NF，Normal Form）：**属性不应该是可分的**。举例：如果将“电话”作为一个属性（一列），是不符合1NF的，因为电话这个属性可以分解为家庭电话和移动电话...如果将“移动电话”作为一个属性，就符合1NF；\n- **第二范式** 2NF：每个非主属性**完全依赖**于主属性集（候选键集）；\n    - B完全依赖于A，就是说A中的所有属性唯一决定B，属性少了就不能唯一决定，属性多了则有冗余（叫依赖不叫完全依赖）。举例：（学号，课程名）这个主属性集可以唯一决定成绩，但是对于学生姓名这个属性，（学号，课程名）这个属性集就是冗余的，所以学生姓名不完全依赖于（学号，课程名）这一属性集；\n    - 主属性集/候选码集：某一组属性能够唯一确定其它的属性（主键就是从候选键集中选的一个键），而其子集不能，这样的属性组中的属性就是主属性；不在候选码集中的属性成为非主属性；\n    - 可以通过分解来满足 2NF：将（学号，课程名，成绩）做成一张表；（学号，学生姓名）做成另一张表，避免大量的数据冗余；\n      满足1NF后，要求表中的所有列，都必须依赖于主键，而不能有任何一列与主键没有关系，也就是说一个表只描述一件事情；\n- **第三范式** 3NF：在 2NF 的基础上，非主属性**不传递依赖**于主属性\n    - 传递依赖：如果C依赖于B，B依赖于A，那么C传递依赖于A；\n    - 3NF在2NF的基础上，消除了非主属性之间的依赖；比如一个表中，主属性有（学号），非主属性有（姓名，院系，院长名），可以看到院长名这个非主属性依赖于院系，传递依赖于学号。消除的办法是分解。\n      必须先满足第二范式（2NF），要求：表中的每一列只与主键直接相关而不是间接相关，（表中的每一列只能依赖于主键）；\n\n- 冗余数据：某些同样的数据多次出现（如学生姓名）；\n- 修改异常：修改了一个记录中的信息，另一个记录中相同的信息却没有修改；\n- 删除异常：删除一个信息，那么也会丢失其它信息（删除一个课程，丢失了一个学生的信息）；\n- 插入异常：无法插入（插入一个还没有课程信息的学生）\n\n### 列举几种表连接方式？\n![](https://cdn.nlark.com/yuque/0/2021/png/1431305/1628085012977-cccccdf6-0f16-4343-8cd4-68631fb6b78a.png)\n\n\n- 内连接（Inner Join）：仅将两个表中满足连接条件的行组合起来作为结果集\n    - 自然连接：只考虑属性相同的元组对；\n    - 等值连接：给定条件进行查询\n\n\n\n- 外连接（Outer Join）\n    - 左连接：左边表的所有数据都有显示出来，右边的表数据只显示共同有的那部分，没有对应的部分补NULL；\n    - 右连接：和左连接相反；\n    - 全外连接（Full Outer Join）：查询出左表和右表所有数据，但是去除两表的重复数据\n\n\n\n- 交叉连接（Cross Join）：返回两表的笛卡尔积（对于所含数据分别为m、n的表，返回m*n的结果）\n\n### 什么是存储过程？有哪些优缺点？\n存储过程是事先经过编译并存储在数据库中的一段SQL语句的集合。想要实现相应的功能时，只需要调用这个存储过程就行了（类似于函数，输入具有输出参数）。\n优点：\n- 预先编译，而不需要每次运行时编译，提高了数据库执行**效率**；\n- 封装了一系列操作，对于一些数据交互比较多的操作，相比于单独执行SQL语句，可以**减少网络通信量**；\n- 具有**可复用性**，减少了数据库开发的工作量；\n- **安全性高**，可以让没有权限的用户通过存储过程间接操作数据库；\n- 更**易于维护**\n\n缺点：\n- **可移植性差**，存储过程将应用程序绑定到了数据库上；\n- **开发调试复杂**：没有好的IDE；\n- **修改复杂**，需要重新编译，有时还需要更新程序中的代码以更新调用\n\n### Drop/Delete/Truncate的区别？\n- **Delete**用来删除表的全部或者**部分数据**，执行delete之后，用户**需要提交**之后才会执行，会触发表上的DELETE**触发器**（包含一个OLD的虚拟表，可以只读访问被删除的数据），DELETE之后表结构还在，删除很慢，一行一行地删，因为会记录日志，可以利用日志还原数据；\n- **Truncate**删除表中的所有数据，这个操作**不能回滚**，也不会触发这个表上的触发器。操作比DELETE快很多（直接把表drop掉，再创建一个新表，删除的数据不能找回）。如果表中有自增（AUTO_INCREMENT）列，则重置为1；\n- **Drop**命令从数据库中**删除表**，所有的数据行，索引和约束都会被删除；不能回滚，不会触发触发器；\n\n触发器（TRIGGER）是由事件（比如INSERT/UPDATE/DELETE）来触发运行的操作（不能被直接调用，不能接收参数）。在数据库里以独立的对象存储，用于**保证数据完整性**（比如可以检验或转换数据）。\n\n约束（Constraint）类型：主键（Primary Key）约束，唯一约束（Unique），检查约束，非空约束，外键（Foreign Key）约束。\n\n### 什么是视图？什么是游标？\n- 视图：从数据库的基本表中通过查询选取出来的数据组成的**虚拟表**（数据库中存放视图的定义）。可以对其进行增/删/改/查等操作。视图是对若干张基本表的引用，一张虚表，查询语句执行的结果，不存储具体的数据（基本表数据发生了改变，视图也会跟着改变）；可以跟基本表一样，进行增删改查操作(ps:增删改操作有条件限制)；如连表查询产生的视图无法进行，对视图的增删改会影响原表的数据。好处：\n    - 通过只给用户访问视图的权限，保证数据的**安全性**；\n    - **简化**复杂的SQL操作，隐藏数据的复杂性（比如复杂的连接）；\n- 游标（Cursor）：用于定位在查询返回的**结果集的特定行**，以对特定行进行操作。使用游标可以方便地对结果集进行移动遍历，根据需要滚动或对浏览/修改任意行中的数据。主要用于交互式应用。\n# MySQL\n### 数据库索引的实现原理（B+树）\n\n见[数据结构部分：B树，B+树](https://github.com/wolverinn/Iridescent/blob/master/Data%20Structure.md#b%E6%A0%91)\n\n##### 使用B树和B+树的比较\nInnoDB的索引使用的是B+树实现，B+树对比B树的好处：\n\n- IO次数少：B+树的中间结点只存放索引，数据都存在叶结点中，因此中间结点可以存更多的数据，让索引树更加矮胖；\n- 范围查询效率更高：B树需要中序遍历整个树，只B+树需要遍历叶结点中的链表；\n- 查询效率更加稳定：每次查询都需要从根结点到叶结点，路径长度相同，所以每次查询的效率都差不多\n\n##### 使用B树索引和哈希索引的比较\n哈希索引能以 O(1) 时间进行查找，但是只支持精确查找，无法用于部分查找和范围查找，无法用于排序与分组；B树索引支持大于小于等于查找，范围查找。哈希索引遇到大量哈希值相等的情况后查找效率会降低。哈希索引不支持数据的排序。\n\n### 使用索引的优点\n- 大大加快了数据的**检索速度**；\n- 可以显著减少查询中**分组和排序**的时间；\n- 通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性；\n- 将随机 I/O 变为**顺序 I/O**（B+Tree 索引是有序的，会将相邻的数据都存储在一起）\n\n缺点：建立和维护索引耗费时间空间，更新索引很慢。\n### 哪些情况下索引会失效？\n- 以“%(表示任意0个或多个字符)”开头的LIKE语句；\n- OR语句前后没有同时使用索引；\n- 数据类型出现隐式转化（如varchar不加单引号的话可能会自动转换为int型）；\n- 对于多列索引，必须满足 **最左匹配原则**/最左前缀原则 (最左优先，eg：多列索引col1、col2和col3，则 索引生效的情形包括 col1或col1，col2或col1，col2，col3)；\n- 如果MySQL估计全表扫描比索引快，则不使用索引（比如非常小的表）\n\n### 在哪些地方适合创建索引？\n- 某列经常作为最大最小值；\n- 经常被查询的字段；\n- 经常用作表连接的字段；\n- 经常出现在ORDER BY/GROUP BY/DISDINCT后面的字段\n\n##### 创建索引时需要注意什么？\n- 只应建立在**小字段**上，而不要对大文本或图片建立索引（一页存储的数据越多一次IO操作获取的数据越大效率越高）；\n- 建立索引的字段应该**非空**，在MySQL中，含有空值的列很难进行查询优化，因为它们使得索引、索引的统计信息以及比较运算更加复杂。应该用0、一个特殊的值或者一个空串代替NULL；\n- 选择**数据密度大**（唯一值占总数的百分比很大）的字段作索引\n\n### 索引的分类？\n- 普通索引\n- 唯一索引 UNIQUE：索引列的值必须唯一，但允许有空值；\n- 主键索引 PRIMARY KEY：必须唯一，不允许空值（是一种特殊的唯一索引；MySQL创建主键时默认为聚集索引，但主键也可以是非聚集索引）；\n- 单列索引和多列索引/复合索引（Composite）：索引的列数；\n- 覆盖（Covering）索引：索引包含了所有满足查询所需要的数据，查询的时候只需要读取索引而不需要回表读取数据；\n- 聚集（Clustered）索引/非聚集索引：对磁盘上存放数据的物理地址重新组织以使这些数据按照指定规则排序的一种索引（数据的物理排列顺序和索引排列顺序一致）。因此每张表只能创建一个聚集索引（因为要改变物理存储顺序）。优点是查询速度快，因为可以直接按照顺序得到需要数据的物理地址。缺点是进行修改的速度较慢。对于需要经常搜索范围的值很有效。非聚集索引只记录逻辑顺序，并不改变物理顺序；\n- 分区索引（？）\n- 虚拟索引（Virtual）：模拟索引的存在而不用真正创建一个索引，用于快速测试创建索引对执行计划的影响。没有相关的索引段，不增加存储空间的使用\n\n### MySQL的两种存储引擎 InnoDB 和 MyISAM 的区别？\n- InnoDB**支持事务**，可以进行Commit和Rollback；\n- MyISAM 只支持表级锁，而 InnoDB 还**支持行级锁**，提高了并发操作的性能；\n- InnoDB **支持外键**；\n- MyISAM **崩溃**后发生损坏的概率比 InnoDB 高很多，而且**恢复的速度**也更慢；\n- MyISAM 支持**压缩**表和空间数据索引，InnoDB需要更多的内存和存储；\n- InnoDB 支持在线**热备份**\n\n- **MyISAM** 管理非事务表。它提供高速存储和检索（MyISAM强调的是性能，每次查询具有原子性，其执行速度比InnoDB更快），以及全文搜索能力。如果表比较小，或者是只读数据（有大量的SELECT），还是可以使用MyISAM；\n- **InnoDB** 支持事务，并发情况下有很好的性能，基本可以替代MyISAM\n\n- 热备份：在数据库运行的情况下备份的方法。优点：可按表或用户备份，备份时数据库仍可使用，可恢复至任一时间点。但是不能出错\n- 冷备份：数据库正常关闭后，将关键性文件复制到另一位置的备份方式。优点：操作简单快速，恢复简单\n\n更详细的可以参考：[MySQL 数据库的存储引擎与适用场景 - Images](https://imageslr.github.io/2020/db-engine.html)\n### 如何优化数据库？\n> 分析慢查询日志：记录了在MySQL中响应时间超过阀值long_query_time的SQL语句，通过日志去找出IO大的SQL以及发现未命中索引的SQL\n\n> 使用 Explain 进行分析：通过explain命令可以得到表的读取顺序、数据读取操作的操作类型、哪些索引可以使用、**哪些索引被实际使用**、表之间的引用以及**被扫描的行数**等问题；\n\n- 应尽量避免在 where 子句中使用`!=`、`<`、`>`操作符或对字段进行null值判断，否则将引擎放弃使用索引而进行全表扫描；\n- 只返回必要的列：最好不要使用 SELECT * 语句；\n- 只返回必要的行：使用 LIMIT 语句来限制返回的数据；\n- 将一个大连接查询分解成对每一个表进行一次单表查询，然后在应用程序中进行关联，这样做的好处有：\n    - 让缓存更高效。对于连接查询，如果其中一个表发生变化，那么整个查询缓存就无法使用。而分解后的多个查询，即使其中一个表发生变化，对其它表的查询缓存依然可以使用；\n    - 分解成多个单表查询，这些单表查询的缓存结果更可能被其它查询使用到，从而减少冗余的查询；\n    - 减少锁竞争\n\n注意会引起索引失效的情况，以及在适合的地方建立索引\n\n- 设计表时遵循**三大范式**；\n- 选择合适的**数据类型**：尽可能不要存储NULL字段；使用简单的数据类型（int, varchar/ text）；\n- 表的**水平切分**（Sharding）：将同一个表中的记录拆分到多个结构相同的表中（策略：哈希取模；根据ID范围来分）。当一个表的数据不断增多时，Sharding 是必然的选择，它可以将数据分布到集群的不同节点上，从而缓解单个数据库的压力；\n- 表的**垂直切分**：将一张表按列切分成多个表。可以将不常用的字段单独放在同一个表中；把大字段独立放入一个表中；或者把经常使用的字段（关系密切的）放在一张表中。垂直切分之后业务更加清晰，系统之间整合或扩展容易，数据维护简单\n\n- 操作系统：增加TCP支持的队列数；\n- MySQL配置文件优化：缓存池大小和个数设置\n\n- 磁盘性能：固态硬盘；\n- CPU：多核且高频；\n- 内存：增大内存\n\n### 什么是主从复制？实现原理是什么？\n主从复制（Replication）是指数据可以从一个MySQL数据库主服务器复制到一个或多个从服务器，从服务器可以复制主服务器中的所有数据库或者特定的数据库，或者特定的表。默认采用异步模式。\n\n实现原理：\n- 主服务器 **binary log dump 线程**：将主服务器中的数据更改（增删改）日志写入 Binary log 中；\n- 从服务器 **I/O 线程**：负责从主服务器读取binary log，并写入本地的 Relay log；\n- 从服务器 **SQL 线程**：负责读取 Relay log，解析出主服务器已经执行的数据更改，并在从服务器中重新执行（Replay），保证主从数据的一致性\n\n##### 为什么要主从复制？\n- 读写分离：主服务器负责写，从服务器负责读\n    - 缓解了锁的争用，即使主服务器中加了锁，依然可以进行读操作；\n    - 从服务器可以使用 MyISAM，提升查询性能以及节约系统开销；\n    - 增加冗余，提高可用性\n- 数据实时备份，当系统中某个节点发生故障时，可以方便的故障切换\n- 降低单个服务器磁盘I/O访问的频率，提高单个机器的I/O性能\n\n# NoSQL/Redis\n- [几率大的Redis面试题（含答案） - CSDN](https://blog.csdn.net/Butterfly_resting/article/details/89668661)\n- [CyC2018](https://github.com/CyC2018/CS-Notes/blob/master/notes/Redis.md)\n- [Redis面试题总结 - 简书](https://www.jianshu.com/p/65765dd10671)\n- [Redis常见面试题 - 博客园](https://www.cnblogs.com/jasontec/p/9699242.html)\n- [0voice/interview_internal_reference](https://github.com/0voice/interview_internal_reference#10)\n\n文章内容搬运自本人[语雀](https://www.yuque.com/docs/share/c6097254-4f08-4d0f-b9c0-550c9274e6be)\n","source":"_posts/面试八股文（三）——-数据库.md","raw":"---\ntitle: 面试八股文（三）—— 数据库\ndate: 2021-09-22 22:48:25\nupdated: 2021-09-22 23:24:26\ntags: ['八股文', '数据库', 'MySQL', 'NoSQL']\ncategories:\n - 八股文\n - 数据库\n - NoSQL\ndescription: 根据我多年（其实就一年）复习备考408和春招的经验，总结出来的面试八股文第三篇，也是基础篇之三——计算机网络相关的常见问题。如果文章中有看不懂的知识点，强力推荐极客时间的MySQL45讲相关课程，讲的巨清晰无比。\n---\n\n<meta name=\"referrer\" content=\"no-referrer\" />\n\n# 数据库基础\n### 事务的概念和特性？\n概念：事务（Transaction）是一个操作序列，不可分割的工作单位，以BEGIN TRANSACTION开始，以ROLLBACK/COMMIT结束\n特性（ACID）：\n- **原子性**（Atomicity）：逻辑上是不可分割的操作单元，事务的所有操作要么全部提交成功，要么全部失败回滚（用回滚日志实现，反向执行日志中的操作）；\n- **一致性**（Consistency）：事务的执行必须使数据库保持一致性状态。在一致性状态下，所有事务对一个数据的读取结果都是相同的；\n- **隔离性**（Isolation）：一个事务所做的修改在最终提交以前，对其它事务是不可见的（并发执行的事务之间不能相互影响）；\n- **持久性**（Durability）：一旦事务提交成功，对数据的修改是永久性的\n\n### 会出现哪些并发一致性问题？\n- **丢失修改**：一个事务对数据进行了修改，在事务提交之前，另一个事务对同一个数据进行了修改，覆盖了之前的修改；\n- **脏读**（Dirty Read）：一个事务读取了被另一个事务修改、但未提交（进行了回滚）的数据，造成两个事务得到的数据不一致；\n- **不可重复读**（Nonrepeatable Read）：在同一个事务中，某查询操作在一个时间读取某一行数据和之后一个时间读取该行数据，发现数据已经发生修改（针对**update**操作）；\n- **幻读**（Phantom Read）：当同一查询多次执行时，由于其它事务在这个数据范围内执行了插入操作，会导致每次返回不同的结果集（和不可重复读的区别：针对的是一个数据整体/范围；并且针对**insert/delete**操作）\n\n### 数据库的四种隔离级别？\n- **未提交读**（Read Uncommited）：在一个事务提交之前，它的执行结果对其它事务也是可见的。会导致脏读、不可重复读、幻读；\n- **提交读**（Read Commited）：一个事务只能看见已经提交的事务所作的改变。可避免脏读问题；\n- **可重复读**（Repeatable Read）：可以确保同一个事务在多次读取同样的数据时得到相同的结果。（MySQL的默认隔离级别）。可避免不可重复读；\n- **可串行化**（Serializable）：强制事务串行执行，使之不可能相互冲突，从而解决幻读问题。可能导致大量的超时现象和锁竞争，实际很少使用。\n\n### 什么是乐观锁和悲观锁？\n- 悲观锁：认为数据随时会被修改，因此每次读取数据之前都会上锁，防止其它事务读取或修改数据；应用于**数据更新比较频繁**的场景；\n- 乐观锁：操作数据时不会上锁，但是更新时会判断在此期间有没有别的事务更新这个数据，若被更新过，则失败重试；适用于**读多写少**的场景。乐观锁的实现方式有：\n    - 加一个版本号或者时间戳字段，每次数据更新时同时更新这个字段；\n    - 先读取想要更新的字段或者所有字段，更新的时候比较一下，只有字段没有变化才进行更新\n\n### 常见的封锁类型？\n意向锁是 InnoDB 自动加的， 不需用户干预。\n对于 UPDATE、 DELETE 和 INSERT 语句， InnoDB\n会自动给涉及数据集加排他锁（X)；\n对于普通 SELECT 语句，InnoDB 不会加任何锁；\n事务可以通过以下语句显式给记录集加共享锁或排他锁：\n共享锁（S）：SELECT * FROM table_name WHERE ... LOCK IN SHARE MODE。 其他 session 仍然可以查询记录，并也可以对该记录加 share mode 的共享锁。但是如果当前事务需要对该记录进行更新操作，则很有可能造成死锁。\n排他锁（X)：SELECT * FROM table_name WHERE ... FOR UPDATE。其他 session 可以查询该记录，但是不能对该记录加共享锁或排他锁，而是等待获得锁\n\n- **排它锁**（Exclusive Lock）/ X锁：事务对数据加上X锁时，只允许此事务读取和修改此数据，并且其它事务不能对该数据加任何锁；\n- **共享锁**（Shared Lock）/ S锁：加了S锁后，该事务只能对数据进行读取而不能修改，并且其它事务只能加S锁，不能加X锁\n- **意向锁**（Intention Locks）：\n    - 一个事务在获得某个**数据行**对象的 S 锁之前，必须先获得**整个表**的 IS 锁或更强的锁；\n    - 一个事务在获得某个数据行对象的 X 锁之前，必须先获得整个表的 IX 锁；\n    - IS/IX 锁之间都是兼容的；\n    - 好处：如果一个事务想要对整个表加X锁，就需要先检测是否有其它事务对该表或者该表中的某一行加了锁，这种检测非常耗时。有了意向锁之后，只需要检测整个表是否存在IX/IS/X/S锁就行了\n\n锁的作用：用于管理对共享资源的并发访问，保证数据库的完整性和一致性\n\nMySQL 中提供了两种封锁粒度：**行级锁**以及**表级锁**。\n封锁粒度小：\n\n- 好处：锁定的数据量越少，发生锁争用的可能就越小，系统的**并发程度**就越高；\n- 坏处：**系统开销**大（加锁、释放锁、检查锁的状态都需要消耗资源）\n\n```\nSELECT ... LOCK In SHARE MODE;\nSELECT ... FOR UPDATE;\n```\n\n### 什么是三级封锁协议？\n- 一级封锁协议：事务在修改数据之前必须先对其加X锁，直到事务结束才释放。可以解决丢失修改问题（两个事务不能同时对一个数据加X锁，避免了修改被覆盖）；\n- 二级封锁协议：在一级的基础上，事务在读取数据之前必须先加S锁，读完后释放。可以解决脏读问题（如果已经有事务在修改数据，就意味着已经加了X锁，此时想要读取数据的事务并不能加S锁，也就无法进行读取，避免了读取脏数据）；\n- 三级封锁协议：在二级的基础上，事务在读取数据之前必须先加S锁，直到事务结束才能释放。可以解决不可重复读问题（避免了在事务结束前其它事务对数据加X锁进行修改，保证了事务期间数据不会被其它事务更新）\n\n### 什么是两段锁协议？\n事务必须严格分为两个阶段对数据进行**加锁和解锁**的操作，第一阶段加锁，第二阶段解锁。也就是说一个事务中一旦释放了锁，就不能再申请新锁了。\n\n**可串行化调度**是指，通过并发控制，使得并发执行的事务结果与某个串行执行的事务结果相同。事务遵循两段锁协议是保证可串行化调度的充分条件。\n\n### 什么是 MVCC？\n多版本并发控制（Multi-Version Concurrency Control, MVCC），MVCC在每行记录后面都保存有两个隐藏的列，用来存储**创建版本号**和**删除版本号**。\n\n- 创建版本号：创建一个数据行时的事务版本号（**事务版本号**：事务开始时的系统版本号；系统版本号：每开始一个新的事务，系统版本号就会自动递增）；\n- 删除版本号：删除操作时的事务版本号；\n- 各种操作：\n    - 插入操作时，记录创建版本号；\n    - 删除操作时，记录删除版本号；\n    - 更新操作时，先记录删除版本号，再新增一行记录创建版本号；\n    - 查询操作时，要符合以下条件才能被查询出来：删除版本号未定义或大于当前事务版本号（删除操作是在当前事务启动之后做的）；创建版本号小于或等于当前事务版本号（创建操作是事务完成或者在事务启动之前完成）\n\n通过版本号减少了锁的争用，**提高了系统性能**；可以实现**提交读**和**可重复读**两种隔离级别，未提交读无需使用MVCC\n\n使用 MVCC 读取的是快照中的数据，这样可以减少加锁所带来的开销：\n```\nselect * from table ...;\n```\n当前读读取的是最新的数据，需要加锁。以下第一个语句需要加 S 锁，其它都需要加 X 锁：\n```\nselect * from table where ? lock in share mode;\nselect * from table where ? for update;\ninsert;\nupdate;\ndelete;\n```\n\n### 数据库的范式？\n- **第一范式**（1NF，Normal Form）：**属性不应该是可分的**。举例：如果将“电话”作为一个属性（一列），是不符合1NF的，因为电话这个属性可以分解为家庭电话和移动电话...如果将“移动电话”作为一个属性，就符合1NF；\n- **第二范式** 2NF：每个非主属性**完全依赖**于主属性集（候选键集）；\n    - B完全依赖于A，就是说A中的所有属性唯一决定B，属性少了就不能唯一决定，属性多了则有冗余（叫依赖不叫完全依赖）。举例：（学号，课程名）这个主属性集可以唯一决定成绩，但是对于学生姓名这个属性，（学号，课程名）这个属性集就是冗余的，所以学生姓名不完全依赖于（学号，课程名）这一属性集；\n    - 主属性集/候选码集：某一组属性能够唯一确定其它的属性（主键就是从候选键集中选的一个键），而其子集不能，这样的属性组中的属性就是主属性；不在候选码集中的属性成为非主属性；\n    - 可以通过分解来满足 2NF：将（学号，课程名，成绩）做成一张表；（学号，学生姓名）做成另一张表，避免大量的数据冗余；\n      满足1NF后，要求表中的所有列，都必须依赖于主键，而不能有任何一列与主键没有关系，也就是说一个表只描述一件事情；\n- **第三范式** 3NF：在 2NF 的基础上，非主属性**不传递依赖**于主属性\n    - 传递依赖：如果C依赖于B，B依赖于A，那么C传递依赖于A；\n    - 3NF在2NF的基础上，消除了非主属性之间的依赖；比如一个表中，主属性有（学号），非主属性有（姓名，院系，院长名），可以看到院长名这个非主属性依赖于院系，传递依赖于学号。消除的办法是分解。\n      必须先满足第二范式（2NF），要求：表中的每一列只与主键直接相关而不是间接相关，（表中的每一列只能依赖于主键）；\n\n- 冗余数据：某些同样的数据多次出现（如学生姓名）；\n- 修改异常：修改了一个记录中的信息，另一个记录中相同的信息却没有修改；\n- 删除异常：删除一个信息，那么也会丢失其它信息（删除一个课程，丢失了一个学生的信息）；\n- 插入异常：无法插入（插入一个还没有课程信息的学生）\n\n### 列举几种表连接方式？\n![](https://cdn.nlark.com/yuque/0/2021/png/1431305/1628085012977-cccccdf6-0f16-4343-8cd4-68631fb6b78a.png)\n\n\n- 内连接（Inner Join）：仅将两个表中满足连接条件的行组合起来作为结果集\n    - 自然连接：只考虑属性相同的元组对；\n    - 等值连接：给定条件进行查询\n\n\n\n- 外连接（Outer Join）\n    - 左连接：左边表的所有数据都有显示出来，右边的表数据只显示共同有的那部分，没有对应的部分补NULL；\n    - 右连接：和左连接相反；\n    - 全外连接（Full Outer Join）：查询出左表和右表所有数据，但是去除两表的重复数据\n\n\n\n- 交叉连接（Cross Join）：返回两表的笛卡尔积（对于所含数据分别为m、n的表，返回m*n的结果）\n\n### 什么是存储过程？有哪些优缺点？\n存储过程是事先经过编译并存储在数据库中的一段SQL语句的集合。想要实现相应的功能时，只需要调用这个存储过程就行了（类似于函数，输入具有输出参数）。\n优点：\n- 预先编译，而不需要每次运行时编译，提高了数据库执行**效率**；\n- 封装了一系列操作，对于一些数据交互比较多的操作，相比于单独执行SQL语句，可以**减少网络通信量**；\n- 具有**可复用性**，减少了数据库开发的工作量；\n- **安全性高**，可以让没有权限的用户通过存储过程间接操作数据库；\n- 更**易于维护**\n\n缺点：\n- **可移植性差**，存储过程将应用程序绑定到了数据库上；\n- **开发调试复杂**：没有好的IDE；\n- **修改复杂**，需要重新编译，有时还需要更新程序中的代码以更新调用\n\n### Drop/Delete/Truncate的区别？\n- **Delete**用来删除表的全部或者**部分数据**，执行delete之后，用户**需要提交**之后才会执行，会触发表上的DELETE**触发器**（包含一个OLD的虚拟表，可以只读访问被删除的数据），DELETE之后表结构还在，删除很慢，一行一行地删，因为会记录日志，可以利用日志还原数据；\n- **Truncate**删除表中的所有数据，这个操作**不能回滚**，也不会触发这个表上的触发器。操作比DELETE快很多（直接把表drop掉，再创建一个新表，删除的数据不能找回）。如果表中有自增（AUTO_INCREMENT）列，则重置为1；\n- **Drop**命令从数据库中**删除表**，所有的数据行，索引和约束都会被删除；不能回滚，不会触发触发器；\n\n触发器（TRIGGER）是由事件（比如INSERT/UPDATE/DELETE）来触发运行的操作（不能被直接调用，不能接收参数）。在数据库里以独立的对象存储，用于**保证数据完整性**（比如可以检验或转换数据）。\n\n约束（Constraint）类型：主键（Primary Key）约束，唯一约束（Unique），检查约束，非空约束，外键（Foreign Key）约束。\n\n### 什么是视图？什么是游标？\n- 视图：从数据库的基本表中通过查询选取出来的数据组成的**虚拟表**（数据库中存放视图的定义）。可以对其进行增/删/改/查等操作。视图是对若干张基本表的引用，一张虚表，查询语句执行的结果，不存储具体的数据（基本表数据发生了改变，视图也会跟着改变）；可以跟基本表一样，进行增删改查操作(ps:增删改操作有条件限制)；如连表查询产生的视图无法进行，对视图的增删改会影响原表的数据。好处：\n    - 通过只给用户访问视图的权限，保证数据的**安全性**；\n    - **简化**复杂的SQL操作，隐藏数据的复杂性（比如复杂的连接）；\n- 游标（Cursor）：用于定位在查询返回的**结果集的特定行**，以对特定行进行操作。使用游标可以方便地对结果集进行移动遍历，根据需要滚动或对浏览/修改任意行中的数据。主要用于交互式应用。\n# MySQL\n### 数据库索引的实现原理（B+树）\n\n见[数据结构部分：B树，B+树](https://github.com/wolverinn/Iridescent/blob/master/Data%20Structure.md#b%E6%A0%91)\n\n##### 使用B树和B+树的比较\nInnoDB的索引使用的是B+树实现，B+树对比B树的好处：\n\n- IO次数少：B+树的中间结点只存放索引，数据都存在叶结点中，因此中间结点可以存更多的数据，让索引树更加矮胖；\n- 范围查询效率更高：B树需要中序遍历整个树，只B+树需要遍历叶结点中的链表；\n- 查询效率更加稳定：每次查询都需要从根结点到叶结点，路径长度相同，所以每次查询的效率都差不多\n\n##### 使用B树索引和哈希索引的比较\n哈希索引能以 O(1) 时间进行查找，但是只支持精确查找，无法用于部分查找和范围查找，无法用于排序与分组；B树索引支持大于小于等于查找，范围查找。哈希索引遇到大量哈希值相等的情况后查找效率会降低。哈希索引不支持数据的排序。\n\n### 使用索引的优点\n- 大大加快了数据的**检索速度**；\n- 可以显著减少查询中**分组和排序**的时间；\n- 通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性；\n- 将随机 I/O 变为**顺序 I/O**（B+Tree 索引是有序的，会将相邻的数据都存储在一起）\n\n缺点：建立和维护索引耗费时间空间，更新索引很慢。\n### 哪些情况下索引会失效？\n- 以“%(表示任意0个或多个字符)”开头的LIKE语句；\n- OR语句前后没有同时使用索引；\n- 数据类型出现隐式转化（如varchar不加单引号的话可能会自动转换为int型）；\n- 对于多列索引，必须满足 **最左匹配原则**/最左前缀原则 (最左优先，eg：多列索引col1、col2和col3，则 索引生效的情形包括 col1或col1，col2或col1，col2，col3)；\n- 如果MySQL估计全表扫描比索引快，则不使用索引（比如非常小的表）\n\n### 在哪些地方适合创建索引？\n- 某列经常作为最大最小值；\n- 经常被查询的字段；\n- 经常用作表连接的字段；\n- 经常出现在ORDER BY/GROUP BY/DISDINCT后面的字段\n\n##### 创建索引时需要注意什么？\n- 只应建立在**小字段**上，而不要对大文本或图片建立索引（一页存储的数据越多一次IO操作获取的数据越大效率越高）；\n- 建立索引的字段应该**非空**，在MySQL中，含有空值的列很难进行查询优化，因为它们使得索引、索引的统计信息以及比较运算更加复杂。应该用0、一个特殊的值或者一个空串代替NULL；\n- 选择**数据密度大**（唯一值占总数的百分比很大）的字段作索引\n\n### 索引的分类？\n- 普通索引\n- 唯一索引 UNIQUE：索引列的值必须唯一，但允许有空值；\n- 主键索引 PRIMARY KEY：必须唯一，不允许空值（是一种特殊的唯一索引；MySQL创建主键时默认为聚集索引，但主键也可以是非聚集索引）；\n- 单列索引和多列索引/复合索引（Composite）：索引的列数；\n- 覆盖（Covering）索引：索引包含了所有满足查询所需要的数据，查询的时候只需要读取索引而不需要回表读取数据；\n- 聚集（Clustered）索引/非聚集索引：对磁盘上存放数据的物理地址重新组织以使这些数据按照指定规则排序的一种索引（数据的物理排列顺序和索引排列顺序一致）。因此每张表只能创建一个聚集索引（因为要改变物理存储顺序）。优点是查询速度快，因为可以直接按照顺序得到需要数据的物理地址。缺点是进行修改的速度较慢。对于需要经常搜索范围的值很有效。非聚集索引只记录逻辑顺序，并不改变物理顺序；\n- 分区索引（？）\n- 虚拟索引（Virtual）：模拟索引的存在而不用真正创建一个索引，用于快速测试创建索引对执行计划的影响。没有相关的索引段，不增加存储空间的使用\n\n### MySQL的两种存储引擎 InnoDB 和 MyISAM 的区别？\n- InnoDB**支持事务**，可以进行Commit和Rollback；\n- MyISAM 只支持表级锁，而 InnoDB 还**支持行级锁**，提高了并发操作的性能；\n- InnoDB **支持外键**；\n- MyISAM **崩溃**后发生损坏的概率比 InnoDB 高很多，而且**恢复的速度**也更慢；\n- MyISAM 支持**压缩**表和空间数据索引，InnoDB需要更多的内存和存储；\n- InnoDB 支持在线**热备份**\n\n- **MyISAM** 管理非事务表。它提供高速存储和检索（MyISAM强调的是性能，每次查询具有原子性，其执行速度比InnoDB更快），以及全文搜索能力。如果表比较小，或者是只读数据（有大量的SELECT），还是可以使用MyISAM；\n- **InnoDB** 支持事务，并发情况下有很好的性能，基本可以替代MyISAM\n\n- 热备份：在数据库运行的情况下备份的方法。优点：可按表或用户备份，备份时数据库仍可使用，可恢复至任一时间点。但是不能出错\n- 冷备份：数据库正常关闭后，将关键性文件复制到另一位置的备份方式。优点：操作简单快速，恢复简单\n\n更详细的可以参考：[MySQL 数据库的存储引擎与适用场景 - Images](https://imageslr.github.io/2020/db-engine.html)\n### 如何优化数据库？\n> 分析慢查询日志：记录了在MySQL中响应时间超过阀值long_query_time的SQL语句，通过日志去找出IO大的SQL以及发现未命中索引的SQL\n\n> 使用 Explain 进行分析：通过explain命令可以得到表的读取顺序、数据读取操作的操作类型、哪些索引可以使用、**哪些索引被实际使用**、表之间的引用以及**被扫描的行数**等问题；\n\n- 应尽量避免在 where 子句中使用`!=`、`<`、`>`操作符或对字段进行null值判断，否则将引擎放弃使用索引而进行全表扫描；\n- 只返回必要的列：最好不要使用 SELECT * 语句；\n- 只返回必要的行：使用 LIMIT 语句来限制返回的数据；\n- 将一个大连接查询分解成对每一个表进行一次单表查询，然后在应用程序中进行关联，这样做的好处有：\n    - 让缓存更高效。对于连接查询，如果其中一个表发生变化，那么整个查询缓存就无法使用。而分解后的多个查询，即使其中一个表发生变化，对其它表的查询缓存依然可以使用；\n    - 分解成多个单表查询，这些单表查询的缓存结果更可能被其它查询使用到，从而减少冗余的查询；\n    - 减少锁竞争\n\n注意会引起索引失效的情况，以及在适合的地方建立索引\n\n- 设计表时遵循**三大范式**；\n- 选择合适的**数据类型**：尽可能不要存储NULL字段；使用简单的数据类型（int, varchar/ text）；\n- 表的**水平切分**（Sharding）：将同一个表中的记录拆分到多个结构相同的表中（策略：哈希取模；根据ID范围来分）。当一个表的数据不断增多时，Sharding 是必然的选择，它可以将数据分布到集群的不同节点上，从而缓解单个数据库的压力；\n- 表的**垂直切分**：将一张表按列切分成多个表。可以将不常用的字段单独放在同一个表中；把大字段独立放入一个表中；或者把经常使用的字段（关系密切的）放在一张表中。垂直切分之后业务更加清晰，系统之间整合或扩展容易，数据维护简单\n\n- 操作系统：增加TCP支持的队列数；\n- MySQL配置文件优化：缓存池大小和个数设置\n\n- 磁盘性能：固态硬盘；\n- CPU：多核且高频；\n- 内存：增大内存\n\n### 什么是主从复制？实现原理是什么？\n主从复制（Replication）是指数据可以从一个MySQL数据库主服务器复制到一个或多个从服务器，从服务器可以复制主服务器中的所有数据库或者特定的数据库，或者特定的表。默认采用异步模式。\n\n实现原理：\n- 主服务器 **binary log dump 线程**：将主服务器中的数据更改（增删改）日志写入 Binary log 中；\n- 从服务器 **I/O 线程**：负责从主服务器读取binary log，并写入本地的 Relay log；\n- 从服务器 **SQL 线程**：负责读取 Relay log，解析出主服务器已经执行的数据更改，并在从服务器中重新执行（Replay），保证主从数据的一致性\n\n##### 为什么要主从复制？\n- 读写分离：主服务器负责写，从服务器负责读\n    - 缓解了锁的争用，即使主服务器中加了锁，依然可以进行读操作；\n    - 从服务器可以使用 MyISAM，提升查询性能以及节约系统开销；\n    - 增加冗余，提高可用性\n- 数据实时备份，当系统中某个节点发生故障时，可以方便的故障切换\n- 降低单个服务器磁盘I/O访问的频率，提高单个机器的I/O性能\n\n# NoSQL/Redis\n- [几率大的Redis面试题（含答案） - CSDN](https://blog.csdn.net/Butterfly_resting/article/details/89668661)\n- [CyC2018](https://github.com/CyC2018/CS-Notes/blob/master/notes/Redis.md)\n- [Redis面试题总结 - 简书](https://www.jianshu.com/p/65765dd10671)\n- [Redis常见面试题 - 博客园](https://www.cnblogs.com/jasontec/p/9699242.html)\n- [0voice/interview_internal_reference](https://github.com/0voice/interview_internal_reference#10)\n\n文章内容搬运自本人[语雀](https://www.yuque.com/docs/share/c6097254-4f08-4d0f-b9c0-550c9274e6be)\n","slug":"面试八股文（三）——-数据库","published":1,"comments":1,"layout":"post","photos":[],"link":"","_id":"cktvosiea00092svu742weofz","content":"<meta name=\"referrer\" content=\"no-referrer\" />\n\n<h1 id=\"数据库基础\"><a href=\"#数据库基础\" class=\"headerlink\" title=\"数据库基础\"></a>数据库基础</h1><h3 id=\"事务的概念和特性？\"><a href=\"#事务的概念和特性？\" class=\"headerlink\" title=\"事务的概念和特性？\"></a>事务的概念和特性？</h3><p>概念：事务（Transaction）是一个操作序列，不可分割的工作单位，以BEGIN TRANSACTION开始，以ROLLBACK/COMMIT结束<br>特性（ACID）：</p>\n<ul>\n<li><strong>原子性</strong>（Atomicity）：逻辑上是不可分割的操作单元，事务的所有操作要么全部提交成功，要么全部失败回滚（用回滚日志实现，反向执行日志中的操作）；</li>\n<li><strong>一致性</strong>（Consistency）：事务的执行必须使数据库保持一致性状态。在一致性状态下，所有事务对一个数据的读取结果都是相同的；</li>\n<li><strong>隔离性</strong>（Isolation）：一个事务所做的修改在最终提交以前，对其它事务是不可见的（并发执行的事务之间不能相互影响）；</li>\n<li><strong>持久性</strong>（Durability）：一旦事务提交成功，对数据的修改是永久性的</li>\n</ul>\n<h3 id=\"会出现哪些并发一致性问题？\"><a href=\"#会出现哪些并发一致性问题？\" class=\"headerlink\" title=\"会出现哪些并发一致性问题？\"></a>会出现哪些并发一致性问题？</h3><ul>\n<li><strong>丢失修改</strong>：一个事务对数据进行了修改，在事务提交之前，另一个事务对同一个数据进行了修改，覆盖了之前的修改；</li>\n<li><strong>脏读</strong>（Dirty Read）：一个事务读取了被另一个事务修改、但未提交（进行了回滚）的数据，造成两个事务得到的数据不一致；</li>\n<li><strong>不可重复读</strong>（Nonrepeatable Read）：在同一个事务中，某查询操作在一个时间读取某一行数据和之后一个时间读取该行数据，发现数据已经发生修改（针对<strong>update</strong>操作）；</li>\n<li><strong>幻读</strong>（Phantom Read）：当同一查询多次执行时，由于其它事务在这个数据范围内执行了插入操作，会导致每次返回不同的结果集（和不可重复读的区别：针对的是一个数据整体/范围；并且针对<strong>insert/delete</strong>操作）</li>\n</ul>\n<h3 id=\"数据库的四种隔离级别？\"><a href=\"#数据库的四种隔离级别？\" class=\"headerlink\" title=\"数据库的四种隔离级别？\"></a>数据库的四种隔离级别？</h3><ul>\n<li><strong>未提交读</strong>（Read Uncommited）：在一个事务提交之前，它的执行结果对其它事务也是可见的。会导致脏读、不可重复读、幻读；</li>\n<li><strong>提交读</strong>（Read Commited）：一个事务只能看见已经提交的事务所作的改变。可避免脏读问题；</li>\n<li><strong>可重复读</strong>（Repeatable Read）：可以确保同一个事务在多次读取同样的数据时得到相同的结果。（MySQL的默认隔离级别）。可避免不可重复读；</li>\n<li><strong>可串行化</strong>（Serializable）：强制事务串行执行，使之不可能相互冲突，从而解决幻读问题。可能导致大量的超时现象和锁竞争，实际很少使用。</li>\n</ul>\n<h3 id=\"什么是乐观锁和悲观锁？\"><a href=\"#什么是乐观锁和悲观锁？\" class=\"headerlink\" title=\"什么是乐观锁和悲观锁？\"></a>什么是乐观锁和悲观锁？</h3><ul>\n<li>悲观锁：认为数据随时会被修改，因此每次读取数据之前都会上锁，防止其它事务读取或修改数据；应用于<strong>数据更新比较频繁</strong>的场景；</li>\n<li>乐观锁：操作数据时不会上锁，但是更新时会判断在此期间有没有别的事务更新这个数据，若被更新过，则失败重试；适用于<strong>读多写少</strong>的场景。乐观锁的实现方式有：<ul>\n<li>加一个版本号或者时间戳字段，每次数据更新时同时更新这个字段；</li>\n<li>先读取想要更新的字段或者所有字段，更新的时候比较一下，只有字段没有变化才进行更新</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"常见的封锁类型？\"><a href=\"#常见的封锁类型？\" class=\"headerlink\" title=\"常见的封锁类型？\"></a>常见的封锁类型？</h3><p>意向锁是 InnoDB 自动加的， 不需用户干预。<br>对于 UPDATE、 DELETE 和 INSERT 语句， InnoDB<br>会自动给涉及数据集加排他锁（X)；<br>对于普通 SELECT 语句，InnoDB 不会加任何锁；<br>事务可以通过以下语句显式给记录集加共享锁或排他锁：<br>共享锁（S）：SELECT * FROM table_name WHERE … LOCK IN SHARE MODE。 其他 session 仍然可以查询记录，并也可以对该记录加 share mode 的共享锁。但是如果当前事务需要对该记录进行更新操作，则很有可能造成死锁。<br>排他锁（X)：SELECT * FROM table_name WHERE … FOR UPDATE。其他 session 可以查询该记录，但是不能对该记录加共享锁或排他锁，而是等待获得锁</p>\n<ul>\n<li><strong>排它锁</strong>（Exclusive Lock）/ X锁：事务对数据加上X锁时，只允许此事务读取和修改此数据，并且其它事务不能对该数据加任何锁；</li>\n<li><strong>共享锁</strong>（Shared Lock）/ S锁：加了S锁后，该事务只能对数据进行读取而不能修改，并且其它事务只能加S锁，不能加X锁</li>\n<li><strong>意向锁</strong>（Intention Locks）：<ul>\n<li>一个事务在获得某个<strong>数据行</strong>对象的 S 锁之前，必须先获得<strong>整个表</strong>的 IS 锁或更强的锁；</li>\n<li>一个事务在获得某个数据行对象的 X 锁之前，必须先获得整个表的 IX 锁；</li>\n<li>IS/IX 锁之间都是兼容的；</li>\n<li>好处：如果一个事务想要对整个表加X锁，就需要先检测是否有其它事务对该表或者该表中的某一行加了锁，这种检测非常耗时。有了意向锁之后，只需要检测整个表是否存在IX/IS/X/S锁就行了</li>\n</ul>\n</li>\n</ul>\n<p>锁的作用：用于管理对共享资源的并发访问，保证数据库的完整性和一致性</p>\n<p>MySQL 中提供了两种封锁粒度：<strong>行级锁</strong>以及<strong>表级锁</strong>。<br>封锁粒度小：</p>\n<ul>\n<li>好处：锁定的数据量越少，发生锁争用的可能就越小，系统的<strong>并发程度</strong>就越高；</li>\n<li>坏处：<strong>系统开销</strong>大（加锁、释放锁、检查锁的状态都需要消耗资源）</li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SELECT ... LOCK In SHARE MODE;</span><br><span class=\"line\">SELECT ... FOR UPDATE;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"什么是三级封锁协议？\"><a href=\"#什么是三级封锁协议？\" class=\"headerlink\" title=\"什么是三级封锁协议？\"></a>什么是三级封锁协议？</h3><ul>\n<li>一级封锁协议：事务在修改数据之前必须先对其加X锁，直到事务结束才释放。可以解决丢失修改问题（两个事务不能同时对一个数据加X锁，避免了修改被覆盖）；</li>\n<li>二级封锁协议：在一级的基础上，事务在读取数据之前必须先加S锁，读完后释放。可以解决脏读问题（如果已经有事务在修改数据，就意味着已经加了X锁，此时想要读取数据的事务并不能加S锁，也就无法进行读取，避免了读取脏数据）；</li>\n<li>三级封锁协议：在二级的基础上，事务在读取数据之前必须先加S锁，直到事务结束才能释放。可以解决不可重复读问题（避免了在事务结束前其它事务对数据加X锁进行修改，保证了事务期间数据不会被其它事务更新）</li>\n</ul>\n<h3 id=\"什么是两段锁协议？\"><a href=\"#什么是两段锁协议？\" class=\"headerlink\" title=\"什么是两段锁协议？\"></a>什么是两段锁协议？</h3><p>事务必须严格分为两个阶段对数据进行<strong>加锁和解锁</strong>的操作，第一阶段加锁，第二阶段解锁。也就是说一个事务中一旦释放了锁，就不能再申请新锁了。</p>\n<p><strong>可串行化调度</strong>是指，通过并发控制，使得并发执行的事务结果与某个串行执行的事务结果相同。事务遵循两段锁协议是保证可串行化调度的充分条件。</p>\n<h3 id=\"什么是-MVCC？\"><a href=\"#什么是-MVCC？\" class=\"headerlink\" title=\"什么是 MVCC？\"></a>什么是 MVCC？</h3><p>多版本并发控制（Multi-Version Concurrency Control, MVCC），MVCC在每行记录后面都保存有两个隐藏的列，用来存储<strong>创建版本号</strong>和<strong>删除版本号</strong>。</p>\n<ul>\n<li>创建版本号：创建一个数据行时的事务版本号（<strong>事务版本号</strong>：事务开始时的系统版本号；系统版本号：每开始一个新的事务，系统版本号就会自动递增）；</li>\n<li>删除版本号：删除操作时的事务版本号；</li>\n<li>各种操作：<ul>\n<li>插入操作时，记录创建版本号；</li>\n<li>删除操作时，记录删除版本号；</li>\n<li>更新操作时，先记录删除版本号，再新增一行记录创建版本号；</li>\n<li>查询操作时，要符合以下条件才能被查询出来：删除版本号未定义或大于当前事务版本号（删除操作是在当前事务启动之后做的）；创建版本号小于或等于当前事务版本号（创建操作是事务完成或者在事务启动之前完成）</li>\n</ul>\n</li>\n</ul>\n<p>通过版本号减少了锁的争用，<strong>提高了系统性能</strong>；可以实现<strong>提交读</strong>和<strong>可重复读</strong>两种隔离级别，未提交读无需使用MVCC</p>\n<p>使用 MVCC 读取的是快照中的数据，这样可以减少加锁所带来的开销：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">select * from table ...;</span><br></pre></td></tr></table></figure>\n<p>当前读读取的是最新的数据，需要加锁。以下第一个语句需要加 S 锁，其它都需要加 X 锁：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">select * from table where ? lock in share mode;</span><br><span class=\"line\">select * from table where ? for update;</span><br><span class=\"line\">insert;</span><br><span class=\"line\">update;</span><br><span class=\"line\">delete;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"数据库的范式？\"><a href=\"#数据库的范式？\" class=\"headerlink\" title=\"数据库的范式？\"></a>数据库的范式？</h3><ul>\n<li><p><strong>第一范式</strong>（1NF，Normal Form）：<strong>属性不应该是可分的</strong>。举例：如果将“电话”作为一个属性（一列），是不符合1NF的，因为电话这个属性可以分解为家庭电话和移动电话…如果将“移动电话”作为一个属性，就符合1NF；</p>\n</li>\n<li><p><strong>第二范式</strong> 2NF：每个非主属性<strong>完全依赖</strong>于主属性集（候选键集）；</p>\n<ul>\n<li>B完全依赖于A，就是说A中的所有属性唯一决定B，属性少了就不能唯一决定，属性多了则有冗余（叫依赖不叫完全依赖）。举例：（学号，课程名）这个主属性集可以唯一决定成绩，但是对于学生姓名这个属性，（学号，课程名）这个属性集就是冗余的，所以学生姓名不完全依赖于（学号，课程名）这一属性集；</li>\n<li>主属性集/候选码集：某一组属性能够唯一确定其它的属性（主键就是从候选键集中选的一个键），而其子集不能，这样的属性组中的属性就是主属性；不在候选码集中的属性成为非主属性；</li>\n<li>可以通过分解来满足 2NF：将（学号，课程名，成绩）做成一张表；（学号，学生姓名）做成另一张表，避免大量的数据冗余；<br>满足1NF后，要求表中的所有列，都必须依赖于主键，而不能有任何一列与主键没有关系，也就是说一个表只描述一件事情；</li>\n</ul>\n</li>\n<li><p><strong>第三范式</strong> 3NF：在 2NF 的基础上，非主属性<strong>不传递依赖</strong>于主属性</p>\n<ul>\n<li>传递依赖：如果C依赖于B，B依赖于A，那么C传递依赖于A；</li>\n<li>3NF在2NF的基础上，消除了非主属性之间的依赖；比如一个表中，主属性有（学号），非主属性有（姓名，院系，院长名），可以看到院长名这个非主属性依赖于院系，传递依赖于学号。消除的办法是分解。<br>必须先满足第二范式（2NF），要求：表中的每一列只与主键直接相关而不是间接相关，（表中的每一列只能依赖于主键）；</li>\n</ul>\n</li>\n<li><p>冗余数据：某些同样的数据多次出现（如学生姓名）；</p>\n</li>\n<li><p>修改异常：修改了一个记录中的信息，另一个记录中相同的信息却没有修改；</p>\n</li>\n<li><p>删除异常：删除一个信息，那么也会丢失其它信息（删除一个课程，丢失了一个学生的信息）；</p>\n</li>\n<li><p>插入异常：无法插入（插入一个还没有课程信息的学生）</p>\n</li>\n</ul>\n<h3 id=\"列举几种表连接方式？\"><a href=\"#列举几种表连接方式？\" class=\"headerlink\" title=\"列举几种表连接方式？\"></a>列举几种表连接方式？</h3><p><img src=\"https://cdn.nlark.com/yuque/0/2021/png/1431305/1628085012977-cccccdf6-0f16-4343-8cd4-68631fb6b78a.png\"></p>\n<ul>\n<li>内连接（Inner Join）：仅将两个表中满足连接条件的行组合起来作为结果集<ul>\n<li>自然连接：只考虑属性相同的元组对；</li>\n<li>等值连接：给定条件进行查询</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li>外连接（Outer Join）<ul>\n<li>左连接：左边表的所有数据都有显示出来，右边的表数据只显示共同有的那部分，没有对应的部分补NULL；</li>\n<li>右连接：和左连接相反；</li>\n<li>全外连接（Full Outer Join）：查询出左表和右表所有数据，但是去除两表的重复数据</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li>交叉连接（Cross Join）：返回两表的笛卡尔积（对于所含数据分别为m、n的表，返回m*n的结果）</li>\n</ul>\n<h3 id=\"什么是存储过程？有哪些优缺点？\"><a href=\"#什么是存储过程？有哪些优缺点？\" class=\"headerlink\" title=\"什么是存储过程？有哪些优缺点？\"></a>什么是存储过程？有哪些优缺点？</h3><p>存储过程是事先经过编译并存储在数据库中的一段SQL语句的集合。想要实现相应的功能时，只需要调用这个存储过程就行了（类似于函数，输入具有输出参数）。<br>优点：</p>\n<ul>\n<li>预先编译，而不需要每次运行时编译，提高了数据库执行<strong>效率</strong>；</li>\n<li>封装了一系列操作，对于一些数据交互比较多的操作，相比于单独执行SQL语句，可以<strong>减少网络通信量</strong>；</li>\n<li>具有<strong>可复用性</strong>，减少了数据库开发的工作量；</li>\n<li><strong>安全性高</strong>，可以让没有权限的用户通过存储过程间接操作数据库；</li>\n<li>更<strong>易于维护</strong></li>\n</ul>\n<p>缺点：</p>\n<ul>\n<li><strong>可移植性差</strong>，存储过程将应用程序绑定到了数据库上；</li>\n<li><strong>开发调试复杂</strong>：没有好的IDE；</li>\n<li><strong>修改复杂</strong>，需要重新编译，有时还需要更新程序中的代码以更新调用</li>\n</ul>\n<h3 id=\"Drop-Delete-Truncate的区别？\"><a href=\"#Drop-Delete-Truncate的区别？\" class=\"headerlink\" title=\"Drop/Delete/Truncate的区别？\"></a>Drop/Delete/Truncate的区别？</h3><ul>\n<li><strong>Delete</strong>用来删除表的全部或者<strong>部分数据</strong>，执行delete之后，用户<strong>需要提交</strong>之后才会执行，会触发表上的DELETE<strong>触发器</strong>（包含一个OLD的虚拟表，可以只读访问被删除的数据），DELETE之后表结构还在，删除很慢，一行一行地删，因为会记录日志，可以利用日志还原数据；</li>\n<li><strong>Truncate</strong>删除表中的所有数据，这个操作<strong>不能回滚</strong>，也不会触发这个表上的触发器。操作比DELETE快很多（直接把表drop掉，再创建一个新表，删除的数据不能找回）。如果表中有自增（AUTO_INCREMENT）列，则重置为1；</li>\n<li><strong>Drop</strong>命令从数据库中<strong>删除表</strong>，所有的数据行，索引和约束都会被删除；不能回滚，不会触发触发器；</li>\n</ul>\n<p>触发器（TRIGGER）是由事件（比如INSERT/UPDATE/DELETE）来触发运行的操作（不能被直接调用，不能接收参数）。在数据库里以独立的对象存储，用于<strong>保证数据完整性</strong>（比如可以检验或转换数据）。</p>\n<p>约束（Constraint）类型：主键（Primary Key）约束，唯一约束（Unique），检查约束，非空约束，外键（Foreign Key）约束。</p>\n<h3 id=\"什么是视图？什么是游标？\"><a href=\"#什么是视图？什么是游标？\" class=\"headerlink\" title=\"什么是视图？什么是游标？\"></a>什么是视图？什么是游标？</h3><ul>\n<li>视图：从数据库的基本表中通过查询选取出来的数据组成的<strong>虚拟表</strong>（数据库中存放视图的定义）。可以对其进行增/删/改/查等操作。视图是对若干张基本表的引用，一张虚表，查询语句执行的结果，不存储具体的数据（基本表数据发生了改变，视图也会跟着改变）；可以跟基本表一样，进行增删改查操作(ps:增删改操作有条件限制)；如连表查询产生的视图无法进行，对视图的增删改会影响原表的数据。好处：<ul>\n<li>通过只给用户访问视图的权限，保证数据的<strong>安全性</strong>；</li>\n<li><strong>简化</strong>复杂的SQL操作，隐藏数据的复杂性（比如复杂的连接）；</li>\n</ul>\n</li>\n<li>游标（Cursor）：用于定位在查询返回的<strong>结果集的特定行</strong>，以对特定行进行操作。使用游标可以方便地对结果集进行移动遍历，根据需要滚动或对浏览/修改任意行中的数据。主要用于交互式应用。<h1 id=\"MySQL\"><a href=\"#MySQL\" class=\"headerlink\" title=\"MySQL\"></a>MySQL</h1><h3 id=\"数据库索引的实现原理（B-树）\"><a href=\"#数据库索引的实现原理（B-树）\" class=\"headerlink\" title=\"数据库索引的实现原理（B+树）\"></a>数据库索引的实现原理（B+树）</h3></li>\n</ul>\n<p>见<a href=\"https://github.com/wolverinn/Iridescent/blob/master/Data%20Structure.md#b%E6%A0%91\">数据结构部分：B树，B+树</a></p>\n<h5 id=\"使用B树和B-树的比较\"><a href=\"#使用B树和B-树的比较\" class=\"headerlink\" title=\"使用B树和B+树的比较\"></a>使用B树和B+树的比较</h5><p>InnoDB的索引使用的是B+树实现，B+树对比B树的好处：</p>\n<ul>\n<li>IO次数少：B+树的中间结点只存放索引，数据都存在叶结点中，因此中间结点可以存更多的数据，让索引树更加矮胖；</li>\n<li>范围查询效率更高：B树需要中序遍历整个树，只B+树需要遍历叶结点中的链表；</li>\n<li>查询效率更加稳定：每次查询都需要从根结点到叶结点，路径长度相同，所以每次查询的效率都差不多</li>\n</ul>\n<h5 id=\"使用B树索引和哈希索引的比较\"><a href=\"#使用B树索引和哈希索引的比较\" class=\"headerlink\" title=\"使用B树索引和哈希索引的比较\"></a>使用B树索引和哈希索引的比较</h5><p>哈希索引能以 O(1) 时间进行查找，但是只支持精确查找，无法用于部分查找和范围查找，无法用于排序与分组；B树索引支持大于小于等于查找，范围查找。哈希索引遇到大量哈希值相等的情况后查找效率会降低。哈希索引不支持数据的排序。</p>\n<h3 id=\"使用索引的优点\"><a href=\"#使用索引的优点\" class=\"headerlink\" title=\"使用索引的优点\"></a>使用索引的优点</h3><ul>\n<li>大大加快了数据的<strong>检索速度</strong>；</li>\n<li>可以显著减少查询中<strong>分组和排序</strong>的时间；</li>\n<li>通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性；</li>\n<li>将随机 I/O 变为<strong>顺序 I/O</strong>（B+Tree 索引是有序的，会将相邻的数据都存储在一起）</li>\n</ul>\n<p>缺点：建立和维护索引耗费时间空间，更新索引很慢。</p>\n<h3 id=\"哪些情况下索引会失效？\"><a href=\"#哪些情况下索引会失效？\" class=\"headerlink\" title=\"哪些情况下索引会失效？\"></a>哪些情况下索引会失效？</h3><ul>\n<li>以“%(表示任意0个或多个字符)”开头的LIKE语句；</li>\n<li>OR语句前后没有同时使用索引；</li>\n<li>数据类型出现隐式转化（如varchar不加单引号的话可能会自动转换为int型）；</li>\n<li>对于多列索引，必须满足 <strong>最左匹配原则</strong>/最左前缀原则 (最左优先，eg：多列索引col1、col2和col3，则 索引生效的情形包括 col1或col1，col2或col1，col2，col3)；</li>\n<li>如果MySQL估计全表扫描比索引快，则不使用索引（比如非常小的表）</li>\n</ul>\n<h3 id=\"在哪些地方适合创建索引？\"><a href=\"#在哪些地方适合创建索引？\" class=\"headerlink\" title=\"在哪些地方适合创建索引？\"></a>在哪些地方适合创建索引？</h3><ul>\n<li>某列经常作为最大最小值；</li>\n<li>经常被查询的字段；</li>\n<li>经常用作表连接的字段；</li>\n<li>经常出现在ORDER BY/GROUP BY/DISDINCT后面的字段</li>\n</ul>\n<h5 id=\"创建索引时需要注意什么？\"><a href=\"#创建索引时需要注意什么？\" class=\"headerlink\" title=\"创建索引时需要注意什么？\"></a>创建索引时需要注意什么？</h5><ul>\n<li>只应建立在<strong>小字段</strong>上，而不要对大文本或图片建立索引（一页存储的数据越多一次IO操作获取的数据越大效率越高）；</li>\n<li>建立索引的字段应该<strong>非空</strong>，在MySQL中，含有空值的列很难进行查询优化，因为它们使得索引、索引的统计信息以及比较运算更加复杂。应该用0、一个特殊的值或者一个空串代替NULL；</li>\n<li>选择<strong>数据密度大</strong>（唯一值占总数的百分比很大）的字段作索引</li>\n</ul>\n<h3 id=\"索引的分类？\"><a href=\"#索引的分类？\" class=\"headerlink\" title=\"索引的分类？\"></a>索引的分类？</h3><ul>\n<li>普通索引</li>\n<li>唯一索引 UNIQUE：索引列的值必须唯一，但允许有空值；</li>\n<li>主键索引 PRIMARY KEY：必须唯一，不允许空值（是一种特殊的唯一索引；MySQL创建主键时默认为聚集索引，但主键也可以是非聚集索引）；</li>\n<li>单列索引和多列索引/复合索引（Composite）：索引的列数；</li>\n<li>覆盖（Covering）索引：索引包含了所有满足查询所需要的数据，查询的时候只需要读取索引而不需要回表读取数据；</li>\n<li>聚集（Clustered）索引/非聚集索引：对磁盘上存放数据的物理地址重新组织以使这些数据按照指定规则排序的一种索引（数据的物理排列顺序和索引排列顺序一致）。因此每张表只能创建一个聚集索引（因为要改变物理存储顺序）。优点是查询速度快，因为可以直接按照顺序得到需要数据的物理地址。缺点是进行修改的速度较慢。对于需要经常搜索范围的值很有效。非聚集索引只记录逻辑顺序，并不改变物理顺序；</li>\n<li>分区索引（？）</li>\n<li>虚拟索引（Virtual）：模拟索引的存在而不用真正创建一个索引，用于快速测试创建索引对执行计划的影响。没有相关的索引段，不增加存储空间的使用</li>\n</ul>\n<h3 id=\"MySQL的两种存储引擎-InnoDB-和-MyISAM-的区别？\"><a href=\"#MySQL的两种存储引擎-InnoDB-和-MyISAM-的区别？\" class=\"headerlink\" title=\"MySQL的两种存储引擎 InnoDB 和 MyISAM 的区别？\"></a>MySQL的两种存储引擎 InnoDB 和 MyISAM 的区别？</h3><ul>\n<li><p>InnoDB<strong>支持事务</strong>，可以进行Commit和Rollback；</p>\n</li>\n<li><p>MyISAM 只支持表级锁，而 InnoDB 还<strong>支持行级锁</strong>，提高了并发操作的性能；</p>\n</li>\n<li><p>InnoDB <strong>支持外键</strong>；</p>\n</li>\n<li><p>MyISAM <strong>崩溃</strong>后发生损坏的概率比 InnoDB 高很多，而且<strong>恢复的速度</strong>也更慢；</p>\n</li>\n<li><p>MyISAM 支持<strong>压缩</strong>表和空间数据索引，InnoDB需要更多的内存和存储；</p>\n</li>\n<li><p>InnoDB 支持在线<strong>热备份</strong></p>\n</li>\n<li><p><strong>MyISAM</strong> 管理非事务表。它提供高速存储和检索（MyISAM强调的是性能，每次查询具有原子性，其执行速度比InnoDB更快），以及全文搜索能力。如果表比较小，或者是只读数据（有大量的SELECT），还是可以使用MyISAM；</p>\n</li>\n<li><p><strong>InnoDB</strong> 支持事务，并发情况下有很好的性能，基本可以替代MyISAM</p>\n</li>\n<li><p>热备份：在数据库运行的情况下备份的方法。优点：可按表或用户备份，备份时数据库仍可使用，可恢复至任一时间点。但是不能出错</p>\n</li>\n<li><p>冷备份：数据库正常关闭后，将关键性文件复制到另一位置的备份方式。优点：操作简单快速，恢复简单</p>\n</li>\n</ul>\n<p>更详细的可以参考：<a href=\"https://imageslr.github.io/2020/db-engine.html\">MySQL 数据库的存储引擎与适用场景 - Images</a></p>\n<h3 id=\"如何优化数据库？\"><a href=\"#如何优化数据库？\" class=\"headerlink\" title=\"如何优化数据库？\"></a>如何优化数据库？</h3><blockquote>\n<p>分析慢查询日志：记录了在MySQL中响应时间超过阀值long_query_time的SQL语句，通过日志去找出IO大的SQL以及发现未命中索引的SQL</p>\n</blockquote>\n<blockquote>\n<p>使用 Explain 进行分析：通过explain命令可以得到表的读取顺序、数据读取操作的操作类型、哪些索引可以使用、<strong>哪些索引被实际使用</strong>、表之间的引用以及<strong>被扫描的行数</strong>等问题；</p>\n</blockquote>\n<ul>\n<li>应尽量避免在 where 子句中使用<code>!=</code>、<code>&lt;</code>、<code>&gt;</code>操作符或对字段进行null值判断，否则将引擎放弃使用索引而进行全表扫描；</li>\n<li>只返回必要的列：最好不要使用 SELECT * 语句；</li>\n<li>只返回必要的行：使用 LIMIT 语句来限制返回的数据；</li>\n<li>将一个大连接查询分解成对每一个表进行一次单表查询，然后在应用程序中进行关联，这样做的好处有：<ul>\n<li>让缓存更高效。对于连接查询，如果其中一个表发生变化，那么整个查询缓存就无法使用。而分解后的多个查询，即使其中一个表发生变化，对其它表的查询缓存依然可以使用；</li>\n<li>分解成多个单表查询，这些单表查询的缓存结果更可能被其它查询使用到，从而减少冗余的查询；</li>\n<li>减少锁竞争</li>\n</ul>\n</li>\n</ul>\n<p>注意会引起索引失效的情况，以及在适合的地方建立索引</p>\n<ul>\n<li><p>设计表时遵循<strong>三大范式</strong>；</p>\n</li>\n<li><p>选择合适的<strong>数据类型</strong>：尽可能不要存储NULL字段；使用简单的数据类型（int, varchar/ text）；</p>\n</li>\n<li><p>表的<strong>水平切分</strong>（Sharding）：将同一个表中的记录拆分到多个结构相同的表中（策略：哈希取模；根据ID范围来分）。当一个表的数据不断增多时，Sharding 是必然的选择，它可以将数据分布到集群的不同节点上，从而缓解单个数据库的压力；</p>\n</li>\n<li><p>表的<strong>垂直切分</strong>：将一张表按列切分成多个表。可以将不常用的字段单独放在同一个表中；把大字段独立放入一个表中；或者把经常使用的字段（关系密切的）放在一张表中。垂直切分之后业务更加清晰，系统之间整合或扩展容易，数据维护简单</p>\n</li>\n<li><p>操作系统：增加TCP支持的队列数；</p>\n</li>\n<li><p>MySQL配置文件优化：缓存池大小和个数设置</p>\n</li>\n<li><p>磁盘性能：固态硬盘；</p>\n</li>\n<li><p>CPU：多核且高频；</p>\n</li>\n<li><p>内存：增大内存</p>\n</li>\n</ul>\n<h3 id=\"什么是主从复制？实现原理是什么？\"><a href=\"#什么是主从复制？实现原理是什么？\" class=\"headerlink\" title=\"什么是主从复制？实现原理是什么？\"></a>什么是主从复制？实现原理是什么？</h3><p>主从复制（Replication）是指数据可以从一个MySQL数据库主服务器复制到一个或多个从服务器，从服务器可以复制主服务器中的所有数据库或者特定的数据库，或者特定的表。默认采用异步模式。</p>\n<p>实现原理：</p>\n<ul>\n<li>主服务器 <strong>binary log dump 线程</strong>：将主服务器中的数据更改（增删改）日志写入 Binary log 中；</li>\n<li>从服务器 <strong>I/O 线程</strong>：负责从主服务器读取binary log，并写入本地的 Relay log；</li>\n<li>从服务器 <strong>SQL 线程</strong>：负责读取 Relay log，解析出主服务器已经执行的数据更改，并在从服务器中重新执行（Replay），保证主从数据的一致性</li>\n</ul>\n<h5 id=\"为什么要主从复制？\"><a href=\"#为什么要主从复制？\" class=\"headerlink\" title=\"为什么要主从复制？\"></a>为什么要主从复制？</h5><ul>\n<li>读写分离：主服务器负责写，从服务器负责读<ul>\n<li>缓解了锁的争用，即使主服务器中加了锁，依然可以进行读操作；</li>\n<li>从服务器可以使用 MyISAM，提升查询性能以及节约系统开销；</li>\n<li>增加冗余，提高可用性</li>\n</ul>\n</li>\n<li>数据实时备份，当系统中某个节点发生故障时，可以方便的故障切换</li>\n<li>降低单个服务器磁盘I/O访问的频率，提高单个机器的I/O性能</li>\n</ul>\n<h1 id=\"NoSQL-Redis\"><a href=\"#NoSQL-Redis\" class=\"headerlink\" title=\"NoSQL/Redis\"></a>NoSQL/Redis</h1><ul>\n<li><a href=\"https://blog.csdn.net/Butterfly_resting/article/details/89668661\">几率大的Redis面试题（含答案） - CSDN</a></li>\n<li><a href=\"https://github.com/CyC2018/CS-Notes/blob/master/notes/Redis.md\">CyC2018</a></li>\n<li><a href=\"https://www.jianshu.com/p/65765dd10671\">Redis面试题总结 - 简书</a></li>\n<li><a href=\"https://www.cnblogs.com/jasontec/p/9699242.html\">Redis常见面试题 - 博客园</a></li>\n<li><a href=\"https://github.com/0voice/interview_internal_reference#10\">0voice/interview_internal_reference</a></li>\n</ul>\n<p>文章内容搬运自本人<a href=\"https://www.yuque.com/docs/share/c6097254-4f08-4d0f-b9c0-550c9274e6be\">语雀</a></p>\n","site":{"data":{}},"length":8417,"excerpt":"","more":"<meta name=\"referrer\" content=\"no-referrer\" />\n\n<h1 id=\"数据库基础\"><a href=\"#数据库基础\" class=\"headerlink\" title=\"数据库基础\"></a>数据库基础</h1><h3 id=\"事务的概念和特性？\"><a href=\"#事务的概念和特性？\" class=\"headerlink\" title=\"事务的概念和特性？\"></a>事务的概念和特性？</h3><p>概念：事务（Transaction）是一个操作序列，不可分割的工作单位，以BEGIN TRANSACTION开始，以ROLLBACK/COMMIT结束<br>特性（ACID）：</p>\n<ul>\n<li><strong>原子性</strong>（Atomicity）：逻辑上是不可分割的操作单元，事务的所有操作要么全部提交成功，要么全部失败回滚（用回滚日志实现，反向执行日志中的操作）；</li>\n<li><strong>一致性</strong>（Consistency）：事务的执行必须使数据库保持一致性状态。在一致性状态下，所有事务对一个数据的读取结果都是相同的；</li>\n<li><strong>隔离性</strong>（Isolation）：一个事务所做的修改在最终提交以前，对其它事务是不可见的（并发执行的事务之间不能相互影响）；</li>\n<li><strong>持久性</strong>（Durability）：一旦事务提交成功，对数据的修改是永久性的</li>\n</ul>\n<h3 id=\"会出现哪些并发一致性问题？\"><a href=\"#会出现哪些并发一致性问题？\" class=\"headerlink\" title=\"会出现哪些并发一致性问题？\"></a>会出现哪些并发一致性问题？</h3><ul>\n<li><strong>丢失修改</strong>：一个事务对数据进行了修改，在事务提交之前，另一个事务对同一个数据进行了修改，覆盖了之前的修改；</li>\n<li><strong>脏读</strong>（Dirty Read）：一个事务读取了被另一个事务修改、但未提交（进行了回滚）的数据，造成两个事务得到的数据不一致；</li>\n<li><strong>不可重复读</strong>（Nonrepeatable Read）：在同一个事务中，某查询操作在一个时间读取某一行数据和之后一个时间读取该行数据，发现数据已经发生修改（针对<strong>update</strong>操作）；</li>\n<li><strong>幻读</strong>（Phantom Read）：当同一查询多次执行时，由于其它事务在这个数据范围内执行了插入操作，会导致每次返回不同的结果集（和不可重复读的区别：针对的是一个数据整体/范围；并且针对<strong>insert/delete</strong>操作）</li>\n</ul>\n<h3 id=\"数据库的四种隔离级别？\"><a href=\"#数据库的四种隔离级别？\" class=\"headerlink\" title=\"数据库的四种隔离级别？\"></a>数据库的四种隔离级别？</h3><ul>\n<li><strong>未提交读</strong>（Read Uncommited）：在一个事务提交之前，它的执行结果对其它事务也是可见的。会导致脏读、不可重复读、幻读；</li>\n<li><strong>提交读</strong>（Read Commited）：一个事务只能看见已经提交的事务所作的改变。可避免脏读问题；</li>\n<li><strong>可重复读</strong>（Repeatable Read）：可以确保同一个事务在多次读取同样的数据时得到相同的结果。（MySQL的默认隔离级别）。可避免不可重复读；</li>\n<li><strong>可串行化</strong>（Serializable）：强制事务串行执行，使之不可能相互冲突，从而解决幻读问题。可能导致大量的超时现象和锁竞争，实际很少使用。</li>\n</ul>\n<h3 id=\"什么是乐观锁和悲观锁？\"><a href=\"#什么是乐观锁和悲观锁？\" class=\"headerlink\" title=\"什么是乐观锁和悲观锁？\"></a>什么是乐观锁和悲观锁？</h3><ul>\n<li>悲观锁：认为数据随时会被修改，因此每次读取数据之前都会上锁，防止其它事务读取或修改数据；应用于<strong>数据更新比较频繁</strong>的场景；</li>\n<li>乐观锁：操作数据时不会上锁，但是更新时会判断在此期间有没有别的事务更新这个数据，若被更新过，则失败重试；适用于<strong>读多写少</strong>的场景。乐观锁的实现方式有：<ul>\n<li>加一个版本号或者时间戳字段，每次数据更新时同时更新这个字段；</li>\n<li>先读取想要更新的字段或者所有字段，更新的时候比较一下，只有字段没有变化才进行更新</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"常见的封锁类型？\"><a href=\"#常见的封锁类型？\" class=\"headerlink\" title=\"常见的封锁类型？\"></a>常见的封锁类型？</h3><p>意向锁是 InnoDB 自动加的， 不需用户干预。<br>对于 UPDATE、 DELETE 和 INSERT 语句， InnoDB<br>会自动给涉及数据集加排他锁（X)；<br>对于普通 SELECT 语句，InnoDB 不会加任何锁；<br>事务可以通过以下语句显式给记录集加共享锁或排他锁：<br>共享锁（S）：SELECT * FROM table_name WHERE … LOCK IN SHARE MODE。 其他 session 仍然可以查询记录，并也可以对该记录加 share mode 的共享锁。但是如果当前事务需要对该记录进行更新操作，则很有可能造成死锁。<br>排他锁（X)：SELECT * FROM table_name WHERE … FOR UPDATE。其他 session 可以查询该记录，但是不能对该记录加共享锁或排他锁，而是等待获得锁</p>\n<ul>\n<li><strong>排它锁</strong>（Exclusive Lock）/ X锁：事务对数据加上X锁时，只允许此事务读取和修改此数据，并且其它事务不能对该数据加任何锁；</li>\n<li><strong>共享锁</strong>（Shared Lock）/ S锁：加了S锁后，该事务只能对数据进行读取而不能修改，并且其它事务只能加S锁，不能加X锁</li>\n<li><strong>意向锁</strong>（Intention Locks）：<ul>\n<li>一个事务在获得某个<strong>数据行</strong>对象的 S 锁之前，必须先获得<strong>整个表</strong>的 IS 锁或更强的锁；</li>\n<li>一个事务在获得某个数据行对象的 X 锁之前，必须先获得整个表的 IX 锁；</li>\n<li>IS/IX 锁之间都是兼容的；</li>\n<li>好处：如果一个事务想要对整个表加X锁，就需要先检测是否有其它事务对该表或者该表中的某一行加了锁，这种检测非常耗时。有了意向锁之后，只需要检测整个表是否存在IX/IS/X/S锁就行了</li>\n</ul>\n</li>\n</ul>\n<p>锁的作用：用于管理对共享资源的并发访问，保证数据库的完整性和一致性</p>\n<p>MySQL 中提供了两种封锁粒度：<strong>行级锁</strong>以及<strong>表级锁</strong>。<br>封锁粒度小：</p>\n<ul>\n<li>好处：锁定的数据量越少，发生锁争用的可能就越小，系统的<strong>并发程度</strong>就越高；</li>\n<li>坏处：<strong>系统开销</strong>大（加锁、释放锁、检查锁的状态都需要消耗资源）</li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SELECT ... LOCK In SHARE MODE;</span><br><span class=\"line\">SELECT ... FOR UPDATE;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"什么是三级封锁协议？\"><a href=\"#什么是三级封锁协议？\" class=\"headerlink\" title=\"什么是三级封锁协议？\"></a>什么是三级封锁协议？</h3><ul>\n<li>一级封锁协议：事务在修改数据之前必须先对其加X锁，直到事务结束才释放。可以解决丢失修改问题（两个事务不能同时对一个数据加X锁，避免了修改被覆盖）；</li>\n<li>二级封锁协议：在一级的基础上，事务在读取数据之前必须先加S锁，读完后释放。可以解决脏读问题（如果已经有事务在修改数据，就意味着已经加了X锁，此时想要读取数据的事务并不能加S锁，也就无法进行读取，避免了读取脏数据）；</li>\n<li>三级封锁协议：在二级的基础上，事务在读取数据之前必须先加S锁，直到事务结束才能释放。可以解决不可重复读问题（避免了在事务结束前其它事务对数据加X锁进行修改，保证了事务期间数据不会被其它事务更新）</li>\n</ul>\n<h3 id=\"什么是两段锁协议？\"><a href=\"#什么是两段锁协议？\" class=\"headerlink\" title=\"什么是两段锁协议？\"></a>什么是两段锁协议？</h3><p>事务必须严格分为两个阶段对数据进行<strong>加锁和解锁</strong>的操作，第一阶段加锁，第二阶段解锁。也就是说一个事务中一旦释放了锁，就不能再申请新锁了。</p>\n<p><strong>可串行化调度</strong>是指，通过并发控制，使得并发执行的事务结果与某个串行执行的事务结果相同。事务遵循两段锁协议是保证可串行化调度的充分条件。</p>\n<h3 id=\"什么是-MVCC？\"><a href=\"#什么是-MVCC？\" class=\"headerlink\" title=\"什么是 MVCC？\"></a>什么是 MVCC？</h3><p>多版本并发控制（Multi-Version Concurrency Control, MVCC），MVCC在每行记录后面都保存有两个隐藏的列，用来存储<strong>创建版本号</strong>和<strong>删除版本号</strong>。</p>\n<ul>\n<li>创建版本号：创建一个数据行时的事务版本号（<strong>事务版本号</strong>：事务开始时的系统版本号；系统版本号：每开始一个新的事务，系统版本号就会自动递增）；</li>\n<li>删除版本号：删除操作时的事务版本号；</li>\n<li>各种操作：<ul>\n<li>插入操作时，记录创建版本号；</li>\n<li>删除操作时，记录删除版本号；</li>\n<li>更新操作时，先记录删除版本号，再新增一行记录创建版本号；</li>\n<li>查询操作时，要符合以下条件才能被查询出来：删除版本号未定义或大于当前事务版本号（删除操作是在当前事务启动之后做的）；创建版本号小于或等于当前事务版本号（创建操作是事务完成或者在事务启动之前完成）</li>\n</ul>\n</li>\n</ul>\n<p>通过版本号减少了锁的争用，<strong>提高了系统性能</strong>；可以实现<strong>提交读</strong>和<strong>可重复读</strong>两种隔离级别，未提交读无需使用MVCC</p>\n<p>使用 MVCC 读取的是快照中的数据，这样可以减少加锁所带来的开销：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">select * from table ...;</span><br></pre></td></tr></table></figure>\n<p>当前读读取的是最新的数据，需要加锁。以下第一个语句需要加 S 锁，其它都需要加 X 锁：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">select * from table where ? lock in share mode;</span><br><span class=\"line\">select * from table where ? for update;</span><br><span class=\"line\">insert;</span><br><span class=\"line\">update;</span><br><span class=\"line\">delete;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"数据库的范式？\"><a href=\"#数据库的范式？\" class=\"headerlink\" title=\"数据库的范式？\"></a>数据库的范式？</h3><ul>\n<li><p><strong>第一范式</strong>（1NF，Normal Form）：<strong>属性不应该是可分的</strong>。举例：如果将“电话”作为一个属性（一列），是不符合1NF的，因为电话这个属性可以分解为家庭电话和移动电话…如果将“移动电话”作为一个属性，就符合1NF；</p>\n</li>\n<li><p><strong>第二范式</strong> 2NF：每个非主属性<strong>完全依赖</strong>于主属性集（候选键集）；</p>\n<ul>\n<li>B完全依赖于A，就是说A中的所有属性唯一决定B，属性少了就不能唯一决定，属性多了则有冗余（叫依赖不叫完全依赖）。举例：（学号，课程名）这个主属性集可以唯一决定成绩，但是对于学生姓名这个属性，（学号，课程名）这个属性集就是冗余的，所以学生姓名不完全依赖于（学号，课程名）这一属性集；</li>\n<li>主属性集/候选码集：某一组属性能够唯一确定其它的属性（主键就是从候选键集中选的一个键），而其子集不能，这样的属性组中的属性就是主属性；不在候选码集中的属性成为非主属性；</li>\n<li>可以通过分解来满足 2NF：将（学号，课程名，成绩）做成一张表；（学号，学生姓名）做成另一张表，避免大量的数据冗余；<br>满足1NF后，要求表中的所有列，都必须依赖于主键，而不能有任何一列与主键没有关系，也就是说一个表只描述一件事情；</li>\n</ul>\n</li>\n<li><p><strong>第三范式</strong> 3NF：在 2NF 的基础上，非主属性<strong>不传递依赖</strong>于主属性</p>\n<ul>\n<li>传递依赖：如果C依赖于B，B依赖于A，那么C传递依赖于A；</li>\n<li>3NF在2NF的基础上，消除了非主属性之间的依赖；比如一个表中，主属性有（学号），非主属性有（姓名，院系，院长名），可以看到院长名这个非主属性依赖于院系，传递依赖于学号。消除的办法是分解。<br>必须先满足第二范式（2NF），要求：表中的每一列只与主键直接相关而不是间接相关，（表中的每一列只能依赖于主键）；</li>\n</ul>\n</li>\n<li><p>冗余数据：某些同样的数据多次出现（如学生姓名）；</p>\n</li>\n<li><p>修改异常：修改了一个记录中的信息，另一个记录中相同的信息却没有修改；</p>\n</li>\n<li><p>删除异常：删除一个信息，那么也会丢失其它信息（删除一个课程，丢失了一个学生的信息）；</p>\n</li>\n<li><p>插入异常：无法插入（插入一个还没有课程信息的学生）</p>\n</li>\n</ul>\n<h3 id=\"列举几种表连接方式？\"><a href=\"#列举几种表连接方式？\" class=\"headerlink\" title=\"列举几种表连接方式？\"></a>列举几种表连接方式？</h3><p><img src=\"https://cdn.nlark.com/yuque/0/2021/png/1431305/1628085012977-cccccdf6-0f16-4343-8cd4-68631fb6b78a.png\"></p>\n<ul>\n<li>内连接（Inner Join）：仅将两个表中满足连接条件的行组合起来作为结果集<ul>\n<li>自然连接：只考虑属性相同的元组对；</li>\n<li>等值连接：给定条件进行查询</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li>外连接（Outer Join）<ul>\n<li>左连接：左边表的所有数据都有显示出来，右边的表数据只显示共同有的那部分，没有对应的部分补NULL；</li>\n<li>右连接：和左连接相反；</li>\n<li>全外连接（Full Outer Join）：查询出左表和右表所有数据，但是去除两表的重复数据</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li>交叉连接（Cross Join）：返回两表的笛卡尔积（对于所含数据分别为m、n的表，返回m*n的结果）</li>\n</ul>\n<h3 id=\"什么是存储过程？有哪些优缺点？\"><a href=\"#什么是存储过程？有哪些优缺点？\" class=\"headerlink\" title=\"什么是存储过程？有哪些优缺点？\"></a>什么是存储过程？有哪些优缺点？</h3><p>存储过程是事先经过编译并存储在数据库中的一段SQL语句的集合。想要实现相应的功能时，只需要调用这个存储过程就行了（类似于函数，输入具有输出参数）。<br>优点：</p>\n<ul>\n<li>预先编译，而不需要每次运行时编译，提高了数据库执行<strong>效率</strong>；</li>\n<li>封装了一系列操作，对于一些数据交互比较多的操作，相比于单独执行SQL语句，可以<strong>减少网络通信量</strong>；</li>\n<li>具有<strong>可复用性</strong>，减少了数据库开发的工作量；</li>\n<li><strong>安全性高</strong>，可以让没有权限的用户通过存储过程间接操作数据库；</li>\n<li>更<strong>易于维护</strong></li>\n</ul>\n<p>缺点：</p>\n<ul>\n<li><strong>可移植性差</strong>，存储过程将应用程序绑定到了数据库上；</li>\n<li><strong>开发调试复杂</strong>：没有好的IDE；</li>\n<li><strong>修改复杂</strong>，需要重新编译，有时还需要更新程序中的代码以更新调用</li>\n</ul>\n<h3 id=\"Drop-Delete-Truncate的区别？\"><a href=\"#Drop-Delete-Truncate的区别？\" class=\"headerlink\" title=\"Drop/Delete/Truncate的区别？\"></a>Drop/Delete/Truncate的区别？</h3><ul>\n<li><strong>Delete</strong>用来删除表的全部或者<strong>部分数据</strong>，执行delete之后，用户<strong>需要提交</strong>之后才会执行，会触发表上的DELETE<strong>触发器</strong>（包含一个OLD的虚拟表，可以只读访问被删除的数据），DELETE之后表结构还在，删除很慢，一行一行地删，因为会记录日志，可以利用日志还原数据；</li>\n<li><strong>Truncate</strong>删除表中的所有数据，这个操作<strong>不能回滚</strong>，也不会触发这个表上的触发器。操作比DELETE快很多（直接把表drop掉，再创建一个新表，删除的数据不能找回）。如果表中有自增（AUTO_INCREMENT）列，则重置为1；</li>\n<li><strong>Drop</strong>命令从数据库中<strong>删除表</strong>，所有的数据行，索引和约束都会被删除；不能回滚，不会触发触发器；</li>\n</ul>\n<p>触发器（TRIGGER）是由事件（比如INSERT/UPDATE/DELETE）来触发运行的操作（不能被直接调用，不能接收参数）。在数据库里以独立的对象存储，用于<strong>保证数据完整性</strong>（比如可以检验或转换数据）。</p>\n<p>约束（Constraint）类型：主键（Primary Key）约束，唯一约束（Unique），检查约束，非空约束，外键（Foreign Key）约束。</p>\n<h3 id=\"什么是视图？什么是游标？\"><a href=\"#什么是视图？什么是游标？\" class=\"headerlink\" title=\"什么是视图？什么是游标？\"></a>什么是视图？什么是游标？</h3><ul>\n<li>视图：从数据库的基本表中通过查询选取出来的数据组成的<strong>虚拟表</strong>（数据库中存放视图的定义）。可以对其进行增/删/改/查等操作。视图是对若干张基本表的引用，一张虚表，查询语句执行的结果，不存储具体的数据（基本表数据发生了改变，视图也会跟着改变）；可以跟基本表一样，进行增删改查操作(ps:增删改操作有条件限制)；如连表查询产生的视图无法进行，对视图的增删改会影响原表的数据。好处：<ul>\n<li>通过只给用户访问视图的权限，保证数据的<strong>安全性</strong>；</li>\n<li><strong>简化</strong>复杂的SQL操作，隐藏数据的复杂性（比如复杂的连接）；</li>\n</ul>\n</li>\n<li>游标（Cursor）：用于定位在查询返回的<strong>结果集的特定行</strong>，以对特定行进行操作。使用游标可以方便地对结果集进行移动遍历，根据需要滚动或对浏览/修改任意行中的数据。主要用于交互式应用。<h1 id=\"MySQL\"><a href=\"#MySQL\" class=\"headerlink\" title=\"MySQL\"></a>MySQL</h1><h3 id=\"数据库索引的实现原理（B-树）\"><a href=\"#数据库索引的实现原理（B-树）\" class=\"headerlink\" title=\"数据库索引的实现原理（B+树）\"></a>数据库索引的实现原理（B+树）</h3></li>\n</ul>\n<p>见<a href=\"https://github.com/wolverinn/Iridescent/blob/master/Data%20Structure.md#b%E6%A0%91\">数据结构部分：B树，B+树</a></p>\n<h5 id=\"使用B树和B-树的比较\"><a href=\"#使用B树和B-树的比较\" class=\"headerlink\" title=\"使用B树和B+树的比较\"></a>使用B树和B+树的比较</h5><p>InnoDB的索引使用的是B+树实现，B+树对比B树的好处：</p>\n<ul>\n<li>IO次数少：B+树的中间结点只存放索引，数据都存在叶结点中，因此中间结点可以存更多的数据，让索引树更加矮胖；</li>\n<li>范围查询效率更高：B树需要中序遍历整个树，只B+树需要遍历叶结点中的链表；</li>\n<li>查询效率更加稳定：每次查询都需要从根结点到叶结点，路径长度相同，所以每次查询的效率都差不多</li>\n</ul>\n<h5 id=\"使用B树索引和哈希索引的比较\"><a href=\"#使用B树索引和哈希索引的比较\" class=\"headerlink\" title=\"使用B树索引和哈希索引的比较\"></a>使用B树索引和哈希索引的比较</h5><p>哈希索引能以 O(1) 时间进行查找，但是只支持精确查找，无法用于部分查找和范围查找，无法用于排序与分组；B树索引支持大于小于等于查找，范围查找。哈希索引遇到大量哈希值相等的情况后查找效率会降低。哈希索引不支持数据的排序。</p>\n<h3 id=\"使用索引的优点\"><a href=\"#使用索引的优点\" class=\"headerlink\" title=\"使用索引的优点\"></a>使用索引的优点</h3><ul>\n<li>大大加快了数据的<strong>检索速度</strong>；</li>\n<li>可以显著减少查询中<strong>分组和排序</strong>的时间；</li>\n<li>通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性；</li>\n<li>将随机 I/O 变为<strong>顺序 I/O</strong>（B+Tree 索引是有序的，会将相邻的数据都存储在一起）</li>\n</ul>\n<p>缺点：建立和维护索引耗费时间空间，更新索引很慢。</p>\n<h3 id=\"哪些情况下索引会失效？\"><a href=\"#哪些情况下索引会失效？\" class=\"headerlink\" title=\"哪些情况下索引会失效？\"></a>哪些情况下索引会失效？</h3><ul>\n<li>以“%(表示任意0个或多个字符)”开头的LIKE语句；</li>\n<li>OR语句前后没有同时使用索引；</li>\n<li>数据类型出现隐式转化（如varchar不加单引号的话可能会自动转换为int型）；</li>\n<li>对于多列索引，必须满足 <strong>最左匹配原则</strong>/最左前缀原则 (最左优先，eg：多列索引col1、col2和col3，则 索引生效的情形包括 col1或col1，col2或col1，col2，col3)；</li>\n<li>如果MySQL估计全表扫描比索引快，则不使用索引（比如非常小的表）</li>\n</ul>\n<h3 id=\"在哪些地方适合创建索引？\"><a href=\"#在哪些地方适合创建索引？\" class=\"headerlink\" title=\"在哪些地方适合创建索引？\"></a>在哪些地方适合创建索引？</h3><ul>\n<li>某列经常作为最大最小值；</li>\n<li>经常被查询的字段；</li>\n<li>经常用作表连接的字段；</li>\n<li>经常出现在ORDER BY/GROUP BY/DISDINCT后面的字段</li>\n</ul>\n<h5 id=\"创建索引时需要注意什么？\"><a href=\"#创建索引时需要注意什么？\" class=\"headerlink\" title=\"创建索引时需要注意什么？\"></a>创建索引时需要注意什么？</h5><ul>\n<li>只应建立在<strong>小字段</strong>上，而不要对大文本或图片建立索引（一页存储的数据越多一次IO操作获取的数据越大效率越高）；</li>\n<li>建立索引的字段应该<strong>非空</strong>，在MySQL中，含有空值的列很难进行查询优化，因为它们使得索引、索引的统计信息以及比较运算更加复杂。应该用0、一个特殊的值或者一个空串代替NULL；</li>\n<li>选择<strong>数据密度大</strong>（唯一值占总数的百分比很大）的字段作索引</li>\n</ul>\n<h3 id=\"索引的分类？\"><a href=\"#索引的分类？\" class=\"headerlink\" title=\"索引的分类？\"></a>索引的分类？</h3><ul>\n<li>普通索引</li>\n<li>唯一索引 UNIQUE：索引列的值必须唯一，但允许有空值；</li>\n<li>主键索引 PRIMARY KEY：必须唯一，不允许空值（是一种特殊的唯一索引；MySQL创建主键时默认为聚集索引，但主键也可以是非聚集索引）；</li>\n<li>单列索引和多列索引/复合索引（Composite）：索引的列数；</li>\n<li>覆盖（Covering）索引：索引包含了所有满足查询所需要的数据，查询的时候只需要读取索引而不需要回表读取数据；</li>\n<li>聚集（Clustered）索引/非聚集索引：对磁盘上存放数据的物理地址重新组织以使这些数据按照指定规则排序的一种索引（数据的物理排列顺序和索引排列顺序一致）。因此每张表只能创建一个聚集索引（因为要改变物理存储顺序）。优点是查询速度快，因为可以直接按照顺序得到需要数据的物理地址。缺点是进行修改的速度较慢。对于需要经常搜索范围的值很有效。非聚集索引只记录逻辑顺序，并不改变物理顺序；</li>\n<li>分区索引（？）</li>\n<li>虚拟索引（Virtual）：模拟索引的存在而不用真正创建一个索引，用于快速测试创建索引对执行计划的影响。没有相关的索引段，不增加存储空间的使用</li>\n</ul>\n<h3 id=\"MySQL的两种存储引擎-InnoDB-和-MyISAM-的区别？\"><a href=\"#MySQL的两种存储引擎-InnoDB-和-MyISAM-的区别？\" class=\"headerlink\" title=\"MySQL的两种存储引擎 InnoDB 和 MyISAM 的区别？\"></a>MySQL的两种存储引擎 InnoDB 和 MyISAM 的区别？</h3><ul>\n<li><p>InnoDB<strong>支持事务</strong>，可以进行Commit和Rollback；</p>\n</li>\n<li><p>MyISAM 只支持表级锁，而 InnoDB 还<strong>支持行级锁</strong>，提高了并发操作的性能；</p>\n</li>\n<li><p>InnoDB <strong>支持外键</strong>；</p>\n</li>\n<li><p>MyISAM <strong>崩溃</strong>后发生损坏的概率比 InnoDB 高很多，而且<strong>恢复的速度</strong>也更慢；</p>\n</li>\n<li><p>MyISAM 支持<strong>压缩</strong>表和空间数据索引，InnoDB需要更多的内存和存储；</p>\n</li>\n<li><p>InnoDB 支持在线<strong>热备份</strong></p>\n</li>\n<li><p><strong>MyISAM</strong> 管理非事务表。它提供高速存储和检索（MyISAM强调的是性能，每次查询具有原子性，其执行速度比InnoDB更快），以及全文搜索能力。如果表比较小，或者是只读数据（有大量的SELECT），还是可以使用MyISAM；</p>\n</li>\n<li><p><strong>InnoDB</strong> 支持事务，并发情况下有很好的性能，基本可以替代MyISAM</p>\n</li>\n<li><p>热备份：在数据库运行的情况下备份的方法。优点：可按表或用户备份，备份时数据库仍可使用，可恢复至任一时间点。但是不能出错</p>\n</li>\n<li><p>冷备份：数据库正常关闭后，将关键性文件复制到另一位置的备份方式。优点：操作简单快速，恢复简单</p>\n</li>\n</ul>\n<p>更详细的可以参考：<a href=\"https://imageslr.github.io/2020/db-engine.html\">MySQL 数据库的存储引擎与适用场景 - Images</a></p>\n<h3 id=\"如何优化数据库？\"><a href=\"#如何优化数据库？\" class=\"headerlink\" title=\"如何优化数据库？\"></a>如何优化数据库？</h3><blockquote>\n<p>分析慢查询日志：记录了在MySQL中响应时间超过阀值long_query_time的SQL语句，通过日志去找出IO大的SQL以及发现未命中索引的SQL</p>\n</blockquote>\n<blockquote>\n<p>使用 Explain 进行分析：通过explain命令可以得到表的读取顺序、数据读取操作的操作类型、哪些索引可以使用、<strong>哪些索引被实际使用</strong>、表之间的引用以及<strong>被扫描的行数</strong>等问题；</p>\n</blockquote>\n<ul>\n<li>应尽量避免在 where 子句中使用<code>!=</code>、<code>&lt;</code>、<code>&gt;</code>操作符或对字段进行null值判断，否则将引擎放弃使用索引而进行全表扫描；</li>\n<li>只返回必要的列：最好不要使用 SELECT * 语句；</li>\n<li>只返回必要的行：使用 LIMIT 语句来限制返回的数据；</li>\n<li>将一个大连接查询分解成对每一个表进行一次单表查询，然后在应用程序中进行关联，这样做的好处有：<ul>\n<li>让缓存更高效。对于连接查询，如果其中一个表发生变化，那么整个查询缓存就无法使用。而分解后的多个查询，即使其中一个表发生变化，对其它表的查询缓存依然可以使用；</li>\n<li>分解成多个单表查询，这些单表查询的缓存结果更可能被其它查询使用到，从而减少冗余的查询；</li>\n<li>减少锁竞争</li>\n</ul>\n</li>\n</ul>\n<p>注意会引起索引失效的情况，以及在适合的地方建立索引</p>\n<ul>\n<li><p>设计表时遵循<strong>三大范式</strong>；</p>\n</li>\n<li><p>选择合适的<strong>数据类型</strong>：尽可能不要存储NULL字段；使用简单的数据类型（int, varchar/ text）；</p>\n</li>\n<li><p>表的<strong>水平切分</strong>（Sharding）：将同一个表中的记录拆分到多个结构相同的表中（策略：哈希取模；根据ID范围来分）。当一个表的数据不断增多时，Sharding 是必然的选择，它可以将数据分布到集群的不同节点上，从而缓解单个数据库的压力；</p>\n</li>\n<li><p>表的<strong>垂直切分</strong>：将一张表按列切分成多个表。可以将不常用的字段单独放在同一个表中；把大字段独立放入一个表中；或者把经常使用的字段（关系密切的）放在一张表中。垂直切分之后业务更加清晰，系统之间整合或扩展容易，数据维护简单</p>\n</li>\n<li><p>操作系统：增加TCP支持的队列数；</p>\n</li>\n<li><p>MySQL配置文件优化：缓存池大小和个数设置</p>\n</li>\n<li><p>磁盘性能：固态硬盘；</p>\n</li>\n<li><p>CPU：多核且高频；</p>\n</li>\n<li><p>内存：增大内存</p>\n</li>\n</ul>\n<h3 id=\"什么是主从复制？实现原理是什么？\"><a href=\"#什么是主从复制？实现原理是什么？\" class=\"headerlink\" title=\"什么是主从复制？实现原理是什么？\"></a>什么是主从复制？实现原理是什么？</h3><p>主从复制（Replication）是指数据可以从一个MySQL数据库主服务器复制到一个或多个从服务器，从服务器可以复制主服务器中的所有数据库或者特定的数据库，或者特定的表。默认采用异步模式。</p>\n<p>实现原理：</p>\n<ul>\n<li>主服务器 <strong>binary log dump 线程</strong>：将主服务器中的数据更改（增删改）日志写入 Binary log 中；</li>\n<li>从服务器 <strong>I/O 线程</strong>：负责从主服务器读取binary log，并写入本地的 Relay log；</li>\n<li>从服务器 <strong>SQL 线程</strong>：负责读取 Relay log，解析出主服务器已经执行的数据更改，并在从服务器中重新执行（Replay），保证主从数据的一致性</li>\n</ul>\n<h5 id=\"为什么要主从复制？\"><a href=\"#为什么要主从复制？\" class=\"headerlink\" title=\"为什么要主从复制？\"></a>为什么要主从复制？</h5><ul>\n<li>读写分离：主服务器负责写，从服务器负责读<ul>\n<li>缓解了锁的争用，即使主服务器中加了锁，依然可以进行读操作；</li>\n<li>从服务器可以使用 MyISAM，提升查询性能以及节约系统开销；</li>\n<li>增加冗余，提高可用性</li>\n</ul>\n</li>\n<li>数据实时备份，当系统中某个节点发生故障时，可以方便的故障切换</li>\n<li>降低单个服务器磁盘I/O访问的频率，提高单个机器的I/O性能</li>\n</ul>\n<h1 id=\"NoSQL-Redis\"><a href=\"#NoSQL-Redis\" class=\"headerlink\" title=\"NoSQL/Redis\"></a>NoSQL/Redis</h1><ul>\n<li><a href=\"https://blog.csdn.net/Butterfly_resting/article/details/89668661\">几率大的Redis面试题（含答案） - CSDN</a></li>\n<li><a href=\"https://github.com/CyC2018/CS-Notes/blob/master/notes/Redis.md\">CyC2018</a></li>\n<li><a href=\"https://www.jianshu.com/p/65765dd10671\">Redis面试题总结 - 简书</a></li>\n<li><a href=\"https://www.cnblogs.com/jasontec/p/9699242.html\">Redis常见面试题 - 博客园</a></li>\n<li><a href=\"https://github.com/0voice/interview_internal_reference#10\">0voice/interview_internal_reference</a></li>\n</ul>\n<p>文章内容搬运自本人<a href=\"https://www.yuque.com/docs/share/c6097254-4f08-4d0f-b9c0-550c9274e6be\">语雀</a></p>\n"},{"title":"面试八股文（二）—— 操作系统","date":"2021-09-22T14:43:42.000Z","updated":"2021-09-22T15:24:33.000Z","description":"根据我多年（其实就一年）复习备考408和春招的经验，总结出来的面试八股文第二篇，也是基础篇之二——操作系统相关的常见问题。如果文章中有看不懂的知识点，强力推荐王道考研的OS相关课程，讲的巨清晰无比。如果觉得本文介绍内容过于浅显，大佬请移步机工出版社黑皮书之《现代操作系统》。","_content":" \n<meta name=\"referrer\" content=\"no-referrer\" />\n\n# 进程和线程\n### 进程和线程有什么区别？\n- 进程（Process）是系统进行资源分配和调度的基本单位，线程（Thread）是CPU调度和分派的基本单位；\n- 线程依赖于进程而存在，一个进程至少有一个线程；\n- 进程有自己的独立地址空间，线程共享所属进程的地址空间；\n- 进程是拥有系统资源的一个独立单位，而线程自己基本上不拥有系统资源，只拥有一点在运行中必不可少的资源(如程序计数器,一组寄存器和栈)，和其他线程共享本进程的相关资源如内存、I/O、cpu等；\n- 在进程切换时，涉及到整个当前进程CPU环境的保存环境的设置以及新被调度运行的CPU环境的设置，而线程切换只需保存和设置少量的寄存器的内容，并不涉及存储器管理方面的操作，可见，进程切换的开销远大于线程切换的开销；\n- 线程之间的通信更方便，同一进程下的线程共享全局变量等数据，而进程之间的通信需要以进程间通信(IPC)的方式进行；\n- 多线程程序只要有一个线程崩溃，整个程序就崩溃了，但多进程程序中一个进程崩溃并不会对其它进程造成影响，因为进程有自己的独立地址空间，因此多进程更加健壮\n\n进程操作代码实现，可以参考：[多进程 - 廖雪峰的官方网站](https://www.liaoxuefeng.com/wiki/1016959663602400/1017628290184064)\n\n\n##### 同一进程中的线程可以共享哪些数据？\n- 进程代码段\n- 进程的公有数据（全局变量、静态变量...）\n- 进程打开的文件描述符\n- 进程的当前目录\n- 信号处理器/信号处理函数：对收到的信号的处理方式\n- 进程ID与进程组ID\n\n##### 线程独占哪些资源？\n- 线程ID\n- 一组寄存器的值\n- 线程自身的栈（堆是共享的）\n- 错误返回码：线程可能会产生不同的错误返回码，一个线程的错误返回码不应该被其它线程修改；\n- 信号掩码/信号屏蔽字(Signal mask)：表示是否屏蔽/阻塞相应的信号（SIGKILL,SIGSTOP除外）\n\n\n\n### 进程间通信有哪些方式？\n1. 管道(Pipe)\n- 管道是半双工的，数据只能向一个方向流动；需要双方通信时，需要建立起两个管道；\n- 一个进程向管道中写的内容被管道另一端的进程读出。写入的内容每次都添加在管道缓冲区的末尾，并且每次都是从缓冲区的头部读出数据；\n- 只能用于父子进程或者兄弟进程之间(具有亲缘关系的进程)\n2. 命名管道\n3. 消息队列\n4. 信号(Signal)\n5. 共享内存\n6. 信号量(Semaphore)：初始化操作、P操作、V操作；P操作：信号量-1，检测是否小于0，小于则进程进入阻塞状态；V操作：信号量+1，若小于等于0，则从队列中唤醒一个等待的进程进入就绪态\n7. 套接字(Socket)\n\n更详细的可以参考：\n- [https://imageslr.github.io/2020/02/26/ipc.html](https://imageslr.github.io/2020/02/26/ipc.html)\n- [https://www.jianshu.com/p/c1015f5ffa74](https://www.jianshu.com/p/c1015f5ffa74)\n\n### 进程同步问题\n> 进程的同步是目的，而进程间通信是实现进程同步的手段\n\n管程将共享变量以及对这些共享变量的操作封装起来，形成一个具有一定接口的功能模块，这样只能通过管程提供的某个过程才能访问管程中的资源。进程只能互斥地使用管程，使用完之后必须释放管程并唤醒入口等待队列中的进程。\n当一个进程试图进入管程时，在**入口等待队列**等待。若P进程唤醒了Q进程，则Q进程先执行，P在**紧急等待队列**中等待。（**HOARE管程**）\nwait操作：执行wait操作的进程进入条件变量链末尾，唤醒紧急等待队列或者入口队列中的进程；signal操作：唤醒条件变量链中的进程，自己进入紧急等待队列，若条件变量链为空，则继续执行。（**HOARE管程**）\n**MESA管程**：将HOARE中的signal换成了notify（或者broadcast通知所有满足条件的），进行通知而不是立马交换管程的使用权，在合适的时候，条件队列首位的进程可以进入，进入之前必须用while检查条件是否合适。优点：没有额外的进程切换\n\n> 问题描述：使用一个缓冲区来存放数据，只有缓冲区没有满，生产者才可以写入数据；只有缓冲区不为空，消费者才可以读出数据\n\n代码实现：\n```c\n// 伪代码描述 \n// 定义信号量 full记录缓冲区物品数量 empty代表缓冲区空位数量 mutex为互斥量\nsemaphore full = 0, empty = n, mutex = 1;\n\n// 生产者进程\nvoid producer(){\n\tdo{\n   \t  P(empty);\n\t  P(mutex);\n\n     // 生产者进行生产\n   \t\n   \t  V(mutex);\n   \t  V(full);\n \t} while(1);\n}\n\nvoid consumer(){\n\tdo{\n\t  P(full);\n\t  P(mutex);\n\n    \t// 消费者进行消费\n\n\t  V(mutex);\n\t  V(empty);\n \t} while(1);\n}\n```\n\n\n> 问题描述：有五位哲学家围绕着餐桌坐，每一位哲学家要么思考，要么吃饭。为了吃饭，哲学家必须拿起两双筷子（分别放于左右两端）不幸的是，筷子的数量和哲学家相等，所以每只筷子必须由两位哲学家共享。\n\n代码实现：\n```c\n#define N 5  // number of philosopher\n#define LEFT (i + N - 1)%N // number of i's left neighbors\n#define RIGHT (i + 1)%N // number of i's right neighbors\n#define THINKING 0\n#define HUNGRY 1\n#define EATING 2\ntypedef int semaphore;\nint state[N]; // array to keep track of everyone's state\nsemaphore mutex = 1; // mutual exclusion of critical region\nsemaphore s[N]; \n\nvoid philosopher(int i) {\n\twhile (TRUE) {\n\t\tthink();\n\t\ttake_forks(i);\n\t\teat();\n\t\tput_forks(i);\n\t}\n}\n\nvoid take_forks(int i) {\n\tdown(&mutex); // enter critical region\n\tstate[i] = HUNGRY; // record that i is hungry\n\ttest_forks(i); // try to acquire two forks\n\tup(&mutex); // exit critical region\n\tdown(&s[i]); // block if forks are not acquired\n}\n\nvoid put_forks(int i) {\n\tdown(&mutex); // enter critical region\n\tstate[i] = THINKING; // record that has finished eating\n\ttest_forks(LEFT); // see if left neighbor can now eat\n\ttest_forks(RIGHT); // see if right neighbor can now eat\n\tup(&mutex); // exit critical region\n}\n\nvoid test_forks(int i) {\n\tif (state[i] == HUNGRY && state[LEFT] != EATING && state[RIGHT] != EATING) {\n\t\tstate[i] = EATING;\n\t\tup(&s[i]);\n\t}\n}\n```\n\n##### 临界区的概念？\n各个进程中对临界资源（互斥资源/共享变量，一次只能给一个进程使用）进行操作的程序片段\n\n\n##### 同步与互斥的概念？\n- 同步：多个进程因为合作而使得进程的执行有一定的先后顺序。比如某个进程需要另一个进程提供的消息，获得消息之前进入阻塞态；\n- 互斥：多个进程在同一时刻只有一个进程能进入临界区\n\n##### 并发、并行、异步的区别？\n并发：在一个时间段中同时有多个程序在运行，但其实任一时刻，只有一个程序在CPU上运行，宏观上的并发是通过不断的切换实现的；\n多线程：并发运行的一段代码。是实现异步的手段\n并行（和串行相比）：在多CPU系统中，多个程序无论宏观还是微观上都是同时执行的\n异步（和同步相比）：同步是顺序执行，异步是在等待某个资源的时候继续做自己的事\n\n\n### 进程有哪几种状态？\n![](https://cdn.nlark.com/yuque/0/2021/png/1431305/1628085394606-49204b73-729e-4f57-97bc-d43ad01ec54b.png)\n\n- 就绪状态：进程已获得除处理机以外的所需资源，等待分配处理机资源\n- 运行状态：占用处理机资源运行，处于此状态的进程数小于等于CPU数\n- 阻塞状态： 进程等待某种条件，在条件满足之前无法执行\n\n### 进程调度策略有哪些？\n1. **批处理系统**：\n按照请求的顺序进行调度。非抢占式，开销小，无饥饿问题，响应时间不确定（可能很慢）；\n对短进程不利，对IO密集型进程不利。\n\n按估计运行时间最短的顺序进行调度。非抢占式，吞吐量高，开销可能较大，可能导致饥饿问题；\n对短进程提供好的响应时间，对长进程不利。\n\n按剩余运行时间的顺序进行调度。(最短作业优先的抢占式版本)。吞吐量高，开销可能较大，提供好的响应时间；\n可能导致饥饿问题，对长进程不利。\n\n响应比 = 1+ 等待时间/处理时间。同时考虑了等待时间的长短和估计需要的执行时间长短，很好的平衡了长短进程。非抢占，吞吐量高，开销可能较大，提供好的响应时间，无饥饿问题。\n\n2. **交互式系统**\n   交互式系统有大量的用户交互操作，在该系统中调度算法的目标是快速地进行响应。\n\n将所有就绪进程按 FCFS 的原则排成一个队列，用完时间片的进程排到队列最后。抢占式（时间片用完时），开销小，无饥饿问题，为短进程提供好的响应时间；\n若时间片小，进程切换频繁，吞吐量低；若时间片太长，实时性得不到保证。\n\n为每个进程分配一个优先级，按优先级进行调度。为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。\n\n设置多个就绪队列1、2、3...，优先级递减，时间片递增。只有等到优先级更高的队列为空时才会调度当前队列中的进程。如果进程用完了当前队列的时间片还未执行完，则会被移到下一队列。\n抢占式（时间片用完时），开销可能较大，对IO型进程有利，可能会出现饥饿问题。\n\n##### 什么叫优先级反转？如何解决？\n高优先级的进程等待被一个低优先级进程占用的资源时，就会出现优先级反转，即优先级较低的进程比优先级较高的进程先执行。此处详细解释优先级反转带来的问题：如果有一个中等优先级的进程将低优先级的进程抢占，那么此时低优先级的进程无法正常进行并在后续释放被占用的资源，导致高优先级的任务一直被挂起，直到中等优先级的进程完成后，低优先级的进程才可以继续并在后续释放占用的资源，最后高优先级的进程才可以执行。导致的问题就是高优先级的进程在中等优先级的进程调度之后。\n解决方法：\n\n- 优先级天花板(priority ceiling)：当任务申请某资源时，把该任务的优先级提升到可访问这个资源的所有任务中的最高优先级，这个优先级称为该资源的优先级天花板。简单易行。\n- 优先级继承(priority inheritance)：当任务A申请共享资源S时，如果S正在被任务C使用，通过比较任务C与自身的优先级，如发现任务C的优先级小于自身的优先级，则将任务C的优先级提升到自身的优先级，任务C释放资源S后，再恢复任务C的原优先级。\n\n### 什么是僵尸进程？\n一个子进程结束后，它的父进程并没有等待它（调用wait或者waitpid），那么这个子进程将成为一个僵尸进程。僵尸进程是一个已经死亡的进程，但是并没有真正被销毁。它已经放弃了几乎所有内存空间，没有任何可执行代码，也不能被调度，仅仅在进程表中保留一个位置，记载该进程的进程ID、终止状态以及资源利用信息(CPU时间，内存使用量等等)供父进程收集，除此之外，僵尸进程不再占有任何内存空间。这个僵尸进程可能会一直留在系统中直到系统重启。\n\n危害：占用进程号，而系统所能使用的进程号是有限的；占用内存。\n\n以下情况不会产生僵尸进程：\n\n- 该进程的父进程先结束了。每个进程结束的时候，系统都会扫描是否存在子进程，如果有则用Init进程接管，成为该进程的父进程，并且会调用wait等待其结束。\n- 父进程调用wait或者waitpid等待子进程结束（需要每隔一段时间查询子进程是否结束）。wait系统调用会使父进程暂停执行，直到它的一个子进程结束为止。waitpid则可以加入`WNOHANG`(wait-no-hang)选项，如果没有发现结束的子进程，就会立即返回，不会将调用waitpid的进程阻塞。同时，waitpid还可以选择是等待任一子进程（同wait），还是等待指定pid的子进程，还是等待同一进程组下的任一子进程，还是等待组ID等于pid的任一子进程；\n- 子进程结束时，系统会产生`SIGCHLD`(signal-child)信号，可以注册一个信号处理函数，在该函数中调用waitpid，等待所有结束的子进程（注意：一般都需要循环调用waitpid，因为在信号处理函数开始执行之前，可能已经有多个子进程结束了，而信号处理函数只执行一次，所以要循环调用将所有结束的子进程回收）；\n- 也可以用`signal(SIGCLD, SIG_IGN)`(signal-ignore)通知内核，表示忽略`SIGCHLD`信号，那么子进程结束后，内核会进行回收。\n\n##### 什么是孤儿进程？\n一个父进程已经结束了，但是它的子进程还在运行，那么这些子进程将成为孤儿进程。孤儿进程会被Init（进程ID为1）接管，当这些孤儿进程结束时由Init完成状态收集工作。\n\n### 线程同步有哪些方式？\n> 为什么需要线程同步：线程有时候会和其他线程共享一些资源，比如内存、数据库等。当多个线程同时读写同一份共享资源的时候，可能会发生冲突。因此需要线程的同步，多个线程按顺序访问资源。\n\n- **互斥量** Mutex：互斥量是内核对象，只有拥有互斥对象的线程才有访问互斥资源的权限。因为互斥对象只有一个，所以可以保证互斥资源不会被多个线程同时访问；当前拥有互斥对象的线程处理完任务后必须将互斥对象交出，以便其他线程访问该资源；\n- **信号量** Semaphore：信号量是内核对象，它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量。信号量对象保存了**最大资源计数**和**当前可用资源计数**，每增加一个线程对共享资源的访问，当前可用资源计数就减1，只要当前可用资源计数大于0，就可以发出信号量信号，如果为0，则将线程放入一个队列中等待。线程处理完共享资源后，应在离开的同时通过`ReleaseSemaphore`函数将当前可用资源数加1。如果信号量的取值只能为0或1，那么信号量就成为了互斥量；\n- **事件** Event：允许一个线程在处理完一个任务后，主动唤醒另外一个线程执行任务。事件分为手动重置事件和自动重置事件。手动重置事件被设置为激发状态后，会唤醒所有等待的线程，而且一直保持为激发状态，直到程序重新把它设置为未激发状态。自动重置事件被设置为激发状态后，会唤醒**一个**等待中的线程，然后自动恢复为未激发状态。\n- **临界区** Critical Section：任意时刻只允许一个线程对临界资源进行访问。拥有临界区对象的线程可以访问该临界资源，其它试图访问该资源的线程将被挂起，直到临界区对象被释放。\n\n##### 互斥量和临界区有什么区别？\n互斥量是可以命名的，可以用于不同进程之间的同步；而临界区只能用于同一进程中线程的同步。创建互斥量需要的资源更多，因此临界区的优势是速度快，节省资源。\n\n### 什么是协程？\n\n协程是一种用户态的轻量级线程，协程的调度完全由用户控制。协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈，直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快。\n\n##### 协程多与线程进行比较？\n1. 一个线程可以拥有多个协程，一个进程也可以单独拥有多个协程，这样python中则能使用多核CPU。\n2. 线程进程都是同步机制，而协程则是异步\n3. 协程能保留上一次调用时的状态，每次过程重入时，就相当于进入上一次调用的状态\n\n### 进程的异常控制流：陷阱、中断、异常和信号\n陷阱是**有意**造成的“异常”，是执行一条指令的结果。陷阱是同步的。陷阱的主要作用是实现**系统调用**。比如，进程可以执行 `syscall n` 指令向内核请求服务。当进程执行这条指令后，会中断当前的控制流，**陷入**到内核态，执行相应的系统调用。内核的处理程序在执行结束后，会将结果返回给进程，同时退回到用户态。进程此时继续执行**下一条指令**。\n\n中断由处理器**外部**的**硬件**产生，不是执行某条指令的结果，也无法预测发生时机。由于中断独立于当前执行的程序，因此中断是异步事件。中断包括 I/O 设备发出的 I/O 中断、各种定时器引起的时钟中断、调试程序中设置的断点等引起的调试中断等。\n\n异常是一种错误情况，是执行当前指令的结果，可能被错误处理程序修正，也可能直接终止应用程序。异常是同步的。这里特指因为执行当前指令而产生的**错误情况**，比如除法异常、缺页异常等。有些书上为了区分，也将这类“异常”称为**“故障”**。\n\n信号是一种**更高层的**软件形式的异常，同样会中断进程的控制流，可以由进程进行处理。一个信号代表了一个消息。信号的作用是用来**通知进程**发生了某种系统事件。\n\n更详细的可以参考：[https://imageslr.github.io/2020/07/09/trap-interrupt-exception.html](https://imageslr.github.io/2020/07/09/trap-interrupt-exception.html)\n\n### 什么是IO多路复用？怎么实现？\nIO多路复用（IO Multiplexing）是指单个进程/线程就可以同时处理多个IO请求。\n\n实现原理：用户将想要监视的文件描述符（File Descriptor）添加到select/poll/epoll函数中，由内核监视，函数阻塞。一旦有文件描述符就绪（读就绪或写就绪），或者超时（设置timeout），函数就会返回，然后该进程可以进行相应的读/写操作。\n\n- `select`：将文件描述符放入一个集合中，调用select时，将这个集合从用户空间拷贝到内核空间（缺点1：每次都要复制，**开销大**），由内核根据就绪状态修改该集合的内容。（缺点2）**集合大小有限制**，32位机默认是1024（64位：2048）；采用水平触发机制。select函数返回后，需要通过遍历这个集合，找到就绪的文件描述符（缺点3：**轮询的方式效率较低**），当文件描述符的数量增加时，效率会线性下降；\n- `poll`：和select几乎没有区别，区别在于文件描述符的存储方式不同，poll采用链表的方式存储，没有最大存储数量的限制；\n- `epoll`：通过内核和用户空间共享内存，避免了不断复制的问题；支持的同时连接数上限很高（1G左右的内存支持10W左右的连接数）；文件描述符就绪时，采用回调机制，避免了轮询（回调函数将就绪的描述符添加到一个链表中，执行epoll_wait时，返回这个链表）；支持水平触发和边缘触发，采用边缘触发机制时，只有活跃的描述符才会触发回调函数。\n\n总结，区别主要在于：\n- 一个线程/进程所能打开的最大连接数\n- 文件描述符传递方式（是否复制）\n- 水平触发 or 边缘触发\n- 查询就绪的描述符时的效率（是否轮询）\n\n当连接数较多并且有很多的不活跃连接时，epoll的效率比其它两者高很多；但是当连接数较少并且都十分活跃的情况下，由于epoll需要很多回调，因此性能可能低于其它两者。\n\n文件描述符在形式上是一个非负整数。实际上，它是一个索引值，指向内核为每一个进程所维护的该进程打开文件的记录表。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。\n内核通过文件描述符来访问文件。文件描述符指向一个文件。\n\n##### 什么是水平触发？什么是边缘触发？\n- 水平触发（LT，Level Trigger）模式下，只要一个文件描述符就绪，就会触发通知，如果用户程序没有一次性把数据读写完，下次还会通知；\n- 边缘触发（ET，Edge Trigger）模式下，当描述符从未就绪变为就绪时通知一次，之后不会再通知，直到再次从未就绪变为就绪（缓冲区从不可读/写变为可读/写）。\n- 区别：边缘触发效率更高，减少了被重复触发的次数，函数不会返回大量用户程序可能不需要的文件描述符。\n- 为什么边缘触发一定要用非阻塞（non-block）IO：避免由于一个描述符的阻塞读/阻塞写操作让处理其它描述符的任务出现饥饿状态。\n\n##### 有哪些常见的IO模型？\n- 同步阻塞IO（Blocking IO）：用户线程发起IO读/写操作之后，线程阻塞，直到可以开始处理数据；对CPU资源的利用率不够；\n- 同步非阻塞IO（Non-blocking IO）：发起IO请求之后可以立即返回，如果没有就绪的数据，需要不断地发起IO请求直到数据就绪；不断重复请求消耗了大量的CPU资源；\n- IO多路复用\n- 异步IO（Asynchronous IO）：用户线程发出IO请求之后，继续执行，由内核进行数据的读取并放在用户指定的缓冲区内，在IO完成之后通知用户线程直接使用。\n\n### 什么是用户态和内核态？\n为了限制不同程序的访问能力，防止一些程序访问其它程序的内存数据，CPU划分了用户态和内核态两个权限等级。\n\n- 用户态只能受限地访问内存，且不允许访问外围设备，没有占用CPU的能力，CPU资源可以被其它程序获取；\n- 内核态可以访问内存所有数据以及外围设备，也可以进行程序的切换。\n\n所有用户程序都运行在用户态，但有时需要进行一些内核态的操作，比如从硬盘或者键盘读数据，这时就需要进行系统调用，使用**陷阱指令**，CPU切换到内核态，执行相应的服务，再切换为用户态并返回系统调用的结果。\n\n##### 为什么要分用户态和内核态？\n- 安全性：防止用户程序恶意或者不小心破坏系统/内存/硬件资源；\n- 封装性：用户程序不需要实现更加底层的代码；\n- 利于调度：如果多个用户程序都在等待键盘输入，这时就需要进行调度；统一交给操作系统调度更加方便。\n\n##### 如何从用户态切换到内核态？\n- 系统调用：比如读取命令行输入。本质上还是通过中断实现\n- 用户程序发生异常时：比如缺页异常\n- 外围设备的中断：外围设备完成用户请求的操作之后，会向CPU发出中断信号，这时CPU会转去处理对应的中断处理程序\n\n# 死锁 \n### 什么是死锁？\n在两个或者多个并发进程中，每个进程持有某种资源而又等待其它进程释放它们现在保持着的资源，在未改变这种状态之前都不能向前推进，称这一组进程产生了死锁(deadlock)。\n### 死锁产生的必要条件？\n- **互斥**：一个资源一次只能被一个进程使用；\n- **占有并等待**：一个进程至少占有一个资源，并在等待另一个被其它进程占用的资源；\n- **非抢占**：已经分配给一个进程的资源不能被强制性抢占，只能由进程完成任务之后自愿释放；\n- **循环等待**：若干进程之间形成一种头尾相接的环形等待资源关系，该环路中的每个进程都在等待下一个进程所占有的资源。\n\n### 死锁有哪些处理方法？\n直接忽略死锁。因为解决死锁问题的代价很高，因此鸵鸟策略这种不采取任务措施的方案会获得更高的性能。当发生死锁时不会对用户造成多大影响，或发生死锁的概率很低，可以采用鸵鸟策略。\n\n基本思想是破坏形成死锁的四个必要条件：\n- 破坏互斥条件：允许某些资源同时被多个进程访问。但是有些资源本身并不具有这种属性，因此这种方案实用性有限；\n- 破坏占有并等待条件：\n    - 实行资源预先分配策略（当一个进程开始运行之前，必须一次性向系统申请它所需要的全部资源，否则不运行）；\n    - 或者只允许进程在没有占用资源的时候才能申请资源（申请资源前先释放占有的资源）；\n    - 缺点：很多时候无法预知一个进程所需的全部资源；同时，会降低资源利用率，降低系统的并发性；\n- 破坏非抢占条件：允许进程强行抢占被其它进程占有的资源。会降低系统性能；\n- 破坏循环等待条件：对所有资源统一编号，所有进程对资源的请求必须按照序号递增的顺序提出，即只有占有了编号较小的资源才能申请编号较大的资源。这样避免了占有大号资源的进程去申请小号资源。\n\n动态地检测资源分配状态，以确保系统处于安全状态，只有处于安全状态时才会进行资源的分配。所谓安全状态是指：即使所有进程突然请求需要的所有资源，也能存在某种对进程的资源分配顺序，使得每一个进程运行完毕。\n> 银行家算法\n> 如何检测死锁：检测有向图是否存在环；或者使用类似死锁避免的检测算法。\n死锁解除的方法：\n- 利用抢占：挂起某些进程，并抢占它的资源。但应防止某些进程被长时间挂起而处于饥饿状态；\n- 利用回滚：让某些进程回退到足以解除死锁的地步，进程回退时自愿释放资源。要求系统保持进程的历史信息，设置还原点；\n- 利用杀死进程：强制杀死某些进程直到死锁解除为止，可以按照优先级进行。\n\n# 内存管理 \n### 分页和分段有什么区别？\n- 页式存储：用户空间划分为大小相等的部分称为页（page），内存空间划分为同样大小的区域称为页框，分配时以页为单位，按进程需要的页数分配，逻辑上相邻的页物理上不一定相邻；\n- 段式存储：用户进程地址空间按照自身逻辑关系划分为若干个段（segment）（如代码段，数据段，堆栈段），内存空间被动态划分为长度不同的区域，分配时以段为单位，每段在内存中占据连续空间，各段可以不相邻；\n- 段页式存储：用户进程先按段划分，段内再按页划分，内存划分和分配按页。\n\n区别：\n- 目的不同：分页的目的是管理内存，用于虚拟内存以获得更大的地址空间；分段的目的是满足用户的需要，使程序和数据可以被划分为逻辑上独立的地址空间；\n- 大小不同：段的大小不固定，由其所完成的功能决定；页的大小固定，由系统决定；\n- 地址空间维度不同：分段是二维地址空间（段号+段内偏移），分页是一维地址空间（每个进程一个页表/多级页表，通过一个逻辑地址就能找到对应的物理地址）；\n- 分段便于信息的保护和共享；分页的共享收到限制；\n- 碎片：分段没有内碎片，但会产生外碎片；分页没有外碎片，但会产生内碎片（一个页填不满）\n\n### 什么是虚拟内存？\n每个程序都拥有自己的地址空间，这个地址空间被分成大小相等的页，这些页被映射到物理内存；但不需要所有的页都在物理内存中，当程序引用到不在物理内存中的页时，由操作系统将缺失的部分装入物理内存。这样，对于程序来说，逻辑上似乎有很大的内存空间，只是实际上有一部分是存储在磁盘上，因此叫做虚拟内存。\n\n虚拟内存的优点是让程序可以获得更多的可用内存。\n\n虚拟内存的实现方式、页表/多级页表、缺页中断、不同的页面淘汰算法：[答案](https://imageslr.github.io/2020/07/08/tech-interview.html#virtual-memory)。\n\n##### 如何进行地址空间到物理内存的映射？\n**内存管理单元**（MMU）管理着逻辑地址和物理地址的转换，其中的页表（Page table）存储着页（逻辑地址）和页框（物理内存空间）的映射表，页表中还包含包含有效位（是在内存还是磁盘）、访问位（是否被访问过）、修改位（内存中是否被修改过）、保护位（只读还是可读写）。逻辑地址：页号+页内地址（偏移）；每个进程一个页表，放在内存，页表起始地址在PCB/寄存器中。\n\n### 有哪些页面置换算法？\n在程序运行过程中，如果要访问的页面不在内存中，就发生缺页中断从而将该页调入内存中。此时如果内存已无空闲空间，系统必须从内存中调出一个页面到磁盘中来腾出空间。页面置换算法的主要目标是使页面置换频率最低（也可以说缺页率最低）。\n\n- **最佳页面置换算法**OPT（Optimal replacement algorithm）：置换以后不需要或者最远的将来才需要的页面，是一种理论上的算法，是最优策略；\n- **先进先出**FIFO：置换在内存中驻留时间最长的页面。缺点：有可能将那些经常被访问的页面也被换出，从而使缺页率升高；\n- **第二次机会算法**SCR：按FIFO选择某一页面，若其访问位为1，给第二次机会，并将访问位置0；\n- **时钟算法** Clock：SCR中需要将页面在链表中移动（第二次机会的时候要将这个页面从链表头移到链表尾），时钟算法使用环形链表，再使用一个指针指向最老的页面，避免了移动页面的开销；\n- **最近未使用算法**NRU（Not Recently Used）：检查访问位R、修改位M，优先置换R=M=0，其次是（R=0, M=1）；\n- **最近最少使用算法**LRU（Least Recently Used）：置换出未使用时间最长的一页；实现方式：维护时间戳，或者维护一个所有页面的链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。\n- **最不经常使用算法**NFU：置换出访问次数最少的页面\n\n- 时间上：最近被访问的页在不久的将来还会被访问；\n- 空间上：内存中被访问的页周围的页也很可能被访问。\n\n颠簸本质上是指频繁的页调度行为。进程发生缺页中断时必须置换某一页。然而，其他所有的页都在使用，它置换一个页，但又立刻再次需要这个页。因此会不断产生缺页中断，导致整个系统的效率急剧下降，这种现象称为颠簸。内存颠簸的解决策略包括：\n\n- 修改页面置换算法；\n- 降低同时运行的程序的数量；\n- 终止该进程或增加物理内存容量。\n\n### 缓冲区溢出问题\n防范缓冲区溢出攻击的机制有三种：随机化、栈保护和限制可执行代码区域。\n- 随机化：包括栈随机化（程序开始时在栈上分配一段随机大小的空间）和地址空间布局随机化（Address-Space Layout Randomization，ASLR，即每次运行时程序的不同部分，包括代码段、数据段、栈、堆等都会被加载到内存空间的不同区域），但只能增加攻击一个系统的难度，不能完全保证安全。\n- 栈保护：在每个函数的栈帧的局部变量和栈状态之间存储一个**随机产生的**特殊的值，称为金丝雀值（canary）。在恢复寄存器状态和函数返回之前，程序检测这个金丝雀值是否被改变了，如果是，那么程序异常终止。\n- 限制可执行代码区域：内存页的访问形式有三种：可读、可写、可执行，只有编译器产生的那部分代码所处的内存才是可执行的，其他页限制为只允许读和写。\n\n更详细的可以参考：[https://imageslr.github.io/2020/07/08/tech-interview.html#stackoverflow](https://imageslr.github.io/2020/07/08/tech-interview.html#stackoverflow)\n\n# 磁盘调度\n过程：磁头（找到对应的盘面）；磁道（一个盘面上的同心圆环，寻道时间）；扇区（旋转时间）。为减小寻道时间的调度算法：\n\n- 先来先服务\n- 最短寻道时间优先\n- 电梯算法：电梯总是保持一个方向运行，直到该方向没有请求为止，然后改变运行方向。\n\n# [进程间通信IPC](https://www.jianshu.com/p/c1015f5ffa74)\n\n# 参考\n- [面试/笔试第二弹 —— 操作系统面试问题集锦 - CSDN博客](https://blog.csdn.net/justloveyou_/article/details/78304294)\n- [线程同步与并发 - - SegmentFault](https://segmentfault.com/a/1190000018970361)\n- [彻底搞懂epoll高效运行的原理](http://baijiahao.baidu.com/s?id=1641172494287388070&wfr=spider&for=pc)\n- [用户态与内核态的切换](https://www.cnblogs.com/lirong21/p/4213028.html)\n\n文章内容搬运自本人[语雀](https://www.yuque.com/docs/share/4137d8f0-4b2e-4a18-a5a3-7a01239affcc)\n","source":"_posts/面试八股文（二）——-操作系统.md","raw":"---\ntitle: 面试八股文（二）—— 操作系统\ndate: 2021-09-22 22:43:42\nupdated: 2021-09-22 23:24:33\ntags: ['八股文', '操作系统']\ncategories:\n - 八股文\n - 操作系统\ndescription: 根据我多年（其实就一年）复习备考408和春招的经验，总结出来的面试八股文第二篇，也是基础篇之二——操作系统相关的常见问题。如果文章中有看不懂的知识点，强力推荐王道考研的OS相关课程，讲的巨清晰无比。如果觉得本文介绍内容过于浅显，大佬请移步机工出版社黑皮书之《现代操作系统》。\n---\n \n<meta name=\"referrer\" content=\"no-referrer\" />\n\n# 进程和线程\n### 进程和线程有什么区别？\n- 进程（Process）是系统进行资源分配和调度的基本单位，线程（Thread）是CPU调度和分派的基本单位；\n- 线程依赖于进程而存在，一个进程至少有一个线程；\n- 进程有自己的独立地址空间，线程共享所属进程的地址空间；\n- 进程是拥有系统资源的一个独立单位，而线程自己基本上不拥有系统资源，只拥有一点在运行中必不可少的资源(如程序计数器,一组寄存器和栈)，和其他线程共享本进程的相关资源如内存、I/O、cpu等；\n- 在进程切换时，涉及到整个当前进程CPU环境的保存环境的设置以及新被调度运行的CPU环境的设置，而线程切换只需保存和设置少量的寄存器的内容，并不涉及存储器管理方面的操作，可见，进程切换的开销远大于线程切换的开销；\n- 线程之间的通信更方便，同一进程下的线程共享全局变量等数据，而进程之间的通信需要以进程间通信(IPC)的方式进行；\n- 多线程程序只要有一个线程崩溃，整个程序就崩溃了，但多进程程序中一个进程崩溃并不会对其它进程造成影响，因为进程有自己的独立地址空间，因此多进程更加健壮\n\n进程操作代码实现，可以参考：[多进程 - 廖雪峰的官方网站](https://www.liaoxuefeng.com/wiki/1016959663602400/1017628290184064)\n\n\n##### 同一进程中的线程可以共享哪些数据？\n- 进程代码段\n- 进程的公有数据（全局变量、静态变量...）\n- 进程打开的文件描述符\n- 进程的当前目录\n- 信号处理器/信号处理函数：对收到的信号的处理方式\n- 进程ID与进程组ID\n\n##### 线程独占哪些资源？\n- 线程ID\n- 一组寄存器的值\n- 线程自身的栈（堆是共享的）\n- 错误返回码：线程可能会产生不同的错误返回码，一个线程的错误返回码不应该被其它线程修改；\n- 信号掩码/信号屏蔽字(Signal mask)：表示是否屏蔽/阻塞相应的信号（SIGKILL,SIGSTOP除外）\n\n\n\n### 进程间通信有哪些方式？\n1. 管道(Pipe)\n- 管道是半双工的，数据只能向一个方向流动；需要双方通信时，需要建立起两个管道；\n- 一个进程向管道中写的内容被管道另一端的进程读出。写入的内容每次都添加在管道缓冲区的末尾，并且每次都是从缓冲区的头部读出数据；\n- 只能用于父子进程或者兄弟进程之间(具有亲缘关系的进程)\n2. 命名管道\n3. 消息队列\n4. 信号(Signal)\n5. 共享内存\n6. 信号量(Semaphore)：初始化操作、P操作、V操作；P操作：信号量-1，检测是否小于0，小于则进程进入阻塞状态；V操作：信号量+1，若小于等于0，则从队列中唤醒一个等待的进程进入就绪态\n7. 套接字(Socket)\n\n更详细的可以参考：\n- [https://imageslr.github.io/2020/02/26/ipc.html](https://imageslr.github.io/2020/02/26/ipc.html)\n- [https://www.jianshu.com/p/c1015f5ffa74](https://www.jianshu.com/p/c1015f5ffa74)\n\n### 进程同步问题\n> 进程的同步是目的，而进程间通信是实现进程同步的手段\n\n管程将共享变量以及对这些共享变量的操作封装起来，形成一个具有一定接口的功能模块，这样只能通过管程提供的某个过程才能访问管程中的资源。进程只能互斥地使用管程，使用完之后必须释放管程并唤醒入口等待队列中的进程。\n当一个进程试图进入管程时，在**入口等待队列**等待。若P进程唤醒了Q进程，则Q进程先执行，P在**紧急等待队列**中等待。（**HOARE管程**）\nwait操作：执行wait操作的进程进入条件变量链末尾，唤醒紧急等待队列或者入口队列中的进程；signal操作：唤醒条件变量链中的进程，自己进入紧急等待队列，若条件变量链为空，则继续执行。（**HOARE管程**）\n**MESA管程**：将HOARE中的signal换成了notify（或者broadcast通知所有满足条件的），进行通知而不是立马交换管程的使用权，在合适的时候，条件队列首位的进程可以进入，进入之前必须用while检查条件是否合适。优点：没有额外的进程切换\n\n> 问题描述：使用一个缓冲区来存放数据，只有缓冲区没有满，生产者才可以写入数据；只有缓冲区不为空，消费者才可以读出数据\n\n代码实现：\n```c\n// 伪代码描述 \n// 定义信号量 full记录缓冲区物品数量 empty代表缓冲区空位数量 mutex为互斥量\nsemaphore full = 0, empty = n, mutex = 1;\n\n// 生产者进程\nvoid producer(){\n\tdo{\n   \t  P(empty);\n\t  P(mutex);\n\n     // 生产者进行生产\n   \t\n   \t  V(mutex);\n   \t  V(full);\n \t} while(1);\n}\n\nvoid consumer(){\n\tdo{\n\t  P(full);\n\t  P(mutex);\n\n    \t// 消费者进行消费\n\n\t  V(mutex);\n\t  V(empty);\n \t} while(1);\n}\n```\n\n\n> 问题描述：有五位哲学家围绕着餐桌坐，每一位哲学家要么思考，要么吃饭。为了吃饭，哲学家必须拿起两双筷子（分别放于左右两端）不幸的是，筷子的数量和哲学家相等，所以每只筷子必须由两位哲学家共享。\n\n代码实现：\n```c\n#define N 5  // number of philosopher\n#define LEFT (i + N - 1)%N // number of i's left neighbors\n#define RIGHT (i + 1)%N // number of i's right neighbors\n#define THINKING 0\n#define HUNGRY 1\n#define EATING 2\ntypedef int semaphore;\nint state[N]; // array to keep track of everyone's state\nsemaphore mutex = 1; // mutual exclusion of critical region\nsemaphore s[N]; \n\nvoid philosopher(int i) {\n\twhile (TRUE) {\n\t\tthink();\n\t\ttake_forks(i);\n\t\teat();\n\t\tput_forks(i);\n\t}\n}\n\nvoid take_forks(int i) {\n\tdown(&mutex); // enter critical region\n\tstate[i] = HUNGRY; // record that i is hungry\n\ttest_forks(i); // try to acquire two forks\n\tup(&mutex); // exit critical region\n\tdown(&s[i]); // block if forks are not acquired\n}\n\nvoid put_forks(int i) {\n\tdown(&mutex); // enter critical region\n\tstate[i] = THINKING; // record that has finished eating\n\ttest_forks(LEFT); // see if left neighbor can now eat\n\ttest_forks(RIGHT); // see if right neighbor can now eat\n\tup(&mutex); // exit critical region\n}\n\nvoid test_forks(int i) {\n\tif (state[i] == HUNGRY && state[LEFT] != EATING && state[RIGHT] != EATING) {\n\t\tstate[i] = EATING;\n\t\tup(&s[i]);\n\t}\n}\n```\n\n##### 临界区的概念？\n各个进程中对临界资源（互斥资源/共享变量，一次只能给一个进程使用）进行操作的程序片段\n\n\n##### 同步与互斥的概念？\n- 同步：多个进程因为合作而使得进程的执行有一定的先后顺序。比如某个进程需要另一个进程提供的消息，获得消息之前进入阻塞态；\n- 互斥：多个进程在同一时刻只有一个进程能进入临界区\n\n##### 并发、并行、异步的区别？\n并发：在一个时间段中同时有多个程序在运行，但其实任一时刻，只有一个程序在CPU上运行，宏观上的并发是通过不断的切换实现的；\n多线程：并发运行的一段代码。是实现异步的手段\n并行（和串行相比）：在多CPU系统中，多个程序无论宏观还是微观上都是同时执行的\n异步（和同步相比）：同步是顺序执行，异步是在等待某个资源的时候继续做自己的事\n\n\n### 进程有哪几种状态？\n![](https://cdn.nlark.com/yuque/0/2021/png/1431305/1628085394606-49204b73-729e-4f57-97bc-d43ad01ec54b.png)\n\n- 就绪状态：进程已获得除处理机以外的所需资源，等待分配处理机资源\n- 运行状态：占用处理机资源运行，处于此状态的进程数小于等于CPU数\n- 阻塞状态： 进程等待某种条件，在条件满足之前无法执行\n\n### 进程调度策略有哪些？\n1. **批处理系统**：\n按照请求的顺序进行调度。非抢占式，开销小，无饥饿问题，响应时间不确定（可能很慢）；\n对短进程不利，对IO密集型进程不利。\n\n按估计运行时间最短的顺序进行调度。非抢占式，吞吐量高，开销可能较大，可能导致饥饿问题；\n对短进程提供好的响应时间，对长进程不利。\n\n按剩余运行时间的顺序进行调度。(最短作业优先的抢占式版本)。吞吐量高，开销可能较大，提供好的响应时间；\n可能导致饥饿问题，对长进程不利。\n\n响应比 = 1+ 等待时间/处理时间。同时考虑了等待时间的长短和估计需要的执行时间长短，很好的平衡了长短进程。非抢占，吞吐量高，开销可能较大，提供好的响应时间，无饥饿问题。\n\n2. **交互式系统**\n   交互式系统有大量的用户交互操作，在该系统中调度算法的目标是快速地进行响应。\n\n将所有就绪进程按 FCFS 的原则排成一个队列，用完时间片的进程排到队列最后。抢占式（时间片用完时），开销小，无饥饿问题，为短进程提供好的响应时间；\n若时间片小，进程切换频繁，吞吐量低；若时间片太长，实时性得不到保证。\n\n为每个进程分配一个优先级，按优先级进行调度。为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。\n\n设置多个就绪队列1、2、3...，优先级递减，时间片递增。只有等到优先级更高的队列为空时才会调度当前队列中的进程。如果进程用完了当前队列的时间片还未执行完，则会被移到下一队列。\n抢占式（时间片用完时），开销可能较大，对IO型进程有利，可能会出现饥饿问题。\n\n##### 什么叫优先级反转？如何解决？\n高优先级的进程等待被一个低优先级进程占用的资源时，就会出现优先级反转，即优先级较低的进程比优先级较高的进程先执行。此处详细解释优先级反转带来的问题：如果有一个中等优先级的进程将低优先级的进程抢占，那么此时低优先级的进程无法正常进行并在后续释放被占用的资源，导致高优先级的任务一直被挂起，直到中等优先级的进程完成后，低优先级的进程才可以继续并在后续释放占用的资源，最后高优先级的进程才可以执行。导致的问题就是高优先级的进程在中等优先级的进程调度之后。\n解决方法：\n\n- 优先级天花板(priority ceiling)：当任务申请某资源时，把该任务的优先级提升到可访问这个资源的所有任务中的最高优先级，这个优先级称为该资源的优先级天花板。简单易行。\n- 优先级继承(priority inheritance)：当任务A申请共享资源S时，如果S正在被任务C使用，通过比较任务C与自身的优先级，如发现任务C的优先级小于自身的优先级，则将任务C的优先级提升到自身的优先级，任务C释放资源S后，再恢复任务C的原优先级。\n\n### 什么是僵尸进程？\n一个子进程结束后，它的父进程并没有等待它（调用wait或者waitpid），那么这个子进程将成为一个僵尸进程。僵尸进程是一个已经死亡的进程，但是并没有真正被销毁。它已经放弃了几乎所有内存空间，没有任何可执行代码，也不能被调度，仅仅在进程表中保留一个位置，记载该进程的进程ID、终止状态以及资源利用信息(CPU时间，内存使用量等等)供父进程收集，除此之外，僵尸进程不再占有任何内存空间。这个僵尸进程可能会一直留在系统中直到系统重启。\n\n危害：占用进程号，而系统所能使用的进程号是有限的；占用内存。\n\n以下情况不会产生僵尸进程：\n\n- 该进程的父进程先结束了。每个进程结束的时候，系统都会扫描是否存在子进程，如果有则用Init进程接管，成为该进程的父进程，并且会调用wait等待其结束。\n- 父进程调用wait或者waitpid等待子进程结束（需要每隔一段时间查询子进程是否结束）。wait系统调用会使父进程暂停执行，直到它的一个子进程结束为止。waitpid则可以加入`WNOHANG`(wait-no-hang)选项，如果没有发现结束的子进程，就会立即返回，不会将调用waitpid的进程阻塞。同时，waitpid还可以选择是等待任一子进程（同wait），还是等待指定pid的子进程，还是等待同一进程组下的任一子进程，还是等待组ID等于pid的任一子进程；\n- 子进程结束时，系统会产生`SIGCHLD`(signal-child)信号，可以注册一个信号处理函数，在该函数中调用waitpid，等待所有结束的子进程（注意：一般都需要循环调用waitpid，因为在信号处理函数开始执行之前，可能已经有多个子进程结束了，而信号处理函数只执行一次，所以要循环调用将所有结束的子进程回收）；\n- 也可以用`signal(SIGCLD, SIG_IGN)`(signal-ignore)通知内核，表示忽略`SIGCHLD`信号，那么子进程结束后，内核会进行回收。\n\n##### 什么是孤儿进程？\n一个父进程已经结束了，但是它的子进程还在运行，那么这些子进程将成为孤儿进程。孤儿进程会被Init（进程ID为1）接管，当这些孤儿进程结束时由Init完成状态收集工作。\n\n### 线程同步有哪些方式？\n> 为什么需要线程同步：线程有时候会和其他线程共享一些资源，比如内存、数据库等。当多个线程同时读写同一份共享资源的时候，可能会发生冲突。因此需要线程的同步，多个线程按顺序访问资源。\n\n- **互斥量** Mutex：互斥量是内核对象，只有拥有互斥对象的线程才有访问互斥资源的权限。因为互斥对象只有一个，所以可以保证互斥资源不会被多个线程同时访问；当前拥有互斥对象的线程处理完任务后必须将互斥对象交出，以便其他线程访问该资源；\n- **信号量** Semaphore：信号量是内核对象，它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量。信号量对象保存了**最大资源计数**和**当前可用资源计数**，每增加一个线程对共享资源的访问，当前可用资源计数就减1，只要当前可用资源计数大于0，就可以发出信号量信号，如果为0，则将线程放入一个队列中等待。线程处理完共享资源后，应在离开的同时通过`ReleaseSemaphore`函数将当前可用资源数加1。如果信号量的取值只能为0或1，那么信号量就成为了互斥量；\n- **事件** Event：允许一个线程在处理完一个任务后，主动唤醒另外一个线程执行任务。事件分为手动重置事件和自动重置事件。手动重置事件被设置为激发状态后，会唤醒所有等待的线程，而且一直保持为激发状态，直到程序重新把它设置为未激发状态。自动重置事件被设置为激发状态后，会唤醒**一个**等待中的线程，然后自动恢复为未激发状态。\n- **临界区** Critical Section：任意时刻只允许一个线程对临界资源进行访问。拥有临界区对象的线程可以访问该临界资源，其它试图访问该资源的线程将被挂起，直到临界区对象被释放。\n\n##### 互斥量和临界区有什么区别？\n互斥量是可以命名的，可以用于不同进程之间的同步；而临界区只能用于同一进程中线程的同步。创建互斥量需要的资源更多，因此临界区的优势是速度快，节省资源。\n\n### 什么是协程？\n\n协程是一种用户态的轻量级线程，协程的调度完全由用户控制。协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈，直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快。\n\n##### 协程多与线程进行比较？\n1. 一个线程可以拥有多个协程，一个进程也可以单独拥有多个协程，这样python中则能使用多核CPU。\n2. 线程进程都是同步机制，而协程则是异步\n3. 协程能保留上一次调用时的状态，每次过程重入时，就相当于进入上一次调用的状态\n\n### 进程的异常控制流：陷阱、中断、异常和信号\n陷阱是**有意**造成的“异常”，是执行一条指令的结果。陷阱是同步的。陷阱的主要作用是实现**系统调用**。比如，进程可以执行 `syscall n` 指令向内核请求服务。当进程执行这条指令后，会中断当前的控制流，**陷入**到内核态，执行相应的系统调用。内核的处理程序在执行结束后，会将结果返回给进程，同时退回到用户态。进程此时继续执行**下一条指令**。\n\n中断由处理器**外部**的**硬件**产生，不是执行某条指令的结果，也无法预测发生时机。由于中断独立于当前执行的程序，因此中断是异步事件。中断包括 I/O 设备发出的 I/O 中断、各种定时器引起的时钟中断、调试程序中设置的断点等引起的调试中断等。\n\n异常是一种错误情况，是执行当前指令的结果，可能被错误处理程序修正，也可能直接终止应用程序。异常是同步的。这里特指因为执行当前指令而产生的**错误情况**，比如除法异常、缺页异常等。有些书上为了区分，也将这类“异常”称为**“故障”**。\n\n信号是一种**更高层的**软件形式的异常，同样会中断进程的控制流，可以由进程进行处理。一个信号代表了一个消息。信号的作用是用来**通知进程**发生了某种系统事件。\n\n更详细的可以参考：[https://imageslr.github.io/2020/07/09/trap-interrupt-exception.html](https://imageslr.github.io/2020/07/09/trap-interrupt-exception.html)\n\n### 什么是IO多路复用？怎么实现？\nIO多路复用（IO Multiplexing）是指单个进程/线程就可以同时处理多个IO请求。\n\n实现原理：用户将想要监视的文件描述符（File Descriptor）添加到select/poll/epoll函数中，由内核监视，函数阻塞。一旦有文件描述符就绪（读就绪或写就绪），或者超时（设置timeout），函数就会返回，然后该进程可以进行相应的读/写操作。\n\n- `select`：将文件描述符放入一个集合中，调用select时，将这个集合从用户空间拷贝到内核空间（缺点1：每次都要复制，**开销大**），由内核根据就绪状态修改该集合的内容。（缺点2）**集合大小有限制**，32位机默认是1024（64位：2048）；采用水平触发机制。select函数返回后，需要通过遍历这个集合，找到就绪的文件描述符（缺点3：**轮询的方式效率较低**），当文件描述符的数量增加时，效率会线性下降；\n- `poll`：和select几乎没有区别，区别在于文件描述符的存储方式不同，poll采用链表的方式存储，没有最大存储数量的限制；\n- `epoll`：通过内核和用户空间共享内存，避免了不断复制的问题；支持的同时连接数上限很高（1G左右的内存支持10W左右的连接数）；文件描述符就绪时，采用回调机制，避免了轮询（回调函数将就绪的描述符添加到一个链表中，执行epoll_wait时，返回这个链表）；支持水平触发和边缘触发，采用边缘触发机制时，只有活跃的描述符才会触发回调函数。\n\n总结，区别主要在于：\n- 一个线程/进程所能打开的最大连接数\n- 文件描述符传递方式（是否复制）\n- 水平触发 or 边缘触发\n- 查询就绪的描述符时的效率（是否轮询）\n\n当连接数较多并且有很多的不活跃连接时，epoll的效率比其它两者高很多；但是当连接数较少并且都十分活跃的情况下，由于epoll需要很多回调，因此性能可能低于其它两者。\n\n文件描述符在形式上是一个非负整数。实际上，它是一个索引值，指向内核为每一个进程所维护的该进程打开文件的记录表。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。\n内核通过文件描述符来访问文件。文件描述符指向一个文件。\n\n##### 什么是水平触发？什么是边缘触发？\n- 水平触发（LT，Level Trigger）模式下，只要一个文件描述符就绪，就会触发通知，如果用户程序没有一次性把数据读写完，下次还会通知；\n- 边缘触发（ET，Edge Trigger）模式下，当描述符从未就绪变为就绪时通知一次，之后不会再通知，直到再次从未就绪变为就绪（缓冲区从不可读/写变为可读/写）。\n- 区别：边缘触发效率更高，减少了被重复触发的次数，函数不会返回大量用户程序可能不需要的文件描述符。\n- 为什么边缘触发一定要用非阻塞（non-block）IO：避免由于一个描述符的阻塞读/阻塞写操作让处理其它描述符的任务出现饥饿状态。\n\n##### 有哪些常见的IO模型？\n- 同步阻塞IO（Blocking IO）：用户线程发起IO读/写操作之后，线程阻塞，直到可以开始处理数据；对CPU资源的利用率不够；\n- 同步非阻塞IO（Non-blocking IO）：发起IO请求之后可以立即返回，如果没有就绪的数据，需要不断地发起IO请求直到数据就绪；不断重复请求消耗了大量的CPU资源；\n- IO多路复用\n- 异步IO（Asynchronous IO）：用户线程发出IO请求之后，继续执行，由内核进行数据的读取并放在用户指定的缓冲区内，在IO完成之后通知用户线程直接使用。\n\n### 什么是用户态和内核态？\n为了限制不同程序的访问能力，防止一些程序访问其它程序的内存数据，CPU划分了用户态和内核态两个权限等级。\n\n- 用户态只能受限地访问内存，且不允许访问外围设备，没有占用CPU的能力，CPU资源可以被其它程序获取；\n- 内核态可以访问内存所有数据以及外围设备，也可以进行程序的切换。\n\n所有用户程序都运行在用户态，但有时需要进行一些内核态的操作，比如从硬盘或者键盘读数据，这时就需要进行系统调用，使用**陷阱指令**，CPU切换到内核态，执行相应的服务，再切换为用户态并返回系统调用的结果。\n\n##### 为什么要分用户态和内核态？\n- 安全性：防止用户程序恶意或者不小心破坏系统/内存/硬件资源；\n- 封装性：用户程序不需要实现更加底层的代码；\n- 利于调度：如果多个用户程序都在等待键盘输入，这时就需要进行调度；统一交给操作系统调度更加方便。\n\n##### 如何从用户态切换到内核态？\n- 系统调用：比如读取命令行输入。本质上还是通过中断实现\n- 用户程序发生异常时：比如缺页异常\n- 外围设备的中断：外围设备完成用户请求的操作之后，会向CPU发出中断信号，这时CPU会转去处理对应的中断处理程序\n\n# 死锁 \n### 什么是死锁？\n在两个或者多个并发进程中，每个进程持有某种资源而又等待其它进程释放它们现在保持着的资源，在未改变这种状态之前都不能向前推进，称这一组进程产生了死锁(deadlock)。\n### 死锁产生的必要条件？\n- **互斥**：一个资源一次只能被一个进程使用；\n- **占有并等待**：一个进程至少占有一个资源，并在等待另一个被其它进程占用的资源；\n- **非抢占**：已经分配给一个进程的资源不能被强制性抢占，只能由进程完成任务之后自愿释放；\n- **循环等待**：若干进程之间形成一种头尾相接的环形等待资源关系，该环路中的每个进程都在等待下一个进程所占有的资源。\n\n### 死锁有哪些处理方法？\n直接忽略死锁。因为解决死锁问题的代价很高，因此鸵鸟策略这种不采取任务措施的方案会获得更高的性能。当发生死锁时不会对用户造成多大影响，或发生死锁的概率很低，可以采用鸵鸟策略。\n\n基本思想是破坏形成死锁的四个必要条件：\n- 破坏互斥条件：允许某些资源同时被多个进程访问。但是有些资源本身并不具有这种属性，因此这种方案实用性有限；\n- 破坏占有并等待条件：\n    - 实行资源预先分配策略（当一个进程开始运行之前，必须一次性向系统申请它所需要的全部资源，否则不运行）；\n    - 或者只允许进程在没有占用资源的时候才能申请资源（申请资源前先释放占有的资源）；\n    - 缺点：很多时候无法预知一个进程所需的全部资源；同时，会降低资源利用率，降低系统的并发性；\n- 破坏非抢占条件：允许进程强行抢占被其它进程占有的资源。会降低系统性能；\n- 破坏循环等待条件：对所有资源统一编号，所有进程对资源的请求必须按照序号递增的顺序提出，即只有占有了编号较小的资源才能申请编号较大的资源。这样避免了占有大号资源的进程去申请小号资源。\n\n动态地检测资源分配状态，以确保系统处于安全状态，只有处于安全状态时才会进行资源的分配。所谓安全状态是指：即使所有进程突然请求需要的所有资源，也能存在某种对进程的资源分配顺序，使得每一个进程运行完毕。\n> 银行家算法\n> 如何检测死锁：检测有向图是否存在环；或者使用类似死锁避免的检测算法。\n死锁解除的方法：\n- 利用抢占：挂起某些进程，并抢占它的资源。但应防止某些进程被长时间挂起而处于饥饿状态；\n- 利用回滚：让某些进程回退到足以解除死锁的地步，进程回退时自愿释放资源。要求系统保持进程的历史信息，设置还原点；\n- 利用杀死进程：强制杀死某些进程直到死锁解除为止，可以按照优先级进行。\n\n# 内存管理 \n### 分页和分段有什么区别？\n- 页式存储：用户空间划分为大小相等的部分称为页（page），内存空间划分为同样大小的区域称为页框，分配时以页为单位，按进程需要的页数分配，逻辑上相邻的页物理上不一定相邻；\n- 段式存储：用户进程地址空间按照自身逻辑关系划分为若干个段（segment）（如代码段，数据段，堆栈段），内存空间被动态划分为长度不同的区域，分配时以段为单位，每段在内存中占据连续空间，各段可以不相邻；\n- 段页式存储：用户进程先按段划分，段内再按页划分，内存划分和分配按页。\n\n区别：\n- 目的不同：分页的目的是管理内存，用于虚拟内存以获得更大的地址空间；分段的目的是满足用户的需要，使程序和数据可以被划分为逻辑上独立的地址空间；\n- 大小不同：段的大小不固定，由其所完成的功能决定；页的大小固定，由系统决定；\n- 地址空间维度不同：分段是二维地址空间（段号+段内偏移），分页是一维地址空间（每个进程一个页表/多级页表，通过一个逻辑地址就能找到对应的物理地址）；\n- 分段便于信息的保护和共享；分页的共享收到限制；\n- 碎片：分段没有内碎片，但会产生外碎片；分页没有外碎片，但会产生内碎片（一个页填不满）\n\n### 什么是虚拟内存？\n每个程序都拥有自己的地址空间，这个地址空间被分成大小相等的页，这些页被映射到物理内存；但不需要所有的页都在物理内存中，当程序引用到不在物理内存中的页时，由操作系统将缺失的部分装入物理内存。这样，对于程序来说，逻辑上似乎有很大的内存空间，只是实际上有一部分是存储在磁盘上，因此叫做虚拟内存。\n\n虚拟内存的优点是让程序可以获得更多的可用内存。\n\n虚拟内存的实现方式、页表/多级页表、缺页中断、不同的页面淘汰算法：[答案](https://imageslr.github.io/2020/07/08/tech-interview.html#virtual-memory)。\n\n##### 如何进行地址空间到物理内存的映射？\n**内存管理单元**（MMU）管理着逻辑地址和物理地址的转换，其中的页表（Page table）存储着页（逻辑地址）和页框（物理内存空间）的映射表，页表中还包含包含有效位（是在内存还是磁盘）、访问位（是否被访问过）、修改位（内存中是否被修改过）、保护位（只读还是可读写）。逻辑地址：页号+页内地址（偏移）；每个进程一个页表，放在内存，页表起始地址在PCB/寄存器中。\n\n### 有哪些页面置换算法？\n在程序运行过程中，如果要访问的页面不在内存中，就发生缺页中断从而将该页调入内存中。此时如果内存已无空闲空间，系统必须从内存中调出一个页面到磁盘中来腾出空间。页面置换算法的主要目标是使页面置换频率最低（也可以说缺页率最低）。\n\n- **最佳页面置换算法**OPT（Optimal replacement algorithm）：置换以后不需要或者最远的将来才需要的页面，是一种理论上的算法，是最优策略；\n- **先进先出**FIFO：置换在内存中驻留时间最长的页面。缺点：有可能将那些经常被访问的页面也被换出，从而使缺页率升高；\n- **第二次机会算法**SCR：按FIFO选择某一页面，若其访问位为1，给第二次机会，并将访问位置0；\n- **时钟算法** Clock：SCR中需要将页面在链表中移动（第二次机会的时候要将这个页面从链表头移到链表尾），时钟算法使用环形链表，再使用一个指针指向最老的页面，避免了移动页面的开销；\n- **最近未使用算法**NRU（Not Recently Used）：检查访问位R、修改位M，优先置换R=M=0，其次是（R=0, M=1）；\n- **最近最少使用算法**LRU（Least Recently Used）：置换出未使用时间最长的一页；实现方式：维护时间戳，或者维护一个所有页面的链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。\n- **最不经常使用算法**NFU：置换出访问次数最少的页面\n\n- 时间上：最近被访问的页在不久的将来还会被访问；\n- 空间上：内存中被访问的页周围的页也很可能被访问。\n\n颠簸本质上是指频繁的页调度行为。进程发生缺页中断时必须置换某一页。然而，其他所有的页都在使用，它置换一个页，但又立刻再次需要这个页。因此会不断产生缺页中断，导致整个系统的效率急剧下降，这种现象称为颠簸。内存颠簸的解决策略包括：\n\n- 修改页面置换算法；\n- 降低同时运行的程序的数量；\n- 终止该进程或增加物理内存容量。\n\n### 缓冲区溢出问题\n防范缓冲区溢出攻击的机制有三种：随机化、栈保护和限制可执行代码区域。\n- 随机化：包括栈随机化（程序开始时在栈上分配一段随机大小的空间）和地址空间布局随机化（Address-Space Layout Randomization，ASLR，即每次运行时程序的不同部分，包括代码段、数据段、栈、堆等都会被加载到内存空间的不同区域），但只能增加攻击一个系统的难度，不能完全保证安全。\n- 栈保护：在每个函数的栈帧的局部变量和栈状态之间存储一个**随机产生的**特殊的值，称为金丝雀值（canary）。在恢复寄存器状态和函数返回之前，程序检测这个金丝雀值是否被改变了，如果是，那么程序异常终止。\n- 限制可执行代码区域：内存页的访问形式有三种：可读、可写、可执行，只有编译器产生的那部分代码所处的内存才是可执行的，其他页限制为只允许读和写。\n\n更详细的可以参考：[https://imageslr.github.io/2020/07/08/tech-interview.html#stackoverflow](https://imageslr.github.io/2020/07/08/tech-interview.html#stackoverflow)\n\n# 磁盘调度\n过程：磁头（找到对应的盘面）；磁道（一个盘面上的同心圆环，寻道时间）；扇区（旋转时间）。为减小寻道时间的调度算法：\n\n- 先来先服务\n- 最短寻道时间优先\n- 电梯算法：电梯总是保持一个方向运行，直到该方向没有请求为止，然后改变运行方向。\n\n# [进程间通信IPC](https://www.jianshu.com/p/c1015f5ffa74)\n\n# 参考\n- [面试/笔试第二弹 —— 操作系统面试问题集锦 - CSDN博客](https://blog.csdn.net/justloveyou_/article/details/78304294)\n- [线程同步与并发 - - SegmentFault](https://segmentfault.com/a/1190000018970361)\n- [彻底搞懂epoll高效运行的原理](http://baijiahao.baidu.com/s?id=1641172494287388070&wfr=spider&for=pc)\n- [用户态与内核态的切换](https://www.cnblogs.com/lirong21/p/4213028.html)\n\n文章内容搬运自本人[语雀](https://www.yuque.com/docs/share/4137d8f0-4b2e-4a18-a5a3-7a01239affcc)\n","slug":"面试八股文（二）——-操作系统","published":1,"comments":1,"layout":"post","photos":[],"link":"","_id":"cktvosieg000u2svu1ju803ov","content":"<meta name=\"referrer\" content=\"no-referrer\" />\n\n<h1 id=\"进程和线程\"><a href=\"#进程和线程\" class=\"headerlink\" title=\"进程和线程\"></a>进程和线程</h1><h3 id=\"进程和线程有什么区别？\"><a href=\"#进程和线程有什么区别？\" class=\"headerlink\" title=\"进程和线程有什么区别？\"></a>进程和线程有什么区别？</h3><ul>\n<li>进程（Process）是系统进行资源分配和调度的基本单位，线程（Thread）是CPU调度和分派的基本单位；</li>\n<li>线程依赖于进程而存在，一个进程至少有一个线程；</li>\n<li>进程有自己的独立地址空间，线程共享所属进程的地址空间；</li>\n<li>进程是拥有系统资源的一个独立单位，而线程自己基本上不拥有系统资源，只拥有一点在运行中必不可少的资源(如程序计数器,一组寄存器和栈)，和其他线程共享本进程的相关资源如内存、I/O、cpu等；</li>\n<li>在进程切换时，涉及到整个当前进程CPU环境的保存环境的设置以及新被调度运行的CPU环境的设置，而线程切换只需保存和设置少量的寄存器的内容，并不涉及存储器管理方面的操作，可见，进程切换的开销远大于线程切换的开销；</li>\n<li>线程之间的通信更方便，同一进程下的线程共享全局变量等数据，而进程之间的通信需要以进程间通信(IPC)的方式进行；</li>\n<li>多线程程序只要有一个线程崩溃，整个程序就崩溃了，但多进程程序中一个进程崩溃并不会对其它进程造成影响，因为进程有自己的独立地址空间，因此多进程更加健壮</li>\n</ul>\n<p>进程操作代码实现，可以参考：<a href=\"https://www.liaoxuefeng.com/wiki/1016959663602400/1017628290184064\">多进程 - 廖雪峰的官方网站</a></p>\n<h5 id=\"同一进程中的线程可以共享哪些数据？\"><a href=\"#同一进程中的线程可以共享哪些数据？\" class=\"headerlink\" title=\"同一进程中的线程可以共享哪些数据？\"></a>同一进程中的线程可以共享哪些数据？</h5><ul>\n<li>进程代码段</li>\n<li>进程的公有数据（全局变量、静态变量…）</li>\n<li>进程打开的文件描述符</li>\n<li>进程的当前目录</li>\n<li>信号处理器/信号处理函数：对收到的信号的处理方式</li>\n<li>进程ID与进程组ID</li>\n</ul>\n<h5 id=\"线程独占哪些资源？\"><a href=\"#线程独占哪些资源？\" class=\"headerlink\" title=\"线程独占哪些资源？\"></a>线程独占哪些资源？</h5><ul>\n<li>线程ID</li>\n<li>一组寄存器的值</li>\n<li>线程自身的栈（堆是共享的）</li>\n<li>错误返回码：线程可能会产生不同的错误返回码，一个线程的错误返回码不应该被其它线程修改；</li>\n<li>信号掩码/信号屏蔽字(Signal mask)：表示是否屏蔽/阻塞相应的信号（SIGKILL,SIGSTOP除外）</li>\n</ul>\n<h3 id=\"进程间通信有哪些方式？\"><a href=\"#进程间通信有哪些方式？\" class=\"headerlink\" title=\"进程间通信有哪些方式？\"></a>进程间通信有哪些方式？</h3><ol>\n<li>管道(Pipe)</li>\n</ol>\n<ul>\n<li>管道是半双工的，数据只能向一个方向流动；需要双方通信时，需要建立起两个管道；</li>\n<li>一个进程向管道中写的内容被管道另一端的进程读出。写入的内容每次都添加在管道缓冲区的末尾，并且每次都是从缓冲区的头部读出数据；</li>\n<li>只能用于父子进程或者兄弟进程之间(具有亲缘关系的进程)</li>\n</ul>\n<ol start=\"2\">\n<li>命名管道</li>\n<li>消息队列</li>\n<li>信号(Signal)</li>\n<li>共享内存</li>\n<li>信号量(Semaphore)：初始化操作、P操作、V操作；P操作：信号量-1，检测是否小于0，小于则进程进入阻塞状态；V操作：信号量+1，若小于等于0，则从队列中唤醒一个等待的进程进入就绪态</li>\n<li>套接字(Socket)</li>\n</ol>\n<p>更详细的可以参考：</p>\n<ul>\n<li><a href=\"https://imageslr.github.io/2020/02/26/ipc.html\">https://imageslr.github.io/2020/02/26/ipc.html</a></li>\n<li><a href=\"https://www.jianshu.com/p/c1015f5ffa74\">https://www.jianshu.com/p/c1015f5ffa74</a></li>\n</ul>\n<h3 id=\"进程同步问题\"><a href=\"#进程同步问题\" class=\"headerlink\" title=\"进程同步问题\"></a>进程同步问题</h3><blockquote>\n<p>进程的同步是目的，而进程间通信是实现进程同步的手段</p>\n</blockquote>\n<p>管程将共享变量以及对这些共享变量的操作封装起来，形成一个具有一定接口的功能模块，这样只能通过管程提供的某个过程才能访问管程中的资源。进程只能互斥地使用管程，使用完之后必须释放管程并唤醒入口等待队列中的进程。<br>当一个进程试图进入管程时，在<strong>入口等待队列</strong>等待。若P进程唤醒了Q进程，则Q进程先执行，P在<strong>紧急等待队列</strong>中等待。（<strong>HOARE管程</strong>）<br>wait操作：执行wait操作的进程进入条件变量链末尾，唤醒紧急等待队列或者入口队列中的进程；signal操作：唤醒条件变量链中的进程，自己进入紧急等待队列，若条件变量链为空，则继续执行。（<strong>HOARE管程</strong>）<br><strong>MESA管程</strong>：将HOARE中的signal换成了notify（或者broadcast通知所有满足条件的），进行通知而不是立马交换管程的使用权，在合适的时候，条件队列首位的进程可以进入，进入之前必须用while检查条件是否合适。优点：没有额外的进程切换</p>\n<blockquote>\n<p>问题描述：使用一个缓冲区来存放数据，只有缓冲区没有满，生产者才可以写入数据；只有缓冲区不为空，消费者才可以读出数据</p>\n</blockquote>\n<p>代码实现：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 伪代码描述 </span></span><br><span class=\"line\"><span class=\"comment\">// 定义信号量 full记录缓冲区物品数量 empty代表缓冲区空位数量 mutex为互斥量</span></span><br><span class=\"line\">semaphore full = <span class=\"number\">0</span>, empty = n, mutex = <span class=\"number\">1</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 生产者进程</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">producer</span><span class=\"params\">()</span></span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">do</span>&#123;</span><br><span class=\"line\">   \t  P(empty);</span><br><span class=\"line\">\t  P(mutex);</span><br><span class=\"line\"></span><br><span class=\"line\">     <span class=\"comment\">// 生产者进行生产</span></span><br><span class=\"line\">   \t</span><br><span class=\"line\">   \t  V(mutex);</span><br><span class=\"line\">   \t  V(full);</span><br><span class=\"line\"> \t&#125; <span class=\"keyword\">while</span>(<span class=\"number\">1</span>);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">consumer</span><span class=\"params\">()</span></span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">do</span>&#123;</span><br><span class=\"line\">\t  P(full);</span><br><span class=\"line\">\t  P(mutex);</span><br><span class=\"line\"></span><br><span class=\"line\">    \t<span class=\"comment\">// 消费者进行消费</span></span><br><span class=\"line\"></span><br><span class=\"line\">\t  V(mutex);</span><br><span class=\"line\">\t  V(empty);</span><br><span class=\"line\"> \t&#125; <span class=\"keyword\">while</span>(<span class=\"number\">1</span>);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n\n<blockquote>\n<p>问题描述：有五位哲学家围绕着餐桌坐，每一位哲学家要么思考，要么吃饭。为了吃饭，哲学家必须拿起两双筷子（分别放于左右两端）不幸的是，筷子的数量和哲学家相等，所以每只筷子必须由两位哲学家共享。</p>\n</blockquote>\n<p>代码实现：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> N 5  <span class=\"comment\">// number of philosopher</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> LEFT (i + N - 1)%N <span class=\"comment\">// number of i&#x27;s left neighbors</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> RIGHT (i + 1)%N <span class=\"comment\">// number of i&#x27;s right neighbors</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> THINKING 0</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> HUNGRY 1</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> EATING 2</span></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"keyword\">int</span> semaphore;</span><br><span class=\"line\"><span class=\"keyword\">int</span> state[N]; <span class=\"comment\">// array to keep track of everyone&#x27;s state</span></span><br><span class=\"line\">semaphore mutex = <span class=\"number\">1</span>; <span class=\"comment\">// mutual exclusion of critical region</span></span><br><span class=\"line\">semaphore s[N]; </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">philosopher</span><span class=\"params\">(<span class=\"keyword\">int</span> i)</span> </span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (TRUE) &#123;</span><br><span class=\"line\">\t\tthink();</span><br><span class=\"line\">\t\ttake_forks(i);</span><br><span class=\"line\">\t\teat();</span><br><span class=\"line\">\t\tput_forks(i);</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">take_forks</span><span class=\"params\">(<span class=\"keyword\">int</span> i)</span> </span>&#123;</span><br><span class=\"line\">\tdown(&amp;mutex); <span class=\"comment\">// enter critical region</span></span><br><span class=\"line\">\tstate[i] = HUNGRY; <span class=\"comment\">// record that i is hungry</span></span><br><span class=\"line\">\ttest_forks(i); <span class=\"comment\">// try to acquire two forks</span></span><br><span class=\"line\">\tup(&amp;mutex); <span class=\"comment\">// exit critical region</span></span><br><span class=\"line\">\tdown(&amp;s[i]); <span class=\"comment\">// block if forks are not acquired</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">put_forks</span><span class=\"params\">(<span class=\"keyword\">int</span> i)</span> </span>&#123;</span><br><span class=\"line\">\tdown(&amp;mutex); <span class=\"comment\">// enter critical region</span></span><br><span class=\"line\">\tstate[i] = THINKING; <span class=\"comment\">// record that has finished eating</span></span><br><span class=\"line\">\ttest_forks(LEFT); <span class=\"comment\">// see if left neighbor can now eat</span></span><br><span class=\"line\">\ttest_forks(RIGHT); <span class=\"comment\">// see if right neighbor can now eat</span></span><br><span class=\"line\">\tup(&amp;mutex); <span class=\"comment\">// exit critical region</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">test_forks</span><span class=\"params\">(<span class=\"keyword\">int</span> i)</span> </span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (state[i] == HUNGRY &amp;&amp; state[LEFT] != EATING &amp;&amp; state[RIGHT] != EATING) &#123;</span><br><span class=\"line\">\t\tstate[i] = EATING;</span><br><span class=\"line\">\t\tup(&amp;s[i]);</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h5 id=\"临界区的概念？\"><a href=\"#临界区的概念？\" class=\"headerlink\" title=\"临界区的概念？\"></a>临界区的概念？</h5><p>各个进程中对临界资源（互斥资源/共享变量，一次只能给一个进程使用）进行操作的程序片段</p>\n<h5 id=\"同步与互斥的概念？\"><a href=\"#同步与互斥的概念？\" class=\"headerlink\" title=\"同步与互斥的概念？\"></a>同步与互斥的概念？</h5><ul>\n<li>同步：多个进程因为合作而使得进程的执行有一定的先后顺序。比如某个进程需要另一个进程提供的消息，获得消息之前进入阻塞态；</li>\n<li>互斥：多个进程在同一时刻只有一个进程能进入临界区</li>\n</ul>\n<h5 id=\"并发、并行、异步的区别？\"><a href=\"#并发、并行、异步的区别？\" class=\"headerlink\" title=\"并发、并行、异步的区别？\"></a>并发、并行、异步的区别？</h5><p>并发：在一个时间段中同时有多个程序在运行，但其实任一时刻，只有一个程序在CPU上运行，宏观上的并发是通过不断的切换实现的；<br>多线程：并发运行的一段代码。是实现异步的手段<br>并行（和串行相比）：在多CPU系统中，多个程序无论宏观还是微观上都是同时执行的<br>异步（和同步相比）：同步是顺序执行，异步是在等待某个资源的时候继续做自己的事</p>\n<h3 id=\"进程有哪几种状态？\"><a href=\"#进程有哪几种状态？\" class=\"headerlink\" title=\"进程有哪几种状态？\"></a>进程有哪几种状态？</h3><p><img src=\"https://cdn.nlark.com/yuque/0/2021/png/1431305/1628085394606-49204b73-729e-4f57-97bc-d43ad01ec54b.png\"></p>\n<ul>\n<li>就绪状态：进程已获得除处理机以外的所需资源，等待分配处理机资源</li>\n<li>运行状态：占用处理机资源运行，处于此状态的进程数小于等于CPU数</li>\n<li>阻塞状态： 进程等待某种条件，在条件满足之前无法执行</li>\n</ul>\n<h3 id=\"进程调度策略有哪些？\"><a href=\"#进程调度策略有哪些？\" class=\"headerlink\" title=\"进程调度策略有哪些？\"></a>进程调度策略有哪些？</h3><ol>\n<li><strong>批处理系统</strong>：<br>按照请求的顺序进行调度。非抢占式，开销小，无饥饿问题，响应时间不确定（可能很慢）；<br>对短进程不利，对IO密集型进程不利。</li>\n</ol>\n<p>按估计运行时间最短的顺序进行调度。非抢占式，吞吐量高，开销可能较大，可能导致饥饿问题；<br>对短进程提供好的响应时间，对长进程不利。</p>\n<p>按剩余运行时间的顺序进行调度。(最短作业优先的抢占式版本)。吞吐量高，开销可能较大，提供好的响应时间；<br>可能导致饥饿问题，对长进程不利。</p>\n<p>响应比 = 1+ 等待时间/处理时间。同时考虑了等待时间的长短和估计需要的执行时间长短，很好的平衡了长短进程。非抢占，吞吐量高，开销可能较大，提供好的响应时间，无饥饿问题。</p>\n<ol start=\"2\">\n<li><strong>交互式系统</strong><br>交互式系统有大量的用户交互操作，在该系统中调度算法的目标是快速地进行响应。</li>\n</ol>\n<p>将所有就绪进程按 FCFS 的原则排成一个队列，用完时间片的进程排到队列最后。抢占式（时间片用完时），开销小，无饥饿问题，为短进程提供好的响应时间；<br>若时间片小，进程切换频繁，吞吐量低；若时间片太长，实时性得不到保证。</p>\n<p>为每个进程分配一个优先级，按优先级进行调度。为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。</p>\n<p>设置多个就绪队列1、2、3…，优先级递减，时间片递增。只有等到优先级更高的队列为空时才会调度当前队列中的进程。如果进程用完了当前队列的时间片还未执行完，则会被移到下一队列。<br>抢占式（时间片用完时），开销可能较大，对IO型进程有利，可能会出现饥饿问题。</p>\n<h5 id=\"什么叫优先级反转？如何解决？\"><a href=\"#什么叫优先级反转？如何解决？\" class=\"headerlink\" title=\"什么叫优先级反转？如何解决？\"></a>什么叫优先级反转？如何解决？</h5><p>高优先级的进程等待被一个低优先级进程占用的资源时，就会出现优先级反转，即优先级较低的进程比优先级较高的进程先执行。此处详细解释优先级反转带来的问题：如果有一个中等优先级的进程将低优先级的进程抢占，那么此时低优先级的进程无法正常进行并在后续释放被占用的资源，导致高优先级的任务一直被挂起，直到中等优先级的进程完成后，低优先级的进程才可以继续并在后续释放占用的资源，最后高优先级的进程才可以执行。导致的问题就是高优先级的进程在中等优先级的进程调度之后。<br>解决方法：</p>\n<ul>\n<li>优先级天花板(priority ceiling)：当任务申请某资源时，把该任务的优先级提升到可访问这个资源的所有任务中的最高优先级，这个优先级称为该资源的优先级天花板。简单易行。</li>\n<li>优先级继承(priority inheritance)：当任务A申请共享资源S时，如果S正在被任务C使用，通过比较任务C与自身的优先级，如发现任务C的优先级小于自身的优先级，则将任务C的优先级提升到自身的优先级，任务C释放资源S后，再恢复任务C的原优先级。</li>\n</ul>\n<h3 id=\"什么是僵尸进程？\"><a href=\"#什么是僵尸进程？\" class=\"headerlink\" title=\"什么是僵尸进程？\"></a>什么是僵尸进程？</h3><p>一个子进程结束后，它的父进程并没有等待它（调用wait或者waitpid），那么这个子进程将成为一个僵尸进程。僵尸进程是一个已经死亡的进程，但是并没有真正被销毁。它已经放弃了几乎所有内存空间，没有任何可执行代码，也不能被调度，仅仅在进程表中保留一个位置，记载该进程的进程ID、终止状态以及资源利用信息(CPU时间，内存使用量等等)供父进程收集，除此之外，僵尸进程不再占有任何内存空间。这个僵尸进程可能会一直留在系统中直到系统重启。</p>\n<p>危害：占用进程号，而系统所能使用的进程号是有限的；占用内存。</p>\n<p>以下情况不会产生僵尸进程：</p>\n<ul>\n<li>该进程的父进程先结束了。每个进程结束的时候，系统都会扫描是否存在子进程，如果有则用Init进程接管，成为该进程的父进程，并且会调用wait等待其结束。</li>\n<li>父进程调用wait或者waitpid等待子进程结束（需要每隔一段时间查询子进程是否结束）。wait系统调用会使父进程暂停执行，直到它的一个子进程结束为止。waitpid则可以加入<code>WNOHANG</code>(wait-no-hang)选项，如果没有发现结束的子进程，就会立即返回，不会将调用waitpid的进程阻塞。同时，waitpid还可以选择是等待任一子进程（同wait），还是等待指定pid的子进程，还是等待同一进程组下的任一子进程，还是等待组ID等于pid的任一子进程；</li>\n<li>子进程结束时，系统会产生<code>SIGCHLD</code>(signal-child)信号，可以注册一个信号处理函数，在该函数中调用waitpid，等待所有结束的子进程（注意：一般都需要循环调用waitpid，因为在信号处理函数开始执行之前，可能已经有多个子进程结束了，而信号处理函数只执行一次，所以要循环调用将所有结束的子进程回收）；</li>\n<li>也可以用<code>signal(SIGCLD, SIG_IGN)</code>(signal-ignore)通知内核，表示忽略<code>SIGCHLD</code>信号，那么子进程结束后，内核会进行回收。</li>\n</ul>\n<h5 id=\"什么是孤儿进程？\"><a href=\"#什么是孤儿进程？\" class=\"headerlink\" title=\"什么是孤儿进程？\"></a>什么是孤儿进程？</h5><p>一个父进程已经结束了，但是它的子进程还在运行，那么这些子进程将成为孤儿进程。孤儿进程会被Init（进程ID为1）接管，当这些孤儿进程结束时由Init完成状态收集工作。</p>\n<h3 id=\"线程同步有哪些方式？\"><a href=\"#线程同步有哪些方式？\" class=\"headerlink\" title=\"线程同步有哪些方式？\"></a>线程同步有哪些方式？</h3><blockquote>\n<p>为什么需要线程同步：线程有时候会和其他线程共享一些资源，比如内存、数据库等。当多个线程同时读写同一份共享资源的时候，可能会发生冲突。因此需要线程的同步，多个线程按顺序访问资源。</p>\n</blockquote>\n<ul>\n<li><strong>互斥量</strong> Mutex：互斥量是内核对象，只有拥有互斥对象的线程才有访问互斥资源的权限。因为互斥对象只有一个，所以可以保证互斥资源不会被多个线程同时访问；当前拥有互斥对象的线程处理完任务后必须将互斥对象交出，以便其他线程访问该资源；</li>\n<li><strong>信号量</strong> Semaphore：信号量是内核对象，它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量。信号量对象保存了<strong>最大资源计数</strong>和<strong>当前可用资源计数</strong>，每增加一个线程对共享资源的访问，当前可用资源计数就减1，只要当前可用资源计数大于0，就可以发出信号量信号，如果为0，则将线程放入一个队列中等待。线程处理完共享资源后，应在离开的同时通过<code>ReleaseSemaphore</code>函数将当前可用资源数加1。如果信号量的取值只能为0或1，那么信号量就成为了互斥量；</li>\n<li><strong>事件</strong> Event：允许一个线程在处理完一个任务后，主动唤醒另外一个线程执行任务。事件分为手动重置事件和自动重置事件。手动重置事件被设置为激发状态后，会唤醒所有等待的线程，而且一直保持为激发状态，直到程序重新把它设置为未激发状态。自动重置事件被设置为激发状态后，会唤醒<strong>一个</strong>等待中的线程，然后自动恢复为未激发状态。</li>\n<li><strong>临界区</strong> Critical Section：任意时刻只允许一个线程对临界资源进行访问。拥有临界区对象的线程可以访问该临界资源，其它试图访问该资源的线程将被挂起，直到临界区对象被释放。</li>\n</ul>\n<h5 id=\"互斥量和临界区有什么区别？\"><a href=\"#互斥量和临界区有什么区别？\" class=\"headerlink\" title=\"互斥量和临界区有什么区别？\"></a>互斥量和临界区有什么区别？</h5><p>互斥量是可以命名的，可以用于不同进程之间的同步；而临界区只能用于同一进程中线程的同步。创建互斥量需要的资源更多，因此临界区的优势是速度快，节省资源。</p>\n<h3 id=\"什么是协程？\"><a href=\"#什么是协程？\" class=\"headerlink\" title=\"什么是协程？\"></a>什么是协程？</h3><p>协程是一种用户态的轻量级线程，协程的调度完全由用户控制。协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈，直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快。</p>\n<h5 id=\"协程多与线程进行比较？\"><a href=\"#协程多与线程进行比较？\" class=\"headerlink\" title=\"协程多与线程进行比较？\"></a>协程多与线程进行比较？</h5><ol>\n<li>一个线程可以拥有多个协程，一个进程也可以单独拥有多个协程，这样python中则能使用多核CPU。</li>\n<li>线程进程都是同步机制，而协程则是异步</li>\n<li>协程能保留上一次调用时的状态，每次过程重入时，就相当于进入上一次调用的状态</li>\n</ol>\n<h3 id=\"进程的异常控制流：陷阱、中断、异常和信号\"><a href=\"#进程的异常控制流：陷阱、中断、异常和信号\" class=\"headerlink\" title=\"进程的异常控制流：陷阱、中断、异常和信号\"></a>进程的异常控制流：陷阱、中断、异常和信号</h3><p>陷阱是<strong>有意</strong>造成的“异常”，是执行一条指令的结果。陷阱是同步的。陷阱的主要作用是实现<strong>系统调用</strong>。比如，进程可以执行 <code>syscall n</code> 指令向内核请求服务。当进程执行这条指令后，会中断当前的控制流，<strong>陷入</strong>到内核态，执行相应的系统调用。内核的处理程序在执行结束后，会将结果返回给进程，同时退回到用户态。进程此时继续执行<strong>下一条指令</strong>。</p>\n<p>中断由处理器<strong>外部</strong>的<strong>硬件</strong>产生，不是执行某条指令的结果，也无法预测发生时机。由于中断独立于当前执行的程序，因此中断是异步事件。中断包括 I/O 设备发出的 I/O 中断、各种定时器引起的时钟中断、调试程序中设置的断点等引起的调试中断等。</p>\n<p>异常是一种错误情况，是执行当前指令的结果，可能被错误处理程序修正，也可能直接终止应用程序。异常是同步的。这里特指因为执行当前指令而产生的<strong>错误情况</strong>，比如除法异常、缺页异常等。有些书上为了区分，也将这类“异常”称为<strong>“故障”</strong>。</p>\n<p>信号是一种<strong>更高层的</strong>软件形式的异常，同样会中断进程的控制流，可以由进程进行处理。一个信号代表了一个消息。信号的作用是用来<strong>通知进程</strong>发生了某种系统事件。</p>\n<p>更详细的可以参考：<a href=\"https://imageslr.github.io/2020/07/09/trap-interrupt-exception.html\">https://imageslr.github.io/2020/07/09/trap-interrupt-exception.html</a></p>\n<h3 id=\"什么是IO多路复用？怎么实现？\"><a href=\"#什么是IO多路复用？怎么实现？\" class=\"headerlink\" title=\"什么是IO多路复用？怎么实现？\"></a>什么是IO多路复用？怎么实现？</h3><p>IO多路复用（IO Multiplexing）是指单个进程/线程就可以同时处理多个IO请求。</p>\n<p>实现原理：用户将想要监视的文件描述符（File Descriptor）添加到select/poll/epoll函数中，由内核监视，函数阻塞。一旦有文件描述符就绪（读就绪或写就绪），或者超时（设置timeout），函数就会返回，然后该进程可以进行相应的读/写操作。</p>\n<ul>\n<li><code>select</code>：将文件描述符放入一个集合中，调用select时，将这个集合从用户空间拷贝到内核空间（缺点1：每次都要复制，<strong>开销大</strong>），由内核根据就绪状态修改该集合的内容。（缺点2）<strong>集合大小有限制</strong>，32位机默认是1024（64位：2048）；采用水平触发机制。select函数返回后，需要通过遍历这个集合，找到就绪的文件描述符（缺点3：<strong>轮询的方式效率较低</strong>），当文件描述符的数量增加时，效率会线性下降；</li>\n<li><code>poll</code>：和select几乎没有区别，区别在于文件描述符的存储方式不同，poll采用链表的方式存储，没有最大存储数量的限制；</li>\n<li><code>epoll</code>：通过内核和用户空间共享内存，避免了不断复制的问题；支持的同时连接数上限很高（1G左右的内存支持10W左右的连接数）；文件描述符就绪时，采用回调机制，避免了轮询（回调函数将就绪的描述符添加到一个链表中，执行epoll_wait时，返回这个链表）；支持水平触发和边缘触发，采用边缘触发机制时，只有活跃的描述符才会触发回调函数。</li>\n</ul>\n<p>总结，区别主要在于：</p>\n<ul>\n<li>一个线程/进程所能打开的最大连接数</li>\n<li>文件描述符传递方式（是否复制）</li>\n<li>水平触发 or 边缘触发</li>\n<li>查询就绪的描述符时的效率（是否轮询）</li>\n</ul>\n<p>当连接数较多并且有很多的不活跃连接时，epoll的效率比其它两者高很多；但是当连接数较少并且都十分活跃的情况下，由于epoll需要很多回调，因此性能可能低于其它两者。</p>\n<p>文件描述符在形式上是一个非负整数。实际上，它是一个索引值，指向内核为每一个进程所维护的该进程打开文件的记录表。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。<br>内核通过文件描述符来访问文件。文件描述符指向一个文件。</p>\n<h5 id=\"什么是水平触发？什么是边缘触发？\"><a href=\"#什么是水平触发？什么是边缘触发？\" class=\"headerlink\" title=\"什么是水平触发？什么是边缘触发？\"></a>什么是水平触发？什么是边缘触发？</h5><ul>\n<li>水平触发（LT，Level Trigger）模式下，只要一个文件描述符就绪，就会触发通知，如果用户程序没有一次性把数据读写完，下次还会通知；</li>\n<li>边缘触发（ET，Edge Trigger）模式下，当描述符从未就绪变为就绪时通知一次，之后不会再通知，直到再次从未就绪变为就绪（缓冲区从不可读/写变为可读/写）。</li>\n<li>区别：边缘触发效率更高，减少了被重复触发的次数，函数不会返回大量用户程序可能不需要的文件描述符。</li>\n<li>为什么边缘触发一定要用非阻塞（non-block）IO：避免由于一个描述符的阻塞读/阻塞写操作让处理其它描述符的任务出现饥饿状态。</li>\n</ul>\n<h5 id=\"有哪些常见的IO模型？\"><a href=\"#有哪些常见的IO模型？\" class=\"headerlink\" title=\"有哪些常见的IO模型？\"></a>有哪些常见的IO模型？</h5><ul>\n<li>同步阻塞IO（Blocking IO）：用户线程发起IO读/写操作之后，线程阻塞，直到可以开始处理数据；对CPU资源的利用率不够；</li>\n<li>同步非阻塞IO（Non-blocking IO）：发起IO请求之后可以立即返回，如果没有就绪的数据，需要不断地发起IO请求直到数据就绪；不断重复请求消耗了大量的CPU资源；</li>\n<li>IO多路复用</li>\n<li>异步IO（Asynchronous IO）：用户线程发出IO请求之后，继续执行，由内核进行数据的读取并放在用户指定的缓冲区内，在IO完成之后通知用户线程直接使用。</li>\n</ul>\n<h3 id=\"什么是用户态和内核态？\"><a href=\"#什么是用户态和内核态？\" class=\"headerlink\" title=\"什么是用户态和内核态？\"></a>什么是用户态和内核态？</h3><p>为了限制不同程序的访问能力，防止一些程序访问其它程序的内存数据，CPU划分了用户态和内核态两个权限等级。</p>\n<ul>\n<li>用户态只能受限地访问内存，且不允许访问外围设备，没有占用CPU的能力，CPU资源可以被其它程序获取；</li>\n<li>内核态可以访问内存所有数据以及外围设备，也可以进行程序的切换。</li>\n</ul>\n<p>所有用户程序都运行在用户态，但有时需要进行一些内核态的操作，比如从硬盘或者键盘读数据，这时就需要进行系统调用，使用<strong>陷阱指令</strong>，CPU切换到内核态，执行相应的服务，再切换为用户态并返回系统调用的结果。</p>\n<h5 id=\"为什么要分用户态和内核态？\"><a href=\"#为什么要分用户态和内核态？\" class=\"headerlink\" title=\"为什么要分用户态和内核态？\"></a>为什么要分用户态和内核态？</h5><ul>\n<li>安全性：防止用户程序恶意或者不小心破坏系统/内存/硬件资源；</li>\n<li>封装性：用户程序不需要实现更加底层的代码；</li>\n<li>利于调度：如果多个用户程序都在等待键盘输入，这时就需要进行调度；统一交给操作系统调度更加方便。</li>\n</ul>\n<h5 id=\"如何从用户态切换到内核态？\"><a href=\"#如何从用户态切换到内核态？\" class=\"headerlink\" title=\"如何从用户态切换到内核态？\"></a>如何从用户态切换到内核态？</h5><ul>\n<li>系统调用：比如读取命令行输入。本质上还是通过中断实现</li>\n<li>用户程序发生异常时：比如缺页异常</li>\n<li>外围设备的中断：外围设备完成用户请求的操作之后，会向CPU发出中断信号，这时CPU会转去处理对应的中断处理程序</li>\n</ul>\n<h1 id=\"死锁\"><a href=\"#死锁\" class=\"headerlink\" title=\"死锁\"></a>死锁</h1><h3 id=\"什么是死锁？\"><a href=\"#什么是死锁？\" class=\"headerlink\" title=\"什么是死锁？\"></a>什么是死锁？</h3><p>在两个或者多个并发进程中，每个进程持有某种资源而又等待其它进程释放它们现在保持着的资源，在未改变这种状态之前都不能向前推进，称这一组进程产生了死锁(deadlock)。</p>\n<h3 id=\"死锁产生的必要条件？\"><a href=\"#死锁产生的必要条件？\" class=\"headerlink\" title=\"死锁产生的必要条件？\"></a>死锁产生的必要条件？</h3><ul>\n<li><strong>互斥</strong>：一个资源一次只能被一个进程使用；</li>\n<li><strong>占有并等待</strong>：一个进程至少占有一个资源，并在等待另一个被其它进程占用的资源；</li>\n<li><strong>非抢占</strong>：已经分配给一个进程的资源不能被强制性抢占，只能由进程完成任务之后自愿释放；</li>\n<li><strong>循环等待</strong>：若干进程之间形成一种头尾相接的环形等待资源关系，该环路中的每个进程都在等待下一个进程所占有的资源。</li>\n</ul>\n<h3 id=\"死锁有哪些处理方法？\"><a href=\"#死锁有哪些处理方法？\" class=\"headerlink\" title=\"死锁有哪些处理方法？\"></a>死锁有哪些处理方法？</h3><p>直接忽略死锁。因为解决死锁问题的代价很高，因此鸵鸟策略这种不采取任务措施的方案会获得更高的性能。当发生死锁时不会对用户造成多大影响，或发生死锁的概率很低，可以采用鸵鸟策略。</p>\n<p>基本思想是破坏形成死锁的四个必要条件：</p>\n<ul>\n<li>破坏互斥条件：允许某些资源同时被多个进程访问。但是有些资源本身并不具有这种属性，因此这种方案实用性有限；</li>\n<li>破坏占有并等待条件：<ul>\n<li>实行资源预先分配策略（当一个进程开始运行之前，必须一次性向系统申请它所需要的全部资源，否则不运行）；</li>\n<li>或者只允许进程在没有占用资源的时候才能申请资源（申请资源前先释放占有的资源）；</li>\n<li>缺点：很多时候无法预知一个进程所需的全部资源；同时，会降低资源利用率，降低系统的并发性；</li>\n</ul>\n</li>\n<li>破坏非抢占条件：允许进程强行抢占被其它进程占有的资源。会降低系统性能；</li>\n<li>破坏循环等待条件：对所有资源统一编号，所有进程对资源的请求必须按照序号递增的顺序提出，即只有占有了编号较小的资源才能申请编号较大的资源。这样避免了占有大号资源的进程去申请小号资源。</li>\n</ul>\n<p>动态地检测资源分配状态，以确保系统处于安全状态，只有处于安全状态时才会进行资源的分配。所谓安全状态是指：即使所有进程突然请求需要的所有资源，也能存在某种对进程的资源分配顺序，使得每一个进程运行完毕。</p>\n<blockquote>\n<p>银行家算法<br>如何检测死锁：检测有向图是否存在环；或者使用类似死锁避免的检测算法。<br>死锁解除的方法：</p>\n</blockquote>\n<ul>\n<li>利用抢占：挂起某些进程，并抢占它的资源。但应防止某些进程被长时间挂起而处于饥饿状态；</li>\n<li>利用回滚：让某些进程回退到足以解除死锁的地步，进程回退时自愿释放资源。要求系统保持进程的历史信息，设置还原点；</li>\n<li>利用杀死进程：强制杀死某些进程直到死锁解除为止，可以按照优先级进行。</li>\n</ul>\n<h1 id=\"内存管理\"><a href=\"#内存管理\" class=\"headerlink\" title=\"内存管理\"></a>内存管理</h1><h3 id=\"分页和分段有什么区别？\"><a href=\"#分页和分段有什么区别？\" class=\"headerlink\" title=\"分页和分段有什么区别？\"></a>分页和分段有什么区别？</h3><ul>\n<li>页式存储：用户空间划分为大小相等的部分称为页（page），内存空间划分为同样大小的区域称为页框，分配时以页为单位，按进程需要的页数分配，逻辑上相邻的页物理上不一定相邻；</li>\n<li>段式存储：用户进程地址空间按照自身逻辑关系划分为若干个段（segment）（如代码段，数据段，堆栈段），内存空间被动态划分为长度不同的区域，分配时以段为单位，每段在内存中占据连续空间，各段可以不相邻；</li>\n<li>段页式存储：用户进程先按段划分，段内再按页划分，内存划分和分配按页。</li>\n</ul>\n<p>区别：</p>\n<ul>\n<li>目的不同：分页的目的是管理内存，用于虚拟内存以获得更大的地址空间；分段的目的是满足用户的需要，使程序和数据可以被划分为逻辑上独立的地址空间；</li>\n<li>大小不同：段的大小不固定，由其所完成的功能决定；页的大小固定，由系统决定；</li>\n<li>地址空间维度不同：分段是二维地址空间（段号+段内偏移），分页是一维地址空间（每个进程一个页表/多级页表，通过一个逻辑地址就能找到对应的物理地址）；</li>\n<li>分段便于信息的保护和共享；分页的共享收到限制；</li>\n<li>碎片：分段没有内碎片，但会产生外碎片；分页没有外碎片，但会产生内碎片（一个页填不满）</li>\n</ul>\n<h3 id=\"什么是虚拟内存？\"><a href=\"#什么是虚拟内存？\" class=\"headerlink\" title=\"什么是虚拟内存？\"></a>什么是虚拟内存？</h3><p>每个程序都拥有自己的地址空间，这个地址空间被分成大小相等的页，这些页被映射到物理内存；但不需要所有的页都在物理内存中，当程序引用到不在物理内存中的页时，由操作系统将缺失的部分装入物理内存。这样，对于程序来说，逻辑上似乎有很大的内存空间，只是实际上有一部分是存储在磁盘上，因此叫做虚拟内存。</p>\n<p>虚拟内存的优点是让程序可以获得更多的可用内存。</p>\n<p>虚拟内存的实现方式、页表/多级页表、缺页中断、不同的页面淘汰算法：<a href=\"https://imageslr.github.io/2020/07/08/tech-interview.html#virtual-memory\">答案</a>。</p>\n<h5 id=\"如何进行地址空间到物理内存的映射？\"><a href=\"#如何进行地址空间到物理内存的映射？\" class=\"headerlink\" title=\"如何进行地址空间到物理内存的映射？\"></a>如何进行地址空间到物理内存的映射？</h5><p><strong>内存管理单元</strong>（MMU）管理着逻辑地址和物理地址的转换，其中的页表（Page table）存储着页（逻辑地址）和页框（物理内存空间）的映射表，页表中还包含包含有效位（是在内存还是磁盘）、访问位（是否被访问过）、修改位（内存中是否被修改过）、保护位（只读还是可读写）。逻辑地址：页号+页内地址（偏移）；每个进程一个页表，放在内存，页表起始地址在PCB/寄存器中。</p>\n<h3 id=\"有哪些页面置换算法？\"><a href=\"#有哪些页面置换算法？\" class=\"headerlink\" title=\"有哪些页面置换算法？\"></a>有哪些页面置换算法？</h3><p>在程序运行过程中，如果要访问的页面不在内存中，就发生缺页中断从而将该页调入内存中。此时如果内存已无空闲空间，系统必须从内存中调出一个页面到磁盘中来腾出空间。页面置换算法的主要目标是使页面置换频率最低（也可以说缺页率最低）。</p>\n<ul>\n<li><p><strong>最佳页面置换算法</strong>OPT（Optimal replacement algorithm）：置换以后不需要或者最远的将来才需要的页面，是一种理论上的算法，是最优策略；</p>\n</li>\n<li><p><strong>先进先出</strong>FIFO：置换在内存中驻留时间最长的页面。缺点：有可能将那些经常被访问的页面也被换出，从而使缺页率升高；</p>\n</li>\n<li><p><strong>第二次机会算法</strong>SCR：按FIFO选择某一页面，若其访问位为1，给第二次机会，并将访问位置0；</p>\n</li>\n<li><p><strong>时钟算法</strong> Clock：SCR中需要将页面在链表中移动（第二次机会的时候要将这个页面从链表头移到链表尾），时钟算法使用环形链表，再使用一个指针指向最老的页面，避免了移动页面的开销；</p>\n</li>\n<li><p><strong>最近未使用算法</strong>NRU（Not Recently Used）：检查访问位R、修改位M，优先置换R=M=0，其次是（R=0, M=1）；</p>\n</li>\n<li><p><strong>最近最少使用算法</strong>LRU（Least Recently Used）：置换出未使用时间最长的一页；实现方式：维护时间戳，或者维护一个所有页面的链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。</p>\n</li>\n<li><p><strong>最不经常使用算法</strong>NFU：置换出访问次数最少的页面</p>\n</li>\n<li><p>时间上：最近被访问的页在不久的将来还会被访问；</p>\n</li>\n<li><p>空间上：内存中被访问的页周围的页也很可能被访问。</p>\n</li>\n</ul>\n<p>颠簸本质上是指频繁的页调度行为。进程发生缺页中断时必须置换某一页。然而，其他所有的页都在使用，它置换一个页，但又立刻再次需要这个页。因此会不断产生缺页中断，导致整个系统的效率急剧下降，这种现象称为颠簸。内存颠簸的解决策略包括：</p>\n<ul>\n<li>修改页面置换算法；</li>\n<li>降低同时运行的程序的数量；</li>\n<li>终止该进程或增加物理内存容量。</li>\n</ul>\n<h3 id=\"缓冲区溢出问题\"><a href=\"#缓冲区溢出问题\" class=\"headerlink\" title=\"缓冲区溢出问题\"></a>缓冲区溢出问题</h3><p>防范缓冲区溢出攻击的机制有三种：随机化、栈保护和限制可执行代码区域。</p>\n<ul>\n<li>随机化：包括栈随机化（程序开始时在栈上分配一段随机大小的空间）和地址空间布局随机化（Address-Space Layout Randomization，ASLR，即每次运行时程序的不同部分，包括代码段、数据段、栈、堆等都会被加载到内存空间的不同区域），但只能增加攻击一个系统的难度，不能完全保证安全。</li>\n<li>栈保护：在每个函数的栈帧的局部变量和栈状态之间存储一个<strong>随机产生的</strong>特殊的值，称为金丝雀值（canary）。在恢复寄存器状态和函数返回之前，程序检测这个金丝雀值是否被改变了，如果是，那么程序异常终止。</li>\n<li>限制可执行代码区域：内存页的访问形式有三种：可读、可写、可执行，只有编译器产生的那部分代码所处的内存才是可执行的，其他页限制为只允许读和写。</li>\n</ul>\n<p>更详细的可以参考：<a href=\"https://imageslr.github.io/2020/07/08/tech-interview.html#stackoverflow\">https://imageslr.github.io/2020/07/08/tech-interview.html#stackoverflow</a></p>\n<h1 id=\"磁盘调度\"><a href=\"#磁盘调度\" class=\"headerlink\" title=\"磁盘调度\"></a>磁盘调度</h1><p>过程：磁头（找到对应的盘面）；磁道（一个盘面上的同心圆环，寻道时间）；扇区（旋转时间）。为减小寻道时间的调度算法：</p>\n<ul>\n<li>先来先服务</li>\n<li>最短寻道时间优先</li>\n<li>电梯算法：电梯总是保持一个方向运行，直到该方向没有请求为止，然后改变运行方向。</li>\n</ul>\n<h1 id=\"进程间通信IPC\"><a href=\"#进程间通信IPC\" class=\"headerlink\" title=\"进程间通信IPC\"></a><a href=\"https://www.jianshu.com/p/c1015f5ffa74\">进程间通信IPC</a></h1><h1 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h1><ul>\n<li><a href=\"https://blog.csdn.net/justloveyou_/article/details/78304294\">面试/笔试第二弹 —— 操作系统面试问题集锦 - CSDN博客</a></li>\n<li><a href=\"https://segmentfault.com/a/1190000018970361\">线程同步与并发 - - SegmentFault</a></li>\n<li><a href=\"http://baijiahao.baidu.com/s?id=1641172494287388070&wfr=spider&for=pc\">彻底搞懂epoll高效运行的原理</a></li>\n<li><a href=\"https://www.cnblogs.com/lirong21/p/4213028.html\">用户态与内核态的切换</a></li>\n</ul>\n<p>文章内容搬运自本人<a href=\"https://www.yuque.com/docs/share/4137d8f0-4b2e-4a18-a5a3-7a01239affcc\">语雀</a></p>\n","site":{"data":{}},"length":12206,"excerpt":"","more":"<meta name=\"referrer\" content=\"no-referrer\" />\n\n<h1 id=\"进程和线程\"><a href=\"#进程和线程\" class=\"headerlink\" title=\"进程和线程\"></a>进程和线程</h1><h3 id=\"进程和线程有什么区别？\"><a href=\"#进程和线程有什么区别？\" class=\"headerlink\" title=\"进程和线程有什么区别？\"></a>进程和线程有什么区别？</h3><ul>\n<li>进程（Process）是系统进行资源分配和调度的基本单位，线程（Thread）是CPU调度和分派的基本单位；</li>\n<li>线程依赖于进程而存在，一个进程至少有一个线程；</li>\n<li>进程有自己的独立地址空间，线程共享所属进程的地址空间；</li>\n<li>进程是拥有系统资源的一个独立单位，而线程自己基本上不拥有系统资源，只拥有一点在运行中必不可少的资源(如程序计数器,一组寄存器和栈)，和其他线程共享本进程的相关资源如内存、I/O、cpu等；</li>\n<li>在进程切换时，涉及到整个当前进程CPU环境的保存环境的设置以及新被调度运行的CPU环境的设置，而线程切换只需保存和设置少量的寄存器的内容，并不涉及存储器管理方面的操作，可见，进程切换的开销远大于线程切换的开销；</li>\n<li>线程之间的通信更方便，同一进程下的线程共享全局变量等数据，而进程之间的通信需要以进程间通信(IPC)的方式进行；</li>\n<li>多线程程序只要有一个线程崩溃，整个程序就崩溃了，但多进程程序中一个进程崩溃并不会对其它进程造成影响，因为进程有自己的独立地址空间，因此多进程更加健壮</li>\n</ul>\n<p>进程操作代码实现，可以参考：<a href=\"https://www.liaoxuefeng.com/wiki/1016959663602400/1017628290184064\">多进程 - 廖雪峰的官方网站</a></p>\n<h5 id=\"同一进程中的线程可以共享哪些数据？\"><a href=\"#同一进程中的线程可以共享哪些数据？\" class=\"headerlink\" title=\"同一进程中的线程可以共享哪些数据？\"></a>同一进程中的线程可以共享哪些数据？</h5><ul>\n<li>进程代码段</li>\n<li>进程的公有数据（全局变量、静态变量…）</li>\n<li>进程打开的文件描述符</li>\n<li>进程的当前目录</li>\n<li>信号处理器/信号处理函数：对收到的信号的处理方式</li>\n<li>进程ID与进程组ID</li>\n</ul>\n<h5 id=\"线程独占哪些资源？\"><a href=\"#线程独占哪些资源？\" class=\"headerlink\" title=\"线程独占哪些资源？\"></a>线程独占哪些资源？</h5><ul>\n<li>线程ID</li>\n<li>一组寄存器的值</li>\n<li>线程自身的栈（堆是共享的）</li>\n<li>错误返回码：线程可能会产生不同的错误返回码，一个线程的错误返回码不应该被其它线程修改；</li>\n<li>信号掩码/信号屏蔽字(Signal mask)：表示是否屏蔽/阻塞相应的信号（SIGKILL,SIGSTOP除外）</li>\n</ul>\n<h3 id=\"进程间通信有哪些方式？\"><a href=\"#进程间通信有哪些方式？\" class=\"headerlink\" title=\"进程间通信有哪些方式？\"></a>进程间通信有哪些方式？</h3><ol>\n<li>管道(Pipe)</li>\n</ol>\n<ul>\n<li>管道是半双工的，数据只能向一个方向流动；需要双方通信时，需要建立起两个管道；</li>\n<li>一个进程向管道中写的内容被管道另一端的进程读出。写入的内容每次都添加在管道缓冲区的末尾，并且每次都是从缓冲区的头部读出数据；</li>\n<li>只能用于父子进程或者兄弟进程之间(具有亲缘关系的进程)</li>\n</ul>\n<ol start=\"2\">\n<li>命名管道</li>\n<li>消息队列</li>\n<li>信号(Signal)</li>\n<li>共享内存</li>\n<li>信号量(Semaphore)：初始化操作、P操作、V操作；P操作：信号量-1，检测是否小于0，小于则进程进入阻塞状态；V操作：信号量+1，若小于等于0，则从队列中唤醒一个等待的进程进入就绪态</li>\n<li>套接字(Socket)</li>\n</ol>\n<p>更详细的可以参考：</p>\n<ul>\n<li><a href=\"https://imageslr.github.io/2020/02/26/ipc.html\">https://imageslr.github.io/2020/02/26/ipc.html</a></li>\n<li><a href=\"https://www.jianshu.com/p/c1015f5ffa74\">https://www.jianshu.com/p/c1015f5ffa74</a></li>\n</ul>\n<h3 id=\"进程同步问题\"><a href=\"#进程同步问题\" class=\"headerlink\" title=\"进程同步问题\"></a>进程同步问题</h3><blockquote>\n<p>进程的同步是目的，而进程间通信是实现进程同步的手段</p>\n</blockquote>\n<p>管程将共享变量以及对这些共享变量的操作封装起来，形成一个具有一定接口的功能模块，这样只能通过管程提供的某个过程才能访问管程中的资源。进程只能互斥地使用管程，使用完之后必须释放管程并唤醒入口等待队列中的进程。<br>当一个进程试图进入管程时，在<strong>入口等待队列</strong>等待。若P进程唤醒了Q进程，则Q进程先执行，P在<strong>紧急等待队列</strong>中等待。（<strong>HOARE管程</strong>）<br>wait操作：执行wait操作的进程进入条件变量链末尾，唤醒紧急等待队列或者入口队列中的进程；signal操作：唤醒条件变量链中的进程，自己进入紧急等待队列，若条件变量链为空，则继续执行。（<strong>HOARE管程</strong>）<br><strong>MESA管程</strong>：将HOARE中的signal换成了notify（或者broadcast通知所有满足条件的），进行通知而不是立马交换管程的使用权，在合适的时候，条件队列首位的进程可以进入，进入之前必须用while检查条件是否合适。优点：没有额外的进程切换</p>\n<blockquote>\n<p>问题描述：使用一个缓冲区来存放数据，只有缓冲区没有满，生产者才可以写入数据；只有缓冲区不为空，消费者才可以读出数据</p>\n</blockquote>\n<p>代码实现：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 伪代码描述 </span></span><br><span class=\"line\"><span class=\"comment\">// 定义信号量 full记录缓冲区物品数量 empty代表缓冲区空位数量 mutex为互斥量</span></span><br><span class=\"line\">semaphore full = <span class=\"number\">0</span>, empty = n, mutex = <span class=\"number\">1</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 生产者进程</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">producer</span><span class=\"params\">()</span></span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">do</span>&#123;</span><br><span class=\"line\">   \t  P(empty);</span><br><span class=\"line\">\t  P(mutex);</span><br><span class=\"line\"></span><br><span class=\"line\">     <span class=\"comment\">// 生产者进行生产</span></span><br><span class=\"line\">   \t</span><br><span class=\"line\">   \t  V(mutex);</span><br><span class=\"line\">   \t  V(full);</span><br><span class=\"line\"> \t&#125; <span class=\"keyword\">while</span>(<span class=\"number\">1</span>);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">consumer</span><span class=\"params\">()</span></span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">do</span>&#123;</span><br><span class=\"line\">\t  P(full);</span><br><span class=\"line\">\t  P(mutex);</span><br><span class=\"line\"></span><br><span class=\"line\">    \t<span class=\"comment\">// 消费者进行消费</span></span><br><span class=\"line\"></span><br><span class=\"line\">\t  V(mutex);</span><br><span class=\"line\">\t  V(empty);</span><br><span class=\"line\"> \t&#125; <span class=\"keyword\">while</span>(<span class=\"number\">1</span>);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n\n<blockquote>\n<p>问题描述：有五位哲学家围绕着餐桌坐，每一位哲学家要么思考，要么吃饭。为了吃饭，哲学家必须拿起两双筷子（分别放于左右两端）不幸的是，筷子的数量和哲学家相等，所以每只筷子必须由两位哲学家共享。</p>\n</blockquote>\n<p>代码实现：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> N 5  <span class=\"comment\">// number of philosopher</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> LEFT (i + N - 1)%N <span class=\"comment\">// number of i&#x27;s left neighbors</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> RIGHT (i + 1)%N <span class=\"comment\">// number of i&#x27;s right neighbors</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> THINKING 0</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> HUNGRY 1</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> EATING 2</span></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"keyword\">int</span> semaphore;</span><br><span class=\"line\"><span class=\"keyword\">int</span> state[N]; <span class=\"comment\">// array to keep track of everyone&#x27;s state</span></span><br><span class=\"line\">semaphore mutex = <span class=\"number\">1</span>; <span class=\"comment\">// mutual exclusion of critical region</span></span><br><span class=\"line\">semaphore s[N]; </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">philosopher</span><span class=\"params\">(<span class=\"keyword\">int</span> i)</span> </span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (TRUE) &#123;</span><br><span class=\"line\">\t\tthink();</span><br><span class=\"line\">\t\ttake_forks(i);</span><br><span class=\"line\">\t\teat();</span><br><span class=\"line\">\t\tput_forks(i);</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">take_forks</span><span class=\"params\">(<span class=\"keyword\">int</span> i)</span> </span>&#123;</span><br><span class=\"line\">\tdown(&amp;mutex); <span class=\"comment\">// enter critical region</span></span><br><span class=\"line\">\tstate[i] = HUNGRY; <span class=\"comment\">// record that i is hungry</span></span><br><span class=\"line\">\ttest_forks(i); <span class=\"comment\">// try to acquire two forks</span></span><br><span class=\"line\">\tup(&amp;mutex); <span class=\"comment\">// exit critical region</span></span><br><span class=\"line\">\tdown(&amp;s[i]); <span class=\"comment\">// block if forks are not acquired</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">put_forks</span><span class=\"params\">(<span class=\"keyword\">int</span> i)</span> </span>&#123;</span><br><span class=\"line\">\tdown(&amp;mutex); <span class=\"comment\">// enter critical region</span></span><br><span class=\"line\">\tstate[i] = THINKING; <span class=\"comment\">// record that has finished eating</span></span><br><span class=\"line\">\ttest_forks(LEFT); <span class=\"comment\">// see if left neighbor can now eat</span></span><br><span class=\"line\">\ttest_forks(RIGHT); <span class=\"comment\">// see if right neighbor can now eat</span></span><br><span class=\"line\">\tup(&amp;mutex); <span class=\"comment\">// exit critical region</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">test_forks</span><span class=\"params\">(<span class=\"keyword\">int</span> i)</span> </span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (state[i] == HUNGRY &amp;&amp; state[LEFT] != EATING &amp;&amp; state[RIGHT] != EATING) &#123;</span><br><span class=\"line\">\t\tstate[i] = EATING;</span><br><span class=\"line\">\t\tup(&amp;s[i]);</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h5 id=\"临界区的概念？\"><a href=\"#临界区的概念？\" class=\"headerlink\" title=\"临界区的概念？\"></a>临界区的概念？</h5><p>各个进程中对临界资源（互斥资源/共享变量，一次只能给一个进程使用）进行操作的程序片段</p>\n<h5 id=\"同步与互斥的概念？\"><a href=\"#同步与互斥的概念？\" class=\"headerlink\" title=\"同步与互斥的概念？\"></a>同步与互斥的概念？</h5><ul>\n<li>同步：多个进程因为合作而使得进程的执行有一定的先后顺序。比如某个进程需要另一个进程提供的消息，获得消息之前进入阻塞态；</li>\n<li>互斥：多个进程在同一时刻只有一个进程能进入临界区</li>\n</ul>\n<h5 id=\"并发、并行、异步的区别？\"><a href=\"#并发、并行、异步的区别？\" class=\"headerlink\" title=\"并发、并行、异步的区别？\"></a>并发、并行、异步的区别？</h5><p>并发：在一个时间段中同时有多个程序在运行，但其实任一时刻，只有一个程序在CPU上运行，宏观上的并发是通过不断的切换实现的；<br>多线程：并发运行的一段代码。是实现异步的手段<br>并行（和串行相比）：在多CPU系统中，多个程序无论宏观还是微观上都是同时执行的<br>异步（和同步相比）：同步是顺序执行，异步是在等待某个资源的时候继续做自己的事</p>\n<h3 id=\"进程有哪几种状态？\"><a href=\"#进程有哪几种状态？\" class=\"headerlink\" title=\"进程有哪几种状态？\"></a>进程有哪几种状态？</h3><p><img src=\"https://cdn.nlark.com/yuque/0/2021/png/1431305/1628085394606-49204b73-729e-4f57-97bc-d43ad01ec54b.png\"></p>\n<ul>\n<li>就绪状态：进程已获得除处理机以外的所需资源，等待分配处理机资源</li>\n<li>运行状态：占用处理机资源运行，处于此状态的进程数小于等于CPU数</li>\n<li>阻塞状态： 进程等待某种条件，在条件满足之前无法执行</li>\n</ul>\n<h3 id=\"进程调度策略有哪些？\"><a href=\"#进程调度策略有哪些？\" class=\"headerlink\" title=\"进程调度策略有哪些？\"></a>进程调度策略有哪些？</h3><ol>\n<li><strong>批处理系统</strong>：<br>按照请求的顺序进行调度。非抢占式，开销小，无饥饿问题，响应时间不确定（可能很慢）；<br>对短进程不利，对IO密集型进程不利。</li>\n</ol>\n<p>按估计运行时间最短的顺序进行调度。非抢占式，吞吐量高，开销可能较大，可能导致饥饿问题；<br>对短进程提供好的响应时间，对长进程不利。</p>\n<p>按剩余运行时间的顺序进行调度。(最短作业优先的抢占式版本)。吞吐量高，开销可能较大，提供好的响应时间；<br>可能导致饥饿问题，对长进程不利。</p>\n<p>响应比 = 1+ 等待时间/处理时间。同时考虑了等待时间的长短和估计需要的执行时间长短，很好的平衡了长短进程。非抢占，吞吐量高，开销可能较大，提供好的响应时间，无饥饿问题。</p>\n<ol start=\"2\">\n<li><strong>交互式系统</strong><br>交互式系统有大量的用户交互操作，在该系统中调度算法的目标是快速地进行响应。</li>\n</ol>\n<p>将所有就绪进程按 FCFS 的原则排成一个队列，用完时间片的进程排到队列最后。抢占式（时间片用完时），开销小，无饥饿问题，为短进程提供好的响应时间；<br>若时间片小，进程切换频繁，吞吐量低；若时间片太长，实时性得不到保证。</p>\n<p>为每个进程分配一个优先级，按优先级进行调度。为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。</p>\n<p>设置多个就绪队列1、2、3…，优先级递减，时间片递增。只有等到优先级更高的队列为空时才会调度当前队列中的进程。如果进程用完了当前队列的时间片还未执行完，则会被移到下一队列。<br>抢占式（时间片用完时），开销可能较大，对IO型进程有利，可能会出现饥饿问题。</p>\n<h5 id=\"什么叫优先级反转？如何解决？\"><a href=\"#什么叫优先级反转？如何解决？\" class=\"headerlink\" title=\"什么叫优先级反转？如何解决？\"></a>什么叫优先级反转？如何解决？</h5><p>高优先级的进程等待被一个低优先级进程占用的资源时，就会出现优先级反转，即优先级较低的进程比优先级较高的进程先执行。此处详细解释优先级反转带来的问题：如果有一个中等优先级的进程将低优先级的进程抢占，那么此时低优先级的进程无法正常进行并在后续释放被占用的资源，导致高优先级的任务一直被挂起，直到中等优先级的进程完成后，低优先级的进程才可以继续并在后续释放占用的资源，最后高优先级的进程才可以执行。导致的问题就是高优先级的进程在中等优先级的进程调度之后。<br>解决方法：</p>\n<ul>\n<li>优先级天花板(priority ceiling)：当任务申请某资源时，把该任务的优先级提升到可访问这个资源的所有任务中的最高优先级，这个优先级称为该资源的优先级天花板。简单易行。</li>\n<li>优先级继承(priority inheritance)：当任务A申请共享资源S时，如果S正在被任务C使用，通过比较任务C与自身的优先级，如发现任务C的优先级小于自身的优先级，则将任务C的优先级提升到自身的优先级，任务C释放资源S后，再恢复任务C的原优先级。</li>\n</ul>\n<h3 id=\"什么是僵尸进程？\"><a href=\"#什么是僵尸进程？\" class=\"headerlink\" title=\"什么是僵尸进程？\"></a>什么是僵尸进程？</h3><p>一个子进程结束后，它的父进程并没有等待它（调用wait或者waitpid），那么这个子进程将成为一个僵尸进程。僵尸进程是一个已经死亡的进程，但是并没有真正被销毁。它已经放弃了几乎所有内存空间，没有任何可执行代码，也不能被调度，仅仅在进程表中保留一个位置，记载该进程的进程ID、终止状态以及资源利用信息(CPU时间，内存使用量等等)供父进程收集，除此之外，僵尸进程不再占有任何内存空间。这个僵尸进程可能会一直留在系统中直到系统重启。</p>\n<p>危害：占用进程号，而系统所能使用的进程号是有限的；占用内存。</p>\n<p>以下情况不会产生僵尸进程：</p>\n<ul>\n<li>该进程的父进程先结束了。每个进程结束的时候，系统都会扫描是否存在子进程，如果有则用Init进程接管，成为该进程的父进程，并且会调用wait等待其结束。</li>\n<li>父进程调用wait或者waitpid等待子进程结束（需要每隔一段时间查询子进程是否结束）。wait系统调用会使父进程暂停执行，直到它的一个子进程结束为止。waitpid则可以加入<code>WNOHANG</code>(wait-no-hang)选项，如果没有发现结束的子进程，就会立即返回，不会将调用waitpid的进程阻塞。同时，waitpid还可以选择是等待任一子进程（同wait），还是等待指定pid的子进程，还是等待同一进程组下的任一子进程，还是等待组ID等于pid的任一子进程；</li>\n<li>子进程结束时，系统会产生<code>SIGCHLD</code>(signal-child)信号，可以注册一个信号处理函数，在该函数中调用waitpid，等待所有结束的子进程（注意：一般都需要循环调用waitpid，因为在信号处理函数开始执行之前，可能已经有多个子进程结束了，而信号处理函数只执行一次，所以要循环调用将所有结束的子进程回收）；</li>\n<li>也可以用<code>signal(SIGCLD, SIG_IGN)</code>(signal-ignore)通知内核，表示忽略<code>SIGCHLD</code>信号，那么子进程结束后，内核会进行回收。</li>\n</ul>\n<h5 id=\"什么是孤儿进程？\"><a href=\"#什么是孤儿进程？\" class=\"headerlink\" title=\"什么是孤儿进程？\"></a>什么是孤儿进程？</h5><p>一个父进程已经结束了，但是它的子进程还在运行，那么这些子进程将成为孤儿进程。孤儿进程会被Init（进程ID为1）接管，当这些孤儿进程结束时由Init完成状态收集工作。</p>\n<h3 id=\"线程同步有哪些方式？\"><a href=\"#线程同步有哪些方式？\" class=\"headerlink\" title=\"线程同步有哪些方式？\"></a>线程同步有哪些方式？</h3><blockquote>\n<p>为什么需要线程同步：线程有时候会和其他线程共享一些资源，比如内存、数据库等。当多个线程同时读写同一份共享资源的时候，可能会发生冲突。因此需要线程的同步，多个线程按顺序访问资源。</p>\n</blockquote>\n<ul>\n<li><strong>互斥量</strong> Mutex：互斥量是内核对象，只有拥有互斥对象的线程才有访问互斥资源的权限。因为互斥对象只有一个，所以可以保证互斥资源不会被多个线程同时访问；当前拥有互斥对象的线程处理完任务后必须将互斥对象交出，以便其他线程访问该资源；</li>\n<li><strong>信号量</strong> Semaphore：信号量是内核对象，它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量。信号量对象保存了<strong>最大资源计数</strong>和<strong>当前可用资源计数</strong>，每增加一个线程对共享资源的访问，当前可用资源计数就减1，只要当前可用资源计数大于0，就可以发出信号量信号，如果为0，则将线程放入一个队列中等待。线程处理完共享资源后，应在离开的同时通过<code>ReleaseSemaphore</code>函数将当前可用资源数加1。如果信号量的取值只能为0或1，那么信号量就成为了互斥量；</li>\n<li><strong>事件</strong> Event：允许一个线程在处理完一个任务后，主动唤醒另外一个线程执行任务。事件分为手动重置事件和自动重置事件。手动重置事件被设置为激发状态后，会唤醒所有等待的线程，而且一直保持为激发状态，直到程序重新把它设置为未激发状态。自动重置事件被设置为激发状态后，会唤醒<strong>一个</strong>等待中的线程，然后自动恢复为未激发状态。</li>\n<li><strong>临界区</strong> Critical Section：任意时刻只允许一个线程对临界资源进行访问。拥有临界区对象的线程可以访问该临界资源，其它试图访问该资源的线程将被挂起，直到临界区对象被释放。</li>\n</ul>\n<h5 id=\"互斥量和临界区有什么区别？\"><a href=\"#互斥量和临界区有什么区别？\" class=\"headerlink\" title=\"互斥量和临界区有什么区别？\"></a>互斥量和临界区有什么区别？</h5><p>互斥量是可以命名的，可以用于不同进程之间的同步；而临界区只能用于同一进程中线程的同步。创建互斥量需要的资源更多，因此临界区的优势是速度快，节省资源。</p>\n<h3 id=\"什么是协程？\"><a href=\"#什么是协程？\" class=\"headerlink\" title=\"什么是协程？\"></a>什么是协程？</h3><p>协程是一种用户态的轻量级线程，协程的调度完全由用户控制。协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈，直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快。</p>\n<h5 id=\"协程多与线程进行比较？\"><a href=\"#协程多与线程进行比较？\" class=\"headerlink\" title=\"协程多与线程进行比较？\"></a>协程多与线程进行比较？</h5><ol>\n<li>一个线程可以拥有多个协程，一个进程也可以单独拥有多个协程，这样python中则能使用多核CPU。</li>\n<li>线程进程都是同步机制，而协程则是异步</li>\n<li>协程能保留上一次调用时的状态，每次过程重入时，就相当于进入上一次调用的状态</li>\n</ol>\n<h3 id=\"进程的异常控制流：陷阱、中断、异常和信号\"><a href=\"#进程的异常控制流：陷阱、中断、异常和信号\" class=\"headerlink\" title=\"进程的异常控制流：陷阱、中断、异常和信号\"></a>进程的异常控制流：陷阱、中断、异常和信号</h3><p>陷阱是<strong>有意</strong>造成的“异常”，是执行一条指令的结果。陷阱是同步的。陷阱的主要作用是实现<strong>系统调用</strong>。比如，进程可以执行 <code>syscall n</code> 指令向内核请求服务。当进程执行这条指令后，会中断当前的控制流，<strong>陷入</strong>到内核态，执行相应的系统调用。内核的处理程序在执行结束后，会将结果返回给进程，同时退回到用户态。进程此时继续执行<strong>下一条指令</strong>。</p>\n<p>中断由处理器<strong>外部</strong>的<strong>硬件</strong>产生，不是执行某条指令的结果，也无法预测发生时机。由于中断独立于当前执行的程序，因此中断是异步事件。中断包括 I/O 设备发出的 I/O 中断、各种定时器引起的时钟中断、调试程序中设置的断点等引起的调试中断等。</p>\n<p>异常是一种错误情况，是执行当前指令的结果，可能被错误处理程序修正，也可能直接终止应用程序。异常是同步的。这里特指因为执行当前指令而产生的<strong>错误情况</strong>，比如除法异常、缺页异常等。有些书上为了区分，也将这类“异常”称为<strong>“故障”</strong>。</p>\n<p>信号是一种<strong>更高层的</strong>软件形式的异常，同样会中断进程的控制流，可以由进程进行处理。一个信号代表了一个消息。信号的作用是用来<strong>通知进程</strong>发生了某种系统事件。</p>\n<p>更详细的可以参考：<a href=\"https://imageslr.github.io/2020/07/09/trap-interrupt-exception.html\">https://imageslr.github.io/2020/07/09/trap-interrupt-exception.html</a></p>\n<h3 id=\"什么是IO多路复用？怎么实现？\"><a href=\"#什么是IO多路复用？怎么实现？\" class=\"headerlink\" title=\"什么是IO多路复用？怎么实现？\"></a>什么是IO多路复用？怎么实现？</h3><p>IO多路复用（IO Multiplexing）是指单个进程/线程就可以同时处理多个IO请求。</p>\n<p>实现原理：用户将想要监视的文件描述符（File Descriptor）添加到select/poll/epoll函数中，由内核监视，函数阻塞。一旦有文件描述符就绪（读就绪或写就绪），或者超时（设置timeout），函数就会返回，然后该进程可以进行相应的读/写操作。</p>\n<ul>\n<li><code>select</code>：将文件描述符放入一个集合中，调用select时，将这个集合从用户空间拷贝到内核空间（缺点1：每次都要复制，<strong>开销大</strong>），由内核根据就绪状态修改该集合的内容。（缺点2）<strong>集合大小有限制</strong>，32位机默认是1024（64位：2048）；采用水平触发机制。select函数返回后，需要通过遍历这个集合，找到就绪的文件描述符（缺点3：<strong>轮询的方式效率较低</strong>），当文件描述符的数量增加时，效率会线性下降；</li>\n<li><code>poll</code>：和select几乎没有区别，区别在于文件描述符的存储方式不同，poll采用链表的方式存储，没有最大存储数量的限制；</li>\n<li><code>epoll</code>：通过内核和用户空间共享内存，避免了不断复制的问题；支持的同时连接数上限很高（1G左右的内存支持10W左右的连接数）；文件描述符就绪时，采用回调机制，避免了轮询（回调函数将就绪的描述符添加到一个链表中，执行epoll_wait时，返回这个链表）；支持水平触发和边缘触发，采用边缘触发机制时，只有活跃的描述符才会触发回调函数。</li>\n</ul>\n<p>总结，区别主要在于：</p>\n<ul>\n<li>一个线程/进程所能打开的最大连接数</li>\n<li>文件描述符传递方式（是否复制）</li>\n<li>水平触发 or 边缘触发</li>\n<li>查询就绪的描述符时的效率（是否轮询）</li>\n</ul>\n<p>当连接数较多并且有很多的不活跃连接时，epoll的效率比其它两者高很多；但是当连接数较少并且都十分活跃的情况下，由于epoll需要很多回调，因此性能可能低于其它两者。</p>\n<p>文件描述符在形式上是一个非负整数。实际上，它是一个索引值，指向内核为每一个进程所维护的该进程打开文件的记录表。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。<br>内核通过文件描述符来访问文件。文件描述符指向一个文件。</p>\n<h5 id=\"什么是水平触发？什么是边缘触发？\"><a href=\"#什么是水平触发？什么是边缘触发？\" class=\"headerlink\" title=\"什么是水平触发？什么是边缘触发？\"></a>什么是水平触发？什么是边缘触发？</h5><ul>\n<li>水平触发（LT，Level Trigger）模式下，只要一个文件描述符就绪，就会触发通知，如果用户程序没有一次性把数据读写完，下次还会通知；</li>\n<li>边缘触发（ET，Edge Trigger）模式下，当描述符从未就绪变为就绪时通知一次，之后不会再通知，直到再次从未就绪变为就绪（缓冲区从不可读/写变为可读/写）。</li>\n<li>区别：边缘触发效率更高，减少了被重复触发的次数，函数不会返回大量用户程序可能不需要的文件描述符。</li>\n<li>为什么边缘触发一定要用非阻塞（non-block）IO：避免由于一个描述符的阻塞读/阻塞写操作让处理其它描述符的任务出现饥饿状态。</li>\n</ul>\n<h5 id=\"有哪些常见的IO模型？\"><a href=\"#有哪些常见的IO模型？\" class=\"headerlink\" title=\"有哪些常见的IO模型？\"></a>有哪些常见的IO模型？</h5><ul>\n<li>同步阻塞IO（Blocking IO）：用户线程发起IO读/写操作之后，线程阻塞，直到可以开始处理数据；对CPU资源的利用率不够；</li>\n<li>同步非阻塞IO（Non-blocking IO）：发起IO请求之后可以立即返回，如果没有就绪的数据，需要不断地发起IO请求直到数据就绪；不断重复请求消耗了大量的CPU资源；</li>\n<li>IO多路复用</li>\n<li>异步IO（Asynchronous IO）：用户线程发出IO请求之后，继续执行，由内核进行数据的读取并放在用户指定的缓冲区内，在IO完成之后通知用户线程直接使用。</li>\n</ul>\n<h3 id=\"什么是用户态和内核态？\"><a href=\"#什么是用户态和内核态？\" class=\"headerlink\" title=\"什么是用户态和内核态？\"></a>什么是用户态和内核态？</h3><p>为了限制不同程序的访问能力，防止一些程序访问其它程序的内存数据，CPU划分了用户态和内核态两个权限等级。</p>\n<ul>\n<li>用户态只能受限地访问内存，且不允许访问外围设备，没有占用CPU的能力，CPU资源可以被其它程序获取；</li>\n<li>内核态可以访问内存所有数据以及外围设备，也可以进行程序的切换。</li>\n</ul>\n<p>所有用户程序都运行在用户态，但有时需要进行一些内核态的操作，比如从硬盘或者键盘读数据，这时就需要进行系统调用，使用<strong>陷阱指令</strong>，CPU切换到内核态，执行相应的服务，再切换为用户态并返回系统调用的结果。</p>\n<h5 id=\"为什么要分用户态和内核态？\"><a href=\"#为什么要分用户态和内核态？\" class=\"headerlink\" title=\"为什么要分用户态和内核态？\"></a>为什么要分用户态和内核态？</h5><ul>\n<li>安全性：防止用户程序恶意或者不小心破坏系统/内存/硬件资源；</li>\n<li>封装性：用户程序不需要实现更加底层的代码；</li>\n<li>利于调度：如果多个用户程序都在等待键盘输入，这时就需要进行调度；统一交给操作系统调度更加方便。</li>\n</ul>\n<h5 id=\"如何从用户态切换到内核态？\"><a href=\"#如何从用户态切换到内核态？\" class=\"headerlink\" title=\"如何从用户态切换到内核态？\"></a>如何从用户态切换到内核态？</h5><ul>\n<li>系统调用：比如读取命令行输入。本质上还是通过中断实现</li>\n<li>用户程序发生异常时：比如缺页异常</li>\n<li>外围设备的中断：外围设备完成用户请求的操作之后，会向CPU发出中断信号，这时CPU会转去处理对应的中断处理程序</li>\n</ul>\n<h1 id=\"死锁\"><a href=\"#死锁\" class=\"headerlink\" title=\"死锁\"></a>死锁</h1><h3 id=\"什么是死锁？\"><a href=\"#什么是死锁？\" class=\"headerlink\" title=\"什么是死锁？\"></a>什么是死锁？</h3><p>在两个或者多个并发进程中，每个进程持有某种资源而又等待其它进程释放它们现在保持着的资源，在未改变这种状态之前都不能向前推进，称这一组进程产生了死锁(deadlock)。</p>\n<h3 id=\"死锁产生的必要条件？\"><a href=\"#死锁产生的必要条件？\" class=\"headerlink\" title=\"死锁产生的必要条件？\"></a>死锁产生的必要条件？</h3><ul>\n<li><strong>互斥</strong>：一个资源一次只能被一个进程使用；</li>\n<li><strong>占有并等待</strong>：一个进程至少占有一个资源，并在等待另一个被其它进程占用的资源；</li>\n<li><strong>非抢占</strong>：已经分配给一个进程的资源不能被强制性抢占，只能由进程完成任务之后自愿释放；</li>\n<li><strong>循环等待</strong>：若干进程之间形成一种头尾相接的环形等待资源关系，该环路中的每个进程都在等待下一个进程所占有的资源。</li>\n</ul>\n<h3 id=\"死锁有哪些处理方法？\"><a href=\"#死锁有哪些处理方法？\" class=\"headerlink\" title=\"死锁有哪些处理方法？\"></a>死锁有哪些处理方法？</h3><p>直接忽略死锁。因为解决死锁问题的代价很高，因此鸵鸟策略这种不采取任务措施的方案会获得更高的性能。当发生死锁时不会对用户造成多大影响，或发生死锁的概率很低，可以采用鸵鸟策略。</p>\n<p>基本思想是破坏形成死锁的四个必要条件：</p>\n<ul>\n<li>破坏互斥条件：允许某些资源同时被多个进程访问。但是有些资源本身并不具有这种属性，因此这种方案实用性有限；</li>\n<li>破坏占有并等待条件：<ul>\n<li>实行资源预先分配策略（当一个进程开始运行之前，必须一次性向系统申请它所需要的全部资源，否则不运行）；</li>\n<li>或者只允许进程在没有占用资源的时候才能申请资源（申请资源前先释放占有的资源）；</li>\n<li>缺点：很多时候无法预知一个进程所需的全部资源；同时，会降低资源利用率，降低系统的并发性；</li>\n</ul>\n</li>\n<li>破坏非抢占条件：允许进程强行抢占被其它进程占有的资源。会降低系统性能；</li>\n<li>破坏循环等待条件：对所有资源统一编号，所有进程对资源的请求必须按照序号递增的顺序提出，即只有占有了编号较小的资源才能申请编号较大的资源。这样避免了占有大号资源的进程去申请小号资源。</li>\n</ul>\n<p>动态地检测资源分配状态，以确保系统处于安全状态，只有处于安全状态时才会进行资源的分配。所谓安全状态是指：即使所有进程突然请求需要的所有资源，也能存在某种对进程的资源分配顺序，使得每一个进程运行完毕。</p>\n<blockquote>\n<p>银行家算法<br>如何检测死锁：检测有向图是否存在环；或者使用类似死锁避免的检测算法。<br>死锁解除的方法：</p>\n</blockquote>\n<ul>\n<li>利用抢占：挂起某些进程，并抢占它的资源。但应防止某些进程被长时间挂起而处于饥饿状态；</li>\n<li>利用回滚：让某些进程回退到足以解除死锁的地步，进程回退时自愿释放资源。要求系统保持进程的历史信息，设置还原点；</li>\n<li>利用杀死进程：强制杀死某些进程直到死锁解除为止，可以按照优先级进行。</li>\n</ul>\n<h1 id=\"内存管理\"><a href=\"#内存管理\" class=\"headerlink\" title=\"内存管理\"></a>内存管理</h1><h3 id=\"分页和分段有什么区别？\"><a href=\"#分页和分段有什么区别？\" class=\"headerlink\" title=\"分页和分段有什么区别？\"></a>分页和分段有什么区别？</h3><ul>\n<li>页式存储：用户空间划分为大小相等的部分称为页（page），内存空间划分为同样大小的区域称为页框，分配时以页为单位，按进程需要的页数分配，逻辑上相邻的页物理上不一定相邻；</li>\n<li>段式存储：用户进程地址空间按照自身逻辑关系划分为若干个段（segment）（如代码段，数据段，堆栈段），内存空间被动态划分为长度不同的区域，分配时以段为单位，每段在内存中占据连续空间，各段可以不相邻；</li>\n<li>段页式存储：用户进程先按段划分，段内再按页划分，内存划分和分配按页。</li>\n</ul>\n<p>区别：</p>\n<ul>\n<li>目的不同：分页的目的是管理内存，用于虚拟内存以获得更大的地址空间；分段的目的是满足用户的需要，使程序和数据可以被划分为逻辑上独立的地址空间；</li>\n<li>大小不同：段的大小不固定，由其所完成的功能决定；页的大小固定，由系统决定；</li>\n<li>地址空间维度不同：分段是二维地址空间（段号+段内偏移），分页是一维地址空间（每个进程一个页表/多级页表，通过一个逻辑地址就能找到对应的物理地址）；</li>\n<li>分段便于信息的保护和共享；分页的共享收到限制；</li>\n<li>碎片：分段没有内碎片，但会产生外碎片；分页没有外碎片，但会产生内碎片（一个页填不满）</li>\n</ul>\n<h3 id=\"什么是虚拟内存？\"><a href=\"#什么是虚拟内存？\" class=\"headerlink\" title=\"什么是虚拟内存？\"></a>什么是虚拟内存？</h3><p>每个程序都拥有自己的地址空间，这个地址空间被分成大小相等的页，这些页被映射到物理内存；但不需要所有的页都在物理内存中，当程序引用到不在物理内存中的页时，由操作系统将缺失的部分装入物理内存。这样，对于程序来说，逻辑上似乎有很大的内存空间，只是实际上有一部分是存储在磁盘上，因此叫做虚拟内存。</p>\n<p>虚拟内存的优点是让程序可以获得更多的可用内存。</p>\n<p>虚拟内存的实现方式、页表/多级页表、缺页中断、不同的页面淘汰算法：<a href=\"https://imageslr.github.io/2020/07/08/tech-interview.html#virtual-memory\">答案</a>。</p>\n<h5 id=\"如何进行地址空间到物理内存的映射？\"><a href=\"#如何进行地址空间到物理内存的映射？\" class=\"headerlink\" title=\"如何进行地址空间到物理内存的映射？\"></a>如何进行地址空间到物理内存的映射？</h5><p><strong>内存管理单元</strong>（MMU）管理着逻辑地址和物理地址的转换，其中的页表（Page table）存储着页（逻辑地址）和页框（物理内存空间）的映射表，页表中还包含包含有效位（是在内存还是磁盘）、访问位（是否被访问过）、修改位（内存中是否被修改过）、保护位（只读还是可读写）。逻辑地址：页号+页内地址（偏移）；每个进程一个页表，放在内存，页表起始地址在PCB/寄存器中。</p>\n<h3 id=\"有哪些页面置换算法？\"><a href=\"#有哪些页面置换算法？\" class=\"headerlink\" title=\"有哪些页面置换算法？\"></a>有哪些页面置换算法？</h3><p>在程序运行过程中，如果要访问的页面不在内存中，就发生缺页中断从而将该页调入内存中。此时如果内存已无空闲空间，系统必须从内存中调出一个页面到磁盘中来腾出空间。页面置换算法的主要目标是使页面置换频率最低（也可以说缺页率最低）。</p>\n<ul>\n<li><p><strong>最佳页面置换算法</strong>OPT（Optimal replacement algorithm）：置换以后不需要或者最远的将来才需要的页面，是一种理论上的算法，是最优策略；</p>\n</li>\n<li><p><strong>先进先出</strong>FIFO：置换在内存中驻留时间最长的页面。缺点：有可能将那些经常被访问的页面也被换出，从而使缺页率升高；</p>\n</li>\n<li><p><strong>第二次机会算法</strong>SCR：按FIFO选择某一页面，若其访问位为1，给第二次机会，并将访问位置0；</p>\n</li>\n<li><p><strong>时钟算法</strong> Clock：SCR中需要将页面在链表中移动（第二次机会的时候要将这个页面从链表头移到链表尾），时钟算法使用环形链表，再使用一个指针指向最老的页面，避免了移动页面的开销；</p>\n</li>\n<li><p><strong>最近未使用算法</strong>NRU（Not Recently Used）：检查访问位R、修改位M，优先置换R=M=0，其次是（R=0, M=1）；</p>\n</li>\n<li><p><strong>最近最少使用算法</strong>LRU（Least Recently Used）：置换出未使用时间最长的一页；实现方式：维护时间戳，或者维护一个所有页面的链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。</p>\n</li>\n<li><p><strong>最不经常使用算法</strong>NFU：置换出访问次数最少的页面</p>\n</li>\n<li><p>时间上：最近被访问的页在不久的将来还会被访问；</p>\n</li>\n<li><p>空间上：内存中被访问的页周围的页也很可能被访问。</p>\n</li>\n</ul>\n<p>颠簸本质上是指频繁的页调度行为。进程发生缺页中断时必须置换某一页。然而，其他所有的页都在使用，它置换一个页，但又立刻再次需要这个页。因此会不断产生缺页中断，导致整个系统的效率急剧下降，这种现象称为颠簸。内存颠簸的解决策略包括：</p>\n<ul>\n<li>修改页面置换算法；</li>\n<li>降低同时运行的程序的数量；</li>\n<li>终止该进程或增加物理内存容量。</li>\n</ul>\n<h3 id=\"缓冲区溢出问题\"><a href=\"#缓冲区溢出问题\" class=\"headerlink\" title=\"缓冲区溢出问题\"></a>缓冲区溢出问题</h3><p>防范缓冲区溢出攻击的机制有三种：随机化、栈保护和限制可执行代码区域。</p>\n<ul>\n<li>随机化：包括栈随机化（程序开始时在栈上分配一段随机大小的空间）和地址空间布局随机化（Address-Space Layout Randomization，ASLR，即每次运行时程序的不同部分，包括代码段、数据段、栈、堆等都会被加载到内存空间的不同区域），但只能增加攻击一个系统的难度，不能完全保证安全。</li>\n<li>栈保护：在每个函数的栈帧的局部变量和栈状态之间存储一个<strong>随机产生的</strong>特殊的值，称为金丝雀值（canary）。在恢复寄存器状态和函数返回之前，程序检测这个金丝雀值是否被改变了，如果是，那么程序异常终止。</li>\n<li>限制可执行代码区域：内存页的访问形式有三种：可读、可写、可执行，只有编译器产生的那部分代码所处的内存才是可执行的，其他页限制为只允许读和写。</li>\n</ul>\n<p>更详细的可以参考：<a href=\"https://imageslr.github.io/2020/07/08/tech-interview.html#stackoverflow\">https://imageslr.github.io/2020/07/08/tech-interview.html#stackoverflow</a></p>\n<h1 id=\"磁盘调度\"><a href=\"#磁盘调度\" class=\"headerlink\" title=\"磁盘调度\"></a>磁盘调度</h1><p>过程：磁头（找到对应的盘面）；磁道（一个盘面上的同心圆环，寻道时间）；扇区（旋转时间）。为减小寻道时间的调度算法：</p>\n<ul>\n<li>先来先服务</li>\n<li>最短寻道时间优先</li>\n<li>电梯算法：电梯总是保持一个方向运行，直到该方向没有请求为止，然后改变运行方向。</li>\n</ul>\n<h1 id=\"进程间通信IPC\"><a href=\"#进程间通信IPC\" class=\"headerlink\" title=\"进程间通信IPC\"></a><a href=\"https://www.jianshu.com/p/c1015f5ffa74\">进程间通信IPC</a></h1><h1 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h1><ul>\n<li><a href=\"https://blog.csdn.net/justloveyou_/article/details/78304294\">面试/笔试第二弹 —— 操作系统面试问题集锦 - CSDN博客</a></li>\n<li><a href=\"https://segmentfault.com/a/1190000018970361\">线程同步与并发 - - SegmentFault</a></li>\n<li><a href=\"http://baijiahao.baidu.com/s?id=1641172494287388070&wfr=spider&for=pc\">彻底搞懂epoll高效运行的原理</a></li>\n<li><a href=\"https://www.cnblogs.com/lirong21/p/4213028.html\">用户态与内核态的切换</a></li>\n</ul>\n<p>文章内容搬运自本人<a href=\"https://www.yuque.com/docs/share/4137d8f0-4b2e-4a18-a5a3-7a01239affcc\">语雀</a></p>\n"}],"PostAsset":[],"PostCategory":[{"post_id":"ckttol7iw00074cvu4xsa305a","category_id":"ckttol7ix00084cvu6wiuaxl6","_id":"ckttol7iy000b4cvu5ikucj94"},{"post_id":"ckttosy8j0000y0vub3d8dbxb","category_id":"ckttosy8n0001y0vueayl4vhm","_id":"ckttosy8q0004y0vu2dihcu11"},{"post_id":"cktvosie100012svu1hay76ev","category_id":"cktvosie500022svu3nl8duj9","_id":"cktvosie800052svu9697828u"},{"post_id":"cktvosie900082svuc1lf6su1","category_id":"cktvosieb000a2svu4bydgrpr","_id":"cktvosiee000k2svuew8y0x20"},{"post_id":"cktvosie900082svuc1lf6su1","category_id":"cktvosied000g2svu7od4ffnn","_id":"cktvosiee000l2svudfbbhly9"},{"post_id":"cktvosiea00092svu742weofz","category_id":"cktvosiec000c2svuhze8ajrm","_id":"cktvosief000r2svu47l0hb2f"},{"post_id":"cktvosiea00092svu742weofz","category_id":"cktvosiee000i2svu7m5s0kg8","_id":"cktvosief000s2svug55x0iil"},{"post_id":"cktvosiea00092svu742weofz","category_id":"cktvosiee000n2svu9t9xgolw","_id":"cktvosief000t2svuhye3gy0n"},{"post_id":"cktvosieg000u2svu1ju803ov","category_id":"cktvosiec000c2svuhze8ajrm","_id":"cktvosieh000z2svu8jqode6h"},{"post_id":"cktvosieg000u2svu1ju803ov","category_id":"cktvosieh000w2svug3i186du","_id":"cktvosieh00102svucabn2mhb"}],"PostTag":[{"post_id":"ckttol7iw00074cvu4xsa305a","tag_id":"ckttol7ix00094cvu0ev1dmvc","_id":"ckttol7iy000a4cvu3kwj03h8"},{"post_id":"ckttosy8j0000y0vub3d8dbxb","tag_id":"ckttosy8p0002y0vu4smq2qff","_id":"ckttosy8r0006y0vucuvib4n7"},{"post_id":"ckttosy8j0000y0vub3d8dbxb","tag_id":"ckttosy8q0003y0vu73zg2536","_id":"ckttosy8r0007y0vu5ccyflkt"},{"post_id":"ckttosy8j0000y0vub3d8dbxb","tag_id":"ckttosy8q0005y0vu5nmj2d4e","_id":"ckttosy8r0008y0vueuya2r83"},{"post_id":"cktvosie100012svu1hay76ev","tag_id":"cktvosie700032svu6qhd7eym","_id":"cktvosie800062svu493k6sfn"},{"post_id":"cktvosie100012svu1hay76ev","tag_id":"cktvosie800042svu4l277t41","_id":"cktvosie800072svu6js5gga3"},{"post_id":"cktvosie900082svuc1lf6su1","tag_id":"ckttosy8p0002y0vu4smq2qff","_id":"cktvosied000e2svu1cxw5xhs"},{"post_id":"cktvosie900082svuc1lf6su1","tag_id":"cktvosiec000b2svubhgtf4au","_id":"cktvosied000f2svuaf3y8epo"},{"post_id":"cktvosiea00092svu742weofz","tag_id":"ckttosy8p0002y0vu4smq2qff","_id":"cktvosiee000m2svu7s75c361"},{"post_id":"cktvosiea00092svu742weofz","tag_id":"cktvosiec000d2svu1szp9hxh","_id":"cktvosief000o2svu6ur71e1p"},{"post_id":"cktvosiea00092svu742weofz","tag_id":"cktvosied000h2svu98vgbww6","_id":"cktvosief000p2svub4l1by5a"},{"post_id":"cktvosiea00092svu742weofz","tag_id":"cktvosiee000j2svudau6cz2m","_id":"cktvosief000q2svu6e95etvs"},{"post_id":"cktvosieg000u2svu1ju803ov","tag_id":"ckttosy8p0002y0vu4smq2qff","_id":"cktvosieh000x2svuel2max0b"},{"post_id":"cktvosieg000u2svu1ju803ov","tag_id":"cktvosieg000v2svu9u9v0osf","_id":"cktvosieh000y2svu53i247im"}],"Tag":[{"name":"测试","_id":"ckttol7ij00024cvugpiif6at"},{"name":"travis","_id":"ckttol7ij00034cvu02774moc"},{"name":"mysql","_id":"ckttol7ix00094cvu0ev1dmvc"},{"name":"八股文","_id":"ckttosy8p0002y0vu4smq2qff"},{"name":"rabbitmq","_id":"ckttosy8q0003y0vu73zg2536"},{"name":"mq","_id":"ckttosy8q0005y0vu5nmj2d4e"},{"name":"leetcode","_id":"cktvosie700032svu6qhd7eym"},{"name":"算法","_id":"cktvosie800042svu4l277t41"},{"name":"计算机网络","_id":"cktvosiec000b2svubhgtf4au"},{"name":"数据库","_id":"cktvosiec000d2svu1szp9hxh"},{"name":"MySQL","_id":"cktvosied000h2svu98vgbww6"},{"name":"NoSQL","_id":"cktvosiee000j2svudau6cz2m"},{"name":"操作系统","_id":"cktvosieg000v2svu9u9v0osf"}]}}